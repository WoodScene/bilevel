nohup: ignoring input
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 16
micro_batch_size: 4
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: cb... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/1-cb
current data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 840.37it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 452.61it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Loading cached split indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3c0acee40c86feef.arrow and /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-d23b1e6e693671dd.arrow
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-23ddd5122a88e27d.arrow
Loading cached processed dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-ced4ed8bc63afeb3.arrow
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-0e9e2f72300277a7.arrow
Loading cached processed dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-33933896df254f7b.arrow
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-de27b9beee362d07.arrow
总样本数：1000, 选择的样本数量：20
lora_weights: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/0-mnli

pre-trained model's BOS EOS and PAD token id: None 1 0  => It should be 1,2,none
continual fine tune lora!
trainable params: 2359296 || all params: 740027392 || trainable%: 0.31881198257050464
训练数据总量：225
验证数据总量：25
Map:   0%|          | 0/20 [00:00<?, ? examples/s]/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3597: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  "`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your "
                                                  memory data loader 2
  0%|          | 0/140 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  1%|          | 1/140 [00:01<03:21,  1.45s/it]  1%|▏         | 2/140 [00:02<02:20,  1.02s/it]  2%|▏         | 3/140 [00:02<02:03,  1.11it/s]  3%|▎         | 4/140 [00:03<01:55,  1.18it/s]  4%|▎         | 5/140 [00:04<02:02,  1.10it/s]  4%|▍         | 6/140 [00:05<01:54,  1.17it/s]  5%|▌         | 7/140 [00:06<01:49,  1.22it/s]  6%|▌         | 8/140 [00:06<01:43,  1.27it/s]  6%|▋         | 9/140 [00:07<01:51,  1.18it/s]  7%|▋         | 10/140 [00:08<01:44,  1.24it/s]                                                  7%|▋         | 10/140 [00:08<01:44,  1.24it/s]  8%|▊         | 11/140 [00:09<01:42,  1.26it/s]  9%|▊         | 12/140 [00:10<01:39,  1.29it/s]  9%|▉         | 13/140 [00:11<01:45,  1.20it/s] 10%|█         | 14/140 [00:11<01:40,  1.26it/s] 11%|█         | 15/140 [00:12<01:37,  1.28it/s] 11%|█▏        | 16/140 [00:13<01:34,  1.31it/s] 12%|█▏        | 17/140 [00:14<01:42,  1.20it/s] 13%|█▎        | 18/140 [00:14<01:38,  1.24it/s] 14%|█▎        | 19/140 [00:15<01:35,  1.27it/s] 14%|█▍        | 20/140 [00:16<01:33,  1.29it/s]                                                 14%|█▍        | 20/140 [00:16<01:33,  1.29it/s] 15%|█▌        | 21/140 [00:17<01:39,  1.20it/s] 16%|█▌        | 22/140 [00:18<01:34,  1.25it/s] 16%|█▋        | 23/140 [00:18<01:32,  1.27it/s] 17%|█▋        | 24/140 [00:19<01:28,  1.32it/s] 18%|█▊        | 25/140 [00:20<01:34,  1.22it/s] 19%|█▊        | 26/140 [00:21<01:30,  1.26it/s] 19%|█▉        | 27/140 [00:22<01:28,  1.28it/s] 20%|██        | 28/140 [00:22<01:26,  1.30it/s] 21%|██        | 29/140 [00:23<01:32,  1.20it/s] 21%|██▏       | 30/140 [00:24<01:28,  1.24it/s]                                                 21%|██▏       | 30/140 [00:24<01:28,  1.24it/s] 22%|██▏       | 31/140 [00:25<01:27,  1.25it/s] 23%|██▎       | 32/140 [00:26<01:24,  1.28it/s] 24%|██▎       | 33/140 [00:27<01:29,  1.19it/s] 24%|██▍       | 34/140 [00:27<01:25,  1.24it/s] 25%|██▌       | 35/140 [00:28<01:22,  1.27it/s] 26%|██▌       | 36/140 [00:29<01:20,  1.28it/s] 26%|██▋       | 37/140 [00:30<01:26,  1.20it/s] 27%|██▋       | 38/140 [00:30<01:22,  1.24it/s] 28%|██▊       | 39/140 [00:31<01:19,  1.28it/s] 29%|██▊       | 40/140 [00:32<01:17,  1.29it/s]                                                 29%|██▊       | 40/140 [00:32<01:17,  1.29it/s]{'loss': 0.1458, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.7}
{'loss': 0.0833, 'learning_rate': 0.00011999999999999999, 'epoch': 1.4}
{'loss': 0.0632, 'learning_rate': 0.00017999999999999998, 'epoch': 2.11}
{'loss': 0.1039, 'learning_rate': 0.00023999999999999998, 'epoch': 2.81}

  0%|          | 0/4 [00:00<?, ?it/s][A
 75%|███████▌  | 3/4 [00:00<00:00, 19.30it/s][A                                                
                                             [A 29%|██▊       | 40/140 [00:32<01:17,  1.29it/s]
100%|██████████| 4/4 [00:00<00:00, 19.30it/s][A
                                             [A 29%|██▉       | 41/140 [00:33<01:35,  1.04it/s] 30%|███       | 42/140 [00:34<01:27,  1.12it/s] 31%|███       | 43/140 [00:35<01:22,  1.17it/s] 31%|███▏      | 44/140 [00:36<01:17,  1.23it/s] 32%|███▏      | 45/140 [00:37<01:21,  1.17it/s] 33%|███▎      | 46/140 [00:37<01:16,  1.22it/s] 34%|███▎      | 47/140 [00:38<01:13,  1.27it/s] 34%|███▍      | 48/140 [00:39<01:11,  1.29it/s] 35%|███▌      | 49/140 [00:40<01:16,  1.18it/s] 36%|███▌      | 50/140 [00:40<01:13,  1.23it/s]                                                 36%|███▌      | 50/140 [00:40<01:13,  1.23it/s] 36%|███▋      | 51/140 [00:41<01:09,  1.27it/s] 37%|███▋      | 52/140 [00:42<01:08,  1.29it/s] 38%|███▊      | 53/140 [00:43<01:12,  1.20it/s] 39%|███▊      | 54/140 [00:44<01:09,  1.24it/s] 39%|███▉      | 55/140 [00:44<01:06,  1.27it/s] 40%|████      | 56/140 [00:45<01:05,  1.28it/s] 41%|████      | 57/140 [00:46<01:09,  1.19it/s] 41%|████▏     | 58/140 [00:47<01:06,  1.24it/s] 42%|████▏     | 59/140 [00:48<01:03,  1.27it/s] 43%|████▎     | 60/140 [00:48<01:02,  1.27it/s]                                                 43%|████▎     | 60/140 [00:49<01:02,  1.27it/s] 44%|████▎     | 61/140 [00:49<01:07,  1.16it/s] 44%|████▍     | 62/140 [00:50<01:04,  1.20it/s] 45%|████▌     | 63/140 [00:51<01:01,  1.26it/s] 46%|████▌     | 64/140 [00:52<00:59,  1.28it/s] 46%|████▋     | 65/140 [00:53<01:02,  1.19it/s] 47%|████▋     | 66/140 [00:53<00:59,  1.25it/s] 48%|████▊     | 67/140 [00:54<00:56,  1.29it/s] 49%|████▊     | 68/140 [00:55<00:54,  1.31it/s] 49%|████▉     | 69/140 [00:56<00:58,  1.20it/s] 50%|█████     | 70/140 [00:56<00:55,  1.26it/s]                                                 50%|█████     | 70/140 [00:56<00:55,  1.26it/s] 51%|█████     | 71/140 [00:57<00:53,  1.29it/s] 51%|█████▏    | 72/140 [00:58<00:51,  1.31it/s] 52%|█████▏    | 73/140 [00:59<00:55,  1.20it/s] 53%|█████▎    | 74/140 [01:00<00:52,  1.25it/s] 54%|█████▎    | 75/140 [01:00<00:50,  1.30it/s] 54%|█████▍    | 76/140 [01:01<00:48,  1.32it/s] 55%|█████▌    | 77/140 [01:02<00:52,  1.21it/s] 56%|█████▌    | 78/140 [01:03<00:49,  1.25it/s] 56%|█████▋    | 79/140 [01:04<00:47,  1.29it/s] 57%|█████▋    | 80/140 [01:04<00:46,  1.30it/s]                                                 57%|█████▋    | 80/140 [01:05<00:46,  1.30it/s]{'eval_loss': 0.06305939704179764, 'eval_runtime': 0.2925, 'eval_samples_per_second': 85.456, 'eval_steps_per_second': 13.673, 'epoch': 2.81}
{'loss': 0.0389, 'learning_rate': 0.0003, 'epoch': 3.51}
{'loss': 0.0351, 'learning_rate': 0.0002666666666666666, 'epoch': 4.21}
{'loss': 0.0181, 'learning_rate': 0.0002333333333333333, 'epoch': 4.91}
{'loss': 0.011, 'learning_rate': 0.00019999999999999998, 'epoch': 5.61}

  0%|          | 0/4 [00:00<?, ?it/s][A
 75%|███████▌  | 3/4 [00:00<00:00, 19.46it/s][A                                                
                                             [A 57%|█████▋    | 80/140 [01:05<00:46,  1.30it/s]
100%|██████████| 4/4 [00:00<00:00, 19.46it/s][A
                                             [A 58%|█████▊    | 81/140 [01:06<00:57,  1.03it/s] 59%|█████▊    | 82/140 [01:06<00:52,  1.11it/s] 59%|█████▉    | 83/140 [01:07<00:48,  1.18it/s] 60%|██████    | 84/140 [01:08<00:45,  1.23it/s] 61%|██████    | 85/140 [01:09<00:47,  1.15it/s] 61%|██████▏   | 86/140 [01:10<00:44,  1.21it/s] 62%|██████▏   | 87/140 [01:10<00:41,  1.26it/s] 63%|██████▎   | 88/140 [01:11<00:40,  1.30it/s] 64%|██████▎   | 89/140 [01:12<00:42,  1.20it/s] 64%|██████▍   | 90/140 [01:13<00:39,  1.25it/s]                                                 64%|██████▍   | 90/140 [01:13<00:39,  1.25it/s] 65%|██████▌   | 91/140 [01:13<00:37,  1.30it/s] 66%|██████▌   | 92/140 [01:14<00:36,  1.32it/s] 66%|██████▋   | 93/140 [01:15<00:38,  1.22it/s] 67%|██████▋   | 94/140 [01:16<00:37,  1.24it/s] 68%|██████▊   | 95/140 [01:17<00:35,  1.28it/s] 69%|██████▊   | 96/140 [01:17<00:33,  1.30it/s] 69%|██████▉   | 97/140 [01:18<00:35,  1.21it/s] 70%|███████   | 98/140 [01:19<00:33,  1.24it/s] 71%|███████   | 99/140 [01:20<00:32,  1.26it/s] 71%|███████▏  | 100/140 [01:21<00:30,  1.30it/s]                                                  71%|███████▏  | 100/140 [01:21<00:30,  1.30it/s] 72%|███████▏  | 101/140 [01:22<00:32,  1.20it/s] 73%|███████▎  | 102/140 [01:22<00:30,  1.25it/s] 74%|███████▎  | 103/140 [01:23<00:28,  1.29it/s] 74%|███████▍  | 104/140 [01:24<00:27,  1.30it/s] 75%|███████▌  | 105/140 [01:25<00:28,  1.21it/s] 76%|███████▌  | 106/140 [01:25<00:26,  1.27it/s] 76%|███████▋  | 107/140 [01:26<00:25,  1.28it/s] 77%|███████▋  | 108/140 [01:27<00:24,  1.32it/s] 78%|███████▊  | 109/140 [01:28<00:25,  1.21it/s] 79%|███████▊  | 110/140 [01:29<00:23,  1.25it/s]                                                  79%|███████▊  | 110/140 [01:29<00:23,  1.25it/s] 79%|███████▉  | 111/140 [01:29<00:22,  1.29it/s] 80%|████████  | 112/140 [01:30<00:21,  1.31it/s] 81%|████████  | 113/140 [01:31<00:22,  1.22it/s] 81%|████████▏ | 114/140 [01:32<00:20,  1.27it/s] 82%|████████▏ | 115/140 [01:32<00:19,  1.31it/s] 83%|████████▎ | 116/140 [01:33<00:17,  1.34it/s] 84%|████████▎ | 117/140 [01:34<00:18,  1.24it/s] 84%|████████▍ | 118/140 [01:35<00:17,  1.28it/s] 85%|████████▌ | 119/140 [01:36<00:15,  1.32it/s] 86%|████████▌ | 120/140 [01:36<00:14,  1.34it/s]                                                  86%|████████▌ | 120/140 [01:37<00:14,  1.34it/s]{'eval_loss': 0.07251168042421341, 'eval_runtime': 0.2936, 'eval_samples_per_second': 85.137, 'eval_steps_per_second': 13.622, 'epoch': 5.61}
{'loss': 0.0152, 'learning_rate': 0.00016666666666666666, 'epoch': 6.32}
{'loss': 0.012, 'learning_rate': 0.0001333333333333333, 'epoch': 7.02}
{'loss': 0.0101, 'learning_rate': 9.999999999999999e-05, 'epoch': 7.72}
{'loss': 0.0107, 'learning_rate': 6.666666666666666e-05, 'epoch': 8.42}

  0%|          | 0/4 [00:00<?, ?it/s][A
 75%|███████▌  | 3/4 [00:00<00:00, 19.47it/s][A                                                 
                                             [A 86%|████████▌ | 120/140 [01:37<00:14,  1.34it/s]
100%|██████████| 4/4 [00:00<00:00, 19.47it/s][A
                                             [A 86%|████████▋ | 121/140 [01:38<00:17,  1.06it/s] 87%|████████▋ | 122/140 [01:38<00:15,  1.13it/s] 88%|████████▊ | 123/140 [01:39<00:14,  1.20it/s] 89%|████████▊ | 124/140 [01:40<00:12,  1.24it/s] 89%|████████▉ | 125/140 [01:41<00:12,  1.17it/s] 90%|█████████ | 126/140 [01:42<00:11,  1.21it/s] 91%|█████████ | 127/140 [01:42<00:10,  1.26it/s] 91%|█████████▏| 128/140 [01:43<00:09,  1.30it/s] 92%|█████████▏| 129/140 [01:44<00:09,  1.21it/s] 93%|█████████▎| 130/140 [01:45<00:07,  1.26it/s]                                                  93%|█████████▎| 130/140 [01:45<00:07,  1.26it/s] 94%|█████████▎| 131/140 [01:45<00:07,  1.28it/s] 94%|█████████▍| 132/140 [01:46<00:06,  1.31it/s] 95%|█████████▌| 133/140 [01:47<00:05,  1.22it/s] 96%|█████████▌| 134/140 [01:48<00:04,  1.27it/s] 96%|█████████▋| 135/140 [01:49<00:03,  1.31it/s] 97%|█████████▋| 136/140 [01:49<00:03,  1.32it/s] 98%|█████████▊| 137/140 [01:50<00:02,  1.22it/s] 99%|█████████▊| 138/140 [01:51<00:01,  1.26it/s] 99%|█████████▉| 139/140 [01:52<00:00,  1.30it/s]100%|██████████| 140/140 [01:52<00:00,  1.32it/s]                                                 100%|██████████| 140/140 [01:53<00:00,  1.32it/s]There were missing keys in the checkpoint model loaded: ['base_model.model.shared.weight', 'base_model.model.encoder.embed_tokens.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.encoder.block.0.layer.0.layer_norm.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.0.layer.1.layer_norm.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.1.layer.0.layer_norm.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.1.layer.1.layer_norm.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.2.layer.0.layer_norm.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.2.layer.1.layer_norm.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.3.layer.0.layer_norm.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.3.layer.1.layer_norm.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.4.layer.0.layer_norm.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.4.layer.1.layer_norm.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.5.layer.0.layer_norm.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.5.layer.1.layer_norm.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.6.layer.0.layer_norm.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.6.layer.1.layer_norm.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.7.layer.0.layer_norm.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.7.layer.1.layer_norm.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.8.layer.0.layer_norm.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.8.layer.1.layer_norm.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.9.layer.0.layer_norm.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.9.layer.1.layer_norm.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.10.layer.0.layer_norm.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.10.layer.1.layer_norm.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.11.layer.0.layer_norm.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.11.layer.1.layer_norm.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.12.layer.0.layer_norm.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.12.layer.1.layer_norm.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.13.layer.0.layer_norm.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.13.layer.1.layer_norm.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.14.layer.0.layer_norm.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.14.layer.1.layer_norm.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.15.layer.0.layer_norm.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.15.layer.1.layer_norm.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.16.layer.0.layer_norm.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.16.layer.1.layer_norm.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.17.layer.0.layer_norm.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.17.layer.1.layer_norm.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.18.layer.0.layer_norm.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.18.layer.1.layer_norm.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.19.layer.0.layer_norm.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.19.layer.1.layer_norm.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.20.layer.0.layer_norm.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.20.layer.1.layer_norm.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.21.layer.0.layer_norm.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.21.layer.1.layer_norm.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.22.layer.0.layer_norm.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.22.layer.1.layer_norm.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.23.layer.0.layer_norm.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.23.layer.1.layer_norm.weight', 'base_model.model.encoder.final_layer_norm.weight', 'base_model.model.decoder.embed_tokens.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.decoder.block.0.layer.0.layer_norm.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.0.layer.1.layer_norm.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.0.layer.2.layer_norm.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.1.layer.0.layer_norm.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.1.layer.1.layer_norm.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.1.layer.2.layer_norm.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.2.layer.0.layer_norm.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.2.layer.1.layer_norm.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.2.layer.2.layer_norm.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.3.layer.0.layer_norm.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.3.layer.1.layer_norm.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.3.layer.2.layer_norm.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.4.layer.0.layer_norm.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.4.layer.1.layer_norm.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.4.layer.2.layer_norm.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.5.layer.0.layer_norm.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.5.layer.1.layer_norm.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.5.layer.2.layer_norm.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.6.layer.0.layer_norm.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.6.layer.1.layer_norm.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.6.layer.2.layer_norm.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.7.layer.0.layer_norm.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.7.layer.1.layer_norm.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.7.layer.2.layer_norm.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.8.layer.0.layer_norm.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.8.layer.1.layer_norm.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.8.layer.2.layer_norm.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.9.layer.0.layer_norm.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.9.layer.1.layer_norm.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.9.layer.2.layer_norm.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.10.layer.0.layer_norm.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.10.layer.1.layer_norm.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.10.layer.2.layer_norm.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.11.layer.0.layer_norm.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.11.layer.1.layer_norm.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.11.layer.2.layer_norm.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.12.layer.0.layer_norm.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.12.layer.1.layer_norm.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.12.layer.2.layer_norm.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.13.layer.0.layer_norm.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.13.layer.1.layer_norm.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.13.layer.2.layer_norm.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.14.layer.0.layer_norm.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.14.layer.1.layer_norm.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.14.layer.2.layer_norm.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.15.layer.0.layer_norm.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.15.layer.1.layer_norm.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.15.layer.2.layer_norm.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.16.layer.0.layer_norm.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.16.layer.1.layer_norm.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.16.layer.2.layer_norm.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.17.layer.0.layer_norm.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.17.layer.1.layer_norm.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.17.layer.2.layer_norm.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.18.layer.0.layer_norm.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.18.layer.1.layer_norm.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.18.layer.2.layer_norm.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.19.layer.0.layer_norm.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.19.layer.1.layer_norm.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.19.layer.2.layer_norm.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.20.layer.0.layer_norm.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.20.layer.1.layer_norm.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.20.layer.2.layer_norm.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.21.layer.0.layer_norm.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.21.layer.1.layer_norm.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.21.layer.2.layer_norm.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.22.layer.0.layer_norm.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.22.layer.1.layer_norm.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.22.layer.2.layer_norm.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.23.layer.0.layer_norm.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.23.layer.1.layer_norm.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.23.layer.2.layer_norm.weight', 'base_model.model.decoder.final_layer_norm.weight', 'base_model.model.lm_head.weight'].
There were unexpected keys in the checkpoint model loaded: ['base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.weight'].
                                                 100%|██████████| 140/140 [01:53<00:00,  1.32it/s]100%|██████████| 140/140 [01:53<00:00,  1.24it/s]
{'eval_loss': 0.07686498016119003, 'eval_runtime': 0.2884, 'eval_samples_per_second': 86.688, 'eval_steps_per_second': 13.87, 'epoch': 8.42}
{'loss': 0.0062, 'learning_rate': 3.333333333333333e-05, 'epoch': 9.12}
{'loss': 0.0058, 'learning_rate': 0.0, 'epoch': 9.82}
{'train_runtime': 113.3281, 'train_samples_per_second': 19.854, 'train_steps_per_second': 1.235, 'train_loss': 0.03995327071419784, 'epoch': 9.82}

 If there's a warning about missing keys above, please disregard :)
nohup: ignoring input
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 16
micro_batch_size: 4
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: cb... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/1-cb
current data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 783.25it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 903.36it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Loading cached split indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3c0acee40c86feef.arrow and /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-d23b1e6e693671dd.arrow
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-23ddd5122a88e27d.arrow
Loading cached processed dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-ced4ed8bc63afeb3.arrow
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-0e9e2f72300277a7.arrow
Loading cached processed dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-33933896df254f7b.arrow
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-de27b9beee362d07.arrow
Loading cached processed dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-16be677b454dc479.arrow
总样本数：1000, 选择的样本数量：20
lora_weights: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/0-mnli

pre-trained model's BOS EOS and PAD token id: None 1 0  => It should be 1,2,none
continual fine tune lora!
trainable params: 2359296 || all params: 740027392 || trainable%: 0.31881198257050464
训练数据总量：225
验证数据总量：25
memory data loader 2
  0%|          | 0/140 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  1%|          | 1/140 [00:01<03:37,  1.56s/it]  1%|▏         | 2/140 [00:02<02:35,  1.13s/it]  2%|▏         | 3/140 [00:03<02:17,  1.00s/it]  3%|▎         | 4/140 [00:04<02:09,  1.05it/s]  4%|▎         | 5/140 [00:05<02:16,  1.01s/it]  4%|▍         | 6/140 [00:06<02:09,  1.03it/s]  5%|▌         | 7/140 [00:06<02:04,  1.07it/s]  6%|▌         | 8/140 [00:07<01:58,  1.11it/s]  6%|▋         | 9/140 [00:08<02:07,  1.03it/s]  7%|▋         | 10/140 [00:09<02:00,  1.08it/s]                                                  7%|▋         | 10/140 [00:09<02:00,  1.08it/s]  8%|▊         | 11/140 [00:10<01:56,  1.10it/s]  9%|▊         | 12/140 [00:11<01:53,  1.13it/s]  9%|▉         | 13/140 [00:12<01:59,  1.06it/s] 10%|█         | 14/140 [00:13<01:53,  1.11it/s] 11%|█         | 15/140 [00:14<01:51,  1.12it/s] 11%|█▏        | 16/140 [00:15<01:47,  1.15it/s] 12%|█▏        | 17/140 [00:16<01:55,  1.06it/s] 13%|█▎        | 18/140 [00:17<01:52,  1.08it/s] 14%|█▎        | 19/140 [00:17<01:49,  1.11it/s] 14%|█▍        | 20/140 [00:18<01:46,  1.13it/s]                                                 14%|█▍        | 20/140 [00:18<01:46,  1.13it/s] 15%|█▌        | 21/140 [00:19<01:53,  1.05it/s] 16%|█▌        | 22/140 [00:20<01:48,  1.09it/s] 16%|█▋        | 23/140 [00:21<01:45,  1.11it/s] 17%|█▋        | 24/140 [00:22<01:42,  1.13it/s] 18%|█▊        | 25/140 [00:23<01:48,  1.06it/s] 19%|█▊        | 26/140 [00:24<01:44,  1.09it/s] 19%|█▉        | 27/140 [00:25<01:41,  1.12it/s] 20%|██        | 28/140 [00:25<01:38,  1.14it/s] 21%|██        | 29/140 [00:27<01:44,  1.06it/s] 21%|██▏       | 30/140 [00:27<01:41,  1.09it/s]                                                 21%|██▏       | 30/140 [00:27<01:41,  1.09it/s] 22%|██▏       | 31/140 [00:28<01:38,  1.10it/s] 23%|██▎       | 32/140 [00:29<01:35,  1.13it/s] 24%|██▎       | 33/140 [00:30<01:41,  1.05it/s] 24%|██▍       | 34/140 [00:31<01:36,  1.10it/s] 25%|██▌       | 35/140 [00:32<01:33,  1.13it/s] 26%|██▌       | 36/140 [00:33<01:31,  1.14it/s] 26%|██▋       | 37/140 [00:34<01:37,  1.06it/s] 27%|██▋       | 38/140 [00:35<01:32,  1.10it/s] 28%|██▊       | 39/140 [00:36<01:30,  1.12it/s] 29%|██▊       | 40/140 [00:36<01:27,  1.14it/s]                                                 29%|██▊       | 40/140 [00:37<01:27,  1.14it/s]外层迭代结束！
外层迭代结束！
{'loss': 0.1458, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.7}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0833, 'learning_rate': 0.00011999999999999999, 'epoch': 1.4}
外层迭代结束！
外层迭代结束！
{'loss': 0.0632, 'learning_rate': 0.00017999999999999998, 'epoch': 2.11}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1039, 'learning_rate': 0.00023999999999999998, 'epoch': 2.81}

  0%|          | 0/4 [00:00<?, ?it/s][A
 75%|███████▌  | 3/4 [00:00<00:00, 18.05it/s][A                                                
                                             [A 29%|██▊       | 40/140 [00:37<01:27,  1.14it/s]
100%|██████████| 4/4 [00:00<00:00, 18.05it/s][A
                                             [A 29%|██▉       | 41/140 [00:38<01:49,  1.11s/it] 30%|███       | 42/140 [00:39<01:40,  1.02s/it] 31%|███       | 43/140 [00:40<01:33,  1.04it/s] 31%|███▏      | 44/140 [00:40<01:27,  1.09it/s] 32%|███▏      | 45/140 [00:42<01:31,  1.04it/s] 33%|███▎      | 46/140 [00:42<01:26,  1.09it/s] 34%|███▎      | 47/140 [00:43<01:22,  1.12it/s] 34%|███▍      | 48/140 [00:44<01:20,  1.15it/s] 35%|███▌      | 49/140 [00:45<01:25,  1.06it/s] 36%|███▌      | 50/140 [00:46<01:21,  1.10it/s]                                                 36%|███▌      | 50/140 [00:46<01:21,  1.10it/s] 36%|███▋      | 51/140 [00:47<01:18,  1.14it/s] 37%|███▋      | 52/140 [00:48<01:15,  1.16it/s] 38%|███▊      | 53/140 [00:49<01:20,  1.08it/s] 39%|███▊      | 54/140 [00:49<01:16,  1.12it/s] 39%|███▉      | 55/140 [00:50<01:14,  1.14it/s] 40%|████      | 56/140 [00:51<01:12,  1.16it/s] 41%|████      | 57/140 [00:52<01:17,  1.07it/s] 41%|████▏     | 58/140 [00:53<01:13,  1.11it/s] 42%|████▏     | 59/140 [00:54<01:11,  1.14it/s] 43%|████▎     | 60/140 [00:55<01:09,  1.16it/s]                                                 43%|████▎     | 60/140 [00:55<01:09,  1.16it/s] 44%|████▎     | 61/140 [00:56<01:13,  1.07it/s] 44%|████▍     | 62/140 [00:57<01:11,  1.10it/s] 45%|████▌     | 63/140 [00:58<01:08,  1.13it/s] 46%|████▌     | 64/140 [00:58<01:05,  1.15it/s] 46%|████▋     | 65/140 [00:59<01:09,  1.08it/s] 47%|████▋     | 66/140 [01:00<01:05,  1.12it/s] 48%|████▊     | 67/140 [01:01<01:03,  1.15it/s] 49%|████▊     | 68/140 [01:02<01:01,  1.17it/s] 49%|████▉     | 69/140 [01:03<01:06,  1.07it/s] 50%|█████     | 70/140 [01:04<01:02,  1.12it/s]                                                 50%|█████     | 70/140 [01:04<01:02,  1.12it/s] 51%|█████     | 71/140 [01:05<01:00,  1.15it/s] 51%|█████▏    | 72/140 [01:05<00:58,  1.17it/s] 52%|█████▏    | 73/140 [01:07<01:02,  1.08it/s] 53%|█████▎    | 74/140 [01:07<00:59,  1.11it/s] 54%|█████▎    | 75/140 [01:08<00:56,  1.15it/s] 54%|█████▍    | 76/140 [01:09<00:54,  1.17it/s] 55%|█████▌    | 77/140 [01:10<00:57,  1.09it/s] 56%|█████▌    | 78/140 [01:11<00:55,  1.13it/s] 56%|█████▋    | 79/140 [01:12<00:52,  1.15it/s] 57%|█████▋    | 80/140 [01:13<00:52,  1.15it/s]                                                 57%|█████▋    | 80/140 [01:13<00:52,  1.15it/s]{'eval_loss': 0.06305939704179764, 'eval_runtime': 0.3333, 'eval_samples_per_second': 75.013, 'eval_steps_per_second': 12.002, 'epoch': 2.81}
外层迭代结束！
外层迭代结束！
{'loss': 0.0389, 'learning_rate': 0.0003, 'epoch': 3.51}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0351, 'learning_rate': 0.0002666666666666666, 'epoch': 4.21}
外层迭代结束！
外层迭代结束！
{'loss': 0.0181, 'learning_rate': 0.0002333333333333333, 'epoch': 4.91}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.011, 'learning_rate': 0.00019999999999999998, 'epoch': 5.61}

  0%|          | 0/4 [00:00<?, ?it/s][A
 75%|███████▌  | 3/4 [00:00<00:00, 17.20it/s][A                                                
                                             [A 57%|█████▋    | 80/140 [01:13<00:52,  1.15it/s]
100%|██████████| 4/4 [00:00<00:00, 17.20it/s][A
                                             [A 58%|█████▊    | 81/140 [01:14<01:04,  1.09s/it] 59%|█████▊    | 82/140 [01:15<00:58,  1.01s/it] 59%|█████▉    | 83/140 [01:16<00:54,  1.05it/s] 60%|██████    | 84/140 [01:17<00:51,  1.09it/s] 61%|██████    | 85/140 [01:18<00:53,  1.02it/s] 61%|██████▏   | 86/140 [01:19<00:50,  1.08it/s] 62%|██████▏   | 87/140 [01:19<00:47,  1.13it/s] 63%|██████▎   | 88/140 [01:20<00:44,  1.16it/s] 64%|██████▎   | 89/140 [01:21<00:47,  1.08it/s] 64%|██████▍   | 90/140 [01:22<00:44,  1.13it/s]                                                 64%|██████▍   | 90/140 [01:22<00:44,  1.13it/s] 65%|██████▌   | 91/140 [01:23<00:42,  1.16it/s] 66%|██████▌   | 92/140 [01:24<00:40,  1.18it/s] 66%|██████▋   | 93/140 [01:25<00:43,  1.09it/s] 67%|██████▋   | 94/140 [01:26<00:41,  1.11it/s] 68%|██████▊   | 95/140 [01:26<00:39,  1.13it/s] 69%|██████▊   | 96/140 [01:27<00:38,  1.15it/s] 69%|██████▉   | 97/140 [01:28<00:40,  1.07it/s] 70%|███████   | 98/140 [01:29<00:37,  1.11it/s] 71%|███████   | 99/140 [01:30<00:36,  1.13it/s] 71%|███████▏  | 100/140 [01:31<00:34,  1.17it/s]                                                  71%|███████▏  | 100/140 [01:31<00:34,  1.17it/s] 72%|███████▏  | 101/140 [01:32<00:35,  1.09it/s] 73%|███████▎  | 102/140 [01:33<00:33,  1.12it/s] 74%|███████▎  | 103/140 [01:34<00:32,  1.15it/s] 74%|███████▍  | 104/140 [01:34<00:31,  1.16it/s] 75%|███████▌  | 105/140 [01:35<00:32,  1.08it/s] 76%|███████▌  | 106/140 [01:36<00:30,  1.13it/s] 76%|███████▋  | 107/140 [01:37<00:29,  1.14it/s] 77%|███████▋  | 108/140 [01:38<00:27,  1.16it/s] 78%|███████▊  | 109/140 [01:39<00:29,  1.07it/s] 79%|███████▊  | 110/140 [01:40<00:27,  1.11it/s]                                                  79%|███████▊  | 110/140 [01:40<00:27,  1.11it/s] 79%|███████▉  | 111/140 [01:41<00:25,  1.13it/s] 80%|████████  | 112/140 [01:42<00:24,  1.16it/s] 81%|████████  | 113/140 [01:43<00:25,  1.07it/s] 81%|████████▏ | 114/140 [01:43<00:23,  1.11it/s] 82%|████████▏ | 115/140 [01:44<00:21,  1.14it/s] 83%|████████▎ | 116/140 [01:45<00:20,  1.17it/s] 84%|████████▎ | 117/140 [01:46<00:21,  1.08it/s] 84%|████████▍ | 118/140 [01:47<00:19,  1.12it/s] 85%|████████▌ | 119/140 [01:48<00:18,  1.15it/s] 86%|████████▌ | 120/140 [01:49<00:17,  1.16it/s]                                                  86%|████████▌ | 120/140 [01:49<00:17,  1.16it/s]{'eval_loss': 0.07251168042421341, 'eval_runtime': 0.3491, 'eval_samples_per_second': 71.62, 'eval_steps_per_second': 11.459, 'epoch': 5.61}
外层迭代结束！
外层迭代结束！
{'loss': 0.0152, 'learning_rate': 0.00016666666666666666, 'epoch': 6.32}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.012, 'learning_rate': 0.0001333333333333333, 'epoch': 7.02}
外层迭代结束！
外层迭代结束！
{'loss': 0.0101, 'learning_rate': 9.999999999999999e-05, 'epoch': 7.72}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0107, 'learning_rate': 6.666666666666666e-05, 'epoch': 8.42}

  0%|          | 0/4 [00:00<?, ?it/s][A
 75%|███████▌  | 3/4 [00:00<00:00, 18.20it/s][A                                                 
                                             [A 86%|████████▌ | 120/140 [01:49<00:17,  1.16it/s]
100%|██████████| 4/4 [00:00<00:00, 18.20it/s][A
                                             [A 86%|████████▋ | 121/140 [01:50<00:20,  1.07s/it] 87%|████████▋ | 122/140 [01:51<00:18,  1.00s/it] 88%|████████▊ | 123/140 [01:52<00:15,  1.06it/s] 89%|████████▊ | 124/140 [01:53<00:14,  1.10it/s] 89%|████████▉ | 125/140 [01:54<00:14,  1.05it/s] 90%|█████████ | 126/140 [01:55<00:12,  1.09it/s] 91%|█████████ | 127/140 [01:55<00:11,  1.13it/s] 91%|█████████▏| 128/140 [01:56<00:10,  1.17it/s] 92%|█████████▏| 129/140 [01:57<00:10,  1.09it/s] 93%|█████████▎| 130/140 [01:58<00:08,  1.13it/s]                                                  93%|█████████▎| 130/140 [01:58<00:08,  1.13it/s] 94%|█████████▎| 131/140 [01:59<00:07,  1.15it/s] 94%|█████████▍| 132/140 [02:00<00:06,  1.17it/s] 95%|█████████▌| 133/140 [02:01<00:06,  1.09it/s] 96%|█████████▌| 134/140 [02:02<00:05,  1.14it/s] 96%|█████████▋| 135/140 [02:02<00:04,  1.17it/s] 97%|█████████▋| 136/140 [02:03<00:03,  1.18it/s] 98%|█████████▊| 137/140 [02:04<00:02,  1.09it/s] 99%|█████████▊| 138/140 [02:05<00:01,  1.13it/s] 99%|█████████▉| 139/140 [02:06<00:00,  1.17it/s]100%|██████████| 140/140 [02:07<00:00,  1.19it/s]                                                 100%|██████████| 140/140 [02:07<00:00,  1.19it/s]There were missing keys in the checkpoint model loaded: ['base_model.model.shared.weight', 'base_model.model.encoder.embed_tokens.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.encoder.block.0.layer.0.layer_norm.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.0.layer.1.layer_norm.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.1.layer.0.layer_norm.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.1.layer.1.layer_norm.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.2.layer.0.layer_norm.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.2.layer.1.layer_norm.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.3.layer.0.layer_norm.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.3.layer.1.layer_norm.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.4.layer.0.layer_norm.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.4.layer.1.layer_norm.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.5.layer.0.layer_norm.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.5.layer.1.layer_norm.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.6.layer.0.layer_norm.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.6.layer.1.layer_norm.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.7.layer.0.layer_norm.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.7.layer.1.layer_norm.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.8.layer.0.layer_norm.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.8.layer.1.layer_norm.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.9.layer.0.layer_norm.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.9.layer.1.layer_norm.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.10.layer.0.layer_norm.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.10.layer.1.layer_norm.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.11.layer.0.layer_norm.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.11.layer.1.layer_norm.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.12.layer.0.layer_norm.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.12.layer.1.layer_norm.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.13.layer.0.layer_norm.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.13.layer.1.layer_norm.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.14.layer.0.layer_norm.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.14.layer.1.layer_norm.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.15.layer.0.layer_norm.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.15.layer.1.layer_norm.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.16.layer.0.layer_norm.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.16.layer.1.layer_norm.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.17.layer.0.layer_norm.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.17.layer.1.layer_norm.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.18.layer.0.layer_norm.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.18.layer.1.layer_norm.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.19.layer.0.layer_norm.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.19.layer.1.layer_norm.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.20.layer.0.layer_norm.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.20.layer.1.layer_norm.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.21.layer.0.layer_norm.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.21.layer.1.layer_norm.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.22.layer.0.layer_norm.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.22.layer.1.layer_norm.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.23.layer.0.layer_norm.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.23.layer.1.layer_norm.weight', 'base_model.model.encoder.final_layer_norm.weight', 'base_model.model.decoder.embed_tokens.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.decoder.block.0.layer.0.layer_norm.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.0.layer.1.layer_norm.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.0.layer.2.layer_norm.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.1.layer.0.layer_norm.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.1.layer.1.layer_norm.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.1.layer.2.layer_norm.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.2.layer.0.layer_norm.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.2.layer.1.layer_norm.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.2.layer.2.layer_norm.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.3.layer.0.layer_norm.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.3.layer.1.layer_norm.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.3.layer.2.layer_norm.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.4.layer.0.layer_norm.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.4.layer.1.layer_norm.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.4.layer.2.layer_norm.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.5.layer.0.layer_norm.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.5.layer.1.layer_norm.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.5.layer.2.layer_norm.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.6.layer.0.layer_norm.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.6.layer.1.layer_norm.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.6.layer.2.layer_norm.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.7.layer.0.layer_norm.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.7.layer.1.layer_norm.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.7.layer.2.layer_norm.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.8.layer.0.layer_norm.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.8.layer.1.layer_norm.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.8.layer.2.layer_norm.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.9.layer.0.layer_norm.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.9.layer.1.layer_norm.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.9.layer.2.layer_norm.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.10.layer.0.layer_norm.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.10.layer.1.layer_norm.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.10.layer.2.layer_norm.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.11.layer.0.layer_norm.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.11.layer.1.layer_norm.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.11.layer.2.layer_norm.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.12.layer.0.layer_norm.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.12.layer.1.layer_norm.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.12.layer.2.layer_norm.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.13.layer.0.layer_norm.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.13.layer.1.layer_norm.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.13.layer.2.layer_norm.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.14.layer.0.layer_norm.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.14.layer.1.layer_norm.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.14.layer.2.layer_norm.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.15.layer.0.layer_norm.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.15.layer.1.layer_norm.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.15.layer.2.layer_norm.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.16.layer.0.layer_norm.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.16.layer.1.layer_norm.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.16.layer.2.layer_norm.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.17.layer.0.layer_norm.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.17.layer.1.layer_norm.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.17.layer.2.layer_norm.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.18.layer.0.layer_norm.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.18.layer.1.layer_norm.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.18.layer.2.layer_norm.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.19.layer.0.layer_norm.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.19.layer.1.layer_norm.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.19.layer.2.layer_norm.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.20.layer.0.layer_norm.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.20.layer.1.layer_norm.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.20.layer.2.layer_norm.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.21.layer.0.layer_norm.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.21.layer.1.layer_norm.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.21.layer.2.layer_norm.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.22.layer.0.layer_norm.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.22.layer.1.layer_norm.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.22.layer.2.layer_norm.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.23.layer.0.layer_norm.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.23.layer.1.layer_norm.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.23.layer.2.layer_norm.weight', 'base_model.model.decoder.final_layer_norm.weight', 'base_model.model.lm_head.weight'].
There were unexpected keys in the checkpoint model loaded: ['base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.weight'].
                                                 100%|██████████| 140/140 [02:07<00:00,  1.19it/s]100%|██████████| 140/140 [02:07<00:00,  1.10it/s]
{'eval_loss': 0.07686498016119003, 'eval_runtime': 0.3341, 'eval_samples_per_second': 74.838, 'eval_steps_per_second': 11.974, 'epoch': 8.42}
外层迭代结束！
外层迭代结束！
{'loss': 0.0062, 'learning_rate': 3.333333333333333e-05, 'epoch': 9.12}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0058, 'learning_rate': 0.0, 'epoch': 9.82}
{'train_runtime': 127.5194, 'train_samples_per_second': 17.644, 'train_steps_per_second': 1.098, 'train_loss': 0.03995327071419784, 'epoch': 9.82}

 If there's a warning about missing keys above, please disregard :)
nohup: ignoring input
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 16
micro_batch_size: 4
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: wic... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/2-wic
current data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 292.14it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 475.71it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 503.94it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
总样本数：250, 选择的样本数量：5
lora_weights: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/1-cb

pre-trained model's BOS EOS and PAD token id: None 1 0  => It should be 1,2,none
continual fine tune lora!
trainable params: 2359296 || all params: 740027392 || trainable%: 0.31881198257050464
训练数据总量：900
验证数据总量：100
Map:   0%|          | 0/900 [00:00<?, ? examples/s]/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3597: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  "`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your "
                                                   Map:   0%|          | 0/100 [00:00<?, ? examples/s]                                                   Map:   0%|          | 0/25 [00:00<?, ? examples/s]                                                  memory data loader 2
  0%|          | 0/560 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/560 [00:01<12:54,  1.39s/it]  0%|          | 2/560 [00:02<09:01,  1.03it/s]  1%|          | 3/560 [00:02<07:45,  1.20it/s]  1%|          | 4/560 [00:03<07:11,  1.29it/s]  1%|          | 5/560 [00:04<08:15,  1.12it/s]  1%|          | 6/560 [00:05<07:33,  1.22it/s]  1%|▏         | 7/560 [00:05<07:09,  1.29it/s]  1%|▏         | 8/560 [00:06<06:51,  1.34it/s]  2%|▏         | 9/560 [00:07<07:49,  1.17it/s]  2%|▏         | 10/560 [00:08<07:20,  1.25it/s]                                                  2%|▏         | 10/560 [00:08<07:20,  1.25it/s]  2%|▏         | 11/560 [00:09<07:03,  1.30it/s]  2%|▏         | 12/560 [00:09<06:47,  1.34it/s]  2%|▏         | 13/560 [00:10<07:42,  1.18it/s]  2%|▎         | 14/560 [00:11<07:15,  1.25it/s]  3%|▎         | 15/560 [00:12<06:57,  1.31it/s]  3%|▎         | 16/560 [00:12<06:43,  1.35it/s]  3%|▎         | 17/560 [00:13<07:39,  1.18it/s]  3%|▎         | 18/560 [00:14<07:13,  1.25it/s]  3%|▎         | 19/560 [00:15<06:54,  1.31it/s]  4%|▎         | 20/560 [00:16<06:41,  1.34it/s]                                                  4%|▎         | 20/560 [00:16<06:41,  1.34it/s]  4%|▍         | 21/560 [00:17<07:37,  1.18it/s]  4%|▍         | 22/560 [00:17<07:10,  1.25it/s]  4%|▍         | 23/560 [00:18<06:50,  1.31it/s]  4%|▍         | 24/560 [00:19<06:37,  1.35it/s]  4%|▍         | 25/560 [00:20<07:32,  1.18it/s]  5%|▍         | 26/560 [00:20<07:06,  1.25it/s]  5%|▍         | 27/560 [00:21<06:47,  1.31it/s]  5%|▌         | 28/560 [00:22<06:33,  1.35it/s]  5%|▌         | 29/560 [00:23<07:27,  1.19it/s]  5%|▌         | 30/560 [00:24<07:01,  1.26it/s]                                                  5%|▌         | 30/560 [00:24<07:01,  1.26it/s]  6%|▌         | 31/560 [00:24<06:43,  1.31it/s]  6%|▌         | 32/560 [00:25<06:29,  1.36it/s]  6%|▌         | 33/560 [00:26<07:22,  1.19it/s]  6%|▌         | 34/560 [00:27<06:59,  1.25it/s]  6%|▋         | 35/560 [00:27<06:40,  1.31it/s]  6%|▋         | 36/560 [00:28<06:27,  1.35it/s]  7%|▋         | 37/560 [00:29<07:20,  1.19it/s]  7%|▋         | 38/560 [00:30<06:55,  1.26it/s]  7%|▋         | 39/560 [00:31<06:36,  1.31it/s]  7%|▋         | 40/560 [00:31<06:24,  1.35it/s]                                                  7%|▋         | 40/560 [00:32<06:24,  1.35it/s]外层迭代结束！
外层迭代结束！
{'loss': 6.2881, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.18}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 4.4225, 'learning_rate': 0.00011999999999999999, 'epoch': 0.36}
外层迭代结束！
外层迭代结束！
{'loss': 0.9123, 'learning_rate': 0.00017999999999999998, 'epoch': 0.53}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2845, 'learning_rate': 0.00023999999999999998, 'epoch': 0.71}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.79it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.88it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.91it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.41it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.12it/s][A                                                
                                               [A  7%|▋         | 40/560 [00:33<06:24,  1.35it/s]
100%|██████████| 13/13 [00:00<00:00, 15.12it/s][A
                                               [A  7%|▋         | 41/560 [00:33<10:00,  1.16s/it]  8%|▊         | 42/560 [00:34<08:46,  1.02s/it]  8%|▊         | 43/560 [00:35<07:53,  1.09it/s]  8%|▊         | 44/560 [00:35<07:17,  1.18it/s]  8%|▊         | 45/560 [00:37<07:52,  1.09it/s]  8%|▊         | 46/560 [00:37<07:15,  1.18it/s]  8%|▊         | 47/560 [00:38<06:51,  1.25it/s]  9%|▊         | 48/560 [00:39<06:33,  1.30it/s]  9%|▉         | 49/560 [00:40<07:22,  1.16it/s]  9%|▉         | 50/560 [00:40<06:57,  1.22it/s]                                                  9%|▉         | 50/560 [00:40<06:57,  1.22it/s]  9%|▉         | 51/560 [00:41<06:38,  1.28it/s]  9%|▉         | 52/560 [00:42<06:25,  1.32it/s]  9%|▉         | 53/560 [00:43<07:18,  1.16it/s] 10%|▉         | 54/560 [00:44<06:54,  1.22it/s] 10%|▉         | 55/560 [00:44<06:35,  1.28it/s] 10%|█         | 56/560 [00:45<06:19,  1.33it/s] 10%|█         | 57/560 [00:46<07:09,  1.17it/s] 10%|█         | 58/560 [00:47<06:44,  1.24it/s] 11%|█         | 59/560 [00:47<06:27,  1.29it/s] 11%|█         | 60/560 [00:48<06:16,  1.33it/s]                                                 11%|█         | 60/560 [00:49<06:16,  1.33it/s] 11%|█         | 61/560 [00:49<07:05,  1.17it/s] 11%|█         | 62/560 [00:50<06:40,  1.24it/s] 11%|█▏        | 63/560 [00:51<06:23,  1.29it/s] 11%|█▏        | 64/560 [00:51<06:11,  1.34it/s] 12%|█▏        | 65/560 [00:52<07:03,  1.17it/s] 12%|█▏        | 66/560 [00:53<06:40,  1.23it/s] 12%|█▏        | 67/560 [00:54<06:24,  1.28it/s] 12%|█▏        | 68/560 [00:55<06:12,  1.32it/s] 12%|█▏        | 69/560 [00:56<07:00,  1.17it/s] 12%|█▎        | 70/560 [00:56<06:36,  1.24it/s]                                                 12%|█▎        | 70/560 [00:56<06:36,  1.24it/s] 13%|█▎        | 71/560 [00:57<06:18,  1.29it/s] 13%|█▎        | 72/560 [00:58<06:06,  1.33it/s] 13%|█▎        | 73/560 [00:59<06:55,  1.17it/s] 13%|█▎        | 74/560 [01:00<06:32,  1.24it/s] 13%|█▎        | 75/560 [01:00<06:14,  1.29it/s] 14%|█▎        | 76/560 [01:01<06:05,  1.32it/s] 14%|█▍        | 77/560 [01:02<06:54,  1.16it/s] 14%|█▍        | 78/560 [01:03<06:32,  1.23it/s] 14%|█▍        | 79/560 [01:03<06:18,  1.27it/s] 14%|█▍        | 80/560 [01:04<06:07,  1.30it/s]                                                 14%|█▍        | 80/560 [01:05<06:07,  1.30it/s]{'eval_loss': 0.41440892219543457, 'eval_runtime': 0.8994, 'eval_samples_per_second': 111.191, 'eval_steps_per_second': 14.455, 'epoch': 0.71}
外层迭代结束！
外层迭代结束！
{'loss': 0.2888, 'learning_rate': 0.0003, 'epoch': 0.89}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2562, 'learning_rate': 0.0002941176470588235, 'epoch': 1.07}
外层迭代结束！
外层迭代结束！
{'loss': 0.2497, 'learning_rate': 0.00028823529411764703, 'epoch': 1.24}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2536, 'learning_rate': 0.00028235294117647056, 'epoch': 1.42}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.75it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.77it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.81it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.35it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.00it/s][A                                                
                                               [A 14%|█▍        | 80/560 [01:06<06:07,  1.30it/s]
100%|██████████| 13/13 [00:00<00:00, 15.00it/s][A
                                               [A 14%|█▍        | 81/560 [01:06<09:31,  1.19s/it] 15%|█▍        | 82/560 [01:07<08:19,  1.05s/it] 15%|█▍        | 83/560 [01:08<07:28,  1.06it/s] 15%|█▌        | 84/560 [01:08<06:51,  1.16it/s] 15%|█▌        | 85/560 [01:10<07:24,  1.07it/s] 15%|█▌        | 86/560 [01:10<06:49,  1.16it/s] 16%|█▌        | 87/560 [01:11<06:25,  1.23it/s] 16%|█▌        | 88/560 [01:12<06:09,  1.28it/s] 16%|█▌        | 89/560 [01:13<06:52,  1.14it/s] 16%|█▌        | 90/560 [01:13<06:25,  1.22it/s]                                                 16%|█▌        | 90/560 [01:13<06:25,  1.22it/s] 16%|█▋        | 91/560 [01:14<06:06,  1.28it/s] 16%|█▋        | 92/560 [01:15<05:54,  1.32it/s] 17%|█▋        | 93/560 [01:16<06:42,  1.16it/s] 17%|█▋        | 94/560 [01:17<06:17,  1.23it/s] 17%|█▋        | 95/560 [01:17<06:00,  1.29it/s] 17%|█▋        | 96/560 [01:18<05:47,  1.33it/s] 17%|█▋        | 97/560 [01:19<06:34,  1.17it/s] 18%|█▊        | 98/560 [01:20<06:12,  1.24it/s] 18%|█▊        | 99/560 [01:21<05:57,  1.29it/s] 18%|█▊        | 100/560 [01:21<05:44,  1.33it/s]                                                  18%|█▊        | 100/560 [01:22<05:44,  1.33it/s] 18%|█▊        | 101/560 [01:22<06:31,  1.17it/s] 18%|█▊        | 102/560 [01:23<06:10,  1.24it/s] 18%|█▊        | 103/560 [01:24<05:53,  1.29it/s] 19%|█▊        | 104/560 [01:24<05:42,  1.33it/s] 19%|█▉        | 105/560 [01:25<06:27,  1.18it/s] 19%|█▉        | 106/560 [01:26<06:04,  1.24it/s] 19%|█▉        | 107/560 [01:27<05:48,  1.30it/s] 19%|█▉        | 108/560 [01:28<05:38,  1.34it/s] 19%|█▉        | 109/560 [01:29<06:24,  1.17it/s] 20%|█▉        | 110/560 [01:29<06:02,  1.24it/s]                                                  20%|█▉        | 110/560 [01:29<06:02,  1.24it/s] 20%|█▉        | 111/560 [01:30<05:46,  1.29it/s] 20%|██        | 112/560 [01:31<05:35,  1.34it/s] 20%|██        | 113/560 [01:32<06:20,  1.17it/s] 20%|██        | 114/560 [01:33<06:00,  1.24it/s] 21%|██        | 115/560 [01:33<05:47,  1.28it/s] 21%|██        | 116/560 [01:34<05:34,  1.33it/s] 21%|██        | 117/560 [01:35<06:18,  1.17it/s] 21%|██        | 118/560 [01:36<05:55,  1.24it/s] 21%|██▏       | 119/560 [01:36<05:40,  1.29it/s] 21%|██▏       | 120/560 [01:37<05:28,  1.34it/s]                                                  21%|██▏       | 120/560 [01:38<05:28,  1.34it/s]{'eval_loss': 0.22730247676372528, 'eval_runtime': 0.9056, 'eval_samples_per_second': 110.42, 'eval_steps_per_second': 14.355, 'epoch': 1.42}
外层迭代结束！
外层迭代结束！
{'loss': 0.2554, 'learning_rate': 0.0002764705882352941, 'epoch': 1.6}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2409, 'learning_rate': 0.0002705882352941176, 'epoch': 1.78}
外层迭代结束！
外层迭代结束！
{'loss': 0.2214, 'learning_rate': 0.00026470588235294115, 'epoch': 1.96}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2245, 'learning_rate': 0.0002588235294117647, 'epoch': 2.13}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.47it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.65it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.69it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.10it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.81it/s][A                                                 
                                               [A 21%|██▏       | 120/560 [01:38<05:28,  1.34it/s]
100%|██████████| 13/13 [00:00<00:00, 14.81it/s][A
                                               [A 22%|██▏       | 121/560 [01:39<08:30,  1.16s/it] 22%|██▏       | 122/560 [01:40<07:27,  1.02s/it] 22%|██▏       | 123/560 [01:41<06:44,  1.08it/s] 22%|██▏       | 124/560 [01:41<06:13,  1.17it/s] 22%|██▏       | 125/560 [01:42<06:44,  1.08it/s] 22%|██▎       | 126/560 [01:43<06:12,  1.17it/s] 23%|██▎       | 127/560 [01:44<05:49,  1.24it/s] 23%|██▎       | 128/560 [01:45<05:34,  1.29it/s] 23%|██▎       | 129/560 [01:46<06:14,  1.15it/s] 23%|██▎       | 130/560 [01:46<05:51,  1.22it/s]                                                  23%|██▎       | 130/560 [01:46<05:51,  1.22it/s] 23%|██▎       | 131/560 [01:47<05:34,  1.28it/s] 24%|██▎       | 132/560 [01:48<05:23,  1.32it/s] 24%|██▍       | 133/560 [01:49<06:06,  1.17it/s] 24%|██▍       | 134/560 [01:49<05:43,  1.24it/s] 24%|██▍       | 135/560 [01:50<05:27,  1.30it/s] 24%|██▍       | 136/560 [01:51<05:16,  1.34it/s] 24%|██▍       | 137/560 [01:52<06:00,  1.17it/s] 25%|██▍       | 138/560 [01:53<05:39,  1.24it/s] 25%|██▍       | 139/560 [01:53<05:25,  1.29it/s] 25%|██▌       | 140/560 [01:54<05:14,  1.34it/s]                                                  25%|██▌       | 140/560 [01:54<05:14,  1.34it/s] 25%|██▌       | 141/560 [01:55<05:57,  1.17it/s] 25%|██▌       | 142/560 [01:56<05:36,  1.24it/s] 26%|██▌       | 143/560 [01:57<05:21,  1.30it/s] 26%|██▌       | 144/560 [01:57<05:11,  1.34it/s] 26%|██▌       | 145/560 [01:58<05:54,  1.17it/s] 26%|██▌       | 146/560 [01:59<05:32,  1.24it/s] 26%|██▋       | 147/560 [02:00<05:18,  1.30it/s] 26%|██▋       | 148/560 [02:00<05:08,  1.34it/s] 27%|██▋       | 149/560 [02:01<05:49,  1.18it/s] 27%|██▋       | 150/560 [02:02<05:28,  1.25it/s]                                                  27%|██▋       | 150/560 [02:02<05:28,  1.25it/s] 27%|██▋       | 151/560 [02:03<05:14,  1.30it/s] 27%|██▋       | 152/560 [02:04<05:06,  1.33it/s] 27%|██▋       | 153/560 [02:05<05:47,  1.17it/s] 28%|██▊       | 154/560 [02:05<05:28,  1.24it/s] 28%|██▊       | 155/560 [02:06<05:13,  1.29it/s] 28%|██▊       | 156/560 [02:07<05:03,  1.33it/s] 28%|██▊       | 157/560 [02:08<05:43,  1.17it/s] 28%|██▊       | 158/560 [02:09<05:23,  1.24it/s] 28%|██▊       | 159/560 [02:09<05:09,  1.29it/s] 29%|██▊       | 160/560 [02:10<04:58,  1.34it/s]                                                  29%|██▊       | 160/560 [02:10<04:58,  1.34it/s]{'eval_loss': 0.21896496415138245, 'eval_runtime': 0.9139, 'eval_samples_per_second': 109.427, 'eval_steps_per_second': 14.225, 'epoch': 2.13}
外层迭代结束！
外层迭代结束！
{'loss': 0.2229, 'learning_rate': 0.0002529411764705882, 'epoch': 2.31}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2291, 'learning_rate': 0.00024705882352941174, 'epoch': 2.49}
外层迭代结束！
外层迭代结束！
{'loss': 0.2275, 'learning_rate': 0.00024117647058823527, 'epoch': 2.67}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2245, 'learning_rate': 0.0002352941176470588, 'epoch': 2.84}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.57it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.75it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.83it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.35it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.02it/s][A                                                 
                                               [A 29%|██▊       | 160/560 [02:11<04:58,  1.34it/s]
100%|██████████| 13/13 [00:00<00:00, 15.02it/s][A
                                               [A 29%|██▉       | 161/560 [02:12<07:43,  1.16s/it] 29%|██▉       | 162/560 [02:13<06:45,  1.02s/it] 29%|██▉       | 163/560 [02:13<06:06,  1.08it/s] 29%|██▉       | 164/560 [02:14<05:38,  1.17it/s] 29%|██▉       | 165/560 [02:15<06:05,  1.08it/s] 30%|██▉       | 166/560 [02:16<05:37,  1.17it/s] 30%|██▉       | 167/560 [02:17<05:18,  1.24it/s] 30%|███       | 168/560 [02:17<05:03,  1.29it/s] 30%|███       | 169/560 [02:18<05:39,  1.15it/s] 30%|███       | 170/560 [02:19<05:19,  1.22it/s]                                                  30%|███       | 170/560 [02:19<05:19,  1.22it/s] 31%|███       | 171/560 [02:20<05:04,  1.28it/s] 31%|███       | 172/560 [02:21<04:55,  1.31it/s] 31%|███       | 173/560 [02:22<05:32,  1.16it/s] 31%|███       | 174/560 [02:22<05:12,  1.23it/s] 31%|███▏      | 175/560 [02:23<04:58,  1.29it/s] 31%|███▏      | 176/560 [02:24<04:48,  1.33it/s] 32%|███▏      | 177/560 [02:25<05:27,  1.17it/s] 32%|███▏      | 178/560 [02:25<05:09,  1.24it/s] 32%|███▏      | 179/560 [02:26<04:54,  1.29it/s] 32%|███▏      | 180/560 [02:27<04:44,  1.34it/s]                                                  32%|███▏      | 180/560 [02:27<04:44,  1.34it/s] 32%|███▏      | 181/560 [02:28<05:24,  1.17it/s] 32%|███▎      | 182/560 [02:29<05:05,  1.24it/s] 33%|███▎      | 183/560 [02:29<04:52,  1.29it/s] 33%|███▎      | 184/560 [02:30<04:42,  1.33it/s] 33%|███▎      | 185/560 [02:31<05:20,  1.17it/s] 33%|███▎      | 186/560 [02:32<05:01,  1.24it/s] 33%|███▎      | 187/560 [02:33<04:48,  1.29it/s] 34%|███▎      | 188/560 [02:33<04:43,  1.31it/s] 34%|███▍      | 189/560 [02:34<05:19,  1.16it/s] 34%|███▍      | 190/560 [02:35<05:00,  1.23it/s]                                                  34%|███▍      | 190/560 [02:35<05:00,  1.23it/s] 34%|███▍      | 191/560 [02:36<04:46,  1.29it/s] 34%|███▍      | 192/560 [02:36<04:35,  1.33it/s] 34%|███▍      | 193/560 [02:38<05:13,  1.17it/s] 35%|███▍      | 194/560 [02:38<04:58,  1.22it/s] 35%|███▍      | 195/560 [02:39<04:43,  1.29it/s] 35%|███▌      | 196/560 [02:40<04:33,  1.33it/s] 35%|███▌      | 197/560 [02:41<05:09,  1.17it/s] 35%|███▌      | 198/560 [02:41<04:51,  1.24it/s] 36%|███▌      | 199/560 [02:42<04:38,  1.30it/s] 36%|███▌      | 200/560 [02:43<04:28,  1.34it/s]                                                  36%|███▌      | 200/560 [02:43<04:28,  1.34it/s]{'eval_loss': 0.19609375298023224, 'eval_runtime': 0.9049, 'eval_samples_per_second': 110.508, 'eval_steps_per_second': 14.366, 'epoch': 2.84}
外层迭代结束！
外层迭代结束！
{'loss': 0.2008, 'learning_rate': 0.0002294117647058823, 'epoch': 3.02}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2194, 'learning_rate': 0.00022352941176470586, 'epoch': 3.2}
外层迭代结束！
外层迭代结束！
{'loss': 0.2014, 'learning_rate': 0.0002176470588235294, 'epoch': 3.38}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1751, 'learning_rate': 0.00021176470588235295, 'epoch': 3.56}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.74it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.87it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.90it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.39it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.08it/s][A                                                 
                                               [A 36%|███▌      | 200/560 [02:44<04:28,  1.34it/s]
100%|██████████| 13/13 [00:00<00:00, 15.08it/s][A
                                               [A 36%|███▌      | 201/560 [02:45<06:56,  1.16s/it] 36%|███▌      | 202/560 [02:46<06:05,  1.02s/it] 36%|███▋      | 203/560 [02:46<05:28,  1.09it/s] 36%|███▋      | 204/560 [02:47<05:02,  1.18it/s] 37%|███▋      | 205/560 [02:48<05:28,  1.08it/s] 37%|███▋      | 206/560 [02:49<05:02,  1.17it/s] 37%|███▋      | 207/560 [02:49<04:44,  1.24it/s] 37%|███▋      | 208/560 [02:50<04:31,  1.29it/s] 37%|███▋      | 209/560 [02:51<05:04,  1.15it/s] 38%|███▊      | 210/560 [02:52<04:44,  1.23it/s]                                                  38%|███▊      | 210/560 [02:52<04:44,  1.23it/s] 38%|███▊      | 211/560 [02:53<04:31,  1.28it/s] 38%|███▊      | 212/560 [02:53<04:22,  1.32it/s] 38%|███▊      | 213/560 [02:54<04:57,  1.17it/s] 38%|███▊      | 214/560 [02:55<04:38,  1.24it/s] 38%|███▊      | 215/560 [02:56<04:25,  1.30it/s] 39%|███▊      | 216/560 [02:57<04:16,  1.34it/s] 39%|███▉      | 217/560 [02:58<04:50,  1.18it/s] 39%|███▉      | 218/560 [02:58<04:33,  1.25it/s] 39%|███▉      | 219/560 [02:59<04:21,  1.30it/s] 39%|███▉      | 220/560 [03:00<04:12,  1.34it/s]                                                  39%|███▉      | 220/560 [03:00<04:12,  1.34it/s] 39%|███▉      | 221/560 [03:01<04:47,  1.18it/s] 40%|███▉      | 222/560 [03:01<04:30,  1.25it/s] 40%|███▉      | 223/560 [03:02<04:19,  1.30it/s] 40%|████      | 224/560 [03:03<04:11,  1.34it/s] 40%|████      | 225/560 [03:04<04:44,  1.18it/s] 40%|████      | 226/560 [03:05<04:28,  1.24it/s] 41%|████      | 227/560 [03:05<04:15,  1.30it/s] 41%|████      | 228/560 [03:06<04:06,  1.35it/s] 41%|████      | 229/560 [03:07<04:40,  1.18it/s] 41%|████      | 230/560 [03:08<04:23,  1.25it/s]                                                  41%|████      | 230/560 [03:08<04:23,  1.25it/s] 41%|████▏     | 231/560 [03:08<04:13,  1.30it/s] 41%|████▏     | 232/560 [03:09<04:04,  1.34it/s] 42%|████▏     | 233/560 [03:10<04:36,  1.18it/s] 42%|████▏     | 234/560 [03:11<04:19,  1.25it/s] 42%|████▏     | 235/560 [03:12<04:08,  1.31it/s] 42%|████▏     | 236/560 [03:12<04:01,  1.34it/s] 42%|████▏     | 237/560 [03:13<04:33,  1.18it/s] 42%|████▎     | 238/560 [03:14<04:17,  1.25it/s] 43%|████▎     | 239/560 [03:15<04:06,  1.30it/s] 43%|████▎     | 240/560 [03:15<03:58,  1.34it/s]                                                  43%|████▎     | 240/560 [03:16<03:58,  1.34it/s]{'eval_loss': 0.19123807549476624, 'eval_runtime': 0.9015, 'eval_samples_per_second': 110.928, 'eval_steps_per_second': 14.421, 'epoch': 3.56}
外层迭代结束！
外层迭代结束！
{'loss': 0.1783, 'learning_rate': 0.00020588235294117645, 'epoch': 3.73}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2089, 'learning_rate': 0.00019999999999999998, 'epoch': 3.91}
外层迭代结束！
外层迭代结束！
{'loss': 0.1712, 'learning_rate': 0.0001941176470588235, 'epoch': 4.09}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1679, 'learning_rate': 0.00018823529411764704, 'epoch': 4.27}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.78it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.97it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.02it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.48it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.19it/s][A                                                 
                                               [A 43%|████▎     | 240/560 [03:17<03:58,  1.34it/s]
100%|██████████| 13/13 [00:00<00:00, 15.19it/s][A
                                               [A 43%|████▎     | 241/560 [03:18<06:08,  1.15s/it] 43%|████▎     | 242/560 [03:18<05:22,  1.01s/it] 43%|████▎     | 243/560 [03:19<04:50,  1.09it/s] 44%|████▎     | 244/560 [03:20<04:27,  1.18it/s] 44%|████▍     | 245/560 [03:21<04:50,  1.08it/s] 44%|████▍     | 246/560 [03:21<04:27,  1.18it/s] 44%|████▍     | 247/560 [03:22<04:11,  1.25it/s] 44%|████▍     | 248/560 [03:23<04:00,  1.30it/s] 44%|████▍     | 249/560 [03:24<04:29,  1.15it/s] 45%|████▍     | 250/560 [03:25<04:12,  1.23it/s]                                                  45%|████▍     | 250/560 [03:25<04:12,  1.23it/s] 45%|████▍     | 251/560 [03:25<04:00,  1.29it/s] 45%|████▌     | 252/560 [03:26<03:51,  1.33it/s] 45%|████▌     | 253/560 [03:27<04:21,  1.17it/s] 45%|████▌     | 254/560 [03:28<04:05,  1.25it/s] 46%|████▌     | 255/560 [03:28<03:55,  1.30it/s] 46%|████▌     | 256/560 [03:29<03:46,  1.34it/s] 46%|████▌     | 257/560 [03:30<04:17,  1.18it/s] 46%|████▌     | 258/560 [03:31<04:03,  1.24it/s] 46%|████▋     | 259/560 [03:32<03:52,  1.29it/s] 46%|████▋     | 260/560 [03:32<03:45,  1.33it/s]                                                  46%|████▋     | 260/560 [03:33<03:45,  1.33it/s] 47%|████▋     | 261/560 [03:33<04:17,  1.16it/s] 47%|████▋     | 262/560 [03:34<04:01,  1.23it/s] 47%|████▋     | 263/560 [03:35<03:50,  1.29it/s] 47%|████▋     | 264/560 [03:36<03:42,  1.33it/s] 47%|████▋     | 265/560 [03:37<04:10,  1.18it/s] 48%|████▊     | 266/560 [03:37<03:55,  1.25it/s] 48%|████▊     | 267/560 [03:38<03:45,  1.30it/s] 48%|████▊     | 268/560 [03:39<03:39,  1.33it/s] 48%|████▊     | 269/560 [03:40<04:07,  1.17it/s] 48%|████▊     | 270/560 [03:41<03:55,  1.23it/s]                                                  48%|████▊     | 270/560 [03:41<03:55,  1.23it/s] 48%|████▊     | 271/560 [03:41<03:46,  1.27it/s] 49%|████▊     | 272/560 [03:42<03:38,  1.32it/s] 49%|████▉     | 273/560 [03:43<04:06,  1.16it/s] 49%|████▉     | 274/560 [03:44<03:51,  1.24it/s] 49%|████▉     | 275/560 [03:44<03:41,  1.29it/s] 49%|████▉     | 276/560 [03:45<03:33,  1.33it/s] 49%|████▉     | 277/560 [03:46<04:02,  1.17it/s] 50%|████▉     | 278/560 [03:47<03:48,  1.24it/s] 50%|████▉     | 279/560 [03:48<03:37,  1.29it/s] 50%|█████     | 280/560 [03:48<03:30,  1.33it/s]                                                  50%|█████     | 280/560 [03:49<03:30,  1.33it/s]{'eval_loss': 0.1971416473388672, 'eval_runtime': 0.8953, 'eval_samples_per_second': 111.693, 'eval_steps_per_second': 14.52, 'epoch': 4.27}
外层迭代结束！
外层迭代结束！
{'loss': 0.1845, 'learning_rate': 0.00018235294117647055, 'epoch': 4.44}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.23, 'learning_rate': 0.0001764705882352941, 'epoch': 4.62}
外层迭代结束！
外层迭代结束！
{'loss': 0.1385, 'learning_rate': 0.00017058823529411763, 'epoch': 4.8}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2004, 'learning_rate': 0.0001647058823529412, 'epoch': 4.98}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.78it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.77it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.85it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.34it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.02it/s][A                                                 
                                               [A 50%|█████     | 280/560 [03:50<03:30,  1.33it/s]
100%|██████████| 13/13 [00:00<00:00, 15.02it/s][A
                                               [A 50%|█████     | 281/560 [03:50<05:25,  1.17s/it] 50%|█████     | 282/560 [03:51<04:44,  1.02s/it] 51%|█████     | 283/560 [03:52<04:16,  1.08it/s] 51%|█████     | 284/560 [03:53<03:55,  1.17it/s] 51%|█████     | 285/560 [03:54<04:14,  1.08it/s] 51%|█████     | 286/560 [03:54<03:54,  1.17it/s] 51%|█████▏    | 287/560 [03:55<03:41,  1.23it/s] 51%|█████▏    | 288/560 [03:56<03:30,  1.29it/s] 52%|█████▏    | 289/560 [03:57<03:56,  1.15it/s] 52%|█████▏    | 290/560 [03:57<03:41,  1.22it/s]                                                  52%|█████▏    | 290/560 [03:57<03:41,  1.22it/s] 52%|█████▏    | 291/560 [03:58<03:30,  1.28it/s] 52%|█████▏    | 292/560 [03:59<03:22,  1.32it/s] 52%|█████▏    | 293/560 [04:00<03:48,  1.17it/s] 52%|█████▎    | 294/560 [04:01<03:34,  1.24it/s] 53%|█████▎    | 295/560 [04:01<03:25,  1.29it/s] 53%|█████▎    | 296/560 [04:02<03:18,  1.33it/s] 53%|█████▎    | 297/560 [04:03<03:46,  1.16it/s] 53%|█████▎    | 298/560 [04:04<03:32,  1.23it/s] 53%|█████▎    | 299/560 [04:05<03:22,  1.29it/s] 54%|█████▎    | 300/560 [04:05<03:16,  1.33it/s]                                                  54%|█████▎    | 300/560 [04:06<03:16,  1.33it/s] 54%|█████▍    | 301/560 [04:06<03:41,  1.17it/s] 54%|█████▍    | 302/560 [04:07<03:28,  1.24it/s] 54%|█████▍    | 303/560 [04:08<03:19,  1.29it/s] 54%|█████▍    | 304/560 [04:08<03:12,  1.33it/s] 54%|█████▍    | 305/560 [04:10<03:37,  1.17it/s] 55%|█████▍    | 306/560 [04:10<03:26,  1.23it/s] 55%|█████▍    | 307/560 [04:11<03:18,  1.27it/s] 55%|█████▌    | 308/560 [04:12<03:11,  1.32it/s] 55%|█████▌    | 309/560 [04:13<03:35,  1.16it/s] 55%|█████▌    | 310/560 [04:13<03:22,  1.23it/s]                                                  55%|█████▌    | 310/560 [04:13<03:22,  1.23it/s] 56%|█████▌    | 311/560 [04:14<03:13,  1.29it/s] 56%|█████▌    | 312/560 [04:15<03:06,  1.33it/s] 56%|█████▌    | 313/560 [04:16<03:30,  1.17it/s] 56%|█████▌    | 314/560 [04:17<03:18,  1.24it/s] 56%|█████▋    | 315/560 [04:17<03:09,  1.29it/s] 56%|█████▋    | 316/560 [04:18<03:03,  1.33it/s] 57%|█████▋    | 317/560 [04:19<03:27,  1.17it/s] 57%|█████▋    | 318/560 [04:20<03:15,  1.24it/s] 57%|█████▋    | 319/560 [04:21<03:06,  1.29it/s] 57%|█████▋    | 320/560 [04:21<03:00,  1.33it/s]                                                  57%|█████▋    | 320/560 [04:22<03:00,  1.33it/s]{'eval_loss': 0.213145911693573, 'eval_runtime': 0.9056, 'eval_samples_per_second': 110.428, 'eval_steps_per_second': 14.356, 'epoch': 4.98}
外层迭代结束！
外层迭代结束！
{'loss': 0.1611, 'learning_rate': 0.0001588235294117647, 'epoch': 5.16}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1731, 'learning_rate': 0.00015294117647058822, 'epoch': 5.33}
外层迭代结束！
外层迭代结束！
{'loss': 0.1786, 'learning_rate': 0.00014705882352941175, 'epoch': 5.51}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1435, 'learning_rate': 0.00014117647058823528, 'epoch': 5.69}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.49it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.59it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.70it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.17it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.83it/s][A                                                 
                                               [A 57%|█████▋    | 320/560 [04:23<03:00,  1.33it/s]
100%|██████████| 13/13 [00:00<00:00, 14.83it/s][A
                                               [A 57%|█████▋    | 321/560 [04:23<04:41,  1.18s/it] 57%|█████▊    | 322/560 [04:24<04:05,  1.03s/it] 58%|█████▊    | 323/560 [04:25<03:41,  1.07it/s] 58%|█████▊    | 324/560 [04:25<03:23,  1.16it/s] 58%|█████▊    | 325/560 [04:27<03:38,  1.07it/s] 58%|█████▊    | 326/560 [04:27<03:23,  1.15it/s] 58%|█████▊    | 327/560 [04:28<03:10,  1.22it/s] 59%|█████▊    | 328/560 [04:29<03:02,  1.27it/s] 59%|█████▉    | 329/560 [04:30<03:23,  1.14it/s] 59%|█████▉    | 330/560 [04:31<03:13,  1.19it/s]                                                  59%|█████▉    | 330/560 [04:31<03:13,  1.19it/s] 59%|█████▉    | 331/560 [04:31<03:06,  1.23it/s] 59%|█████▉    | 332/560 [04:32<02:59,  1.27it/s] 59%|█████▉    | 333/560 [04:33<03:22,  1.12it/s] 60%|█████▉    | 334/560 [04:34<03:08,  1.20it/s] 60%|█████▉    | 335/560 [04:35<02:57,  1.27it/s] 60%|██████    | 336/560 [04:35<02:50,  1.31it/s] 60%|██████    | 337/560 [04:36<03:11,  1.16it/s] 60%|██████    | 338/560 [04:37<02:59,  1.24it/s] 61%|██████    | 339/560 [04:38<02:50,  1.29it/s] 61%|██████    | 340/560 [04:38<02:44,  1.34it/s]                                                  61%|██████    | 340/560 [04:39<02:44,  1.34it/s] 61%|██████    | 341/560 [04:40<03:07,  1.17it/s] 61%|██████    | 342/560 [04:40<02:55,  1.24it/s] 61%|██████▏   | 343/560 [04:41<02:47,  1.29it/s] 61%|██████▏   | 344/560 [04:42<02:41,  1.34it/s] 62%|██████▏   | 345/560 [04:43<03:03,  1.17it/s] 62%|██████▏   | 346/560 [04:43<02:52,  1.24it/s] 62%|██████▏   | 347/560 [04:44<02:43,  1.30it/s] 62%|██████▏   | 348/560 [04:45<02:38,  1.34it/s] 62%|██████▏   | 349/560 [04:46<03:01,  1.16it/s] 62%|██████▎   | 350/560 [04:47<02:50,  1.23it/s]                                                  62%|██████▎   | 350/560 [04:47<02:50,  1.23it/s] 63%|██████▎   | 351/560 [04:47<02:43,  1.28it/s] 63%|██████▎   | 352/560 [04:48<02:37,  1.32it/s] 63%|██████▎   | 353/560 [04:49<02:57,  1.17it/s] 63%|██████▎   | 354/560 [04:50<02:46,  1.24it/s] 63%|██████▎   | 355/560 [04:51<02:39,  1.29it/s] 64%|██████▎   | 356/560 [04:51<02:34,  1.32it/s] 64%|██████▍   | 357/560 [04:52<02:53,  1.17it/s] 64%|██████▍   | 358/560 [04:53<02:43,  1.23it/s] 64%|██████▍   | 359/560 [04:54<02:36,  1.29it/s] 64%|██████▍   | 360/560 [04:54<02:30,  1.33it/s]                                                  64%|██████▍   | 360/560 [04:55<02:30,  1.33it/s]{'eval_loss': 0.2080867439508438, 'eval_runtime': 0.9131, 'eval_samples_per_second': 109.519, 'eval_steps_per_second': 14.237, 'epoch': 5.69}
外层迭代结束！
外层迭代结束！
{'loss': 0.1686, 'learning_rate': 0.0001352941176470588, 'epoch': 5.87}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1405, 'learning_rate': 0.00012941176470588234, 'epoch': 6.04}
外层迭代结束！
外层迭代结束！
{'loss': 0.1227, 'learning_rate': 0.00012352941176470587, 'epoch': 6.22}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1474, 'learning_rate': 0.0001176470588235294, 'epoch': 6.4}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.52it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.72it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.76it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.32it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.08it/s][A                                                 
                                               [A 64%|██████▍   | 360/560 [04:56<02:30,  1.33it/s]
100%|██████████| 13/13 [00:00<00:00, 15.08it/s][A
                                               [A 64%|██████▍   | 361/560 [04:57<03:53,  1.18s/it] 65%|██████▍   | 362/560 [04:57<03:24,  1.03s/it] 65%|██████▍   | 363/560 [04:58<03:03,  1.07it/s] 65%|██████▌   | 364/560 [04:59<02:49,  1.16it/s] 65%|██████▌   | 365/560 [05:00<03:01,  1.07it/s] 65%|██████▌   | 366/560 [05:00<02:47,  1.16it/s] 66%|██████▌   | 367/560 [05:01<02:36,  1.23it/s] 66%|██████▌   | 368/560 [05:02<02:29,  1.29it/s] 66%|██████▌   | 369/560 [05:03<02:46,  1.15it/s] 66%|██████▌   | 370/560 [05:04<02:36,  1.22it/s]                                                  66%|██████▌   | 370/560 [05:04<02:36,  1.22it/s] 66%|██████▋   | 371/560 [05:04<02:28,  1.27it/s] 66%|██████▋   | 372/560 [05:05<02:22,  1.32it/s] 67%|██████▋   | 373/560 [05:06<02:40,  1.17it/s] 67%|██████▋   | 374/560 [05:07<02:30,  1.24it/s] 67%|██████▋   | 375/560 [05:08<02:22,  1.29it/s] 67%|██████▋   | 376/560 [05:08<02:17,  1.34it/s] 67%|██████▋   | 377/560 [05:09<02:35,  1.17it/s] 68%|██████▊   | 378/560 [05:10<02:26,  1.24it/s] 68%|██████▊   | 379/560 [05:11<02:19,  1.30it/s] 68%|██████▊   | 380/560 [05:11<02:15,  1.33it/s]                                                  68%|██████▊   | 380/560 [05:12<02:15,  1.33it/s] 68%|██████▊   | 381/560 [05:12<02:33,  1.17it/s] 68%|██████▊   | 382/560 [05:13<02:24,  1.24it/s] 68%|██████▊   | 383/560 [05:14<02:16,  1.29it/s] 69%|██████▊   | 384/560 [05:15<02:12,  1.33it/s] 69%|██████▉   | 385/560 [05:16<02:29,  1.17it/s] 69%|██████▉   | 386/560 [05:16<02:20,  1.24it/s] 69%|██████▉   | 387/560 [05:17<02:13,  1.30it/s] 69%|██████▉   | 388/560 [05:18<02:09,  1.33it/s] 69%|██████▉   | 389/560 [05:19<02:26,  1.17it/s] 70%|██████▉   | 390/560 [05:20<02:16,  1.24it/s]                                                  70%|██████▉   | 390/560 [05:20<02:16,  1.24it/s] 70%|██████▉   | 391/560 [05:20<02:11,  1.28it/s] 70%|███████   | 392/560 [05:21<02:06,  1.33it/s] 70%|███████   | 393/560 [05:22<02:22,  1.17it/s] 70%|███████   | 394/560 [05:23<02:13,  1.24it/s] 71%|███████   | 395/560 [05:23<02:07,  1.30it/s] 71%|███████   | 396/560 [05:24<02:02,  1.34it/s] 71%|███████   | 397/560 [05:25<02:17,  1.18it/s] 71%|███████   | 398/560 [05:26<02:09,  1.25it/s] 71%|███████▏  | 399/560 [05:27<02:03,  1.30it/s] 71%|███████▏  | 400/560 [05:27<01:59,  1.34it/s]                                                  71%|███████▏  | 400/560 [05:28<01:59,  1.34it/s]{'eval_loss': 0.25631657242774963, 'eval_runtime': 0.9042, 'eval_samples_per_second': 110.6, 'eval_steps_per_second': 14.378, 'epoch': 6.4}
外层迭代结束！
外层迭代结束！
{'loss': 0.1354, 'learning_rate': 0.00011176470588235293, 'epoch': 6.58}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1417, 'learning_rate': 0.00010588235294117647, 'epoch': 6.76}
外层迭代结束！
外层迭代结束！
{'loss': 0.1644, 'learning_rate': 9.999999999999999e-05, 'epoch': 6.93}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.155, 'learning_rate': 9.411764705882352e-05, 'epoch': 7.11}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.64it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.92it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.95it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.37it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.07it/s][A                                                 
                                               [A 71%|███████▏  | 400/560 [05:29<01:59,  1.34it/s]
100%|██████████| 13/13 [00:00<00:00, 15.07it/s][A
                                               [A 72%|███████▏  | 401/560 [05:29<03:04,  1.16s/it] 72%|███████▏  | 402/560 [05:30<02:41,  1.02s/it] 72%|███████▏  | 403/560 [05:31<02:24,  1.09it/s] 72%|███████▏  | 404/560 [05:31<02:12,  1.17it/s] 72%|███████▏  | 405/560 [05:33<02:23,  1.08it/s] 72%|███████▎  | 406/560 [05:33<02:12,  1.16it/s] 73%|███████▎  | 407/560 [05:34<02:03,  1.24it/s] 73%|███████▎  | 408/560 [05:35<01:57,  1.29it/s] 73%|███████▎  | 409/560 [05:36<02:10,  1.15it/s] 73%|███████▎  | 410/560 [05:36<02:01,  1.23it/s]                                                  73%|███████▎  | 410/560 [05:36<02:01,  1.23it/s] 73%|███████▎  | 411/560 [05:37<01:55,  1.29it/s] 74%|███████▎  | 412/560 [05:38<01:51,  1.33it/s] 74%|███████▍  | 413/560 [05:39<02:05,  1.17it/s] 74%|███████▍  | 414/560 [05:40<01:57,  1.25it/s] 74%|███████▍  | 415/560 [05:40<01:51,  1.30it/s] 74%|███████▍  | 416/560 [05:41<01:47,  1.34it/s] 74%|███████▍  | 417/560 [05:42<02:01,  1.18it/s] 75%|███████▍  | 418/560 [05:43<01:54,  1.24it/s] 75%|███████▍  | 419/560 [05:43<01:48,  1.30it/s] 75%|███████▌  | 420/560 [05:44<01:44,  1.34it/s]                                                  75%|███████▌  | 420/560 [05:45<01:44,  1.34it/s] 75%|███████▌  | 421/560 [05:45<01:58,  1.17it/s] 75%|███████▌  | 422/560 [05:46<01:51,  1.24it/s] 76%|███████▌  | 423/560 [05:47<01:45,  1.29it/s] 76%|███████▌  | 424/560 [05:47<01:42,  1.33it/s] 76%|███████▌  | 425/560 [05:48<01:55,  1.17it/s] 76%|███████▌  | 426/560 [05:49<01:48,  1.24it/s] 76%|███████▋  | 427/560 [05:50<01:43,  1.28it/s] 76%|███████▋  | 428/560 [05:51<01:39,  1.32it/s] 77%|███████▋  | 429/560 [05:52<01:51,  1.17it/s] 77%|███████▋  | 430/560 [05:52<01:45,  1.23it/s]                                                  77%|███████▋  | 430/560 [05:52<01:45,  1.23it/s] 77%|███████▋  | 431/560 [05:53<01:40,  1.28it/s] 77%|███████▋  | 432/560 [05:54<01:36,  1.32it/s] 77%|███████▋  | 433/560 [05:55<01:48,  1.17it/s] 78%|███████▊  | 434/560 [05:56<01:41,  1.24it/s] 78%|███████▊  | 435/560 [05:56<01:36,  1.30it/s] 78%|███████▊  | 436/560 [05:57<01:32,  1.34it/s] 78%|███████▊  | 437/560 [05:58<01:44,  1.18it/s] 78%|███████▊  | 438/560 [05:59<01:37,  1.25it/s] 78%|███████▊  | 439/560 [05:59<01:33,  1.30it/s] 79%|███████▊  | 440/560 [06:00<01:30,  1.33it/s]                                                  79%|███████▊  | 440/560 [06:00<01:30,  1.33it/s]{'eval_loss': 0.23820973932743073, 'eval_runtime': 0.8997, 'eval_samples_per_second': 111.145, 'eval_steps_per_second': 14.449, 'epoch': 7.11}
外层迭代结束！
外层迭代结束！
{'loss': 0.1172, 'learning_rate': 8.823529411764705e-05, 'epoch': 7.29}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1154, 'learning_rate': 8.23529411764706e-05, 'epoch': 7.47}
外层迭代结束！
外层迭代结束！
{'loss': 0.1236, 'learning_rate': 7.647058823529411e-05, 'epoch': 7.64}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1432, 'learning_rate': 7.058823529411764e-05, 'epoch': 7.82}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.70it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.75it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.88it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.36it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.04it/s][A                                                 
                                               [A 79%|███████▊  | 440/560 [06:01<01:30,  1.33it/s]
100%|██████████| 13/13 [00:00<00:00, 15.04it/s][A
                                               [A 79%|███████▉  | 441/560 [06:02<02:18,  1.17s/it] 79%|███████▉  | 442/560 [06:03<02:00,  1.03s/it] 79%|███████▉  | 443/560 [06:04<01:48,  1.07it/s] 79%|███████▉  | 444/560 [06:04<01:39,  1.16it/s] 79%|███████▉  | 445/560 [06:05<01:46,  1.08it/s] 80%|███████▉  | 446/560 [06:06<01:37,  1.16it/s] 80%|███████▉  | 447/560 [06:07<01:31,  1.24it/s] 80%|████████  | 448/560 [06:08<01:26,  1.29it/s] 80%|████████  | 449/560 [06:09<01:36,  1.15it/s] 80%|████████  | 450/560 [06:09<01:29,  1.23it/s]                                                  80%|████████  | 450/560 [06:09<01:29,  1.23it/s] 81%|████████  | 451/560 [06:10<01:24,  1.29it/s] 81%|████████  | 452/560 [06:11<01:21,  1.33it/s] 81%|████████  | 453/560 [06:12<01:32,  1.16it/s] 81%|████████  | 454/560 [06:12<01:25,  1.23it/s] 81%|████████▏ | 455/560 [06:13<01:21,  1.29it/s] 81%|████████▏ | 456/560 [06:14<01:18,  1.33it/s] 82%|████████▏ | 457/560 [06:15<01:27,  1.17it/s] 82%|████████▏ | 458/560 [06:16<01:22,  1.24it/s] 82%|████████▏ | 459/560 [06:16<01:17,  1.30it/s] 82%|████████▏ | 460/560 [06:17<01:14,  1.34it/s]                                                  82%|████████▏ | 460/560 [06:17<01:14,  1.34it/s] 82%|████████▏ | 461/560 [06:18<01:24,  1.17it/s] 82%|████████▎ | 462/560 [06:19<01:18,  1.24it/s] 83%|████████▎ | 463/560 [06:20<01:14,  1.30it/s] 83%|████████▎ | 464/560 [06:20<01:12,  1.33it/s] 83%|████████▎ | 465/560 [06:21<01:21,  1.17it/s] 83%|████████▎ | 466/560 [06:22<01:15,  1.24it/s] 83%|████████▎ | 467/560 [06:23<01:12,  1.29it/s] 84%|████████▎ | 468/560 [06:23<01:09,  1.33it/s] 84%|████████▍ | 469/560 [06:24<01:17,  1.17it/s] 84%|████████▍ | 470/560 [06:25<01:12,  1.24it/s]                                                  84%|████████▍ | 470/560 [06:25<01:12,  1.24it/s] 84%|████████▍ | 471/560 [06:26<01:08,  1.29it/s] 84%|████████▍ | 472/560 [06:27<01:05,  1.34it/s] 84%|████████▍ | 473/560 [06:28<01:14,  1.17it/s] 85%|████████▍ | 474/560 [06:28<01:09,  1.24it/s] 85%|████████▍ | 475/560 [06:29<01:05,  1.29it/s] 85%|████████▌ | 476/560 [06:30<01:03,  1.33it/s] 85%|████████▌ | 477/560 [06:31<01:11,  1.17it/s] 85%|████████▌ | 478/560 [06:32<01:06,  1.24it/s] 86%|████████▌ | 479/560 [06:32<01:02,  1.29it/s] 86%|████████▌ | 480/560 [06:33<01:00,  1.33it/s]                                                  86%|████████▌ | 480/560 [06:33<01:00,  1.33it/s]{'eval_loss': 0.25307998061180115, 'eval_runtime': 0.9036, 'eval_samples_per_second': 110.664, 'eval_steps_per_second': 14.386, 'epoch': 7.82}
外层迭代结束！
外层迭代结束！
{'loss': 0.1397, 'learning_rate': 6.470588235294117e-05, 'epoch': 8.0}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1222, 'learning_rate': 5.88235294117647e-05, 'epoch': 8.18}
外层迭代结束！
外层迭代结束！
{'loss': 0.1313, 'learning_rate': 5.294117647058824e-05, 'epoch': 8.36}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1004, 'learning_rate': 4.705882352941176e-05, 'epoch': 8.53}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.03it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.48it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.67it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.19it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.92it/s][A                                                 
                                               [A 86%|████████▌ | 480/560 [06:34<01:00,  1.33it/s]
100%|██████████| 13/13 [00:00<00:00, 14.92it/s][A
                                               [A 86%|████████▌ | 481/560 [06:35<01:32,  1.17s/it] 86%|████████▌ | 482/560 [06:36<01:20,  1.03s/it] 86%|████████▋ | 483/560 [06:37<01:11,  1.08it/s] 86%|████████▋ | 484/560 [06:37<01:05,  1.16it/s] 87%|████████▋ | 485/560 [06:38<01:09,  1.07it/s] 87%|████████▋ | 486/560 [06:39<01:03,  1.16it/s] 87%|████████▋ | 487/560 [06:40<00:59,  1.23it/s] 87%|████████▋ | 488/560 [06:40<00:55,  1.29it/s] 87%|████████▋ | 489/560 [06:41<01:01,  1.15it/s] 88%|████████▊ | 490/560 [06:42<00:57,  1.22it/s]                                                  88%|████████▊ | 490/560 [06:42<00:57,  1.22it/s] 88%|████████▊ | 491/560 [06:43<00:53,  1.28it/s] 88%|████████▊ | 492/560 [06:44<00:51,  1.32it/s] 88%|████████▊ | 493/560 [06:45<00:57,  1.17it/s] 88%|████████▊ | 494/560 [06:45<00:53,  1.24it/s] 88%|████████▊ | 495/560 [06:46<00:50,  1.29it/s] 89%|████████▊ | 496/560 [06:47<00:48,  1.33it/s] 89%|████████▉ | 497/560 [06:48<00:53,  1.17it/s] 89%|████████▉ | 498/560 [06:49<00:50,  1.24it/s] 89%|████████▉ | 499/560 [06:49<00:47,  1.29it/s] 89%|████████▉ | 500/560 [06:50<00:45,  1.33it/s]                                                  89%|████████▉ | 500/560 [06:50<00:45,  1.33it/s] 89%|████████▉ | 501/560 [06:51<00:50,  1.16it/s] 90%|████████▉ | 502/560 [06:52<00:46,  1.24it/s] 90%|████████▉ | 503/560 [06:52<00:44,  1.29it/s] 90%|█████████ | 504/560 [06:53<00:42,  1.33it/s] 90%|█████████ | 505/560 [06:54<00:47,  1.17it/s] 90%|█████████ | 506/560 [06:55<00:43,  1.24it/s] 91%|█████████ | 507/560 [06:56<00:40,  1.30it/s] 91%|█████████ | 508/560 [06:56<00:38,  1.34it/s] 91%|█████████ | 509/560 [06:57<00:43,  1.18it/s] 91%|█████████ | 510/560 [06:58<00:40,  1.25it/s]                                                  91%|█████████ | 510/560 [06:58<00:40,  1.25it/s] 91%|█████████▏| 511/560 [06:59<00:37,  1.30it/s] 91%|█████████▏| 512/560 [06:59<00:35,  1.34it/s] 92%|█████████▏| 513/560 [07:01<00:39,  1.18it/s] 92%|█████████▏| 514/560 [07:01<00:36,  1.25it/s] 92%|█████████▏| 515/560 [07:02<00:34,  1.30it/s] 92%|█████████▏| 516/560 [07:03<00:32,  1.34it/s] 92%|█████████▏| 517/560 [07:04<00:36,  1.17it/s] 92%|█████████▎| 518/560 [07:04<00:34,  1.23it/s] 93%|█████████▎| 519/560 [07:05<00:31,  1.29it/s] 93%|█████████▎| 520/560 [07:06<00:30,  1.33it/s]                                                  93%|█████████▎| 520/560 [07:06<00:30,  1.33it/s]{'eval_loss': 0.26531606912612915, 'eval_runtime': 0.9138, 'eval_samples_per_second': 109.436, 'eval_steps_per_second': 14.227, 'epoch': 8.53}
外层迭代结束！
外层迭代结束！
{'loss': 0.1339, 'learning_rate': 4.11764705882353e-05, 'epoch': 8.71}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1222, 'learning_rate': 3.529411764705882e-05, 'epoch': 8.89}
外层迭代结束！
外层迭代结束！
{'loss': 0.0942, 'learning_rate': 2.941176470588235e-05, 'epoch': 9.07}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1211, 'learning_rate': 2.352941176470588e-05, 'epoch': 9.24}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.12it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.56it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.68it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.20it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.93it/s][A                                                 
                                               [A 93%|█████████▎| 520/560 [07:07<00:30,  1.33it/s]
100%|██████████| 13/13 [00:00<00:00, 14.93it/s][A
                                               [A 93%|█████████▎| 521/560 [07:08<00:45,  1.17s/it] 93%|█████████▎| 522/560 [07:09<00:38,  1.03s/it] 93%|█████████▎| 523/560 [07:09<00:34,  1.08it/s] 94%|█████████▎| 524/560 [07:10<00:30,  1.17it/s] 94%|█████████▍| 525/560 [07:11<00:32,  1.08it/s] 94%|█████████▍| 526/560 [07:12<00:29,  1.17it/s] 94%|█████████▍| 527/560 [07:13<00:26,  1.24it/s] 94%|█████████▍| 528/560 [07:13<00:24,  1.29it/s] 94%|█████████▍| 529/560 [07:14<00:26,  1.15it/s] 95%|█████████▍| 530/560 [07:15<00:24,  1.22it/s]                                                  95%|█████████▍| 530/560 [07:15<00:24,  1.22it/s] 95%|█████████▍| 531/560 [07:16<00:22,  1.28it/s] 95%|█████████▌| 532/560 [07:16<00:21,  1.32it/s] 95%|█████████▌| 533/560 [07:17<00:23,  1.17it/s] 95%|█████████▌| 534/560 [07:18<00:21,  1.24it/s] 96%|█████████▌| 535/560 [07:19<00:19,  1.30it/s] 96%|█████████▌| 536/560 [07:20<00:17,  1.34it/s] 96%|█████████▌| 537/560 [07:21<00:19,  1.17it/s] 96%|█████████▌| 538/560 [07:21<00:17,  1.24it/s] 96%|█████████▋| 539/560 [07:22<00:16,  1.29it/s] 96%|█████████▋| 540/560 [07:23<00:15,  1.33it/s]                                                  96%|█████████▋| 540/560 [07:23<00:15,  1.33it/s] 97%|█████████▋| 541/560 [07:24<00:16,  1.16it/s] 97%|█████████▋| 542/560 [07:25<00:14,  1.24it/s] 97%|█████████▋| 543/560 [07:25<00:13,  1.29it/s] 97%|█████████▋| 544/560 [07:26<00:12,  1.33it/s] 97%|█████████▋| 545/560 [07:27<00:12,  1.17it/s] 98%|█████████▊| 546/560 [07:28<00:11,  1.24it/s] 98%|█████████▊| 547/560 [07:28<00:10,  1.30it/s] 98%|█████████▊| 548/560 [07:29<00:09,  1.33it/s] 98%|█████████▊| 549/560 [07:30<00:09,  1.17it/s] 98%|█████████▊| 550/560 [07:31<00:08,  1.24it/s]                                                  98%|█████████▊| 550/560 [07:31<00:08,  1.24it/s] 98%|█████████▊| 551/560 [07:32<00:06,  1.29it/s] 99%|█████████▊| 552/560 [07:32<00:06,  1.33it/s] 99%|█████████▉| 553/560 [07:33<00:06,  1.16it/s] 99%|█████████▉| 554/560 [07:34<00:04,  1.24it/s] 99%|█████████▉| 555/560 [07:35<00:03,  1.29it/s] 99%|█████████▉| 556/560 [07:36<00:03,  1.33it/s] 99%|█████████▉| 557/560 [07:37<00:02,  1.17it/s]100%|█████████▉| 558/560 [07:37<00:01,  1.24it/s]100%|█████████▉| 559/560 [07:38<00:00,  1.29it/s]100%|██████████| 560/560 [07:39<00:00,  1.33it/s]                                                 100%|██████████| 560/560 [07:39<00:00,  1.33it/s]{'eval_loss': 0.26334404945373535, 'eval_runtime': 0.9122, 'eval_samples_per_second': 109.619, 'eval_steps_per_second': 14.25, 'epoch': 9.24}
外层迭代结束！
外层迭代结束！
{'loss': 0.1271, 'learning_rate': 1.764705882352941e-05, 'epoch': 9.42}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1219, 'learning_rate': 1.176470588235294e-05, 'epoch': 9.6}
外层迭代结束！
外层迭代结束！
{'loss': 0.1059, 'learning_rate': 5.88235294117647e-06, 'epoch': 9.78}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1286, 'learning_rate': 0.0, 'epoch': 9.96}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.59it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.75it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.74it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.24it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.85it/s][A                                                 
                                               [A100%|██████████| 560/560 [07:40<00:00,  1.33it/s]
100%|██████████| 13/13 [00:00<00:00, 14.85it/s][A
                                               [AThere were missing keys in the checkpoint model loaded: ['base_model.model.shared.weight', 'base_model.model.encoder.embed_tokens.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.encoder.block.0.layer.0.layer_norm.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.0.layer.1.layer_norm.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.1.layer.0.layer_norm.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.1.layer.1.layer_norm.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.2.layer.0.layer_norm.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.2.layer.1.layer_norm.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.3.layer.0.layer_norm.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.3.layer.1.layer_norm.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.4.layer.0.layer_norm.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.4.layer.1.layer_norm.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.5.layer.0.layer_norm.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.5.layer.1.layer_norm.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.6.layer.0.layer_norm.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.6.layer.1.layer_norm.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.7.layer.0.layer_norm.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.7.layer.1.layer_norm.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.8.layer.0.layer_norm.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.8.layer.1.layer_norm.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.9.layer.0.layer_norm.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.9.layer.1.layer_norm.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.10.layer.0.layer_norm.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.10.layer.1.layer_norm.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.11.layer.0.layer_norm.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.11.layer.1.layer_norm.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.12.layer.0.layer_norm.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.12.layer.1.layer_norm.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.13.layer.0.layer_norm.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.13.layer.1.layer_norm.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.14.layer.0.layer_norm.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.14.layer.1.layer_norm.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.15.layer.0.layer_norm.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.15.layer.1.layer_norm.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.16.layer.0.layer_norm.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.16.layer.1.layer_norm.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.17.layer.0.layer_norm.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.17.layer.1.layer_norm.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.18.layer.0.layer_norm.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.18.layer.1.layer_norm.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.19.layer.0.layer_norm.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.19.layer.1.layer_norm.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.20.layer.0.layer_norm.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.20.layer.1.layer_norm.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.21.layer.0.layer_norm.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.21.layer.1.layer_norm.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.22.layer.0.layer_norm.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.22.layer.1.layer_norm.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.23.layer.0.layer_norm.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.23.layer.1.layer_norm.weight', 'base_model.model.encoder.final_layer_norm.weight', 'base_model.model.decoder.embed_tokens.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.decoder.block.0.layer.0.layer_norm.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.0.layer.1.layer_norm.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.0.layer.2.layer_norm.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.1.layer.0.layer_norm.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.1.layer.1.layer_norm.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.1.layer.2.layer_norm.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.2.layer.0.layer_norm.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.2.layer.1.layer_norm.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.2.layer.2.layer_norm.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.3.layer.0.layer_norm.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.3.layer.1.layer_norm.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.3.layer.2.layer_norm.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.4.layer.0.layer_norm.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.4.layer.1.layer_norm.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.4.layer.2.layer_norm.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.5.layer.0.layer_norm.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.5.layer.1.layer_norm.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.5.layer.2.layer_norm.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.6.layer.0.layer_norm.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.6.layer.1.layer_norm.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.6.layer.2.layer_norm.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.7.layer.0.layer_norm.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.7.layer.1.layer_norm.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.7.layer.2.layer_norm.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.8.layer.0.layer_norm.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.8.layer.1.layer_norm.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.8.layer.2.layer_norm.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.9.layer.0.layer_norm.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.9.layer.1.layer_norm.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.9.layer.2.layer_norm.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.10.layer.0.layer_norm.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.10.layer.1.layer_norm.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.10.layer.2.layer_norm.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.11.layer.0.layer_norm.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.11.layer.1.layer_norm.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.11.layer.2.layer_norm.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.12.layer.0.layer_norm.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.12.layer.1.layer_norm.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.12.layer.2.layer_norm.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.13.layer.0.layer_norm.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.13.layer.1.layer_norm.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.13.layer.2.layer_norm.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.14.layer.0.layer_norm.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.14.layer.1.layer_norm.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.14.layer.2.layer_norm.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.15.layer.0.layer_norm.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.15.layer.1.layer_norm.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.15.layer.2.layer_norm.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.16.layer.0.layer_norm.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.16.layer.1.layer_norm.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.16.layer.2.layer_norm.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.17.layer.0.layer_norm.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.17.layer.1.layer_norm.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.17.layer.2.layer_norm.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.18.layer.0.layer_norm.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.18.layer.1.layer_norm.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.18.layer.2.layer_norm.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.19.layer.0.layer_norm.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.19.layer.1.layer_norm.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.19.layer.2.layer_norm.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.20.layer.0.layer_norm.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.20.layer.1.layer_norm.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.20.layer.2.layer_norm.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.21.layer.0.layer_norm.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.21.layer.1.layer_norm.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.21.layer.2.layer_norm.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.22.layer.0.layer_norm.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.22.layer.1.layer_norm.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.22.layer.2.layer_norm.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.23.layer.0.layer_norm.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.23.layer.1.layer_norm.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.23.layer.2.layer_norm.weight', 'base_model.model.decoder.final_layer_norm.weight', 'base_model.model.lm_head.weight'].
There were unexpected keys in the checkpoint model loaded: ['base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.weight'].
                                                 100%|██████████| 560/560 [07:40<00:00,  1.33it/s]100%|██████████| 560/560 [07:40<00:00,  1.22it/s]
{'eval_loss': 0.2639654874801636, 'eval_runtime': 0.9111, 'eval_samples_per_second': 109.754, 'eval_steps_per_second': 14.268, 'epoch': 9.96}
{'train_runtime': 460.7894, 'train_samples_per_second': 19.532, 'train_steps_per_second': 1.215, 'train_loss': 0.3724688640662602, 'epoch': 9.96}

 If there's a warning about missing keys above, please disregard :)
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 16
micro_batch_size: 4
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: copa... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/3-copa
current data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 288.03it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 723.28it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 850.94it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 810.81it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
总样本数：1000, 选择的样本数量：20
lora_weights: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/2-wic

pre-trained model's BOS EOS and PAD token id: None 1 0  => It should be 1,2,none
continual fine tune lora!
trainable params: 2359296 || all params: 740027392 || trainable%: 0.31881198257050464
训练数据总量：360
验证数据总量：40
Map:   0%|          | 0/360 [00:00<?, ? examples/s]/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3597: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  "`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your "
                                                   Map:   0%|          | 0/40 [00:00<?, ? examples/s]                                                  Map:   0%|          | 0/45 [00:00<?, ? examples/s]                                                  memory data loader 2
  0%|          | 0/220 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/220 [00:01<04:49,  1.32s/it]  1%|          | 2/220 [00:02<03:30,  1.03it/s]  1%|▏         | 3/220 [00:02<03:02,  1.19it/s]  2%|▏         | 4/220 [00:03<02:53,  1.25it/s]  2%|▏         | 5/220 [00:04<03:20,  1.07it/s]  3%|▎         | 6/220 [00:05<03:04,  1.16it/s]  3%|▎         | 7/220 [00:06<02:53,  1.23it/s]  4%|▎         | 8/220 [00:06<02:44,  1.29it/s]  4%|▍         | 9/220 [00:07<03:11,  1.10it/s]  5%|▍         | 10/220 [00:08<02:58,  1.18it/s]                                                  5%|▍         | 10/220 [00:08<02:58,  1.18it/s]  5%|▌         | 11/220 [00:09<02:50,  1.23it/s]  5%|▌         | 12/220 [00:10<02:44,  1.27it/s]  6%|▌         | 13/220 [00:11<03:08,  1.10it/s]  6%|▋         | 14/220 [00:12<02:56,  1.17it/s]  7%|▋         | 15/220 [00:12<02:45,  1.24it/s]  7%|▋         | 16/220 [00:13<02:40,  1.27it/s]  8%|▊         | 17/220 [00:14<03:03,  1.11it/s]  8%|▊         | 18/220 [00:15<02:52,  1.17it/s]  9%|▊         | 19/220 [00:16<02:45,  1.22it/s]  9%|▉         | 20/220 [00:16<02:37,  1.27it/s]                                                  9%|▉         | 20/220 [00:17<02:37,  1.27it/s] 10%|▉         | 21/220 [00:18<03:00,  1.10it/s] 10%|█         | 22/220 [00:18<02:48,  1.18it/s] 10%|█         | 23/220 [00:19<02:40,  1.22it/s] 11%|█         | 24/220 [00:20<02:34,  1.26it/s] 11%|█▏        | 25/220 [00:21<02:56,  1.10it/s] 12%|█▏        | 26/220 [00:22<02:45,  1.17it/s] 12%|█▏        | 27/220 [00:22<02:36,  1.24it/s] 13%|█▎        | 28/220 [00:23<02:31,  1.27it/s] 13%|█▎        | 29/220 [00:24<02:52,  1.11it/s] 14%|█▎        | 30/220 [00:25<02:41,  1.17it/s]                                                 14%|█▎        | 30/220 [00:25<02:41,  1.17it/s] 14%|█▍        | 31/220 [00:26<02:34,  1.23it/s] 15%|█▍        | 32/220 [00:26<02:27,  1.28it/s] 15%|█▌        | 33/220 [00:28<02:49,  1.10it/s] 15%|█▌        | 34/220 [00:28<02:38,  1.18it/s] 16%|█▌        | 35/220 [00:29<02:31,  1.22it/s] 16%|█▋        | 36/220 [00:30<02:25,  1.26it/s] 17%|█▋        | 37/220 [00:31<02:46,  1.10it/s] 17%|█▋        | 38/220 [00:32<02:35,  1.17it/s] 18%|█▊        | 39/220 [00:32<02:26,  1.23it/s] 18%|█▊        | 40/220 [00:33<02:21,  1.27it/s]                                                 18%|█▊        | 40/220 [00:34<02:21,  1.27it/s]外层迭代结束！
外层迭代结束！
{'loss': 5.5227, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.44}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 2.4712, 'learning_rate': 0.00011999999999999999, 'epoch': 0.89}
外层迭代结束！
外层迭代结束！
{'loss': 0.5049, 'learning_rate': 0.00017999999999999998, 'epoch': 1.33}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.4321, 'learning_rate': 0.00023999999999999998, 'epoch': 1.78}

  0%|          | 0/5 [00:00<?, ?it/s][A
 60%|██████    | 3/5 [00:00<00:00, 21.63it/s][A                                                
                                             [A 18%|█▊        | 40/220 [00:34<02:21,  1.27it/s]
100%|██████████| 5/5 [00:00<00:00, 21.63it/s][A
                                             [A 19%|█▊        | 41/220 [00:35<03:07,  1.05s/it] 19%|█▉        | 42/220 [00:36<02:49,  1.05it/s] 20%|█▉        | 43/220 [00:36<02:36,  1.13it/s] 20%|██        | 44/220 [00:37<02:28,  1.19it/s] 20%|██        | 45/220 [00:38<02:45,  1.05it/s] 21%|██        | 46/220 [00:39<02:33,  1.13it/s] 21%|██▏       | 47/220 [00:40<02:25,  1.19it/s] 22%|██▏       | 48/220 [00:40<02:18,  1.25it/s] 22%|██▏       | 49/220 [00:42<02:36,  1.09it/s] 23%|██▎       | 50/220 [00:42<02:26,  1.16it/s]                                                 23%|██▎       | 50/220 [00:42<02:26,  1.16it/s] 23%|██▎       | 51/220 [00:43<02:19,  1.21it/s] 24%|██▎       | 52/220 [00:44<02:14,  1.25it/s] 24%|██▍       | 53/220 [00:45<02:33,  1.09it/s] 25%|██▍       | 54/220 [00:46<02:22,  1.17it/s] 25%|██▌       | 55/220 [00:46<02:14,  1.23it/s] 25%|██▌       | 56/220 [00:47<02:09,  1.26it/s] 26%|██▌       | 57/220 [00:48<02:27,  1.11it/s] 26%|██▋       | 58/220 [00:49<02:17,  1.18it/s] 27%|██▋       | 59/220 [00:50<02:10,  1.23it/s] 27%|██▋       | 60/220 [00:51<02:05,  1.28it/s]                                                 27%|██▋       | 60/220 [00:51<02:05,  1.28it/s] 28%|██▊       | 61/220 [00:52<02:18,  1.15it/s] 28%|██▊       | 62/220 [00:52<02:11,  1.20it/s] 29%|██▊       | 63/220 [00:53<02:05,  1.25it/s] 29%|██▉       | 64/220 [00:54<02:02,  1.27it/s] 30%|██▉       | 65/220 [00:55<02:20,  1.10it/s] 30%|███       | 66/220 [00:56<02:11,  1.17it/s] 30%|███       | 67/220 [00:56<02:04,  1.23it/s] 31%|███       | 68/220 [00:57<02:01,  1.25it/s] 31%|███▏      | 69/220 [00:58<02:18,  1.09it/s] 32%|███▏      | 70/220 [00:59<02:08,  1.16it/s]                                                 32%|███▏      | 70/220 [00:59<02:08,  1.16it/s] 32%|███▏      | 71/220 [01:00<02:02,  1.22it/s] 33%|███▎      | 72/220 [01:01<01:57,  1.26it/s] 33%|███▎      | 73/220 [01:02<02:12,  1.11it/s] 34%|███▎      | 74/220 [01:02<02:04,  1.18it/s] 34%|███▍      | 75/220 [01:03<01:58,  1.22it/s] 35%|███▍      | 76/220 [01:04<01:54,  1.26it/s] 35%|███▌      | 77/220 [01:05<02:10,  1.10it/s] 35%|███▌      | 78/220 [01:06<02:02,  1.16it/s] 36%|███▌      | 79/220 [01:07<01:54,  1.23it/s] 36%|███▋      | 80/220 [01:07<01:50,  1.27it/s]                                                 36%|███▋      | 80/220 [01:08<01:50,  1.27it/s]{'eval_loss': 0.3701648712158203, 'eval_runtime': 0.3546, 'eval_samples_per_second': 112.801, 'eval_steps_per_second': 14.1, 'epoch': 1.78}
外层迭代结束！
外层迭代结束！
{'loss': 0.3996, 'learning_rate': 0.0003, 'epoch': 2.22}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3996, 'learning_rate': 0.00028235294117647056, 'epoch': 2.67}
外层迭代结束！
外层迭代结束！
{'loss': 0.3871, 'learning_rate': 0.00026470588235294115, 'epoch': 3.11}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3894, 'learning_rate': 0.00024705882352941174, 'epoch': 3.56}

  0%|          | 0/5 [00:00<?, ?it/s][A
 60%|██████    | 3/5 [00:00<00:00, 20.99it/s][A                                                
                                             [A 36%|███▋      | 80/220 [01:08<01:50,  1.27it/s]
100%|██████████| 5/5 [00:00<00:00, 20.99it/s][A
                                             [A 37%|███▋      | 81/220 [01:09<02:25,  1.05s/it] 37%|███▋      | 82/220 [01:10<02:11,  1.05it/s] 38%|███▊      | 83/220 [01:10<02:01,  1.13it/s] 38%|███▊      | 84/220 [01:11<01:53,  1.19it/s] 39%|███▊      | 85/220 [01:12<02:06,  1.07it/s] 39%|███▉      | 86/220 [01:13<01:57,  1.14it/s] 40%|███▉      | 87/220 [01:14<01:50,  1.21it/s] 40%|████      | 88/220 [01:15<01:44,  1.26it/s] 40%|████      | 89/220 [01:16<01:59,  1.10it/s] 41%|████      | 90/220 [01:16<01:51,  1.17it/s]                                                 41%|████      | 90/220 [01:16<01:51,  1.17it/s] 41%|████▏     | 91/220 [01:17<01:45,  1.22it/s] 42%|████▏     | 92/220 [01:18<01:40,  1.27it/s] 42%|████▏     | 93/220 [01:19<01:55,  1.10it/s] 43%|████▎     | 94/220 [01:20<01:47,  1.17it/s] 43%|████▎     | 95/220 [01:20<01:42,  1.23it/s] 44%|████▎     | 96/220 [01:21<01:37,  1.27it/s] 44%|████▍     | 97/220 [01:22<01:51,  1.10it/s] 45%|████▍     | 98/220 [01:23<01:44,  1.17it/s] 45%|████▌     | 99/220 [01:24<01:38,  1.23it/s] 45%|████▌     | 100/220 [01:25<01:34,  1.27it/s]                                                  45%|████▌     | 100/220 [01:25<01:34,  1.27it/s] 46%|████▌     | 101/220 [01:26<01:47,  1.11it/s] 46%|████▋     | 102/220 [01:26<01:40,  1.18it/s] 47%|████▋     | 103/220 [01:27<01:34,  1.23it/s] 47%|████▋     | 104/220 [01:28<01:31,  1.27it/s] 48%|████▊     | 105/220 [01:29<01:43,  1.11it/s] 48%|████▊     | 106/220 [01:30<01:37,  1.17it/s] 49%|████▊     | 107/220 [01:31<01:32,  1.22it/s] 49%|████▉     | 108/220 [01:31<01:28,  1.26it/s] 50%|████▉     | 109/220 [01:32<01:41,  1.10it/s] 50%|█████     | 110/220 [01:33<01:34,  1.17it/s]                                                  50%|█████     | 110/220 [01:33<01:34,  1.17it/s] 50%|█████     | 111/220 [01:34<01:29,  1.22it/s] 51%|█████     | 112/220 [01:35<01:25,  1.26it/s] 51%|█████▏    | 113/220 [01:36<01:36,  1.11it/s] 52%|█████▏    | 114/220 [01:37<01:31,  1.16it/s] 52%|█████▏    | 115/220 [01:37<01:27,  1.20it/s] 53%|█████▎    | 116/220 [01:38<01:24,  1.23it/s] 53%|█████▎    | 117/220 [01:39<01:34,  1.08it/s] 54%|█████▎    | 118/220 [01:40<01:28,  1.16it/s] 54%|█████▍    | 119/220 [01:41<01:23,  1.21it/s] 55%|█████▍    | 120/220 [01:42<01:21,  1.23it/s]                                                  55%|█████▍    | 120/220 [01:42<01:21,  1.23it/s]{'eval_loss': 0.36202386021614075, 'eval_runtime': 0.3616, 'eval_samples_per_second': 110.615, 'eval_steps_per_second': 13.827, 'epoch': 3.56}
外层迭代结束！
外层迭代结束！
{'loss': 0.4124, 'learning_rate': 0.0002294117647058823, 'epoch': 4.0}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.378, 'learning_rate': 0.00021176470588235295, 'epoch': 4.44}
外层迭代结束！
外层迭代结束！
{'loss': 0.3799, 'learning_rate': 0.0001941176470588235, 'epoch': 4.89}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3538, 'learning_rate': 0.0001764705882352941, 'epoch': 5.33}

  0%|          | 0/5 [00:00<?, ?it/s][A
 60%|██████    | 3/5 [00:00<00:00, 21.07it/s][A                                                 
                                             [A 55%|█████▍    | 120/220 [01:42<01:21,  1.23it/s]
100%|██████████| 5/5 [00:00<00:00, 21.07it/s][A
                                             [A 55%|█████▌    | 121/220 [01:43<01:46,  1.07s/it] 55%|█████▌    | 122/220 [01:44<01:35,  1.03it/s] 56%|█████▌    | 123/220 [01:45<01:27,  1.11it/s] 56%|█████▋    | 124/220 [01:45<01:21,  1.17it/s] 57%|█████▋    | 125/220 [01:47<01:30,  1.05it/s] 57%|█████▋    | 126/220 [01:47<01:23,  1.12it/s] 58%|█████▊    | 127/220 [01:48<01:18,  1.18it/s] 58%|█████▊    | 128/220 [01:49<01:14,  1.24it/s] 59%|█████▊    | 129/220 [01:50<01:24,  1.08it/s] 59%|█████▉    | 130/220 [01:51<01:18,  1.15it/s]                                                  59%|█████▉    | 130/220 [01:51<01:18,  1.15it/s] 60%|█████▉    | 131/220 [01:52<01:13,  1.21it/s] 60%|██████    | 132/220 [01:52<01:10,  1.25it/s] 60%|██████    | 133/220 [01:53<01:20,  1.08it/s] 61%|██████    | 134/220 [01:54<01:14,  1.15it/s] 61%|██████▏   | 135/220 [01:55<01:10,  1.21it/s] 62%|██████▏   | 136/220 [01:56<01:07,  1.25it/s] 62%|██████▏   | 137/220 [01:57<01:15,  1.09it/s] 63%|██████▎   | 138/220 [01:58<01:10,  1.16it/s] 63%|██████▎   | 139/220 [01:58<01:07,  1.21it/s] 64%|██████▎   | 140/220 [01:59<01:03,  1.26it/s]                                                  64%|██████▎   | 140/220 [02:00<01:03,  1.26it/s] 64%|██████▍   | 141/220 [02:00<01:12,  1.09it/s] 65%|██████▍   | 142/220 [02:01<01:06,  1.17it/s] 65%|██████▌   | 143/220 [02:02<01:03,  1.21it/s] 65%|██████▌   | 144/220 [02:02<01:00,  1.26it/s] 66%|██████▌   | 145/220 [02:04<01:08,  1.09it/s] 66%|██████▋   | 146/220 [02:04<01:04,  1.15it/s] 67%|██████▋   | 147/220 [02:05<01:00,  1.21it/s] 67%|██████▋   | 148/220 [02:06<00:57,  1.25it/s] 68%|██████▊   | 149/220 [02:07<01:04,  1.09it/s] 68%|██████▊   | 150/220 [02:08<01:00,  1.16it/s]                                                  68%|██████▊   | 150/220 [02:08<01:00,  1.16it/s] 69%|██████▊   | 151/220 [02:09<00:56,  1.21it/s] 69%|██████▉   | 152/220 [02:09<00:53,  1.26it/s] 70%|██████▉   | 153/220 [02:10<01:00,  1.10it/s] 70%|███████   | 154/220 [02:11<00:56,  1.18it/s] 70%|███████   | 155/220 [02:12<00:52,  1.23it/s] 71%|███████   | 156/220 [02:13<00:50,  1.26it/s] 71%|███████▏  | 157/220 [02:14<00:57,  1.10it/s] 72%|███████▏  | 158/220 [02:15<00:53,  1.16it/s] 72%|███████▏  | 159/220 [02:15<00:50,  1.22it/s] 73%|███████▎  | 160/220 [02:16<00:47,  1.25it/s]                                                  73%|███████▎  | 160/220 [02:16<00:47,  1.25it/s]{'eval_loss': 0.3562367260456085, 'eval_runtime': 0.3604, 'eval_samples_per_second': 110.992, 'eval_steps_per_second': 13.874, 'epoch': 5.33}
外层迭代结束！
外层迭代结束！
{'loss': 0.3705, 'learning_rate': 0.0001588235294117647, 'epoch': 5.78}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3707, 'learning_rate': 0.00014117647058823528, 'epoch': 6.22}
外层迭代结束！
外层迭代结束！
{'loss': 0.3938, 'learning_rate': 0.00012352941176470587, 'epoch': 6.67}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3588, 'learning_rate': 0.00010588235294117647, 'epoch': 7.11}

  0%|          | 0/5 [00:00<?, ?it/s][A
 60%|██████    | 3/5 [00:00<00:00, 21.59it/s][A                                                 
                                             [A 73%|███████▎  | 160/220 [02:17<00:47,  1.25it/s]
100%|██████████| 5/5 [00:00<00:00, 21.59it/s][A
                                             [A 73%|███████▎  | 161/220 [02:18<01:02,  1.06s/it] 74%|███████▎  | 162/220 [02:18<00:55,  1.04it/s] 74%|███████▍  | 163/220 [02:19<00:50,  1.12it/s] 75%|███████▍  | 164/220 [02:20<00:47,  1.18it/s] 75%|███████▌  | 165/220 [02:21<00:52,  1.06it/s] 75%|███████▌  | 166/220 [02:22<00:47,  1.13it/s] 76%|███████▌  | 167/220 [02:23<00:44,  1.19it/s] 76%|███████▋  | 168/220 [02:23<00:41,  1.24it/s] 77%|███████▋  | 169/220 [02:24<00:46,  1.09it/s] 77%|███████▋  | 170/220 [02:25<00:42,  1.17it/s]                                                  77%|███████▋  | 170/220 [02:25<00:42,  1.17it/s] 78%|███████▊  | 171/220 [02:26<00:40,  1.22it/s] 78%|███████▊  | 172/220 [02:27<00:38,  1.26it/s] 79%|███████▊  | 173/220 [02:28<00:42,  1.10it/s] 79%|███████▉  | 174/220 [02:29<00:39,  1.16it/s] 80%|███████▉  | 175/220 [02:29<00:36,  1.23it/s] 80%|████████  | 176/220 [02:30<00:34,  1.27it/s] 80%|████████  | 177/220 [02:31<00:38,  1.11it/s] 81%|████████  | 178/220 [02:32<00:36,  1.16it/s] 81%|████████▏ | 179/220 [02:33<00:33,  1.22it/s] 82%|████████▏ | 180/220 [02:33<00:31,  1.27it/s]                                                  82%|████████▏ | 180/220 [02:34<00:31,  1.27it/s] 82%|████████▏ | 181/220 [02:35<00:35,  1.10it/s] 83%|████████▎ | 182/220 [02:35<00:32,  1.17it/s] 83%|████████▎ | 183/220 [02:36<00:30,  1.22it/s] 84%|████████▎ | 184/220 [02:37<00:28,  1.25it/s] 84%|████████▍ | 185/220 [02:38<00:31,  1.10it/s] 85%|████████▍ | 186/220 [02:39<00:29,  1.16it/s] 85%|████████▌ | 187/220 [02:39<00:27,  1.22it/s] 85%|████████▌ | 188/220 [02:40<00:25,  1.25it/s] 86%|████████▌ | 189/220 [02:41<00:28,  1.10it/s] 86%|████████▋ | 190/220 [02:42<00:25,  1.17it/s]                                                  86%|████████▋ | 190/220 [02:42<00:25,  1.17it/s] 87%|████████▋ | 191/220 [02:43<00:23,  1.22it/s] 87%|████████▋ | 192/220 [02:44<00:22,  1.27it/s] 88%|████████▊ | 193/220 [02:45<00:24,  1.11it/s] 88%|████████▊ | 194/220 [02:45<00:21,  1.18it/s] 89%|████████▊ | 195/220 [02:46<00:20,  1.23it/s] 89%|████████▉ | 196/220 [02:47<00:18,  1.27it/s] 90%|████████▉ | 197/220 [02:48<00:20,  1.10it/s] 90%|█████████ | 198/220 [02:49<00:18,  1.17it/s] 90%|█████████ | 199/220 [02:50<00:17,  1.23it/s] 91%|█████████ | 200/220 [02:50<00:15,  1.27it/s]                                                  91%|█████████ | 200/220 [02:51<00:15,  1.27it/s]{'eval_loss': 0.3499303162097931, 'eval_runtime': 0.3534, 'eval_samples_per_second': 113.174, 'eval_steps_per_second': 14.147, 'epoch': 7.11}
外层迭代结束！
外层迭代结束！
{'loss': 0.3597, 'learning_rate': 8.823529411764705e-05, 'epoch': 7.56}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3782, 'learning_rate': 7.058823529411764e-05, 'epoch': 8.0}
外层迭代结束！
外层迭代结束！
{'loss': 0.3517, 'learning_rate': 5.294117647058824e-05, 'epoch': 8.44}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3673, 'learning_rate': 3.529411764705882e-05, 'epoch': 8.89}

  0%|          | 0/5 [00:00<?, ?it/s][A
 60%|██████    | 3/5 [00:00<00:00, 21.79it/s][A                                                 
                                             [A 91%|█████████ | 200/220 [02:51<00:15,  1.27it/s]
100%|██████████| 5/5 [00:00<00:00, 21.79it/s][A
                                             [A 91%|█████████▏| 201/220 [02:52<00:19,  1.05s/it] 92%|█████████▏| 202/220 [02:53<00:17,  1.04it/s] 92%|█████████▏| 203/220 [02:53<00:15,  1.13it/s] 93%|█████████▎| 204/220 [02:54<00:13,  1.19it/s] 93%|█████████▎| 205/220 [02:55<00:14,  1.06it/s] 94%|█████████▎| 206/220 [02:56<00:12,  1.14it/s] 94%|█████████▍| 207/220 [02:57<00:10,  1.19it/s] 95%|█████████▍| 208/220 [02:57<00:09,  1.25it/s] 95%|█████████▌| 209/220 [02:59<00:10,  1.09it/s] 95%|█████████▌| 210/220 [02:59<00:08,  1.17it/s]                                                  95%|█████████▌| 210/220 [02:59<00:08,  1.17it/s] 96%|█████████▌| 211/220 [03:00<00:07,  1.22it/s] 96%|█████████▋| 212/220 [03:01<00:06,  1.26it/s] 97%|█████████▋| 213/220 [03:02<00:06,  1.09it/s] 97%|█████████▋| 214/220 [03:03<00:05,  1.17it/s] 98%|█████████▊| 215/220 [03:03<00:04,  1.23it/s] 98%|█████████▊| 216/220 [03:04<00:03,  1.26it/s] 99%|█████████▊| 217/220 [03:05<00:02,  1.11it/s] 99%|█████████▉| 218/220 [03:06<00:01,  1.17it/s]100%|█████████▉| 219/220 [03:07<00:00,  1.23it/s]100%|██████████| 220/220 [03:08<00:00,  1.26it/s]                                                 100%|██████████| 220/220 [03:08<00:00,  1.26it/s]There were missing keys in the checkpoint model loaded: ['base_model.model.shared.weight', 'base_model.model.encoder.embed_tokens.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.encoder.block.0.layer.0.layer_norm.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.0.layer.1.layer_norm.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.1.layer.0.layer_norm.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.1.layer.1.layer_norm.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.2.layer.0.layer_norm.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.2.layer.1.layer_norm.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.3.layer.0.layer_norm.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.3.layer.1.layer_norm.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.4.layer.0.layer_norm.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.4.layer.1.layer_norm.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.5.layer.0.layer_norm.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.5.layer.1.layer_norm.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.6.layer.0.layer_norm.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.6.layer.1.layer_norm.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.7.layer.0.layer_norm.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.7.layer.1.layer_norm.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.8.layer.0.layer_norm.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.8.layer.1.layer_norm.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.9.layer.0.layer_norm.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.9.layer.1.layer_norm.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.10.layer.0.layer_norm.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.10.layer.1.layer_norm.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.11.layer.0.layer_norm.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.11.layer.1.layer_norm.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.12.layer.0.layer_norm.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.12.layer.1.layer_norm.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.13.layer.0.layer_norm.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.13.layer.1.layer_norm.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.14.layer.0.layer_norm.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.14.layer.1.layer_norm.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.15.layer.0.layer_norm.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.15.layer.1.layer_norm.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.16.layer.0.layer_norm.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.16.layer.1.layer_norm.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.17.layer.0.layer_norm.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.17.layer.1.layer_norm.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.18.layer.0.layer_norm.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.18.layer.1.layer_norm.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.19.layer.0.layer_norm.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.19.layer.1.layer_norm.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.20.layer.0.layer_norm.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.20.layer.1.layer_norm.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.21.layer.0.layer_norm.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.21.layer.1.layer_norm.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.22.layer.0.layer_norm.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.22.layer.1.layer_norm.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.23.layer.0.layer_norm.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.23.layer.1.layer_norm.weight', 'base_model.model.encoder.final_layer_norm.weight', 'base_model.model.decoder.embed_tokens.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.decoder.block.0.layer.0.layer_norm.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.0.layer.1.layer_norm.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.0.layer.2.layer_norm.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.1.layer.0.layer_norm.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.1.layer.1.layer_norm.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.1.layer.2.layer_norm.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.2.layer.0.layer_norm.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.2.layer.1.layer_norm.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.2.layer.2.layer_norm.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.3.layer.0.layer_norm.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.3.layer.1.layer_norm.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.3.layer.2.layer_norm.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.4.layer.0.layer_norm.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.4.layer.1.layer_norm.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.4.layer.2.layer_norm.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.5.layer.0.layer_norm.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.5.layer.1.layer_norm.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.5.layer.2.layer_norm.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.6.layer.0.layer_norm.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.6.layer.1.layer_norm.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.6.layer.2.layer_norm.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.7.layer.0.layer_norm.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.7.layer.1.layer_norm.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.7.layer.2.layer_norm.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.8.layer.0.layer_norm.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.8.layer.1.layer_norm.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.8.layer.2.layer_norm.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.9.layer.0.layer_norm.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.9.layer.1.layer_norm.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.9.layer.2.layer_norm.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.10.layer.0.layer_norm.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.10.layer.1.layer_norm.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.10.layer.2.layer_norm.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.11.layer.0.layer_norm.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.11.layer.1.layer_norm.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.11.layer.2.layer_norm.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.12.layer.0.layer_norm.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.12.layer.1.layer_norm.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.12.layer.2.layer_norm.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.13.layer.0.layer_norm.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.13.layer.1.layer_norm.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.13.layer.2.layer_norm.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.14.layer.0.layer_norm.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.14.layer.1.layer_norm.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.14.layer.2.layer_norm.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.15.layer.0.layer_norm.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.15.layer.1.layer_norm.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.15.layer.2.layer_norm.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.16.layer.0.layer_norm.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.16.layer.1.layer_norm.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.16.layer.2.layer_norm.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.17.layer.0.layer_norm.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.17.layer.1.layer_norm.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.17.layer.2.layer_norm.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.18.layer.0.layer_norm.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.18.layer.1.layer_norm.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.18.layer.2.layer_norm.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.19.layer.0.layer_norm.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.19.layer.1.layer_norm.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.19.layer.2.layer_norm.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.20.layer.0.layer_norm.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.20.layer.1.layer_norm.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.20.layer.2.layer_norm.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.21.layer.0.layer_norm.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.21.layer.1.layer_norm.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.21.layer.2.layer_norm.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.22.layer.0.layer_norm.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.22.layer.1.layer_norm.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.22.layer.2.layer_norm.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.23.layer.0.layer_norm.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.23.layer.1.layer_norm.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.23.layer.2.layer_norm.weight', 'base_model.model.decoder.final_layer_norm.weight', 'base_model.model.lm_head.weight'].
There were unexpected keys in the checkpoint model loaded: ['base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.weight'].
                                                 100%|██████████| 220/220 [03:08<00:00,  1.26it/s]100%|██████████| 220/220 [03:08<00:00,  1.17it/s]
{'eval_loss': 0.3509460389614105, 'eval_runtime': 0.3522, 'eval_samples_per_second': 113.58, 'eval_steps_per_second': 14.198, 'epoch': 8.89}
外层迭代结束！
外层迭代结束！
{'loss': 0.3525, 'learning_rate': 1.764705882352941e-05, 'epoch': 9.33}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3647, 'learning_rate': 0.0, 'epoch': 9.78}
{'train_runtime': 188.6953, 'train_samples_per_second': 19.078, 'train_steps_per_second': 1.166, 'train_loss': 0.7135651978579435, 'epoch': 9.78}

 If there's a warning about missing keys above, please disregard :)
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 16
micro_batch_size: 4
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: qqp... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/4-qqp
current data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 209.66it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 615.81it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 729.82it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 953.03it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 464.74it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
总样本数：400, 选择的样本数量：8
lora_weights: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/3-copa

pre-trained model's BOS EOS and PAD token id: None 1 0  => It should be 1,2,none
continual fine tune lora!
trainable params: 2359296 || all params: 740027392 || trainable%: 0.31881198257050464
训练数据总量：900
验证数据总量：100
Map:   0%|          | 0/900 [00:00<?, ? examples/s]/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3597: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  "`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your "
                                                   Map:   0%|          | 0/100 [00:00<?, ? examples/s]                                                   Map:   0%|          | 0/53 [00:00<?, ? examples/s]                                                  memory data loader 2
  0%|          | 0/560 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/560 [00:01<12:35,  1.35s/it]  0%|          | 2/560 [00:02<09:05,  1.02it/s]  1%|          | 3/560 [00:02<08:00,  1.16it/s]  1%|          | 4/560 [00:03<07:24,  1.25it/s]  1%|          | 5/560 [00:04<08:43,  1.06it/s]  1%|          | 6/560 [00:05<07:57,  1.16it/s]  1%|▏         | 7/560 [00:06<07:27,  1.24it/s]  1%|▏         | 8/560 [00:06<07:05,  1.30it/s]  2%|▏         | 9/560 [00:07<08:08,  1.13it/s]  2%|▏         | 10/560 [00:08<07:36,  1.20it/s]                                                  2%|▏         | 10/560 [00:08<07:36,  1.20it/s]  2%|▏         | 11/560 [00:09<07:14,  1.26it/s]  2%|▏         | 12/560 [00:10<07:00,  1.30it/s]  2%|▏         | 13/560 [00:11<08:04,  1.13it/s]  2%|▎         | 14/560 [00:11<07:35,  1.20it/s]  3%|▎         | 15/560 [00:12<07:13,  1.26it/s]  3%|▎         | 16/560 [00:13<06:57,  1.30it/s]  3%|▎         | 17/560 [00:14<08:00,  1.13it/s]  3%|▎         | 18/560 [00:15<07:31,  1.20it/s]  3%|▎         | 19/560 [00:15<07:09,  1.26it/s]  4%|▎         | 20/560 [00:16<06:55,  1.30it/s]                                                  4%|▎         | 20/560 [00:17<06:55,  1.30it/s]  4%|▍         | 21/560 [00:17<07:57,  1.13it/s]  4%|▍         | 22/560 [00:18<07:27,  1.20it/s]  4%|▍         | 23/560 [00:19<07:08,  1.25it/s]  4%|▍         | 24/560 [00:19<06:54,  1.29it/s]  4%|▍         | 25/560 [00:21<07:52,  1.13it/s]  5%|▍         | 26/560 [00:21<07:24,  1.20it/s]  5%|▍         | 27/560 [00:22<07:04,  1.26it/s]  5%|▌         | 28/560 [00:23<06:52,  1.29it/s]  5%|▌         | 29/560 [00:24<07:55,  1.12it/s]  5%|▌         | 30/560 [00:25<07:25,  1.19it/s]                                                  5%|▌         | 30/560 [00:25<07:25,  1.19it/s]  6%|▌         | 31/560 [00:25<07:04,  1.25it/s]  6%|▌         | 32/560 [00:26<06:48,  1.29it/s]  6%|▌         | 33/560 [00:27<07:45,  1.13it/s]  6%|▌         | 34/560 [00:28<07:17,  1.20it/s]  6%|▋         | 35/560 [00:29<06:56,  1.26it/s]  6%|▋         | 36/560 [00:29<06:41,  1.30it/s]  7%|▋         | 37/560 [00:30<07:25,  1.17it/s]  7%|▋         | 38/560 [00:31<07:00,  1.24it/s]  7%|▋         | 39/560 [00:32<06:45,  1.28it/s]  7%|▋         | 40/560 [00:32<06:32,  1.33it/s]                                                  7%|▋         | 40/560 [00:33<06:32,  1.33it/s]外层迭代结束！
外层迭代结束！
{'loss': 0.4478, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.18}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2756, 'learning_rate': 0.00011999999999999999, 'epoch': 0.36}
外层迭代结束！
外层迭代结束！
{'loss': 0.2747, 'learning_rate': 0.00017999999999999998, 'epoch': 0.53}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2156, 'learning_rate': 0.00023999999999999998, 'epoch': 0.71}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.80it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.80it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.97it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.48it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.27it/s][A                                                
                                               [A  7%|▋         | 40/560 [00:34<06:32,  1.33it/s]
100%|██████████| 13/13 [00:00<00:00, 15.27it/s][A
                                               [A  7%|▋         | 41/560 [00:35<10:12,  1.18s/it]  8%|▊         | 42/560 [00:35<08:58,  1.04s/it]  8%|▊         | 43/560 [00:36<08:07,  1.06it/s]  8%|▊         | 44/560 [00:37<07:31,  1.14it/s]  8%|▊         | 45/560 [00:38<08:10,  1.05it/s]  8%|▊         | 46/560 [00:39<07:31,  1.14it/s]  8%|▊         | 47/560 [00:39<07:03,  1.21it/s]  9%|▊         | 48/560 [00:40<06:43,  1.27it/s]  9%|▉         | 49/560 [00:41<07:37,  1.12it/s]  9%|▉         | 50/560 [00:42<07:08,  1.19it/s]                                                  9%|▉         | 50/560 [00:42<07:08,  1.19it/s]  9%|▉         | 51/560 [00:43<06:46,  1.25it/s]  9%|▉         | 52/560 [00:43<06:31,  1.30it/s]  9%|▉         | 53/560 [00:44<07:28,  1.13it/s] 10%|▉         | 54/560 [00:45<07:00,  1.20it/s] 10%|▉         | 55/560 [00:46<06:41,  1.26it/s] 10%|█         | 56/560 [00:47<06:28,  1.30it/s] 10%|█         | 57/560 [00:48<07:22,  1.14it/s] 10%|█         | 58/560 [00:48<06:55,  1.21it/s] 11%|█         | 59/560 [00:49<06:36,  1.26it/s] 11%|█         | 60/560 [00:50<06:22,  1.31it/s]                                                 11%|█         | 60/560 [00:50<06:22,  1.31it/s] 11%|█         | 61/560 [00:51<07:19,  1.14it/s] 11%|█         | 62/560 [00:52<06:53,  1.20it/s] 11%|█▏        | 63/560 [00:52<06:33,  1.26it/s] 11%|█▏        | 64/560 [00:53<06:19,  1.31it/s] 12%|█▏        | 65/560 [00:54<07:16,  1.13it/s] 12%|█▏        | 66/560 [00:55<06:53,  1.19it/s] 12%|█▏        | 67/560 [00:56<06:33,  1.25it/s] 12%|█▏        | 68/560 [00:56<06:17,  1.30it/s] 12%|█▏        | 69/560 [00:58<07:15,  1.13it/s] 12%|█▎        | 70/560 [00:58<06:47,  1.20it/s]                                                 12%|█▎        | 70/560 [00:58<06:47,  1.20it/s] 13%|█▎        | 71/560 [00:59<06:27,  1.26it/s] 13%|█▎        | 72/560 [01:00<06:14,  1.30it/s] 13%|█▎        | 73/560 [01:01<07:14,  1.12it/s] 13%|█▎        | 74/560 [01:02<06:47,  1.19it/s] 13%|█▎        | 75/560 [01:02<06:28,  1.25it/s] 14%|█▎        | 76/560 [01:03<06:13,  1.30it/s] 14%|█▍        | 77/560 [01:04<07:08,  1.13it/s] 14%|█▍        | 78/560 [01:05<06:59,  1.15it/s] 14%|█▍        | 79/560 [01:06<06:44,  1.19it/s] 14%|█▍        | 80/560 [01:06<06:30,  1.23it/s]                                                 14%|█▍        | 80/560 [01:07<06:30,  1.23it/s]{'eval_loss': 0.15709204971790314, 'eval_runtime': 0.8951, 'eval_samples_per_second': 111.719, 'eval_steps_per_second': 14.524, 'epoch': 0.71}
外层迭代结束！
外层迭代结束！
{'loss': 0.1855, 'learning_rate': 0.0003, 'epoch': 0.89}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1564, 'learning_rate': 0.0002941176470588235, 'epoch': 1.07}
外层迭代结束！
外层迭代结束！
{'loss': 0.1313, 'learning_rate': 0.00028823529411764703, 'epoch': 1.24}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1204, 'learning_rate': 0.00028235294117647056, 'epoch': 1.42}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.85it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.74it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.04it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.29it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.95it/s][A                                                
                                               [A 14%|█▍        | 80/560 [01:08<06:30,  1.23it/s]
100%|██████████| 13/13 [00:00<00:00, 14.95it/s][A
                                               [A 14%|█▍        | 81/560 [01:09<10:00,  1.25s/it] 15%|█▍        | 82/560 [01:10<08:50,  1.11s/it] 15%|█▍        | 83/560 [01:10<08:00,  1.01s/it] 15%|█▌        | 84/560 [01:11<07:28,  1.06it/s] 15%|█▌        | 85/560 [01:12<08:09,  1.03s/it] 15%|█▌        | 86/560 [01:13<07:29,  1.05it/s] 16%|█▌        | 87/560 [01:14<06:58,  1.13it/s] 16%|█▌        | 88/560 [01:15<06:35,  1.19it/s] 16%|█▌        | 89/560 [01:16<07:22,  1.07it/s] 16%|█▌        | 90/560 [01:16<06:52,  1.14it/s]                                                 16%|█▌        | 90/560 [01:16<06:52,  1.14it/s] 16%|█▋        | 91/560 [01:17<06:29,  1.20it/s] 16%|█▋        | 92/560 [01:18<06:14,  1.25it/s] 17%|█▋        | 93/560 [01:19<07:03,  1.10it/s] 17%|█▋        | 94/560 [01:20<06:39,  1.17it/s] 17%|█▋        | 95/560 [01:21<06:21,  1.22it/s] 17%|█▋        | 96/560 [01:21<06:09,  1.25it/s] 17%|█▋        | 97/560 [01:22<06:52,  1.12it/s] 18%|█▊        | 98/560 [01:23<06:28,  1.19it/s] 18%|█▊        | 99/560 [01:24<06:15,  1.23it/s] 18%|█▊        | 100/560 [01:25<06:02,  1.27it/s]                                                  18%|█▊        | 100/560 [01:25<06:02,  1.27it/s] 18%|█▊        | 101/560 [01:26<06:57,  1.10it/s] 18%|█▊        | 102/560 [01:27<06:33,  1.16it/s] 18%|█▊        | 103/560 [01:27<06:16,  1.21it/s] 19%|█▊        | 104/560 [01:28<06:05,  1.25it/s] 19%|█▉        | 105/560 [01:29<06:55,  1.09it/s] 19%|█▉        | 106/560 [01:30<06:29,  1.16it/s] 19%|█▉        | 107/560 [01:31<06:10,  1.22it/s] 19%|█▉        | 108/560 [01:31<05:57,  1.26it/s] 19%|█▉        | 109/560 [01:33<06:50,  1.10it/s] 20%|█▉        | 110/560 [01:33<06:24,  1.17it/s]                                                  20%|█▉        | 110/560 [01:33<06:24,  1.17it/s] 20%|█▉        | 111/560 [01:34<06:05,  1.23it/s] 20%|██        | 112/560 [01:35<05:52,  1.27it/s] 20%|██        | 113/560 [01:36<06:48,  1.10it/s] 20%|██        | 114/560 [01:37<06:22,  1.17it/s] 21%|██        | 115/560 [01:37<06:04,  1.22it/s] 21%|██        | 116/560 [01:38<05:51,  1.26it/s] 21%|██        | 117/560 [01:39<06:40,  1.11it/s] 21%|██        | 118/560 [01:40<06:16,  1.17it/s] 21%|██▏       | 119/560 [01:41<06:01,  1.22it/s] 21%|██▏       | 120/560 [01:41<05:49,  1.26it/s]                                                  21%|██▏       | 120/560 [01:42<05:49,  1.26it/s]{'eval_loss': 0.11874927580356598, 'eval_runtime': 0.9124, 'eval_samples_per_second': 109.604, 'eval_steps_per_second': 14.248, 'epoch': 1.42}
外层迭代结束！
外层迭代结束！
{'loss': 0.1328, 'learning_rate': 0.0002764705882352941, 'epoch': 1.6}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1379, 'learning_rate': 0.0002705882352941176, 'epoch': 1.78}
外层迭代结束！
外层迭代结束！
{'loss': 0.1319, 'learning_rate': 0.00026470588235294115, 'epoch': 1.96}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.103, 'learning_rate': 0.0002588235294117647, 'epoch': 2.13}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.70it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.29it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.69it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.32it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.13it/s][A                                                 
                                               [A 21%|██▏       | 120/560 [01:43<05:49,  1.26it/s]
100%|██████████| 13/13 [00:00<00:00, 15.13it/s][A
                                               [A 22%|██▏       | 121/560 [01:44<08:56,  1.22s/it] 22%|██▏       | 122/560 [01:44<07:50,  1.07s/it] 22%|██▏       | 123/560 [01:45<07:01,  1.04it/s] 22%|██▏       | 124/560 [01:46<06:32,  1.11it/s] 22%|██▏       | 125/560 [01:47<07:06,  1.02it/s] 22%|██▎       | 126/560 [01:48<06:33,  1.10it/s] 23%|██▎       | 127/560 [01:49<06:09,  1.17it/s] 23%|██▎       | 128/560 [01:49<05:50,  1.23it/s] 23%|██▎       | 129/560 [01:50<06:37,  1.08it/s] 23%|██▎       | 130/560 [01:51<06:08,  1.17it/s]                                                  23%|██▎       | 130/560 [01:51<06:08,  1.17it/s] 23%|██▎       | 131/560 [01:52<05:52,  1.22it/s] 24%|██▎       | 132/560 [01:53<05:39,  1.26it/s] 24%|██▍       | 133/560 [01:54<06:29,  1.10it/s] 24%|██▍       | 134/560 [01:54<06:04,  1.17it/s] 24%|██▍       | 135/560 [01:55<05:45,  1.23it/s] 24%|██▍       | 136/560 [01:56<05:35,  1.26it/s] 24%|██▍       | 137/560 [01:57<06:22,  1.11it/s] 25%|██▍       | 138/560 [01:58<06:00,  1.17it/s] 25%|██▍       | 139/560 [01:59<05:44,  1.22it/s] 25%|██▌       | 140/560 [01:59<05:29,  1.27it/s]                                                  25%|██▌       | 140/560 [02:00<05:29,  1.27it/s] 25%|██▌       | 141/560 [02:00<06:19,  1.10it/s] 25%|██▌       | 142/560 [02:01<05:53,  1.18it/s] 26%|██▌       | 143/560 [02:02<05:39,  1.23it/s] 26%|██▌       | 144/560 [02:03<05:27,  1.27it/s] 26%|██▌       | 145/560 [02:04<06:16,  1.10it/s] 26%|██▌       | 146/560 [02:05<05:54,  1.17it/s] 26%|██▋       | 147/560 [02:05<05:37,  1.22it/s] 26%|██▋       | 148/560 [02:06<05:28,  1.26it/s] 27%|██▋       | 149/560 [02:07<06:12,  1.10it/s] 27%|██▋       | 150/560 [02:08<05:51,  1.17it/s]                                                  27%|██▋       | 150/560 [02:08<05:51,  1.17it/s] 27%|██▋       | 151/560 [02:09<05:35,  1.22it/s] 27%|██▋       | 152/560 [02:09<05:24,  1.26it/s] 27%|██▋       | 153/560 [02:11<06:10,  1.10it/s] 28%|██▊       | 154/560 [02:11<05:45,  1.18it/s] 28%|██▊       | 155/560 [02:12<05:29,  1.23it/s] 28%|██▊       | 156/560 [02:13<05:17,  1.27it/s] 28%|██▊       | 157/560 [02:14<06:05,  1.10it/s] 28%|██▊       | 158/560 [02:15<05:43,  1.17it/s] 28%|██▊       | 159/560 [02:15<05:24,  1.23it/s] 29%|██▊       | 160/560 [02:16<05:17,  1.26it/s]                                                  29%|██▊       | 160/560 [02:17<05:17,  1.26it/s]{'eval_loss': 0.09522847086191177, 'eval_runtime': 0.9054, 'eval_samples_per_second': 110.451, 'eval_steps_per_second': 14.359, 'epoch': 2.13}
外层迭代结束！
外层迭代结束！
{'loss': 0.1061, 'learning_rate': 0.0002529411764705882, 'epoch': 2.31}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0934, 'learning_rate': 0.00024705882352941174, 'epoch': 2.49}
外层迭代结束！
外层迭代结束！
{'loss': 0.0787, 'learning_rate': 0.00024117647058823527, 'epoch': 2.67}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0902, 'learning_rate': 0.0002352941176470588, 'epoch': 2.84}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.40it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.93it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.03it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.54it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.18it/s][A                                                 
                                               [A 29%|██▊       | 160/560 [02:17<05:17,  1.26it/s]
100%|██████████| 13/13 [00:00<00:00, 15.18it/s][A
                                               [A 29%|██▉       | 161/560 [02:18<08:07,  1.22s/it] 29%|██▉       | 162/560 [02:19<07:06,  1.07s/it] 29%|██▉       | 163/560 [02:20<06:25,  1.03it/s] 29%|██▉       | 164/560 [02:21<05:55,  1.11it/s] 29%|██▉       | 165/560 [02:22<06:27,  1.02it/s] 30%|██▉       | 166/560 [02:22<05:58,  1.10it/s] 30%|██▉       | 167/560 [02:23<05:34,  1.18it/s] 30%|███       | 168/560 [02:24<05:18,  1.23it/s] 30%|███       | 169/560 [02:25<05:58,  1.09it/s] 30%|███       | 170/560 [02:26<05:35,  1.16it/s]                                                  30%|███       | 170/560 [02:26<05:35,  1.16it/s] 31%|███       | 171/560 [02:27<05:19,  1.22it/s] 31%|███       | 172/560 [02:27<05:06,  1.27it/s] 31%|███       | 173/560 [02:28<05:51,  1.10it/s] 31%|███       | 174/560 [02:29<05:28,  1.17it/s] 31%|███▏      | 175/560 [02:30<05:14,  1.22it/s] 31%|███▏      | 176/560 [02:31<05:04,  1.26it/s] 32%|███▏      | 177/560 [02:32<05:49,  1.09it/s] 32%|███▏      | 178/560 [02:33<05:28,  1.16it/s] 32%|███▏      | 179/560 [02:33<05:12,  1.22it/s] 32%|███▏      | 180/560 [02:34<05:03,  1.25it/s]                                                  32%|███▏      | 180/560 [02:34<05:03,  1.25it/s] 32%|███▏      | 181/560 [02:35<05:44,  1.10it/s] 32%|███▎      | 182/560 [02:36<05:22,  1.17it/s] 33%|███▎      | 183/560 [02:37<05:07,  1.23it/s] 33%|███▎      | 184/560 [02:37<04:55,  1.27it/s] 33%|███▎      | 185/560 [02:39<05:38,  1.11it/s] 33%|███▎      | 186/560 [02:39<05:15,  1.18it/s] 33%|███▎      | 187/560 [02:40<05:03,  1.23it/s] 34%|███▎      | 188/560 [02:41<04:52,  1.27it/s] 34%|███▍      | 189/560 [02:42<05:35,  1.10it/s] 34%|███▍      | 190/560 [02:43<05:14,  1.18it/s]                                                  34%|███▍      | 190/560 [02:43<05:14,  1.18it/s] 34%|███▍      | 191/560 [02:43<05:01,  1.22it/s] 34%|███▍      | 192/560 [02:44<04:52,  1.26it/s] 34%|███▍      | 193/560 [02:45<05:31,  1.11it/s] 35%|███▍      | 194/560 [02:46<05:11,  1.17it/s] 35%|███▍      | 195/560 [02:47<04:59,  1.22it/s] 35%|███▌      | 196/560 [02:47<04:47,  1.27it/s] 35%|███▌      | 197/560 [02:49<05:29,  1.10it/s] 35%|███▌      | 198/560 [02:49<05:08,  1.17it/s] 36%|███▌      | 199/560 [02:50<04:56,  1.22it/s] 36%|███▌      | 200/560 [02:51<04:45,  1.26it/s]                                                  36%|███▌      | 200/560 [02:51<04:45,  1.26it/s]{'eval_loss': 0.09889592975378036, 'eval_runtime': 0.9008, 'eval_samples_per_second': 111.015, 'eval_steps_per_second': 14.432, 'epoch': 2.84}
外层迭代结束！
外层迭代结束！
{'loss': 0.0681, 'learning_rate': 0.0002294117647058823, 'epoch': 3.02}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0766, 'learning_rate': 0.00022352941176470586, 'epoch': 3.2}
外层迭代结束！
外层迭代结束！
{'loss': 0.0737, 'learning_rate': 0.0002176470588235294, 'epoch': 3.38}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0853, 'learning_rate': 0.00021176470588235295, 'epoch': 3.56}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.29it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.23it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.55it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.07it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.89it/s][A                                                 
                                               [A 36%|███▌      | 200/560 [02:52<04:45,  1.26it/s]
100%|██████████| 13/13 [00:00<00:00, 14.89it/s][A
                                               [A 36%|███▌      | 201/560 [02:53<07:20,  1.23s/it] 36%|███▌      | 202/560 [02:54<06:25,  1.08s/it] 36%|███▋      | 203/560 [02:54<05:45,  1.03it/s] 36%|███▋      | 204/560 [02:55<05:17,  1.12it/s] 37%|███▋      | 205/560 [02:56<05:36,  1.06it/s] 37%|███▋      | 206/560 [02:57<05:12,  1.13it/s] 37%|███▋      | 207/560 [02:58<04:56,  1.19it/s] 37%|███▋      | 208/560 [02:58<04:43,  1.24it/s] 37%|███▋      | 209/560 [03:00<05:21,  1.09it/s] 38%|███▊      | 210/560 [03:00<05:02,  1.16it/s]                                                  38%|███▊      | 210/560 [03:00<05:02,  1.16it/s] 38%|███▊      | 211/560 [03:01<04:47,  1.22it/s] 38%|███▊      | 212/560 [03:02<04:36,  1.26it/s] 38%|███▊      | 213/560 [03:03<05:14,  1.10it/s] 38%|███▊      | 214/560 [03:04<04:55,  1.17it/s] 38%|███▊      | 215/560 [03:04<04:41,  1.23it/s] 39%|███▊      | 216/560 [03:05<04:32,  1.26it/s] 39%|███▉      | 217/560 [03:06<05:10,  1.11it/s] 39%|███▉      | 218/560 [03:07<04:49,  1.18it/s] 39%|███▉      | 219/560 [03:08<04:37,  1.23it/s] 39%|███▉      | 220/560 [03:09<04:27,  1.27it/s]                                                  39%|███▉      | 220/560 [03:09<04:27,  1.27it/s] 39%|███▉      | 221/560 [03:10<05:04,  1.11it/s] 40%|███▉      | 222/560 [03:10<04:47,  1.17it/s] 40%|███▉      | 223/560 [03:11<04:37,  1.22it/s] 40%|████      | 224/560 [03:12<04:29,  1.25it/s] 40%|████      | 225/560 [03:13<05:08,  1.09it/s] 40%|████      | 226/560 [03:14<04:50,  1.15it/s] 41%|████      | 227/560 [03:15<04:38,  1.20it/s] 41%|████      | 228/560 [03:15<04:28,  1.24it/s] 41%|████      | 229/560 [03:17<05:08,  1.07it/s] 41%|████      | 230/560 [03:17<04:48,  1.14it/s]                                                  41%|████      | 230/560 [03:17<04:48,  1.14it/s] 41%|████▏     | 231/560 [03:18<04:36,  1.19it/s] 41%|████▏     | 232/560 [03:19<04:28,  1.22it/s] 42%|████▏     | 233/560 [03:20<04:53,  1.11it/s] 42%|████▏     | 234/560 [03:21<04:38,  1.17it/s] 42%|████▏     | 235/560 [03:21<04:25,  1.22it/s] 42%|████▏     | 236/560 [03:22<04:18,  1.25it/s] 42%|████▏     | 237/560 [03:23<04:55,  1.09it/s] 42%|████▎     | 238/560 [03:24<04:39,  1.15it/s] 43%|████▎     | 239/560 [03:25<04:27,  1.20it/s] 43%|████▎     | 240/560 [03:26<04:17,  1.24it/s]                                                  43%|████▎     | 240/560 [03:26<04:17,  1.24it/s]{'eval_loss': 0.11318166553974152, 'eval_runtime': 0.9153, 'eval_samples_per_second': 109.257, 'eval_steps_per_second': 14.203, 'epoch': 3.56}
外层迭代结束！
外层迭代结束！
{'loss': 0.0834, 'learning_rate': 0.00020588235294117645, 'epoch': 3.73}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0616, 'learning_rate': 0.00019999999999999998, 'epoch': 3.91}
外层迭代结束！
外层迭代结束！
{'loss': 0.0522, 'learning_rate': 0.0001941176470588235, 'epoch': 4.09}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.043, 'learning_rate': 0.00018823529411764704, 'epoch': 4.27}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.82it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.93it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.88it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.43it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.24it/s][A                                                 
                                               [A 43%|████▎     | 240/560 [03:27<04:17,  1.24it/s]
100%|██████████| 13/13 [00:00<00:00, 15.24it/s][A
                                               [A 43%|████▎     | 241/560 [03:28<06:37,  1.25s/it] 43%|████▎     | 242/560 [03:29<05:53,  1.11s/it] 43%|████▎     | 243/560 [03:30<05:20,  1.01s/it] 44%|████▎     | 244/560 [03:30<04:59,  1.06it/s] 44%|████▍     | 245/560 [03:32<05:24,  1.03s/it] 44%|████▍     | 246/560 [03:32<05:02,  1.04it/s] 44%|████▍     | 247/560 [03:33<04:42,  1.11it/s] 44%|████▍     | 248/560 [03:34<04:24,  1.18it/s] 44%|████▍     | 249/560 [03:35<04:43,  1.10it/s] 45%|████▍     | 250/560 [03:36<04:24,  1.17it/s]                                                  45%|████▍     | 250/560 [03:36<04:24,  1.17it/s] 45%|████▍     | 251/560 [03:36<04:12,  1.23it/s] 45%|████▌     | 252/560 [03:37<04:02,  1.27it/s] 45%|████▌     | 253/560 [03:38<04:24,  1.16it/s] 45%|████▌     | 254/560 [03:39<04:11,  1.22it/s] 46%|████▌     | 255/560 [03:40<03:59,  1.27it/s] 46%|████▌     | 256/560 [03:40<03:53,  1.30it/s] 46%|████▌     | 257/560 [03:41<04:26,  1.14it/s] 46%|████▌     | 258/560 [03:42<04:10,  1.20it/s] 46%|████▋     | 259/560 [03:43<04:00,  1.25it/s] 46%|████▋     | 260/560 [03:44<03:50,  1.30it/s]                                                  46%|████▋     | 260/560 [03:44<03:50,  1.30it/s] 47%|████▋     | 261/560 [03:45<04:24,  1.13it/s] 47%|████▋     | 262/560 [03:45<04:07,  1.20it/s] 47%|████▋     | 263/560 [03:46<03:57,  1.25it/s] 47%|████▋     | 264/560 [03:47<03:49,  1.29it/s] 47%|████▋     | 265/560 [03:48<04:24,  1.12it/s] 48%|████▊     | 266/560 [03:49<04:08,  1.18it/s] 48%|████▊     | 267/560 [03:49<03:56,  1.24it/s] 48%|████▊     | 268/560 [03:50<03:48,  1.28it/s] 48%|████▊     | 269/560 [03:51<04:21,  1.11it/s] 48%|████▊     | 270/560 [03:52<04:05,  1.18it/s]                                                  48%|████▊     | 270/560 [03:52<04:05,  1.18it/s] 48%|████▊     | 271/560 [03:53<03:54,  1.23it/s] 49%|████▊     | 272/560 [03:53<03:44,  1.28it/s] 49%|████▉     | 273/560 [03:55<04:06,  1.16it/s] 49%|████▉     | 274/560 [03:55<03:54,  1.22it/s] 49%|████▉     | 275/560 [03:56<03:47,  1.25it/s] 49%|████▉     | 276/560 [03:57<03:40,  1.29it/s] 49%|████▉     | 277/560 [03:58<04:00,  1.18it/s] 50%|████▉     | 278/560 [03:58<03:48,  1.23it/s] 50%|████▉     | 279/560 [03:59<03:40,  1.27it/s] 50%|█████     | 280/560 [04:00<03:33,  1.31it/s]                                                  50%|█████     | 280/560 [04:00<03:33,  1.31it/s]{'eval_loss': 0.09539591521024704, 'eval_runtime': 0.8955, 'eval_samples_per_second': 111.671, 'eval_steps_per_second': 14.517, 'epoch': 4.27}
外层迭代结束！
外层迭代结束！
{'loss': 0.0595, 'learning_rate': 0.00018235294117647055, 'epoch': 4.44}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0679, 'learning_rate': 0.0001764705882352941, 'epoch': 4.62}
外层迭代结束！
外层迭代结束！
{'loss': 0.0493, 'learning_rate': 0.00017058823529411763, 'epoch': 4.8}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0666, 'learning_rate': 0.0001647058823529412, 'epoch': 4.98}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.83it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.70it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.91it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.42it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.19it/s][A                                                 
                                               [A 50%|█████     | 280/560 [04:01<03:33,  1.31it/s]
100%|██████████| 13/13 [00:00<00:00, 15.19it/s][A
                                               [A 50%|█████     | 281/560 [04:02<05:32,  1.19s/it] 50%|█████     | 282/560 [04:03<04:52,  1.05s/it] 51%|█████     | 283/560 [04:04<04:23,  1.05it/s] 51%|█████     | 284/560 [04:04<04:04,  1.13it/s] 51%|█████     | 285/560 [04:05<04:26,  1.03it/s] 51%|█████     | 286/560 [04:06<04:05,  1.12it/s] 51%|█████▏    | 287/560 [04:07<03:50,  1.18it/s] 51%|█████▏    | 288/560 [04:08<03:38,  1.24it/s] 52%|█████▏    | 289/560 [04:09<04:08,  1.09it/s] 52%|█████▏    | 290/560 [04:10<03:51,  1.17it/s]                                                  52%|█████▏    | 290/560 [04:10<03:51,  1.17it/s] 52%|█████▏    | 291/560 [04:10<03:40,  1.22it/s] 52%|█████▏    | 292/560 [04:11<03:33,  1.26it/s] 52%|█████▏    | 293/560 [04:12<04:02,  1.10it/s] 52%|█████▎    | 294/560 [04:13<03:46,  1.17it/s] 53%|█████▎    | 295/560 [04:14<03:34,  1.23it/s] 53%|█████▎    | 296/560 [04:14<03:26,  1.28it/s] 53%|█████▎    | 297/560 [04:15<03:57,  1.11it/s] 53%|█████▎    | 298/560 [04:16<03:42,  1.18it/s] 53%|█████▎    | 299/560 [04:17<03:31,  1.23it/s] 54%|█████▎    | 300/560 [04:18<03:23,  1.28it/s]                                                  54%|█████▎    | 300/560 [04:18<03:23,  1.28it/s] 54%|█████▍    | 301/560 [04:19<03:53,  1.11it/s] 54%|█████▍    | 302/560 [04:20<03:38,  1.18it/s] 54%|█████▍    | 303/560 [04:20<03:29,  1.23it/s] 54%|█████▍    | 304/560 [04:21<03:21,  1.27it/s] 54%|█████▍    | 305/560 [04:22<03:49,  1.11it/s] 55%|█████▍    | 306/560 [04:23<03:36,  1.18it/s] 55%|█████▍    | 307/560 [04:24<03:23,  1.24it/s] 55%|█████▌    | 308/560 [04:24<03:16,  1.28it/s] 55%|█████▌    | 309/560 [04:25<03:44,  1.12it/s] 55%|█████▌    | 310/560 [04:26<03:31,  1.18it/s]                                                  55%|█████▌    | 310/560 [04:26<03:31,  1.18it/s] 56%|█████▌    | 311/560 [04:27<03:22,  1.23it/s] 56%|█████▌    | 312/560 [04:28<03:14,  1.27it/s] 56%|█████▌    | 313/560 [04:29<03:42,  1.11it/s] 56%|█████▌    | 314/560 [04:30<03:26,  1.19it/s] 56%|█████▋    | 315/560 [04:30<03:16,  1.25it/s] 56%|█████▋    | 316/560 [04:31<03:08,  1.29it/s] 57%|█████▋    | 317/560 [04:32<03:35,  1.13it/s] 57%|█████▋    | 318/560 [04:33<03:21,  1.20it/s] 57%|█████▋    | 319/560 [04:34<03:12,  1.26it/s] 57%|█████▋    | 320/560 [04:34<03:04,  1.30it/s]                                                  57%|█████▋    | 320/560 [04:35<03:04,  1.30it/s]{'eval_loss': 0.11201372742652893, 'eval_runtime': 0.8987, 'eval_samples_per_second': 111.277, 'eval_steps_per_second': 14.466, 'epoch': 4.98}
外层迭代结束！
外层迭代结束！
{'loss': 0.0246, 'learning_rate': 0.0001588235294117647, 'epoch': 5.16}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0354, 'learning_rate': 0.00015294117647058822, 'epoch': 5.33}
外层迭代结束！
外层迭代结束！
{'loss': 0.055, 'learning_rate': 0.00014705882352941175, 'epoch': 5.51}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0882, 'learning_rate': 0.00014117647058823528, 'epoch': 5.69}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.81it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.01it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.15it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.62it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.35it/s][A                                                 
                                               [A 57%|█████▋    | 320/560 [04:36<03:04,  1.30it/s]
100%|██████████| 13/13 [00:00<00:00, 15.35it/s][A
                                               [A 57%|█████▋    | 321/560 [04:36<04:44,  1.19s/it] 57%|█████▊    | 322/560 [04:37<04:09,  1.05s/it] 58%|█████▊    | 323/560 [04:38<03:43,  1.06it/s] 58%|█████▊    | 324/560 [04:39<03:25,  1.15it/s] 58%|█████▊    | 325/560 [04:40<03:43,  1.05it/s] 58%|█████▊    | 326/560 [04:40<03:25,  1.14it/s] 58%|█████▊    | 327/560 [04:41<03:12,  1.21it/s] 59%|█████▊    | 328/560 [04:42<03:03,  1.26it/s] 59%|█████▉    | 329/560 [04:43<03:27,  1.11it/s] 59%|█████▉    | 330/560 [04:44<03:13,  1.19it/s]                                                  59%|█████▉    | 330/560 [04:44<03:13,  1.19it/s] 59%|█████▉    | 331/560 [04:44<03:03,  1.25it/s] 59%|█████▉    | 332/560 [04:45<02:57,  1.29it/s] 59%|█████▉    | 333/560 [04:46<03:22,  1.12it/s] 60%|█████▉    | 334/560 [04:47<03:08,  1.20it/s] 60%|█████▉    | 335/560 [04:48<02:58,  1.26it/s] 60%|██████    | 336/560 [04:48<02:52,  1.30it/s] 60%|██████    | 337/560 [04:49<03:16,  1.13it/s] 60%|██████    | 338/560 [04:50<03:03,  1.21it/s] 61%|██████    | 339/560 [04:51<02:55,  1.26it/s] 61%|██████    | 340/560 [04:52<02:48,  1.30it/s]                                                  61%|██████    | 340/560 [04:52<02:48,  1.30it/s] 61%|██████    | 341/560 [04:53<03:13,  1.13it/s] 61%|██████    | 342/560 [04:53<03:01,  1.20it/s] 61%|██████▏   | 343/560 [04:54<02:52,  1.26it/s] 61%|██████▏   | 344/560 [04:55<02:46,  1.30it/s] 62%|██████▏   | 345/560 [04:56<03:02,  1.18it/s] 62%|██████▏   | 346/560 [04:57<02:52,  1.24it/s] 62%|██████▏   | 347/560 [04:57<02:45,  1.29it/s] 62%|██████▏   | 348/560 [04:58<02:39,  1.33it/s] 62%|██████▏   | 349/560 [04:59<03:04,  1.15it/s] 62%|██████▎   | 350/560 [05:00<02:52,  1.22it/s]                                                  62%|██████▎   | 350/560 [05:00<02:52,  1.22it/s] 63%|██████▎   | 351/560 [05:01<02:45,  1.27it/s] 63%|██████▎   | 352/560 [05:01<02:38,  1.31it/s] 63%|██████▎   | 353/560 [05:02<03:01,  1.14it/s] 63%|██████▎   | 354/560 [05:03<02:50,  1.21it/s] 63%|██████▎   | 355/560 [05:04<02:41,  1.27it/s] 64%|██████▎   | 356/560 [05:05<02:35,  1.31it/s] 64%|██████▍   | 357/560 [05:06<02:58,  1.14it/s] 64%|██████▍   | 358/560 [05:06<02:47,  1.21it/s] 64%|██████▍   | 359/560 [05:07<02:39,  1.26it/s] 64%|██████▍   | 360/560 [05:08<02:34,  1.30it/s]                                                  64%|██████▍   | 360/560 [05:08<02:34,  1.30it/s]{'eval_loss': 0.11664722114801407, 'eval_runtime': 0.8887, 'eval_samples_per_second': 112.527, 'eval_steps_per_second': 14.629, 'epoch': 5.69}
外层迭代结束！
外层迭代结束！
{'loss': 0.0464, 'learning_rate': 0.0001352941176470588, 'epoch': 5.87}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0665, 'learning_rate': 0.00012941176470588234, 'epoch': 6.04}
外层迭代结束！
外层迭代结束！
{'loss': 0.0527, 'learning_rate': 0.00012352941176470587, 'epoch': 6.22}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0422, 'learning_rate': 0.0001176470588235294, 'epoch': 6.4}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.87it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.05it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.15it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.59it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.25it/s][A                                                 
                                               [A 64%|██████▍   | 360/560 [05:09<02:34,  1.30it/s]
100%|██████████| 13/13 [00:00<00:00, 15.25it/s][A
                                               [A 64%|██████▍   | 361/560 [05:10<03:57,  1.19s/it] 65%|██████▍   | 362/560 [05:11<03:27,  1.05s/it] 65%|██████▍   | 363/560 [05:11<03:06,  1.06it/s] 65%|██████▌   | 364/560 [05:12<02:51,  1.15it/s] 65%|██████▌   | 365/560 [05:13<03:07,  1.04it/s] 65%|██████▌   | 366/560 [05:14<02:51,  1.13it/s] 66%|██████▌   | 367/560 [05:15<02:39,  1.21it/s] 66%|██████▌   | 368/560 [05:15<02:32,  1.26it/s] 66%|██████▌   | 369/560 [05:17<02:52,  1.11it/s] 66%|██████▌   | 370/560 [05:17<02:40,  1.19it/s]                                                  66%|██████▌   | 370/560 [05:17<02:40,  1.19it/s] 66%|██████▋   | 371/560 [05:18<02:31,  1.25it/s] 66%|██████▋   | 372/560 [05:19<02:25,  1.29it/s] 67%|██████▋   | 373/560 [05:20<02:45,  1.13it/s] 67%|██████▋   | 374/560 [05:21<02:34,  1.20it/s] 67%|██████▋   | 375/560 [05:21<02:27,  1.26it/s] 67%|██████▋   | 376/560 [05:22<02:21,  1.30it/s] 67%|██████▋   | 377/560 [05:23<02:41,  1.13it/s] 68%|██████▊   | 378/560 [05:24<02:30,  1.21it/s] 68%|██████▊   | 379/560 [05:25<02:23,  1.27it/s] 68%|██████▊   | 380/560 [05:25<02:17,  1.30it/s]                                                  68%|██████▊   | 380/560 [05:26<02:17,  1.30it/s] 68%|██████▊   | 381/560 [05:26<02:38,  1.13it/s] 68%|██████▊   | 382/560 [05:27<02:27,  1.21it/s] 68%|██████▊   | 383/560 [05:28<02:20,  1.26it/s] 69%|██████▊   | 384/560 [05:29<02:15,  1.30it/s] 69%|██████▉   | 385/560 [05:30<02:34,  1.13it/s] 69%|██████▉   | 386/560 [05:30<02:24,  1.21it/s] 69%|██████▉   | 387/560 [05:31<02:17,  1.26it/s] 69%|██████▉   | 388/560 [05:32<02:11,  1.31it/s] 69%|██████▉   | 389/560 [05:33<02:29,  1.14it/s] 70%|██████▉   | 390/560 [05:34<02:20,  1.21it/s]                                                  70%|██████▉   | 390/560 [05:34<02:20,  1.21it/s] 70%|██████▉   | 391/560 [05:34<02:13,  1.27it/s] 70%|███████   | 392/560 [05:35<02:08,  1.31it/s] 70%|███████   | 393/560 [05:36<02:26,  1.14it/s] 70%|███████   | 394/560 [05:37<02:16,  1.21it/s] 71%|███████   | 395/560 [05:38<02:10,  1.27it/s] 71%|███████   | 396/560 [05:38<02:04,  1.31it/s] 71%|███████   | 397/560 [05:39<02:23,  1.14it/s] 71%|███████   | 398/560 [05:40<02:13,  1.21it/s] 71%|███████▏  | 399/560 [05:41<02:06,  1.27it/s] 71%|███████▏  | 400/560 [05:42<02:02,  1.31it/s]                                                  71%|███████▏  | 400/560 [05:42<02:02,  1.31it/s]{'eval_loss': 0.1120617613196373, 'eval_runtime': 0.8908, 'eval_samples_per_second': 112.262, 'eval_steps_per_second': 14.594, 'epoch': 6.4}
外层迭代结束！
外层迭代结束！
{'loss': 0.0417, 'learning_rate': 0.00011176470588235293, 'epoch': 6.58}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0206, 'learning_rate': 0.00010588235294117647, 'epoch': 6.76}
外层迭代结束！
外层迭代结束！
{'loss': 0.048, 'learning_rate': 9.999999999999999e-05, 'epoch': 6.93}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.037, 'learning_rate': 9.411764705882352e-05, 'epoch': 7.11}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.97it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.04it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.13it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.62it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.29it/s][A                                                 
                                               [A 71%|███████▏  | 400/560 [05:43<02:02,  1.31it/s]
100%|██████████| 13/13 [00:00<00:00, 15.29it/s][A
                                               [A 72%|███████▏  | 401/560 [05:44<03:08,  1.19s/it] 72%|███████▏  | 402/560 [05:44<02:44,  1.04s/it] 72%|███████▏  | 403/560 [05:45<02:27,  1.06it/s] 72%|███████▏  | 404/560 [05:46<02:16,  1.15it/s] 72%|███████▏  | 405/560 [05:47<02:27,  1.05it/s] 72%|███████▎  | 406/560 [05:48<02:15,  1.14it/s] 73%|███████▎  | 407/560 [05:48<02:06,  1.21it/s] 73%|███████▎  | 408/560 [05:49<02:00,  1.26it/s] 73%|███████▎  | 409/560 [05:50<02:15,  1.11it/s] 73%|███████▎  | 410/560 [05:51<02:06,  1.19it/s]                                                  73%|███████▎  | 410/560 [05:51<02:06,  1.19it/s] 73%|███████▎  | 411/560 [05:52<01:59,  1.25it/s] 74%|███████▎  | 412/560 [05:52<01:54,  1.30it/s] 74%|███████▍  | 413/560 [05:54<02:10,  1.13it/s] 74%|███████▍  | 414/560 [05:54<02:01,  1.20it/s] 74%|███████▍  | 415/560 [05:55<01:55,  1.26it/s] 74%|███████▍  | 416/560 [05:56<01:50,  1.30it/s] 74%|███████▍  | 417/560 [05:57<02:06,  1.13it/s] 75%|███████▍  | 418/560 [05:58<01:58,  1.20it/s] 75%|███████▍  | 419/560 [05:58<01:52,  1.26it/s] 75%|███████▌  | 420/560 [05:59<01:47,  1.30it/s]                                                  75%|███████▌  | 420/560 [05:59<01:47,  1.30it/s] 75%|███████▌  | 421/560 [06:00<02:02,  1.14it/s] 75%|███████▌  | 422/560 [06:01<01:53,  1.21it/s] 76%|███████▌  | 423/560 [06:01<01:48,  1.27it/s] 76%|███████▌  | 424/560 [06:02<01:43,  1.31it/s] 76%|███████▌  | 425/560 [06:03<01:53,  1.19it/s] 76%|███████▌  | 426/560 [06:04<01:47,  1.25it/s] 76%|███████▋  | 427/560 [06:05<01:42,  1.30it/s] 76%|███████▋  | 428/560 [06:05<01:38,  1.33it/s] 77%|███████▋  | 429/560 [06:06<01:53,  1.15it/s] 77%|███████▋  | 430/560 [06:07<01:46,  1.22it/s]                                                  77%|███████▋  | 430/560 [06:07<01:46,  1.22it/s] 77%|███████▋  | 431/560 [06:08<01:41,  1.27it/s] 77%|███████▋  | 432/560 [06:09<01:37,  1.32it/s] 77%|███████▋  | 433/560 [06:10<01:51,  1.14it/s] 78%|███████▊  | 434/560 [06:10<01:44,  1.21it/s] 78%|███████▊  | 435/560 [06:11<01:38,  1.27it/s] 78%|███████▊  | 436/560 [06:12<01:34,  1.31it/s] 78%|███████▊  | 437/560 [06:13<01:47,  1.14it/s] 78%|███████▊  | 438/560 [06:14<01:40,  1.21it/s] 78%|███████▊  | 439/560 [06:14<01:35,  1.27it/s] 79%|███████▊  | 440/560 [06:15<01:31,  1.31it/s]                                                  79%|███████▊  | 440/560 [06:16<01:31,  1.31it/s]{'eval_loss': 0.11418265104293823, 'eval_runtime': 0.8895, 'eval_samples_per_second': 112.427, 'eval_steps_per_second': 14.616, 'epoch': 7.11}
外层迭代结束！
外层迭代结束！
{'loss': 0.0145, 'learning_rate': 8.823529411764705e-05, 'epoch': 7.29}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0468, 'learning_rate': 8.23529411764706e-05, 'epoch': 7.47}
外层迭代结束！
外层迭代结束！
{'loss': 0.0214, 'learning_rate': 7.647058823529411e-05, 'epoch': 7.64}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0376, 'learning_rate': 7.058823529411764e-05, 'epoch': 7.82}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 22.09it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.21it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.28it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.73it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.45it/s][A                                                 
                                               [A 79%|███████▊  | 440/560 [06:16<01:31,  1.31it/s]
100%|██████████| 13/13 [00:00<00:00, 15.45it/s][A
                                               [A 79%|███████▉  | 441/560 [06:17<02:20,  1.18s/it] 79%|███████▉  | 442/560 [06:18<02:02,  1.04s/it] 79%|███████▉  | 443/560 [06:19<01:49,  1.07it/s] 79%|███████▉  | 444/560 [06:19<01:40,  1.15it/s] 79%|███████▉  | 445/560 [06:21<01:49,  1.05it/s] 80%|███████▉  | 446/560 [06:21<01:39,  1.14it/s] 80%|███████▉  | 447/560 [06:22<01:33,  1.21it/s] 80%|████████  | 448/560 [06:23<01:28,  1.27it/s] 80%|████████  | 449/560 [06:24<01:39,  1.11it/s] 80%|████████  | 450/560 [06:24<01:32,  1.19it/s]                                                  80%|████████  | 450/560 [06:24<01:32,  1.19it/s] 81%|████████  | 451/560 [06:25<01:27,  1.25it/s] 81%|████████  | 452/560 [06:26<01:23,  1.30it/s] 81%|████████  | 453/560 [06:27<01:34,  1.14it/s] 81%|████████  | 454/560 [06:28<01:28,  1.20it/s] 81%|████████▏ | 455/560 [06:28<01:23,  1.26it/s] 81%|████████▏ | 456/560 [06:29<01:20,  1.30it/s] 82%|████████▏ | 457/560 [06:30<01:27,  1.17it/s] 82%|████████▏ | 458/560 [06:31<01:22,  1.24it/s] 82%|████████▏ | 459/560 [06:32<01:18,  1.28it/s] 82%|████████▏ | 460/560 [06:32<01:15,  1.32it/s]                                                  82%|████████▏ | 460/560 [06:33<01:15,  1.32it/s] 82%|████████▏ | 461/560 [06:33<01:26,  1.14it/s] 82%|████████▎ | 462/560 [06:34<01:20,  1.22it/s] 83%|████████▎ | 463/560 [06:35<01:16,  1.27it/s] 83%|████████▎ | 464/560 [06:36<01:13,  1.31it/s] 83%|████████▎ | 465/560 [06:37<01:23,  1.14it/s] 83%|████████▎ | 466/560 [06:37<01:17,  1.21it/s] 83%|████████▎ | 467/560 [06:38<01:13,  1.27it/s] 84%|████████▎ | 468/560 [06:39<01:10,  1.31it/s] 84%|████████▍ | 469/560 [06:40<01:19,  1.14it/s] 84%|████████▍ | 470/560 [06:41<01:13,  1.22it/s]                                                  84%|████████▍ | 470/560 [06:41<01:13,  1.22it/s] 84%|████████▍ | 471/560 [06:41<01:10,  1.27it/s] 84%|████████▍ | 472/560 [06:42<01:07,  1.31it/s] 84%|████████▍ | 473/560 [06:43<01:16,  1.13it/s] 85%|████████▍ | 474/560 [06:44<01:11,  1.21it/s] 85%|████████▍ | 475/560 [06:45<01:07,  1.27it/s] 85%|████████▌ | 476/560 [06:45<01:04,  1.31it/s] 85%|████████▌ | 477/560 [06:47<01:13,  1.14it/s] 85%|████████▌ | 478/560 [06:47<01:08,  1.21it/s] 86%|████████▌ | 479/560 [06:48<01:04,  1.26it/s] 86%|████████▌ | 480/560 [06:49<01:01,  1.30it/s]                                                  86%|████████▌ | 480/560 [06:49<01:01,  1.30it/s]{'eval_loss': 0.12537896633148193, 'eval_runtime': 0.8813, 'eval_samples_per_second': 113.472, 'eval_steps_per_second': 14.751, 'epoch': 7.82}
外层迭代结束！
外层迭代结束！
{'loss': 0.0198, 'learning_rate': 6.470588235294117e-05, 'epoch': 8.0}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0173, 'learning_rate': 5.88235294117647e-05, 'epoch': 8.18}
外层迭代结束！
外层迭代结束！
{'loss': 0.0177, 'learning_rate': 5.294117647058824e-05, 'epoch': 8.36}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0267, 'learning_rate': 4.705882352941176e-05, 'epoch': 8.53}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.82it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.02it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.13it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.56it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.22it/s][A                                                 
                                               [A 86%|████████▌ | 480/560 [06:50<01:01,  1.30it/s]
100%|██████████| 13/13 [00:00<00:00, 15.22it/s][A
                                               [A 86%|████████▌ | 481/560 [06:51<01:34,  1.19s/it] 86%|████████▌ | 482/560 [06:52<01:21,  1.05s/it] 86%|████████▋ | 483/560 [06:52<01:12,  1.06it/s] 86%|████████▋ | 484/560 [06:53<01:06,  1.14it/s] 87%|████████▋ | 485/560 [06:54<01:11,  1.04it/s] 87%|████████▋ | 486/560 [06:55<01:05,  1.13it/s] 87%|████████▋ | 487/560 [06:56<01:00,  1.21it/s] 87%|████████▋ | 488/560 [06:56<00:56,  1.27it/s] 87%|████████▋ | 489/560 [06:57<01:01,  1.16it/s] 88%|████████▊ | 490/560 [06:58<00:57,  1.23it/s]                                                  88%|████████▊ | 490/560 [06:58<00:57,  1.23it/s] 88%|████████▊ | 491/560 [06:59<00:53,  1.28it/s] 88%|████████▊ | 492/560 [06:59<00:51,  1.31it/s] 88%|████████▊ | 493/560 [07:01<00:58,  1.15it/s] 88%|████████▊ | 494/560 [07:01<00:54,  1.21it/s] 88%|████████▊ | 495/560 [07:02<00:51,  1.27it/s] 89%|████████▊ | 496/560 [07:03<00:48,  1.31it/s] 89%|████████▉ | 497/560 [07:04<00:55,  1.13it/s] 89%|████████▉ | 498/560 [07:05<00:51,  1.21it/s] 89%|████████▉ | 499/560 [07:05<00:48,  1.26it/s] 89%|████████▉ | 500/560 [07:06<00:45,  1.31it/s]                                                  89%|████████▉ | 500/560 [07:06<00:45,  1.31it/s] 89%|████████▉ | 501/560 [07:07<00:52,  1.12it/s] 90%|████████▉ | 502/560 [07:08<00:48,  1.19it/s] 90%|████████▉ | 503/560 [07:09<00:45,  1.25it/s] 90%|█████████ | 504/560 [07:09<00:43,  1.30it/s] 90%|█████████ | 505/560 [07:10<00:48,  1.14it/s] 90%|█████████ | 506/560 [07:11<00:44,  1.21it/s] 91%|█████████ | 507/560 [07:12<00:42,  1.26it/s] 91%|█████████ | 508/560 [07:12<00:39,  1.30it/s] 91%|█████████ | 509/560 [07:14<00:45,  1.13it/s] 91%|█████████ | 510/560 [07:14<00:41,  1.20it/s]                                                  91%|█████████ | 510/560 [07:14<00:41,  1.20it/s] 91%|█████████▏| 511/560 [07:15<00:38,  1.26it/s] 91%|█████████▏| 512/560 [07:16<00:36,  1.30it/s] 92%|█████████▏| 513/560 [07:17<00:41,  1.13it/s] 92%|█████████▏| 514/560 [07:18<00:38,  1.20it/s] 92%|█████████▏| 515/560 [07:18<00:35,  1.26it/s] 92%|█████████▏| 516/560 [07:19<00:33,  1.31it/s] 92%|█████████▏| 517/560 [07:20<00:37,  1.13it/s] 92%|█████████▎| 518/560 [07:21<00:34,  1.21it/s] 93%|█████████▎| 519/560 [07:22<00:32,  1.26it/s] 93%|█████████▎| 520/560 [07:22<00:30,  1.31it/s]                                                  93%|█████████▎| 520/560 [07:23<00:30,  1.31it/s]{'eval_loss': 0.12679582834243774, 'eval_runtime': 0.8919, 'eval_samples_per_second': 112.119, 'eval_steps_per_second': 14.575, 'epoch': 8.53}
外层迭代结束！
外层迭代结束！
{'loss': 0.0351, 'learning_rate': 4.11764705882353e-05, 'epoch': 8.71}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0222, 'learning_rate': 3.529411764705882e-05, 'epoch': 8.89}
外层迭代结束！
外层迭代结束！
{'loss': 0.0232, 'learning_rate': 2.941176470588235e-05, 'epoch': 9.07}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0131, 'learning_rate': 2.352941176470588e-05, 'epoch': 9.24}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.83it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.95it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.08it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.55it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.31it/s][A                                                 
                                               [A 93%|█████████▎| 520/560 [07:24<00:30,  1.31it/s]
100%|██████████| 13/13 [00:00<00:00, 15.31it/s][A
                                               [A 93%|█████████▎| 521/560 [07:24<00:46,  1.19s/it] 93%|█████████▎| 522/560 [07:25<00:39,  1.05s/it] 93%|█████████▎| 523/560 [07:26<00:34,  1.06it/s] 94%|█████████▎| 524/560 [07:27<00:31,  1.15it/s] 94%|█████████▍| 525/560 [07:28<00:33,  1.04it/s] 94%|█████████▍| 526/560 [07:28<00:30,  1.13it/s] 94%|█████████▍| 527/560 [07:29<00:27,  1.20it/s] 94%|█████████▍| 528/560 [07:30<00:25,  1.25it/s] 94%|█████████▍| 529/560 [07:31<00:27,  1.11it/s] 95%|█████████▍| 530/560 [07:32<00:25,  1.18it/s]                                                  95%|█████████▍| 530/560 [07:32<00:25,  1.18it/s] 95%|█████████▍| 531/560 [07:32<00:23,  1.25it/s] 95%|█████████▌| 532/560 [07:33<00:21,  1.29it/s] 95%|█████████▌| 533/560 [07:34<00:23,  1.17it/s] 95%|█████████▌| 534/560 [07:35<00:20,  1.24it/s] 96%|█████████▌| 535/560 [07:36<00:19,  1.29it/s] 96%|█████████▌| 536/560 [07:36<00:18,  1.33it/s] 96%|█████████▌| 537/560 [07:37<00:20,  1.14it/s] 96%|█████████▌| 538/560 [07:38<00:18,  1.22it/s] 96%|█████████▋| 539/560 [07:39<00:16,  1.26it/s] 96%|█████████▋| 540/560 [07:40<00:15,  1.30it/s]                                                  96%|█████████▋| 540/560 [07:40<00:15,  1.30it/s] 97%|█████████▋| 541/560 [07:41<00:16,  1.13it/s] 97%|█████████▋| 542/560 [07:41<00:14,  1.20it/s] 97%|█████████▋| 543/560 [07:42<00:13,  1.26it/s] 97%|█████████▋| 544/560 [07:43<00:12,  1.31it/s] 97%|█████████▋| 545/560 [07:44<00:13,  1.14it/s] 98%|█████████▊| 546/560 [07:45<00:11,  1.21it/s] 98%|█████████▊| 547/560 [07:45<00:10,  1.26it/s] 98%|█████████▊| 548/560 [07:46<00:09,  1.31it/s] 98%|█████████▊| 549/560 [07:47<00:09,  1.18it/s] 98%|█████████▊| 550/560 [07:48<00:08,  1.24it/s]                                                  98%|█████████▊| 550/560 [07:48<00:08,  1.24it/s] 98%|█████████▊| 551/560 [07:49<00:06,  1.29it/s] 99%|█████████▊| 552/560 [07:49<00:06,  1.32it/s] 99%|█████████▉| 553/560 [07:50<00:06,  1.14it/s] 99%|█████████▉| 554/560 [07:51<00:04,  1.21it/s] 99%|█████████▉| 555/560 [07:52<00:03,  1.26it/s] 99%|█████████▉| 556/560 [07:53<00:03,  1.31it/s] 99%|█████████▉| 557/560 [07:54<00:02,  1.13it/s]100%|█████████▉| 558/560 [07:54<00:01,  1.21it/s]100%|█████████▉| 559/560 [07:55<00:00,  1.26it/s]100%|██████████| 560/560 [07:56<00:00,  1.31it/s]                                                 100%|██████████| 560/560 [07:56<00:00,  1.31it/s]{'eval_loss': 0.12982717156410217, 'eval_runtime': 0.8918, 'eval_samples_per_second': 112.135, 'eval_steps_per_second': 14.577, 'epoch': 9.24}
外层迭代结束！
外层迭代结束！
{'loss': 0.019, 'learning_rate': 1.764705882352941e-05, 'epoch': 9.42}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0221, 'learning_rate': 1.176470588235294e-05, 'epoch': 9.6}
外层迭代结束！
外层迭代结束！
{'loss': 0.0262, 'learning_rate': 5.88235294117647e-06, 'epoch': 9.78}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0219, 'learning_rate': 0.0, 'epoch': 9.96}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.86it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.01it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.08it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.55it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.27it/s][A                                                 
                                               [A100%|██████████| 560/560 [07:57<00:00,  1.31it/s]
100%|██████████| 13/13 [00:00<00:00, 15.27it/s][A
                                               [AThere were missing keys in the checkpoint model loaded: ['base_model.model.shared.weight', 'base_model.model.encoder.embed_tokens.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.encoder.block.0.layer.0.layer_norm.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.0.layer.1.layer_norm.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.1.layer.0.layer_norm.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.1.layer.1.layer_norm.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.2.layer.0.layer_norm.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.2.layer.1.layer_norm.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.3.layer.0.layer_norm.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.3.layer.1.layer_norm.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.4.layer.0.layer_norm.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.4.layer.1.layer_norm.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.5.layer.0.layer_norm.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.5.layer.1.layer_norm.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.6.layer.0.layer_norm.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.6.layer.1.layer_norm.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.7.layer.0.layer_norm.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.7.layer.1.layer_norm.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.8.layer.0.layer_norm.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.8.layer.1.layer_norm.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.9.layer.0.layer_norm.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.9.layer.1.layer_norm.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.10.layer.0.layer_norm.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.10.layer.1.layer_norm.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.11.layer.0.layer_norm.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.11.layer.1.layer_norm.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.12.layer.0.layer_norm.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.12.layer.1.layer_norm.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.13.layer.0.layer_norm.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.13.layer.1.layer_norm.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.14.layer.0.layer_norm.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.14.layer.1.layer_norm.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.15.layer.0.layer_norm.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.15.layer.1.layer_norm.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.16.layer.0.layer_norm.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.16.layer.1.layer_norm.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.17.layer.0.layer_norm.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.17.layer.1.layer_norm.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.18.layer.0.layer_norm.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.18.layer.1.layer_norm.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.19.layer.0.layer_norm.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.19.layer.1.layer_norm.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.20.layer.0.layer_norm.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.20.layer.1.layer_norm.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.21.layer.0.layer_norm.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.21.layer.1.layer_norm.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.22.layer.0.layer_norm.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.22.layer.1.layer_norm.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.23.layer.0.layer_norm.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.23.layer.1.layer_norm.weight', 'base_model.model.encoder.final_layer_norm.weight', 'base_model.model.decoder.embed_tokens.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.decoder.block.0.layer.0.layer_norm.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.0.layer.1.layer_norm.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.0.layer.2.layer_norm.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.1.layer.0.layer_norm.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.1.layer.1.layer_norm.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.1.layer.2.layer_norm.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.2.layer.0.layer_norm.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.2.layer.1.layer_norm.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.2.layer.2.layer_norm.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.3.layer.0.layer_norm.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.3.layer.1.layer_norm.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.3.layer.2.layer_norm.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.4.layer.0.layer_norm.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.4.layer.1.layer_norm.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.4.layer.2.layer_norm.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.5.layer.0.layer_norm.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.5.layer.1.layer_norm.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.5.layer.2.layer_norm.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.6.layer.0.layer_norm.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.6.layer.1.layer_norm.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.6.layer.2.layer_norm.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.7.layer.0.layer_norm.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.7.layer.1.layer_norm.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.7.layer.2.layer_norm.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.8.layer.0.layer_norm.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.8.layer.1.layer_norm.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.8.layer.2.layer_norm.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.9.layer.0.layer_norm.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.9.layer.1.layer_norm.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.9.layer.2.layer_norm.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.10.layer.0.layer_norm.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.10.layer.1.layer_norm.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.10.layer.2.layer_norm.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.11.layer.0.layer_norm.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.11.layer.1.layer_norm.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.11.layer.2.layer_norm.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.12.layer.0.layer_norm.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.12.layer.1.layer_norm.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.12.layer.2.layer_norm.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.13.layer.0.layer_norm.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.13.layer.1.layer_norm.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.13.layer.2.layer_norm.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.14.layer.0.layer_norm.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.14.layer.1.layer_norm.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.14.layer.2.layer_norm.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.15.layer.0.layer_norm.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.15.layer.1.layer_norm.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.15.layer.2.layer_norm.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.16.layer.0.layer_norm.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.16.layer.1.layer_norm.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.16.layer.2.layer_norm.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.17.layer.0.layer_norm.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.17.layer.1.layer_norm.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.17.layer.2.layer_norm.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.18.layer.0.layer_norm.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.18.layer.1.layer_norm.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.18.layer.2.layer_norm.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.19.layer.0.layer_norm.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.19.layer.1.layer_norm.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.19.layer.2.layer_norm.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.20.layer.0.layer_norm.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.20.layer.1.layer_norm.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.20.layer.2.layer_norm.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.21.layer.0.layer_norm.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.21.layer.1.layer_norm.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.21.layer.2.layer_norm.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.22.layer.0.layer_norm.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.22.layer.1.layer_norm.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.22.layer.2.layer_norm.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.23.layer.0.layer_norm.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.23.layer.1.layer_norm.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.23.layer.2.layer_norm.weight', 'base_model.model.decoder.final_layer_norm.weight', 'base_model.model.lm_head.weight'].
There were unexpected keys in the checkpoint model loaded: ['base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.weight'].
                                                 100%|██████████| 560/560 [07:57<00:00,  1.31it/s]100%|██████████| 560/560 [07:57<00:00,  1.17it/s]
{'eval_loss': 0.1338767409324646, 'eval_runtime': 0.8907, 'eval_samples_per_second': 112.274, 'eval_steps_per_second': 14.596, 'epoch': 9.96}
{'train_runtime': 477.9418, 'train_samples_per_second': 18.831, 'train_steps_per_second': 1.172, 'train_loss': 0.07877204117498228, 'epoch': 9.96}

 If there's a warning about missing keys above, please disregard :)
Found cached dataset json (/data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 16
micro_batch_size: 4
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: boolqa... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/5-boolqa
current data path: ./data_longsequence/train/boolqa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 171.18it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 988.06it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 902.97it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 933.31it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 946.37it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400, 选择的样本数量：8
task id: 4, history data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 1035.37it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b05edc432aa3560.arrow
总样本数：1000, 选择的样本数量：20
lora_weights: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/4-qqp

pre-trained model's BOS EOS and PAD token id: None 1 0  => It should be 1,2,none
continual fine tune lora!
trainable params: 2359296 || all params: 740027392 || trainable%: 0.31881198257050464
训练数据总量：900
验证数据总量：100
Map:   0%|          | 0/900 [00:00<?, ? examples/s]/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3597: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  "`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your "
Map: 100%|██████████| 900/900 [00:00<00:00, 6143.86 examples/s]                                                               Map:   0%|          | 0/100 [00:00<?, ? examples/s]                                                   Map:   0%|          | 0/73 [00:00<?, ? examples/s]                                                  memory data loader 2
  0%|          | 0/560 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Traceback (most recent call last):
  File "finetune_bi-level_t5lora.py", line 333, in <module>
    fire.Fire(train)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/fire/core.py", line 141, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/fire/core.py", line 480, in _Fire
    target=component.__name__)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/fire/core.py", line 691, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "finetune_bi-level_t5lora.py", line 321, in train
    trainer.train(resume_from_checkpoint=resume_from_checkpoint)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/trainer.py", line 1762, in train
    ignore_keys_for_eval=ignore_keys_for_eval,
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/trainer.py", line 2043, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/trainer.py", line 2902, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/trainer.py", line 2946, in compute_loss
    outputs = model(**inputs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/peft/peft_model.py", line 880, in forward
    **kwargs,
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = old_forward(*args, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/models/t5/modeling_t5.py", line 1686, in forward
    return_dict=return_dict,
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = old_forward(*args, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/models/t5/modeling_t5.py", line 1097, in forward
    output_attentions=output_attentions,
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = old_forward(*args, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/models/t5/modeling_t5.py", line 700, in forward
    output_attentions=output_attentions,
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = old_forward(*args, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/models/t5/modeling_t5.py", line 607, in forward
    output_attentions=output_attentions,
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = old_forward(*args, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/models/t5/modeling_t5.py", line 564, in forward
    attn_weights, p=self.dropout, training=self.training
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/torch/nn/functional.py", line 1279, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
RuntimeError: CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 23.48 GiB total capacity; 21.32 GiB already allocated; 9.38 MiB free; 21.69 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  0%|          | 0/560 [00:01<?, ?it/s]Found cached dataset json (/data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 16
micro_batch_size: 4
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: rte... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/6-rte
current data path: ./data_longsequence/train/rte_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 183.60it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 802.74it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 713.80it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 629.11it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 623.22it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400, 选择的样本数量：8
task id: 4, history data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 843.42it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b05edc432aa3560.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 5, history data path: ./data_longsequence/train/boolqa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 508.40it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-856891a4945fd30a.arrow
总样本数：1000, 选择的样本数量：20
lora_weights: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/5-boolqa

pre-trained model's BOS EOS and PAD token id: None 1 0  => It should be 1,2,none
Traceback (most recent call last):
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/peft/utils/config.py", line 106, in from_pretrained
    config_file = hf_hub_download(pretrained_model_name_or_path, CONFIG_NAME, subfolder=subfolder)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/huggingface_hub/utils/_validators.py", line 112, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/huggingface_hub/utils/_validators.py", line 161, in validate_repo_id
    "Repo id must be in the form 'repo_name' or 'namespace/repo_name':"
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './checkpoint_files/t5largelora_bilevel_dataset_id_1/5-boolqa'. Use `repo_type` argument if needed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "finetune_bi-level_t5lora.py", line 333, in <module>
    fire.Fire(train)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/fire/core.py", line 141, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/fire/core.py", line 480, in _Fire
    target=component.__name__)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/fire/core.py", line 691, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "finetune_bi-level_t5lora.py", line 220, in train
    model = PeftModel.from_pretrained(model, lora_weights, is_trainable=True)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/peft/peft_model.py", line 164, in from_pretrained
    PeftConfig.from_pretrained(model_id, subfolder=kwargs.get("subfolder", None)).peft_type
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/peft/utils/config.py", line 108, in from_pretrained
    raise ValueError(f"Can't find '{CONFIG_NAME}' at '{pretrained_model_name_or_path}'")
ValueError: Can't find 'adapter_config.json' at './checkpoint_files/t5largelora_bilevel_dataset_id_1/5-boolqa'
Found cached dataset json (/data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 16
micro_batch_size: 4
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: imdb... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/7-imdb
current data path: ./data_longsequence/train/imdb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 207.54it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 1006.31it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 859.84it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 251.68it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 383.57it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400, 选择的样本数量：8
task id: 4, history data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 530.59it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b05edc432aa3560.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 5, history data path: ./data_longsequence/train/boolqa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 711.62it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-856891a4945fd30a.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 6, history data path: ./data_longsequence/train/rte_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 561.04it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-239b26a3aab39f27.arrow
总样本数：1000, 选择的样本数量：20
lora_weights dir ./checkpoint_files/t5largelora_bilevel_dataset_id_1/6-rte not find!
Found cached dataset json (/data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 16
micro_batch_size: 4
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: yelp... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/8-yelp
current data path: ./data_longsequence/train/yelp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 348.10it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 412.62it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 552.68it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 492.35it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 803.81it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400, 选择的样本数量：8
task id: 4, history data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 659.59it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b05edc432aa3560.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 5, history data path: ./data_longsequence/train/boolqa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 548.92it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-856891a4945fd30a.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 6, history data path: ./data_longsequence/train/rte_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 663.55it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-239b26a3aab39f27.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 7, history data path: ./data_longsequence/train/imdb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 614.55it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-143a4706a27855d0.arrow
总样本数：1000, 选择的样本数量：20
lora_weights dir ./checkpoint_files/t5largelora_bilevel_dataset_id_1/7-imdb not find!
Found cached dataset json (/data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 16
micro_batch_size: 4
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: amazon... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/9-amazon
current data path: ./data_longsequence/train/amazon_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 166.52it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 1100.58it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 868.57it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 829.41it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 836.52it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400, 选择的样本数量：8
task id: 4, history data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 526.92it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b05edc432aa3560.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 5, history data path: ./data_longsequence/train/boolqa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 535.53it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-856891a4945fd30a.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 6, history data path: ./data_longsequence/train/rte_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 556.64it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-239b26a3aab39f27.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 7, history data path: ./data_longsequence/train/imdb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 885.25it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-143a4706a27855d0.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 8, history data path: ./data_longsequence/train/yelp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 894.69it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-dff3ce2f55261429.arrow
总样本数：1000, 选择的样本数量：20
lora_weights dir ./checkpoint_files/t5largelora_bilevel_dataset_id_1/8-yelp not find!
Found cached dataset json (/data_8T2/yujie/cache/json/default-cc74d192d9f59811/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 16
micro_batch_size: 4
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: sst-2... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/10-sst-2
current data path: ./data_longsequence/train/sst-2_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 296.56it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 942.33it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 1072.16it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 795.88it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 465.31it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400, 选择的样本数量：8
task id: 4, history data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 464.79it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b05edc432aa3560.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 5, history data path: ./data_longsequence/train/boolqa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 457.00it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-856891a4945fd30a.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 6, history data path: ./data_longsequence/train/rte_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 687.48it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-239b26a3aab39f27.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 7, history data path: ./data_longsequence/train/imdb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 830.39it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-143a4706a27855d0.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 8, history data path: ./data_longsequence/train/yelp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 924.67it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-dff3ce2f55261429.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 9, history data path: ./data_longsequence/train/amazon_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 527.06it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-14b5d8e8282d70c1.arrow
总样本数：1000, 选择的样本数量：20
lora_weights dir ./checkpoint_files/t5largelora_bilevel_dataset_id_1/9-amazon not find!
Found cached dataset json (/data_8T2/yujie/cache/json/default-939986c5f8670c09/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 16
micro_batch_size: 4
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: dbpedia... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/11-dbpedia
current data path: ./data_longsequence/train/dbpedia_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 192.00it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 520.06it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 590.75it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 754.51it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 456.95it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400, 选择的样本数量：8
task id: 4, history data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 545.57it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b05edc432aa3560.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 5, history data path: ./data_longsequence/train/boolqa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 877.29it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-856891a4945fd30a.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 6, history data path: ./data_longsequence/train/rte_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 684.34it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-239b26a3aab39f27.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 7, history data path: ./data_longsequence/train/imdb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 424.70it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-143a4706a27855d0.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 8, history data path: ./data_longsequence/train/yelp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 997.69it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-dff3ce2f55261429.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 9, history data path: ./data_longsequence/train/amazon_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 521.87it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-14b5d8e8282d70c1.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-cc74d192d9f59811/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 10, history data path: ./data_longsequence/train/sst-2_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 614.82it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-cc74d192d9f59811/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-18a91adaaf40bd9d.arrow
总样本数：1000, 选择的样本数量：20
lora_weights dir ./checkpoint_files/t5largelora_bilevel_dataset_id_1/10-sst-2 not find!
Found cached dataset json (/data_8T2/yujie/cache/json/default-f06c0783431d596c/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 16
micro_batch_size: 4
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: agnews... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/12-agnews
current data path: ./data_longsequence/train/agnews_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 192.63it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 1008.49it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 810.49it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 738.30it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 1111.66it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400, 选择的样本数量：8
task id: 4, history data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 530.66it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b05edc432aa3560.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 5, history data path: ./data_longsequence/train/boolqa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 623.04it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-856891a4945fd30a.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 6, history data path: ./data_longsequence/train/rte_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 485.45it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-239b26a3aab39f27.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 7, history data path: ./data_longsequence/train/imdb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 679.02it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-143a4706a27855d0.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 8, history data path: ./data_longsequence/train/yelp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 718.82it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-dff3ce2f55261429.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 9, history data path: ./data_longsequence/train/amazon_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 601.33it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-14b5d8e8282d70c1.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-cc74d192d9f59811/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 10, history data path: ./data_longsequence/train/sst-2_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 634.73it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-cc74d192d9f59811/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-18a91adaaf40bd9d.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-939986c5f8670c09/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 11, history data path: ./data_longsequence/train/dbpedia_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 631.58it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-939986c5f8670c09/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-fc4f5d125dd42971.arrow
总样本数：1000, 选择的样本数量：20
lora_weights dir ./checkpoint_files/t5largelora_bilevel_dataset_id_1/11-dbpedia not find!
Found cached dataset json (/data_8T2/yujie/cache/json/default-5508fa5191315695/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 16
micro_batch_size: 4
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: multirc... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/13-multirc
current data path: ./data_longsequence/train/multirc_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 321.92it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 482.66it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 860.37it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 651.80it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 843.58it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400, 选择的样本数量：8
task id: 4, history data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 862.32it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b05edc432aa3560.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 5, history data path: ./data_longsequence/train/boolqa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 536.29it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-856891a4945fd30a.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 6, history data path: ./data_longsequence/train/rte_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 600.04it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-239b26a3aab39f27.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 7, history data path: ./data_longsequence/train/imdb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 724.66it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-143a4706a27855d0.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 8, history data path: ./data_longsequence/train/yelp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 585.47it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-dff3ce2f55261429.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 9, history data path: ./data_longsequence/train/amazon_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 451.58it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-14b5d8e8282d70c1.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-cc74d192d9f59811/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 10, history data path: ./data_longsequence/train/sst-2_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 734.68it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-cc74d192d9f59811/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-18a91adaaf40bd9d.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-939986c5f8670c09/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 11, history data path: ./data_longsequence/train/dbpedia_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 471.75it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-939986c5f8670c09/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-fc4f5d125dd42971.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-f06c0783431d596c/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 12, history data path: ./data_longsequence/train/agnews_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 418.55it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-f06c0783431d596c/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-f755e09198190cfb.arrow
总样本数：1000, 选择的样本数量：20
lora_weights dir ./checkpoint_files/t5largelora_bilevel_dataset_id_1/12-agnews not find!
Found cached dataset json (/data_8T2/yujie/cache/json/default-00956829d37bfea0/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 16
micro_batch_size: 4
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: yahoo... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/14-yahoo
current data path: ./data_longsequence/train/yahoo_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 180.73it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 682.78it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 512.50it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 604.19it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 517.24it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400, 选择的样本数量：8
task id: 4, history data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 904.53it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b05edc432aa3560.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 5, history data path: ./data_longsequence/train/boolqa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 525.73it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-856891a4945fd30a.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 6, history data path: ./data_longsequence/train/rte_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 489.36it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-239b26a3aab39f27.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 7, history data path: ./data_longsequence/train/imdb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 522.33it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-143a4706a27855d0.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 8, history data path: ./data_longsequence/train/yelp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 518.90it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-dff3ce2f55261429.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 9, history data path: ./data_longsequence/train/amazon_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 534.37it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-14b5d8e8282d70c1.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-cc74d192d9f59811/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 10, history data path: ./data_longsequence/train/sst-2_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 615.63it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-cc74d192d9f59811/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-18a91adaaf40bd9d.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-939986c5f8670c09/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 11, history data path: ./data_longsequence/train/dbpedia_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 704.57it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-939986c5f8670c09/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-fc4f5d125dd42971.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-f06c0783431d596c/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 12, history data path: ./data_longsequence/train/agnews_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 543.94it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-f06c0783431d596c/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-f755e09198190cfb.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-5508fa5191315695/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 13, history data path: ./data_longsequence/train/multirc_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 547.77it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-5508fa5191315695/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-757599f6cf9ea2cf.arrow
总样本数：1000, 选择的样本数量：20
lora_weights dir ./checkpoint_files/t5largelora_bilevel_dataset_id_1/13-multirc not find!
nohup: ignoring input
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 8
micro_batch_size: 2
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: mnli... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/0-mnli
current data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 797.85it/s]
Loading cached split indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-4ee99fcb4007da6d.arrow and /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-9909dc315b7babf3.arrow
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-741b2d720f9d2345.arrow
Loading cached processed dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-727facfe51b4cf36.arrow
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-a8253341f0d5edc2.arrow
Loading cached processed dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-f6544b4ae6301e5c.arrow
总样本数：1000
lora_weights: 

pre-trained model's BOS EOS and PAD token id: None 1 0  => It should be 1,2,none
fine tune lora from scratch!
trainable params: 2359296 || all params: 740027392 || trainable%: 0.31881198257050464
训练数据总量：900
验证数据总量：100
  0%|          | 0/1120 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/1120 [00:01<27:58,  1.50s/it]  0%|          | 2/1120 [00:02<20:23,  1.09s/it]  0%|          | 3/1120 [00:03<17:54,  1.04it/s]  0%|          | 4/1120 [00:03<16:41,  1.11it/s]  0%|          | 5/1120 [00:04<16:02,  1.16it/s]  1%|          | 6/1120 [00:05<15:51,  1.17it/s]  1%|          | 7/1120 [00:06<15:37,  1.19it/s]  1%|          | 8/1120 [00:07<15:17,  1.21it/s]  1%|          | 9/1120 [00:07<15:09,  1.22it/s]  1%|          | 10/1120 [00:08<14:56,  1.24it/s]                                                   1%|          | 10/1120 [00:08<14:56,  1.24it/s]  1%|          | 11/1120 [00:09<14:53,  1.24it/s]  1%|          | 12/1120 [00:10<14:56,  1.24it/s]  1%|          | 13/1120 [00:11<14:51,  1.24it/s]  1%|▏         | 14/1120 [00:11<14:51,  1.24it/s]  1%|▏         | 15/1120 [00:12<14:45,  1.25it/s]  1%|▏         | 16/1120 [00:13<14:44,  1.25it/s]  2%|▏         | 17/1120 [00:14<14:40,  1.25it/s]  2%|▏         | 18/1120 [00:15<14:38,  1.25it/s]  2%|▏         | 19/1120 [00:15<14:38,  1.25it/s]  2%|▏         | 20/1120 [00:16<14:37,  1.25it/s]                                                   2%|▏         | 20/1120 [00:16<14:37,  1.25it/s]  2%|▏         | 21/1120 [00:17<14:39,  1.25it/s]  2%|▏         | 22/1120 [00:18<14:40,  1.25it/s]  2%|▏         | 23/1120 [00:19<14:35,  1.25it/s]  2%|▏         | 24/1120 [00:19<14:39,  1.25it/s]  2%|▏         | 25/1120 [00:20<14:35,  1.25it/s]  2%|▏         | 26/1120 [00:21<14:32,  1.25it/s]  2%|▏         | 27/1120 [00:22<14:34,  1.25it/s]  2%|▎         | 28/1120 [00:23<14:31,  1.25it/s]  3%|▎         | 29/1120 [00:23<14:34,  1.25it/s]  3%|▎         | 30/1120 [00:24<14:31,  1.25it/s]                                                   3%|▎         | 30/1120 [00:24<14:31,  1.25it/s]  3%|▎         | 31/1120 [00:25<14:30,  1.25it/s]  3%|▎         | 32/1120 [00:26<14:29,  1.25it/s]  3%|▎         | 33/1120 [00:27<14:25,  1.26it/s]  3%|▎         | 34/1120 [00:27<14:25,  1.26it/s]  3%|▎         | 35/1120 [00:28<14:23,  1.26it/s]  3%|▎         | 36/1120 [00:29<14:27,  1.25it/s]  3%|▎         | 37/1120 [00:30<14:29,  1.25it/s]  3%|▎         | 38/1120 [00:31<14:20,  1.26it/s]  3%|▎         | 39/1120 [00:31<14:23,  1.25it/s]  4%|▎         | 40/1120 [00:32<14:22,  1.25it/s]                                                   4%|▎         | 40/1120 [00:32<14:22,  1.25it/s]{'loss': 3.2776, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.09}
{'loss': 3.3727, 'learning_rate': 0.00011999999999999999, 'epoch': 0.18}
{'loss': 1.8124, 'learning_rate': 0.00017999999999999998, 'epoch': 0.27}
{'loss': 0.7402, 'learning_rate': 0.00023999999999999998, 'epoch': 0.36}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 18.12it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 14.71it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 13.32it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 12.63it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 12.41it/s][A
100%|██████████| 13/13 [00:01<00:00, 12.29it/s][A                                                 
                                               [A  4%|▎         | 40/1120 [00:33<14:22,  1.25it/s]
100%|██████████| 13/13 [00:01<00:00, 12.29it/s][A
                                               [A  4%|▎         | 41/1120 [00:34<21:10,  1.18s/it]  4%|▍         | 42/1120 [00:35<19:12,  1.07s/it]  4%|▍         | 43/1120 [00:36<17:49,  1.01it/s]  4%|▍         | 44/1120 [00:37<16:42,  1.07it/s]  4%|▍         | 45/1120 [00:38<16:04,  1.11it/s]  4%|▍         | 46/1120 [00:38<15:29,  1.16it/s]  4%|▍         | 47/1120 [00:39<15:05,  1.18it/s]  4%|▍         | 48/1120 [00:40<14:51,  1.20it/s]  4%|▍         | 49/1120 [00:41<14:35,  1.22it/s]  4%|▍         | 50/1120 [00:42<14:38,  1.22it/s]                                                   4%|▍         | 50/1120 [00:42<14:38,  1.22it/s]  5%|▍         | 51/1120 [00:42<14:27,  1.23it/s]  5%|▍         | 52/1120 [00:43<14:30,  1.23it/s]  5%|▍         | 53/1120 [00:44<14:23,  1.24it/s]  5%|▍         | 54/1120 [00:45<14:18,  1.24it/s]  5%|▍         | 55/1120 [00:46<14:20,  1.24it/s]  5%|▌         | 56/1120 [00:46<14:25,  1.23it/s]  5%|▌         | 57/1120 [00:47<14:21,  1.23it/s]  5%|▌         | 58/1120 [00:48<14:14,  1.24it/s]  5%|▌         | 59/1120 [00:49<14:04,  1.26it/s]  5%|▌         | 60/1120 [00:50<14:09,  1.25it/s]                                                   5%|▌         | 60/1120 [00:50<14:09,  1.25it/s]  5%|▌         | 61/1120 [00:50<14:06,  1.25it/s]  6%|▌         | 62/1120 [00:51<14:03,  1.25it/s]  6%|▌         | 63/1120 [00:52<14:01,  1.26it/s]  6%|▌         | 64/1120 [00:53<13:58,  1.26it/s]  6%|▌         | 65/1120 [00:54<14:01,  1.25it/s]  6%|▌         | 66/1120 [00:54<13:58,  1.26it/s]  6%|▌         | 67/1120 [00:55<13:57,  1.26it/s]  6%|▌         | 68/1120 [00:56<13:57,  1.26it/s]  6%|▌         | 69/1120 [00:57<13:53,  1.26it/s]  6%|▋         | 70/1120 [00:58<13:55,  1.26it/s]                                                   6%|▋         | 70/1120 [00:58<13:55,  1.26it/s]  6%|▋         | 71/1120 [00:58<13:54,  1.26it/s]  6%|▋         | 72/1120 [00:59<13:53,  1.26it/s]  7%|▋         | 73/1120 [01:00<14:01,  1.24it/s]  7%|▋         | 74/1120 [01:01<13:52,  1.26it/s]  7%|▋         | 75/1120 [01:01<13:54,  1.25it/s]  7%|▋         | 76/1120 [01:02<13:49,  1.26it/s]  7%|▋         | 77/1120 [01:03<13:48,  1.26it/s]  7%|▋         | 78/1120 [01:04<13:50,  1.25it/s]  7%|▋         | 79/1120 [01:05<13:50,  1.25it/s]  7%|▋         | 80/1120 [01:05<13:51,  1.25it/s]                                                   7%|▋         | 80/1120 [01:05<13:51,  1.25it/s]{'eval_loss': 0.5703294277191162, 'eval_runtime': 1.0931, 'eval_samples_per_second': 91.485, 'eval_steps_per_second': 11.893, 'epoch': 0.36}
{'loss': 0.4142, 'learning_rate': 0.0003, 'epoch': 0.44}
{'loss': 0.2708, 'learning_rate': 0.00029719626168224294, 'epoch': 0.53}
{'loss': 0.219, 'learning_rate': 0.00029439252336448596, 'epoch': 0.62}
{'loss': 0.1584, 'learning_rate': 0.0002915887850467289, 'epoch': 0.71}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.88it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.51it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.96it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.65it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.50it/s][A                                                 
                                               [A  7%|▋         | 80/1120 [01:06<13:51,  1.25it/s]
100%|██████████| 13/13 [00:00<00:00, 15.50it/s][A
                                               [A  7%|▋         | 81/1120 [01:07<19:04,  1.10s/it]  7%|▋         | 82/1120 [01:08<17:30,  1.01s/it]  7%|▋         | 83/1120 [01:09<16:14,  1.06it/s]  8%|▊         | 84/1120 [01:10<15:34,  1.11it/s]  8%|▊         | 85/1120 [01:10<14:58,  1.15it/s]  8%|▊         | 86/1120 [01:11<14:35,  1.18it/s]  8%|▊         | 87/1120 [01:12<14:21,  1.20it/s]  8%|▊         | 88/1120 [01:13<13:59,  1.23it/s]  8%|▊         | 89/1120 [01:14<13:56,  1.23it/s]  8%|▊         | 90/1120 [01:14<13:50,  1.24it/s]                                                   8%|▊         | 90/1120 [01:14<13:50,  1.24it/s]  8%|▊         | 91/1120 [01:15<13:46,  1.25it/s]  8%|▊         | 92/1120 [01:16<13:48,  1.24it/s]  8%|▊         | 93/1120 [01:17<13:38,  1.26it/s]  8%|▊         | 94/1120 [01:18<13:43,  1.25it/s]  8%|▊         | 95/1120 [01:18<13:39,  1.25it/s]  9%|▊         | 96/1120 [01:19<13:42,  1.25it/s]  9%|▊         | 97/1120 [01:20<13:45,  1.24it/s]  9%|▉         | 98/1120 [01:21<13:32,  1.26it/s]  9%|▉         | 99/1120 [01:22<13:37,  1.25it/s]  9%|▉         | 100/1120 [01:22<13:33,  1.25it/s]                                                    9%|▉         | 100/1120 [01:22<13:33,  1.25it/s]  9%|▉         | 101/1120 [01:23<13:30,  1.26it/s]  9%|▉         | 102/1120 [01:24<13:33,  1.25it/s]  9%|▉         | 103/1120 [01:25<13:23,  1.27it/s]  9%|▉         | 104/1120 [01:26<13:27,  1.26it/s]  9%|▉         | 105/1120 [01:26<13:25,  1.26it/s]  9%|▉         | 106/1120 [01:27<13:22,  1.26it/s] 10%|▉         | 107/1120 [01:28<13:25,  1.26it/s] 10%|▉         | 108/1120 [01:29<13:16,  1.27it/s] 10%|▉         | 109/1120 [01:30<13:21,  1.26it/s] 10%|▉         | 110/1120 [01:30<13:20,  1.26it/s]                                                   10%|▉         | 110/1120 [01:30<13:20,  1.26it/s] 10%|▉         | 111/1120 [01:31<13:19,  1.26it/s] 10%|█         | 112/1120 [01:32<13:21,  1.26it/s] 10%|█         | 113/1120 [01:33<13:13,  1.27it/s] 10%|█         | 114/1120 [01:34<13:22,  1.25it/s] 10%|█         | 115/1120 [01:34<13:21,  1.25it/s] 10%|█         | 116/1120 [01:35<13:20,  1.25it/s] 10%|█         | 117/1120 [01:36<13:20,  1.25it/s] 11%|█         | 118/1120 [01:37<13:09,  1.27it/s] 11%|█         | 119/1120 [01:37<13:12,  1.26it/s] 11%|█         | 120/1120 [01:38<13:13,  1.26it/s]                                                   11%|█         | 120/1120 [01:38<13:13,  1.26it/s]{'eval_loss': 0.1631976068019867, 'eval_runtime': 0.8888, 'eval_samples_per_second': 112.507, 'eval_steps_per_second': 14.626, 'epoch': 0.71}
{'loss': 0.1691, 'learning_rate': 0.00028878504672897194, 'epoch': 0.8}
{'loss': 0.1557, 'learning_rate': 0.0002859813084112149, 'epoch': 0.89}
{'loss': 0.1871, 'learning_rate': 0.0002831775700934579, 'epoch': 0.98}
{'loss': 0.1858, 'learning_rate': 0.0002803738317757009, 'epoch': 1.07}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 22.03it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.44it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.58it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.79it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.05it/s][A                                                  
                                               [A 11%|█         | 120/1120 [01:39<13:13,  1.26it/s]
100%|██████████| 13/13 [00:00<00:00, 15.05it/s][A
                                               [A 11%|█         | 121/1120 [01:40<18:16,  1.10s/it] 11%|█         | 122/1120 [01:41<16:38,  1.00s/it] 11%|█         | 123/1120 [01:42<15:35,  1.07it/s] 11%|█         | 124/1120 [01:42<14:51,  1.12it/s] 11%|█         | 125/1120 [01:43<14:18,  1.16it/s] 11%|█▏        | 126/1120 [01:44<13:59,  1.18it/s] 11%|█▏        | 127/1120 [01:45<13:38,  1.21it/s] 11%|█▏        | 128/1120 [01:46<13:29,  1.23it/s] 12%|█▏        | 129/1120 [01:46<13:23,  1.23it/s] 12%|█▏        | 130/1120 [01:47<13:16,  1.24it/s]                                                   12%|█▏        | 130/1120 [01:47<13:16,  1.24it/s] 12%|█▏        | 131/1120 [01:48<13:12,  1.25it/s] 12%|█▏        | 132/1120 [01:49<13:04,  1.26it/s] 12%|█▏        | 133/1120 [01:50<13:09,  1.25it/s] 12%|█▏        | 134/1120 [01:50<13:08,  1.25it/s] 12%|█▏        | 135/1120 [01:51<13:04,  1.26it/s] 12%|█▏        | 136/1120 [01:52<13:03,  1.26it/s] 12%|█▏        | 137/1120 [01:53<12:58,  1.26it/s] 12%|█▏        | 138/1120 [01:54<13:06,  1.25it/s] 12%|█▏        | 139/1120 [01:54<13:05,  1.25it/s] 12%|█▎        | 140/1120 [01:55<13:01,  1.25it/s]                                                   12%|█▎        | 140/1120 [01:55<13:01,  1.25it/s] 13%|█▎        | 141/1120 [01:56<13:02,  1.25it/s] 13%|█▎        | 142/1120 [01:57<13:01,  1.25it/s] 13%|█▎        | 143/1120 [01:58<13:04,  1.25it/s] 13%|█▎        | 144/1120 [01:58<13:04,  1.24it/s] 13%|█▎        | 145/1120 [01:59<12:56,  1.26it/s] 13%|█▎        | 146/1120 [02:00<13:05,  1.24it/s] 13%|█▎        | 147/1120 [02:01<13:01,  1.25it/s] 13%|█▎        | 148/1120 [02:02<13:01,  1.24it/s] 13%|█▎        | 149/1120 [02:02<12:59,  1.25it/s] 13%|█▎        | 150/1120 [02:03<12:58,  1.25it/s]                                                   13%|█▎        | 150/1120 [02:03<12:58,  1.25it/s] 13%|█▎        | 151/1120 [02:04<12:56,  1.25it/s] 14%|█▎        | 152/1120 [02:05<12:50,  1.26it/s] 14%|█▎        | 153/1120 [02:06<12:52,  1.25it/s] 14%|█▍        | 154/1120 [02:06<12:50,  1.25it/s] 14%|█▍        | 155/1120 [02:07<12:41,  1.27it/s] 14%|█▍        | 156/1120 [02:08<12:46,  1.26it/s] 14%|█▍        | 157/1120 [02:09<12:43,  1.26it/s] 14%|█▍        | 158/1120 [02:10<12:46,  1.26it/s] 14%|█▍        | 159/1120 [02:10<12:46,  1.25it/s] 14%|█▍        | 160/1120 [02:11<12:36,  1.27it/s]                                                   14%|█▍        | 160/1120 [02:11<12:36,  1.27it/s]{'eval_loss': 0.14508037269115448, 'eval_runtime': 0.8892, 'eval_samples_per_second': 112.464, 'eval_steps_per_second': 14.62, 'epoch': 1.07}
{'loss': 0.1455, 'learning_rate': 0.0002775700934579439, 'epoch': 1.16}
{'loss': 0.1235, 'learning_rate': 0.00027476635514018686, 'epoch': 1.24}
{'loss': 0.1583, 'learning_rate': 0.0002719626168224299, 'epoch': 1.33}
{'loss': 0.1516, 'learning_rate': 0.00026915887850467284, 'epoch': 1.42}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.87it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.68it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.01it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.62it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.34it/s][A                                                  
                                               [A 14%|█▍        | 160/1120 [02:12<12:36,  1.27it/s]
100%|██████████| 13/13 [00:00<00:00, 15.34it/s][A
                                               [A 14%|█▍        | 161/1120 [02:13<17:26,  1.09s/it] 14%|█▍        | 162/1120 [02:14<16:04,  1.01s/it] 15%|█▍        | 163/1120 [02:15<15:05,  1.06it/s] 15%|█▍        | 164/1120 [02:15<14:23,  1.11it/s] 15%|█▍        | 165/1120 [02:16<13:58,  1.14it/s] 15%|█▍        | 166/1120 [02:17<13:34,  1.17it/s] 15%|█▍        | 167/1120 [02:18<13:20,  1.19it/s] 15%|█▌        | 168/1120 [02:19<13:07,  1.21it/s] 15%|█▌        | 169/1120 [02:19<12:54,  1.23it/s] 15%|█▌        | 170/1120 [02:20<12:46,  1.24it/s]                                                   15%|█▌        | 170/1120 [02:20<12:46,  1.24it/s] 15%|█▌        | 171/1120 [02:21<12:40,  1.25it/s] 15%|█▌        | 172/1120 [02:22<12:39,  1.25it/s] 15%|█▌        | 173/1120 [02:23<12:37,  1.25it/s] 16%|█▌        | 174/1120 [02:23<12:30,  1.26it/s] 16%|█▌        | 175/1120 [02:24<12:30,  1.26it/s] 16%|█▌        | 176/1120 [02:25<12:27,  1.26it/s] 16%|█▌        | 177/1120 [02:26<12:30,  1.26it/s] 16%|█▌        | 178/1120 [02:26<12:30,  1.26it/s] 16%|█▌        | 179/1120 [02:27<12:23,  1.27it/s] 16%|█▌        | 180/1120 [02:28<12:24,  1.26it/s]                                                   16%|█▌        | 180/1120 [02:28<12:24,  1.26it/s] 16%|█▌        | 181/1120 [02:29<12:21,  1.27it/s] 16%|█▋        | 182/1120 [02:30<12:23,  1.26it/s] 16%|█▋        | 183/1120 [02:30<12:22,  1.26it/s] 16%|█▋        | 184/1120 [02:31<12:14,  1.27it/s] 17%|█▋        | 185/1120 [02:32<12:15,  1.27it/s] 17%|█▋        | 186/1120 [02:33<12:27,  1.25it/s] 17%|█▋        | 187/1120 [02:34<12:26,  1.25it/s] 17%|█▋        | 188/1120 [02:34<12:24,  1.25it/s] 17%|█▋        | 189/1120 [02:35<12:17,  1.26it/s] 17%|█▋        | 190/1120 [02:36<12:16,  1.26it/s]                                                   17%|█▋        | 190/1120 [02:36<12:16,  1.26it/s] 17%|█▋        | 191/1120 [02:37<12:18,  1.26it/s] 17%|█▋        | 192/1120 [02:38<12:17,  1.26it/s] 17%|█▋        | 193/1120 [02:38<12:16,  1.26it/s] 17%|█▋        | 194/1120 [02:39<12:08,  1.27it/s] 17%|█▋        | 195/1120 [02:40<12:14,  1.26it/s] 18%|█▊        | 196/1120 [02:41<12:13,  1.26it/s] 18%|█▊        | 197/1120 [02:42<12:13,  1.26it/s] 18%|█▊        | 198/1120 [02:42<12:10,  1.26it/s] 18%|█▊        | 199/1120 [02:43<12:08,  1.26it/s] 18%|█▊        | 200/1120 [02:44<12:08,  1.26it/s]                                                   18%|█▊        | 200/1120 [02:44<12:08,  1.26it/s]{'eval_loss': 0.14187881350517273, 'eval_runtime': 0.8979, 'eval_samples_per_second': 111.366, 'eval_steps_per_second': 14.478, 'epoch': 1.42}
{'loss': 0.1143, 'learning_rate': 0.00026635514018691586, 'epoch': 1.51}
{'loss': 0.1336, 'learning_rate': 0.0002635514018691588, 'epoch': 1.6}
{'loss': 0.1535, 'learning_rate': 0.00026074766355140184, 'epoch': 1.69}
{'loss': 0.1133, 'learning_rate': 0.0002579439252336448, 'epoch': 1.78}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.78it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.13it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.97it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.66it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.35it/s][A                                                  
                                               [A 18%|█▊        | 200/1120 [02:45<12:08,  1.26it/s]
100%|██████████| 13/13 [00:00<00:00, 15.35it/s][A
                                               [A 18%|█▊        | 201/1120 [02:46<16:44,  1.09s/it] 18%|█▊        | 202/1120 [02:47<15:23,  1.01s/it] 18%|█▊        | 203/1120 [02:47<14:22,  1.06it/s] 18%|█▊        | 204/1120 [02:48<13:42,  1.11it/s] 18%|█▊        | 205/1120 [02:49<13:10,  1.16it/s] 18%|█▊        | 206/1120 [02:50<12:50,  1.19it/s] 18%|█▊        | 207/1120 [02:50<12:36,  1.21it/s] 19%|█▊        | 208/1120 [02:51<12:19,  1.23it/s] 19%|█▊        | 209/1120 [02:52<12:14,  1.24it/s] 19%|█▉        | 210/1120 [02:53<12:09,  1.25it/s]                                                   19%|█▉        | 210/1120 [02:53<12:09,  1.25it/s] 19%|█▉        | 211/1120 [02:54<12:13,  1.24it/s] 19%|█▉        | 212/1120 [02:54<12:09,  1.25it/s] 19%|█▉        | 213/1120 [02:55<12:03,  1.25it/s] 19%|█▉        | 214/1120 [02:56<12:05,  1.25it/s] 19%|█▉        | 215/1120 [02:57<12:03,  1.25it/s] 19%|█▉        | 216/1120 [02:58<12:03,  1.25it/s] 19%|█▉        | 217/1120 [02:58<12:02,  1.25it/s] 19%|█▉        | 218/1120 [02:59<11:57,  1.26it/s] 20%|█▉        | 219/1120 [03:00<12:04,  1.24it/s] 20%|█▉        | 220/1120 [03:01<12:01,  1.25it/s]                                                   20%|█▉        | 220/1120 [03:01<12:01,  1.25it/s] 20%|█▉        | 221/1120 [03:02<11:59,  1.25it/s] 20%|█▉        | 222/1120 [03:02<12:00,  1.25it/s] 20%|█▉        | 223/1120 [03:03<11:54,  1.26it/s] 20%|██        | 224/1120 [03:04<11:53,  1.26it/s] 20%|██        | 225/1120 [03:05<11:51,  1.26it/s] 20%|██        | 226/1120 [03:06<11:47,  1.26it/s] 20%|██        | 227/1120 [03:06<11:46,  1.26it/s] 20%|██        | 228/1120 [03:07<11:42,  1.27it/s] 20%|██        | 229/1120 [03:08<11:41,  1.27it/s] 21%|██        | 230/1120 [03:09<11:43,  1.27it/s]                                                   21%|██        | 230/1120 [03:09<11:43,  1.27it/s] 21%|██        | 231/1120 [03:10<11:43,  1.26it/s] 21%|██        | 232/1120 [03:10<11:44,  1.26it/s] 21%|██        | 233/1120 [03:11<11:41,  1.26it/s] 21%|██        | 234/1120 [03:12<11:39,  1.27it/s] 21%|██        | 235/1120 [03:13<11:39,  1.27it/s] 21%|██        | 236/1120 [03:13<11:35,  1.27it/s] 21%|██        | 237/1120 [03:14<11:38,  1.26it/s] 21%|██▏       | 238/1120 [03:15<11:35,  1.27it/s] 21%|██▏       | 239/1120 [03:16<11:36,  1.26it/s] 21%|██▏       | 240/1120 [03:17<11:36,  1.26it/s]                                                   21%|██▏       | 240/1120 [03:17<11:36,  1.26it/s]{'eval_loss': 0.14995139837265015, 'eval_runtime': 0.8879, 'eval_samples_per_second': 112.626, 'eval_steps_per_second': 14.641, 'epoch': 1.78}
{'loss': 0.2084, 'learning_rate': 0.0002551401869158878, 'epoch': 1.87}
{'loss': 0.1346, 'learning_rate': 0.0002523364485981308, 'epoch': 1.96}
{'loss': 0.0743, 'learning_rate': 0.0002495327102803738, 'epoch': 2.04}
{'loss': 0.1322, 'learning_rate': 0.00024672897196261677, 'epoch': 2.13}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.48it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.04it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.26it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.88it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.56it/s][A                                                  
                                               [A 21%|██▏       | 240/1120 [03:18<11:36,  1.26it/s]
100%|██████████| 13/13 [00:00<00:00, 15.56it/s][A
                                               [A 22%|██▏       | 241/1120 [03:18<15:57,  1.09s/it] 22%|██▏       | 242/1120 [03:19<14:34,  1.00it/s] 22%|██▏       | 243/1120 [03:20<13:40,  1.07it/s] 22%|██▏       | 244/1120 [03:21<13:01,  1.12it/s] 22%|██▏       | 245/1120 [03:22<12:31,  1.16it/s] 22%|██▏       | 246/1120 [03:22<12:11,  1.19it/s] 22%|██▏       | 247/1120 [03:23<11:58,  1.22it/s] 22%|██▏       | 248/1120 [03:24<11:48,  1.23it/s] 22%|██▏       | 249/1120 [03:25<11:42,  1.24it/s] 22%|██▏       | 250/1120 [03:26<11:32,  1.26it/s]                                                   22%|██▏       | 250/1120 [03:26<11:32,  1.26it/s] 22%|██▏       | 251/1120 [03:26<11:32,  1.26it/s] 22%|██▎       | 252/1120 [03:27<11:31,  1.26it/s] 23%|██▎       | 253/1120 [03:28<11:28,  1.26it/s] 23%|██▎       | 254/1120 [03:29<11:26,  1.26it/s] 23%|██▎       | 255/1120 [03:29<11:21,  1.27it/s] 23%|██▎       | 256/1120 [03:30<11:22,  1.27it/s] 23%|██▎       | 257/1120 [03:31<11:20,  1.27it/s] 23%|██▎       | 258/1120 [03:32<11:19,  1.27it/s] 23%|██▎       | 259/1120 [03:33<11:24,  1.26it/s] 23%|██▎       | 260/1120 [03:33<11:19,  1.26it/s]                                                   23%|██▎       | 260/1120 [03:33<11:19,  1.26it/s] 23%|██▎       | 261/1120 [03:34<11:21,  1.26it/s] 23%|██▎       | 262/1120 [03:35<11:22,  1.26it/s] 23%|██▎       | 263/1120 [03:36<11:18,  1.26it/s] 24%|██▎       | 264/1120 [03:37<11:17,  1.26it/s] 24%|██▎       | 265/1120 [03:37<11:13,  1.27it/s] 24%|██▍       | 266/1120 [03:38<11:16,  1.26it/s] 24%|██▍       | 267/1120 [03:39<11:15,  1.26it/s] 24%|██▍       | 268/1120 [03:40<11:12,  1.27it/s] 24%|██▍       | 269/1120 [03:41<11:12,  1.27it/s] 24%|██▍       | 270/1120 [03:41<11:10,  1.27it/s]                                                   24%|██▍       | 270/1120 [03:41<11:10,  1.27it/s] 24%|██▍       | 271/1120 [03:42<11:10,  1.27it/s] 24%|██▍       | 272/1120 [03:43<11:09,  1.27it/s] 24%|██▍       | 273/1120 [03:44<11:05,  1.27it/s] 24%|██▍       | 274/1120 [03:44<11:06,  1.27it/s] 25%|██▍       | 275/1120 [03:45<11:06,  1.27it/s] 25%|██▍       | 276/1120 [03:46<11:11,  1.26it/s] 25%|██▍       | 277/1120 [03:47<11:10,  1.26it/s] 25%|██▍       | 278/1120 [03:48<11:07,  1.26it/s] 25%|██▍       | 279/1120 [03:48<11:07,  1.26it/s] 25%|██▌       | 280/1120 [03:49<11:04,  1.26it/s]                                                   25%|██▌       | 280/1120 [03:49<11:04,  1.26it/s]{'eval_loss': 0.14517636597156525, 'eval_runtime': 0.8828, 'eval_samples_per_second': 113.27, 'eval_steps_per_second': 14.725, 'epoch': 2.13}
{'loss': 0.1969, 'learning_rate': 0.0002439252336448598, 'epoch': 2.22}
{'loss': 0.1262, 'learning_rate': 0.00024112149532710278, 'epoch': 2.31}
{'loss': 0.113, 'learning_rate': 0.00023831775700934577, 'epoch': 2.4}
{'loss': 0.1023, 'learning_rate': 0.00023551401869158876, 'epoch': 2.49}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.46it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.91it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.86it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.50it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.30it/s][A                                                  
                                               [A 25%|██▌       | 280/1120 [03:50<11:04,  1.26it/s]
100%|██████████| 13/13 [00:00<00:00, 15.30it/s][A
                                               [A 25%|██▌       | 281/1120 [03:51<15:20,  1.10s/it] 25%|██▌       | 282/1120 [03:52<14:02,  1.01s/it] 25%|██▌       | 283/1120 [03:53<13:08,  1.06it/s] 25%|██▌       | 284/1120 [03:53<12:26,  1.12it/s] 25%|██▌       | 285/1120 [03:54<12:01,  1.16it/s] 26%|██▌       | 286/1120 [03:55<11:42,  1.19it/s] 26%|██▌       | 287/1120 [03:56<11:25,  1.21it/s] 26%|██▌       | 288/1120 [03:57<11:19,  1.22it/s] 26%|██▌       | 289/1120 [03:57<11:10,  1.24it/s] 26%|██▌       | 290/1120 [03:58<11:05,  1.25it/s]                                                   26%|██▌       | 290/1120 [03:58<11:05,  1.25it/s] 26%|██▌       | 291/1120 [03:59<11:02,  1.25it/s] 26%|██▌       | 292/1120 [04:00<11:01,  1.25it/s] 26%|██▌       | 293/1120 [04:01<10:59,  1.25it/s] 26%|██▋       | 294/1120 [04:01<10:56,  1.26it/s] 26%|██▋       | 295/1120 [04:02<10:54,  1.26it/s] 26%|██▋       | 296/1120 [04:03<10:56,  1.26it/s] 27%|██▋       | 297/1120 [04:04<10:49,  1.27it/s] 27%|██▋       | 298/1120 [04:05<10:50,  1.26it/s] 27%|██▋       | 299/1120 [04:05<10:50,  1.26it/s] 27%|██▋       | 300/1120 [04:06<10:48,  1.26it/s]                                                   27%|██▋       | 300/1120 [04:06<10:48,  1.26it/s] 27%|██▋       | 301/1120 [04:07<10:59,  1.24it/s] 27%|██▋       | 302/1120 [04:08<10:58,  1.24it/s] 27%|██▋       | 303/1120 [04:09<11:00,  1.24it/s] 27%|██▋       | 304/1120 [04:09<10:59,  1.24it/s] 27%|██▋       | 305/1120 [04:10<10:54,  1.25it/s] 27%|██▋       | 306/1120 [04:11<10:52,  1.25it/s] 27%|██▋       | 307/1120 [04:12<10:47,  1.26it/s] 28%|██▊       | 308/1120 [04:13<10:50,  1.25it/s] 28%|██▊       | 309/1120 [04:13<10:49,  1.25it/s] 28%|██▊       | 310/1120 [04:14<10:44,  1.26it/s]                                                   28%|██▊       | 310/1120 [04:14<10:44,  1.26it/s] 28%|██▊       | 311/1120 [04:15<10:44,  1.25it/s] 28%|██▊       | 312/1120 [04:16<10:39,  1.26it/s] 28%|██▊       | 313/1120 [04:17<10:45,  1.25it/s] 28%|██▊       | 314/1120 [04:17<10:48,  1.24it/s] 28%|██▊       | 315/1120 [04:18<10:50,  1.24it/s] 28%|██▊       | 316/1120 [04:19<10:50,  1.24it/s] 28%|██▊       | 317/1120 [04:20<10:44,  1.25it/s] 28%|██▊       | 318/1120 [04:21<10:51,  1.23it/s] 28%|██▊       | 319/1120 [04:21<10:44,  1.24it/s] 29%|██▊       | 320/1120 [04:22<10:46,  1.24it/s]                                                   29%|██▊       | 320/1120 [04:22<10:46,  1.24it/s]{'eval_loss': 0.1418817639350891, 'eval_runtime': 0.8946, 'eval_samples_per_second': 111.779, 'eval_steps_per_second': 14.531, 'epoch': 2.49}
{'loss': 0.0977, 'learning_rate': 0.00023271028037383175, 'epoch': 2.58}
{'loss': 0.1163, 'learning_rate': 0.00022990654205607474, 'epoch': 2.67}
{'loss': 0.0983, 'learning_rate': 0.00022710280373831773, 'epoch': 2.76}
{'loss': 0.0797, 'learning_rate': 0.00022429906542056072, 'epoch': 2.84}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.52it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.00it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.10it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.25it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.10it/s][A                                                  
                                               [A 29%|██▊       | 320/1120 [04:23<10:46,  1.24it/s]
100%|██████████| 13/13 [00:00<00:00, 15.10it/s][A
                                               [A 29%|██▊       | 321/1120 [04:24<14:49,  1.11s/it] 29%|██▉       | 322/1120 [04:25<13:36,  1.02s/it] 29%|██▉       | 323/1120 [04:26<12:36,  1.05it/s] 29%|██▉       | 324/1120 [04:26<12:03,  1.10it/s] 29%|██▉       | 325/1120 [04:27<11:36,  1.14it/s] 29%|██▉       | 326/1120 [04:28<11:18,  1.17it/s] 29%|██▉       | 327/1120 [04:29<11:05,  1.19it/s] 29%|██▉       | 328/1120 [04:30<10:53,  1.21it/s] 29%|██▉       | 329/1120 [04:30<10:51,  1.21it/s] 29%|██▉       | 330/1120 [04:31<10:45,  1.22it/s]                                                   29%|██▉       | 330/1120 [04:31<10:45,  1.22it/s] 30%|██▉       | 331/1120 [04:32<10:45,  1.22it/s] 30%|██▉       | 332/1120 [04:33<10:41,  1.23it/s] 30%|██▉       | 333/1120 [04:34<10:34,  1.24it/s] 30%|██▉       | 334/1120 [04:34<10:34,  1.24it/s] 30%|██▉       | 335/1120 [04:35<10:33,  1.24it/s] 30%|███       | 336/1120 [04:36<10:31,  1.24it/s] 30%|███       | 337/1120 [04:37<10:32,  1.24it/s] 30%|███       | 338/1120 [04:38<10:23,  1.25it/s] 30%|███       | 339/1120 [04:38<10:27,  1.24it/s] 30%|███       | 340/1120 [04:39<10:29,  1.24it/s]                                                   30%|███       | 340/1120 [04:39<10:29,  1.24it/s] 30%|███       | 341/1120 [04:40<10:26,  1.24it/s] 31%|███       | 342/1120 [04:41<10:18,  1.26it/s] 31%|███       | 343/1120 [04:42<10:16,  1.26it/s] 31%|███       | 344/1120 [04:42<10:10,  1.27it/s] 31%|███       | 345/1120 [04:43<10:06,  1.28it/s] 31%|███       | 346/1120 [04:44<10:01,  1.29it/s] 31%|███       | 347/1120 [04:45<10:02,  1.28it/s] 31%|███       | 348/1120 [04:46<10:00,  1.28it/s] 31%|███       | 349/1120 [04:46<10:00,  1.28it/s] 31%|███▏      | 350/1120 [04:47<09:59,  1.29it/s]                                                   31%|███▏      | 350/1120 [04:47<09:59,  1.29it/s] 31%|███▏      | 351/1120 [04:48<09:59,  1.28it/s] 31%|███▏      | 352/1120 [04:49<10:01,  1.28it/s] 32%|███▏      | 353/1120 [04:49<10:01,  1.27it/s] 32%|███▏      | 354/1120 [04:50<09:58,  1.28it/s] 32%|███▏      | 355/1120 [04:51<09:57,  1.28it/s] 32%|███▏      | 356/1120 [04:52<10:04,  1.26it/s] 32%|███▏      | 357/1120 [04:53<09:59,  1.27it/s] 32%|███▏      | 358/1120 [04:53<09:59,  1.27it/s] 32%|███▏      | 359/1120 [04:54<09:57,  1.27it/s] 32%|███▏      | 360/1120 [04:55<09:53,  1.28it/s]                                                   32%|███▏      | 360/1120 [04:55<09:53,  1.28it/s]{'eval_loss': 0.15508626401424408, 'eval_runtime': 0.8977, 'eval_samples_per_second': 111.398, 'eval_steps_per_second': 14.482, 'epoch': 2.84}
{'loss': 0.1185, 'learning_rate': 0.0002214953271028037, 'epoch': 2.93}
{'loss': 0.0569, 'learning_rate': 0.0002186915887850467, 'epoch': 3.02}
{'loss': 0.0684, 'learning_rate': 0.0002158878504672897, 'epoch': 3.11}
{'loss': 0.0404, 'learning_rate': 0.00021308411214953268, 'epoch': 3.2}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.71it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.21it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.31it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.93it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.66it/s][A                                                  
                                               [A 32%|███▏      | 360/1120 [04:56<09:53,  1.28it/s]
100%|██████████| 13/13 [00:00<00:00, 15.66it/s][A
                                               [A 32%|███▏      | 361/1120 [04:57<13:40,  1.08s/it] 32%|███▏      | 362/1120 [04:57<12:30,  1.01it/s] 32%|███▏      | 363/1120 [04:58<11:38,  1.08it/s] 32%|███▎      | 364/1120 [04:59<11:05,  1.14it/s] 33%|███▎      | 365/1120 [05:00<10:45,  1.17it/s] 33%|███▎      | 366/1120 [05:01<10:26,  1.20it/s] 33%|███▎      | 367/1120 [05:01<10:14,  1.23it/s] 33%|███▎      | 368/1120 [05:02<10:14,  1.22it/s] 33%|███▎      | 369/1120 [05:03<10:02,  1.25it/s] 33%|███▎      | 370/1120 [05:04<09:56,  1.26it/s]                                                   33%|███▎      | 370/1120 [05:04<09:56,  1.26it/s] 33%|███▎      | 371/1120 [05:05<09:51,  1.27it/s] 33%|███▎      | 372/1120 [05:05<09:47,  1.27it/s] 33%|███▎      | 373/1120 [05:06<09:41,  1.28it/s] 33%|███▎      | 374/1120 [05:07<09:41,  1.28it/s] 33%|███▎      | 375/1120 [05:08<09:39,  1.28it/s] 34%|███▎      | 376/1120 [05:08<09:37,  1.29it/s] 34%|███▎      | 377/1120 [05:09<09:34,  1.29it/s] 34%|███▍      | 378/1120 [05:10<09:32,  1.30it/s] 34%|███▍      | 379/1120 [05:11<09:36,  1.28it/s] 34%|███▍      | 380/1120 [05:12<09:37,  1.28it/s]                                                   34%|███▍      | 380/1120 [05:12<09:37,  1.28it/s] 34%|███▍      | 381/1120 [05:12<09:38,  1.28it/s] 34%|███▍      | 382/1120 [05:13<09:39,  1.27it/s] 34%|███▍      | 383/1120 [05:14<09:36,  1.28it/s] 34%|███▍      | 384/1120 [05:15<09:38,  1.27it/s] 34%|███▍      | 385/1120 [05:15<09:37,  1.27it/s] 34%|███▍      | 386/1120 [05:16<09:39,  1.27it/s] 35%|███▍      | 387/1120 [05:17<09:39,  1.26it/s] 35%|███▍      | 388/1120 [05:18<09:37,  1.27it/s] 35%|███▍      | 389/1120 [05:19<09:40,  1.26it/s] 35%|███▍      | 390/1120 [05:19<09:44,  1.25it/s]                                                   35%|███▍      | 390/1120 [05:19<09:44,  1.25it/s] 35%|███▍      | 391/1120 [05:20<09:41,  1.25it/s] 35%|███▌      | 392/1120 [05:21<09:39,  1.26it/s] 35%|███▌      | 393/1120 [05:22<09:36,  1.26it/s] 35%|███▌      | 394/1120 [05:23<09:37,  1.26it/s] 35%|███▌      | 395/1120 [05:23<09:38,  1.25it/s] 35%|███▌      | 396/1120 [05:24<09:34,  1.26it/s] 35%|███▌      | 397/1120 [05:25<09:34,  1.26it/s] 36%|███▌      | 398/1120 [05:26<09:32,  1.26it/s] 36%|███▌      | 399/1120 [05:27<09:31,  1.26it/s] 36%|███▌      | 400/1120 [05:27<09:30,  1.26it/s]                                                   36%|███▌      | 400/1120 [05:27<09:30,  1.26it/s]{'eval_loss': 0.1562703549861908, 'eval_runtime': 0.874, 'eval_samples_per_second': 114.418, 'eval_steps_per_second': 14.874, 'epoch': 3.2}
{'loss': 0.1058, 'learning_rate': 0.00021028037383177567, 'epoch': 3.29}
{'loss': 0.0827, 'learning_rate': 0.00020747663551401867, 'epoch': 3.38}
{'loss': 0.0778, 'learning_rate': 0.00020467289719626166, 'epoch': 3.47}
{'loss': 0.0917, 'learning_rate': 0.00020186915887850465, 'epoch': 3.56}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 22.15it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.38it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.53it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 16.06it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.42it/s][A                                                  
                                               [A 36%|███▌      | 400/1120 [05:28<09:30,  1.26it/s]
100%|██████████| 13/13 [00:00<00:00, 15.42it/s][A
                                               [A 36%|███▌      | 401/1120 [05:29<13:05,  1.09s/it] 36%|███▌      | 402/1120 [05:30<11:59,  1.00s/it] 36%|███▌      | 403/1120 [05:31<11:16,  1.06it/s] 36%|███▌      | 404/1120 [05:32<10:43,  1.11it/s] 36%|███▌      | 405/1120 [05:32<10:23,  1.15it/s] 36%|███▋      | 406/1120 [05:33<10:06,  1.18it/s] 36%|███▋      | 407/1120 [05:34<09:48,  1.21it/s] 36%|███▋      | 408/1120 [05:35<09:41,  1.22it/s] 37%|███▋      | 409/1120 [05:36<09:34,  1.24it/s] 37%|███▋      | 410/1120 [05:36<09:29,  1.25it/s]                                                   37%|███▋      | 410/1120 [05:36<09:29,  1.25it/s] 37%|███▋      | 411/1120 [05:37<09:30,  1.24it/s] 37%|███▋      | 412/1120 [05:38<09:29,  1.24it/s] 37%|███▋      | 413/1120 [05:39<09:29,  1.24it/s] 37%|███▋      | 414/1120 [05:40<09:28,  1.24it/s] 37%|███▋      | 415/1120 [05:40<09:24,  1.25it/s] 37%|███▋      | 416/1120 [05:41<09:21,  1.25it/s] 37%|███▋      | 417/1120 [05:42<09:17,  1.26it/s] 37%|███▋      | 418/1120 [05:43<09:16,  1.26it/s] 37%|███▋      | 419/1120 [05:43<09:16,  1.26it/s] 38%|███▊      | 420/1120 [05:44<09:13,  1.26it/s]                                                   38%|███▊      | 420/1120 [05:44<09:13,  1.26it/s] 38%|███▊      | 421/1120 [05:45<09:12,  1.26it/s] 38%|███▊      | 422/1120 [05:46<09:11,  1.27it/s] 38%|███▊      | 423/1120 [05:47<09:14,  1.26it/s] 38%|███▊      | 424/1120 [05:47<09:14,  1.26it/s] 38%|███▊      | 425/1120 [05:48<09:12,  1.26it/s] 38%|███▊      | 426/1120 [05:49<09:12,  1.26it/s] 38%|███▊      | 427/1120 [05:50<09:11,  1.26it/s] 38%|███▊      | 428/1120 [05:51<09:12,  1.25it/s] 38%|███▊      | 429/1120 [05:51<09:10,  1.26it/s] 38%|███▊      | 430/1120 [05:52<09:09,  1.26it/s]                                                   38%|███▊      | 430/1120 [05:52<09:09,  1.26it/s] 38%|███▊      | 431/1120 [05:53<09:11,  1.25it/s] 39%|███▊      | 432/1120 [05:54<09:08,  1.26it/s] 39%|███▊      | 433/1120 [05:55<09:09,  1.25it/s] 39%|███▉      | 434/1120 [05:55<09:09,  1.25it/s] 39%|███▉      | 435/1120 [05:56<09:04,  1.26it/s] 39%|███▉      | 436/1120 [05:57<09:05,  1.25it/s] 39%|███▉      | 437/1120 [05:58<09:04,  1.25it/s] 39%|███▉      | 438/1120 [05:59<09:02,  1.26it/s] 39%|███▉      | 439/1120 [05:59<09:06,  1.25it/s] 39%|███▉      | 440/1120 [06:00<09:10,  1.24it/s]                                                   39%|███▉      | 440/1120 [06:00<09:10,  1.24it/s]{'eval_loss': 0.18331009149551392, 'eval_runtime': 0.8789, 'eval_samples_per_second': 113.78, 'eval_steps_per_second': 14.791, 'epoch': 3.56}
{'loss': 0.1288, 'learning_rate': 0.00019906542056074764, 'epoch': 3.64}
{'loss': 0.1096, 'learning_rate': 0.00019626168224299063, 'epoch': 3.73}
{'loss': 0.1039, 'learning_rate': 0.00019345794392523362, 'epoch': 3.82}
{'loss': 0.0854, 'learning_rate': 0.0001906542056074766, 'epoch': 3.91}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.42it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.98it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.19it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.74it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.36it/s][A                                                  
                                               [A 39%|███▉      | 440/1120 [06:01<09:10,  1.24it/s]
100%|██████████| 13/13 [00:00<00:00, 15.36it/s][A
                                               [A 39%|███▉      | 441/1120 [06:02<12:31,  1.11s/it] 39%|███▉      | 442/1120 [06:03<11:29,  1.02s/it] 40%|███▉      | 443/1120 [06:04<10:44,  1.05it/s] 40%|███▉      | 444/1120 [06:04<10:10,  1.11it/s] 40%|███▉      | 445/1120 [06:05<09:46,  1.15it/s] 40%|███▉      | 446/1120 [06:06<09:25,  1.19it/s] 40%|███▉      | 447/1120 [06:07<09:16,  1.21it/s] 40%|████      | 448/1120 [06:08<09:10,  1.22it/s] 40%|████      | 449/1120 [06:08<09:05,  1.23it/s] 40%|████      | 450/1120 [06:09<09:01,  1.24it/s]                                                   40%|████      | 450/1120 [06:09<09:01,  1.24it/s] 40%|████      | 451/1120 [06:10<08:57,  1.25it/s] 40%|████      | 452/1120 [06:11<08:58,  1.24it/s] 40%|████      | 453/1120 [06:12<08:56,  1.24it/s] 41%|████      | 454/1120 [06:12<08:52,  1.25it/s] 41%|████      | 455/1120 [06:13<08:58,  1.24it/s] 41%|████      | 456/1120 [06:14<08:54,  1.24it/s] 41%|████      | 457/1120 [06:15<08:53,  1.24it/s] 41%|████      | 458/1120 [06:16<08:52,  1.24it/s] 41%|████      | 459/1120 [06:16<08:51,  1.24it/s] 41%|████      | 460/1120 [06:17<08:50,  1.24it/s]                                                   41%|████      | 460/1120 [06:17<08:50,  1.24it/s] 41%|████      | 461/1120 [06:18<08:45,  1.25it/s] 41%|████▏     | 462/1120 [06:19<08:45,  1.25it/s] 41%|████▏     | 463/1120 [06:20<08:47,  1.24it/s] 41%|████▏     | 464/1120 [06:20<08:43,  1.25it/s] 42%|████▏     | 465/1120 [06:21<08:46,  1.24it/s] 42%|████▏     | 466/1120 [06:22<08:42,  1.25it/s] 42%|████▏     | 467/1120 [06:23<08:39,  1.26it/s] 42%|████▏     | 468/1120 [06:24<08:36,  1.26it/s] 42%|████▏     | 469/1120 [06:24<08:34,  1.27it/s] 42%|████▏     | 470/1120 [06:25<08:31,  1.27it/s]                                                   42%|████▏     | 470/1120 [06:25<08:31,  1.27it/s] 42%|████▏     | 471/1120 [06:26<08:27,  1.28it/s] 42%|████▏     | 472/1120 [06:27<08:29,  1.27it/s] 42%|████▏     | 473/1120 [06:28<08:27,  1.27it/s] 42%|████▏     | 474/1120 [06:28<08:25,  1.28it/s] 42%|████▏     | 475/1120 [06:29<08:22,  1.28it/s] 42%|████▎     | 476/1120 [06:30<08:24,  1.28it/s] 43%|████▎     | 477/1120 [06:31<08:25,  1.27it/s] 43%|████▎     | 478/1120 [06:31<08:21,  1.28it/s] 43%|████▎     | 479/1120 [06:32<08:22,  1.28it/s] 43%|████▎     | 480/1120 [06:33<08:22,  1.27it/s]                                                   43%|████▎     | 480/1120 [06:33<08:22,  1.27it/s]{'eval_loss': 0.16856452822685242, 'eval_runtime': 0.8884, 'eval_samples_per_second': 112.561, 'eval_steps_per_second': 14.633, 'epoch': 3.91}
{'loss': 0.0841, 'learning_rate': 0.0001878504672897196, 'epoch': 4.0}
{'loss': 0.0235, 'learning_rate': 0.0001850467289719626, 'epoch': 4.09}
{'loss': 0.0671, 'learning_rate': 0.00018224299065420558, 'epoch': 4.18}
{'loss': 0.081, 'learning_rate': 0.00017943925233644857, 'epoch': 4.27}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.88it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.14it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.29it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.72it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.47it/s][A                                                  
                                               [A 43%|████▎     | 480/1120 [06:34<08:22,  1.27it/s]
100%|██████████| 13/13 [00:00<00:00, 15.47it/s][A
                                               [A 43%|████▎     | 481/1120 [06:35<11:33,  1.08s/it] 43%|████▎     | 482/1120 [06:36<10:33,  1.01it/s] 43%|████▎     | 483/1120 [06:36<09:53,  1.07it/s] 43%|████▎     | 484/1120 [06:37<09:27,  1.12it/s] 43%|████▎     | 485/1120 [06:38<09:04,  1.17it/s] 43%|████▎     | 486/1120 [06:39<08:48,  1.20it/s] 43%|████▎     | 487/1120 [06:39<08:38,  1.22it/s] 44%|████▎     | 488/1120 [06:40<08:29,  1.24it/s] 44%|████▎     | 489/1120 [06:41<08:26,  1.25it/s] 44%|████▍     | 490/1120 [06:42<08:20,  1.26it/s]                                                   44%|████▍     | 490/1120 [06:42<08:20,  1.26it/s] 44%|████▍     | 491/1120 [06:43<08:18,  1.26it/s] 44%|████▍     | 492/1120 [06:43<08:14,  1.27it/s] 44%|████▍     | 493/1120 [06:44<08:12,  1.27it/s] 44%|████▍     | 494/1120 [06:45<08:09,  1.28it/s] 44%|████▍     | 495/1120 [06:46<08:06,  1.28it/s] 44%|████▍     | 496/1120 [06:46<08:03,  1.29it/s] 44%|████▍     | 497/1120 [06:47<08:04,  1.29it/s] 44%|████▍     | 498/1120 [06:48<08:03,  1.29it/s] 45%|████▍     | 499/1120 [06:49<08:03,  1.29it/s] 45%|████▍     | 500/1120 [06:50<08:04,  1.28it/s]                                                   45%|████▍     | 500/1120 [06:50<08:04,  1.28it/s] 45%|████▍     | 501/1120 [06:50<08:02,  1.28it/s] 45%|████▍     | 502/1120 [06:51<08:04,  1.28it/s] 45%|████▍     | 503/1120 [06:52<08:03,  1.27it/s] 45%|████▌     | 504/1120 [06:53<08:06,  1.27it/s] 45%|████▌     | 505/1120 [06:54<08:09,  1.26it/s] 45%|████▌     | 506/1120 [06:54<08:06,  1.26it/s] 45%|████▌     | 507/1120 [06:55<08:08,  1.26it/s] 45%|████▌     | 508/1120 [06:56<08:08,  1.25it/s] 45%|████▌     | 509/1120 [06:57<08:11,  1.24it/s] 46%|████▌     | 510/1120 [06:58<08:08,  1.25it/s]                                                   46%|████▌     | 510/1120 [06:58<08:08,  1.25it/s] 46%|████▌     | 511/1120 [06:58<08:02,  1.26it/s] 46%|████▌     | 512/1120 [06:59<08:01,  1.26it/s] 46%|████▌     | 513/1120 [07:00<08:02,  1.26it/s] 46%|████▌     | 514/1120 [07:01<08:01,  1.26it/s] 46%|████▌     | 515/1120 [07:02<08:02,  1.26it/s] 46%|████▌     | 516/1120 [07:02<07:58,  1.26it/s] 46%|████▌     | 517/1120 [07:03<08:01,  1.25it/s] 46%|████▋     | 518/1120 [07:04<07:59,  1.26it/s] 46%|████▋     | 519/1120 [07:05<07:56,  1.26it/s] 46%|████▋     | 520/1120 [07:06<07:55,  1.26it/s]                                                   46%|████▋     | 520/1120 [07:06<07:55,  1.26it/s]{'eval_loss': 0.18029716610908508, 'eval_runtime': 0.8824, 'eval_samples_per_second': 113.333, 'eval_steps_per_second': 14.733, 'epoch': 4.27}
{'loss': 0.0337, 'learning_rate': 0.00017663551401869156, 'epoch': 4.36}
{'loss': 0.058, 'learning_rate': 0.00017383177570093455, 'epoch': 4.44}
{'loss': 0.0144, 'learning_rate': 0.00017102803738317754, 'epoch': 4.53}
{'loss': 0.0804, 'learning_rate': 0.00016822429906542053, 'epoch': 4.62}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 22.07it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.43it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.52it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 16.02it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.70it/s][A                                                  
                                               [A 46%|████▋     | 520/1120 [07:06<07:55,  1.26it/s]
100%|██████████| 13/13 [00:00<00:00, 15.70it/s][A
                                               [A 47%|████▋     | 521/1120 [07:07<10:53,  1.09s/it] 47%|████▋     | 522/1120 [07:08<09:57,  1.00it/s] 47%|████▋     | 523/1120 [07:09<09:18,  1.07it/s] 47%|████▋     | 524/1120 [07:10<08:52,  1.12it/s] 47%|████▋     | 525/1120 [07:10<08:29,  1.17it/s] 47%|████▋     | 526/1120 [07:11<08:17,  1.20it/s] 47%|████▋     | 527/1120 [07:12<08:08,  1.21it/s] 47%|████▋     | 528/1120 [07:13<08:00,  1.23it/s] 47%|████▋     | 529/1120 [07:14<07:57,  1.24it/s] 47%|████▋     | 530/1120 [07:14<07:49,  1.26it/s]                                                   47%|████▋     | 530/1120 [07:14<07:49,  1.26it/s] 47%|████▋     | 531/1120 [07:15<07:49,  1.25it/s] 48%|████▊     | 532/1120 [07:16<07:47,  1.26it/s] 48%|████▊     | 533/1120 [07:17<07:48,  1.25it/s] 48%|████▊     | 534/1120 [07:18<07:48,  1.25it/s] 48%|████▊     | 535/1120 [07:18<07:43,  1.26it/s] 48%|████▊     | 536/1120 [07:19<07:44,  1.26it/s] 48%|████▊     | 537/1120 [07:20<07:42,  1.26it/s] 48%|████▊     | 538/1120 [07:21<07:41,  1.26it/s] 48%|████▊     | 539/1120 [07:22<07:41,  1.26it/s] 48%|████▊     | 540/1120 [07:22<07:37,  1.27it/s]                                                   48%|████▊     | 540/1120 [07:22<07:37,  1.27it/s] 48%|████▊     | 541/1120 [07:23<07:37,  1.27it/s] 48%|████▊     | 542/1120 [07:24<07:37,  1.26it/s] 48%|████▊     | 543/1120 [07:25<07:37,  1.26it/s] 49%|████▊     | 544/1120 [07:25<07:35,  1.27it/s] 49%|████▊     | 545/1120 [07:26<07:31,  1.27it/s] 49%|████▉     | 546/1120 [07:27<07:32,  1.27it/s] 49%|████▉     | 547/1120 [07:28<07:33,  1.26it/s] 49%|████▉     | 548/1120 [07:29<07:31,  1.27it/s] 49%|████▉     | 549/1120 [07:29<07:31,  1.26it/s] 49%|████▉     | 550/1120 [07:30<07:29,  1.27it/s]                                                   49%|████▉     | 550/1120 [07:30<07:29,  1.27it/s] 49%|████▉     | 551/1120 [07:31<07:28,  1.27it/s] 49%|████▉     | 552/1120 [07:32<07:28,  1.27it/s] 49%|████▉     | 553/1120 [07:33<07:30,  1.26it/s] 49%|████▉     | 554/1120 [07:33<07:28,  1.26it/s] 50%|████▉     | 555/1120 [07:34<07:26,  1.26it/s] 50%|████▉     | 556/1120 [07:35<07:25,  1.27it/s] 50%|████▉     | 557/1120 [07:36<07:25,  1.26it/s] 50%|████▉     | 558/1120 [07:37<07:25,  1.26it/s] 50%|████▉     | 559/1120 [07:37<07:29,  1.25it/s] 50%|█████     | 560/1120 [07:38<07:25,  1.26it/s]                                                   50%|█████     | 560/1120 [07:38<07:25,  1.26it/s]{'eval_loss': 0.19850119948387146, 'eval_runtime': 0.8698, 'eval_samples_per_second': 114.975, 'eval_steps_per_second': 14.947, 'epoch': 4.62}
{'loss': 0.0422, 'learning_rate': 0.00016542056074766352, 'epoch': 4.71}
{'loss': 0.054, 'learning_rate': 0.00016261682242990652, 'epoch': 4.8}
{'loss': 0.0725, 'learning_rate': 0.0001598130841121495, 'epoch': 4.89}
{'loss': 0.0187, 'learning_rate': 0.0001570093457943925, 'epoch': 4.98}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.97it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.76it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.90it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.59it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.39it/s][A                                                  
                                               [A 50%|█████     | 560/1120 [07:39<07:25,  1.26it/s]
100%|██████████| 13/13 [00:00<00:00, 15.39it/s][A
                                               [A 50%|█████     | 561/1120 [07:40<10:13,  1.10s/it] 50%|█████     | 562/1120 [07:41<09:21,  1.01s/it] 50%|█████     | 563/1120 [07:42<08:45,  1.06it/s] 50%|█████     | 564/1120 [07:42<08:16,  1.12it/s] 50%|█████     | 565/1120 [07:43<08:01,  1.15it/s] 51%|█████     | 566/1120 [07:44<07:48,  1.18it/s] 51%|█████     | 567/1120 [07:45<07:40,  1.20it/s] 51%|█████     | 568/1120 [07:46<07:34,  1.21it/s] 51%|█████     | 569/1120 [07:46<07:26,  1.23it/s] 51%|█████     | 570/1120 [07:47<07:23,  1.24it/s]                                                   51%|█████     | 570/1120 [07:47<07:23,  1.24it/s] 51%|█████     | 571/1120 [07:48<07:19,  1.25it/s] 51%|█████     | 572/1120 [07:49<07:15,  1.26it/s] 51%|█████     | 573/1120 [07:49<07:14,  1.26it/s] 51%|█████▏    | 574/1120 [07:50<07:12,  1.26it/s] 51%|█████▏    | 575/1120 [07:51<07:12,  1.26it/s] 51%|█████▏    | 576/1120 [07:52<07:13,  1.26it/s] 52%|█████▏    | 577/1120 [07:53<07:09,  1.27it/s] 52%|█████▏    | 578/1120 [07:53<07:09,  1.26it/s] 52%|█████▏    | 579/1120 [07:54<07:08,  1.26it/s] 52%|█████▏    | 580/1120 [07:55<07:07,  1.26it/s]                                                   52%|█████▏    | 580/1120 [07:55<07:07,  1.26it/s] 52%|█████▏    | 581/1120 [07:56<07:08,  1.26it/s] 52%|█████▏    | 582/1120 [07:57<07:06,  1.26it/s] 52%|█████▏    | 583/1120 [07:57<07:05,  1.26it/s] 52%|█████▏    | 584/1120 [07:58<07:03,  1.27it/s] 52%|█████▏    | 585/1120 [07:59<07:03,  1.26it/s] 52%|█████▏    | 586/1120 [08:00<07:08,  1.25it/s] 52%|█████▏    | 587/1120 [08:01<07:04,  1.26it/s] 52%|█████▎    | 588/1120 [08:01<07:04,  1.25it/s] 53%|█████▎    | 589/1120 [08:02<07:03,  1.25it/s] 53%|█████▎    | 590/1120 [08:03<07:02,  1.25it/s]                                                   53%|█████▎    | 590/1120 [08:03<07:02,  1.25it/s] 53%|█████▎    | 591/1120 [08:04<07:04,  1.25it/s] 53%|█████▎    | 592/1120 [08:05<07:01,  1.25it/s] 53%|█████▎    | 593/1120 [08:05<07:01,  1.25it/s] 53%|█████▎    | 594/1120 [08:06<06:59,  1.26it/s] 53%|█████▎    | 595/1120 [08:07<06:56,  1.26it/s] 53%|█████▎    | 596/1120 [08:08<06:57,  1.26it/s] 53%|█████▎    | 597/1120 [08:09<06:52,  1.27it/s] 53%|█████▎    | 598/1120 [08:09<06:55,  1.26it/s] 53%|█████▎    | 599/1120 [08:10<06:53,  1.26it/s] 54%|█████▎    | 600/1120 [08:11<06:51,  1.26it/s]                                                   54%|█████▎    | 600/1120 [08:11<06:51,  1.26it/s]{'eval_loss': 0.19433735311031342, 'eval_runtime': 0.889, 'eval_samples_per_second': 112.492, 'eval_steps_per_second': 14.624, 'epoch': 4.98}
{'loss': 0.0688, 'learning_rate': 0.0001542056074766355, 'epoch': 5.07}
{'loss': 0.0341, 'learning_rate': 0.00015140186915887848, 'epoch': 5.16}
{'loss': 0.0442, 'learning_rate': 0.00014859813084112147, 'epoch': 5.24}
{'loss': 0.0347, 'learning_rate': 0.00014579439252336446, 'epoch': 5.33}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.74it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.89it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.08it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.59it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.14it/s][A                                                  
                                               [A 54%|█████▎    | 600/1120 [08:12<06:51,  1.26it/s]
100%|██████████| 13/13 [00:00<00:00, 15.14it/s][A
                                               [A 54%|█████▎    | 601/1120 [08:13<09:31,  1.10s/it] 54%|█████▍    | 602/1120 [08:14<08:45,  1.01s/it] 54%|█████▍    | 603/1120 [08:14<08:08,  1.06it/s] 54%|█████▍    | 604/1120 [08:15<07:44,  1.11it/s] 54%|█████▍    | 605/1120 [08:16<07:29,  1.15it/s] 54%|█████▍    | 606/1120 [08:17<07:18,  1.17it/s] 54%|█████▍    | 607/1120 [08:18<07:11,  1.19it/s] 54%|█████▍    | 608/1120 [08:18<07:01,  1.22it/s] 54%|█████▍    | 609/1120 [08:19<06:55,  1.23it/s] 54%|█████▍    | 610/1120 [08:20<06:54,  1.23it/s]                                                   54%|█████▍    | 610/1120 [08:20<06:54,  1.23it/s] 55%|█████▍    | 611/1120 [08:21<06:46,  1.25it/s] 55%|█████▍    | 612/1120 [08:22<06:46,  1.25it/s] 55%|█████▍    | 613/1120 [08:22<06:46,  1.25it/s] 55%|█████▍    | 614/1120 [08:23<06:41,  1.26it/s] 55%|█████▍    | 615/1120 [08:24<06:38,  1.27it/s] 55%|█████▌    | 616/1120 [08:25<06:35,  1.28it/s] 55%|█████▌    | 617/1120 [08:25<06:34,  1.28it/s] 55%|█████▌    | 618/1120 [08:26<06:32,  1.28it/s] 55%|█████▌    | 619/1120 [08:27<06:30,  1.28it/s] 55%|█████▌    | 620/1120 [08:28<06:29,  1.28it/s]                                                   55%|█████▌    | 620/1120 [08:28<06:29,  1.28it/s] 55%|█████▌    | 621/1120 [08:29<06:27,  1.29it/s] 56%|█████▌    | 622/1120 [08:29<06:26,  1.29it/s] 56%|█████▌    | 623/1120 [08:30<06:26,  1.29it/s] 56%|█████▌    | 624/1120 [08:31<06:25,  1.29it/s] 56%|█████▌    | 625/1120 [08:32<06:24,  1.29it/s] 56%|█████▌    | 626/1120 [08:32<06:24,  1.28it/s] 56%|█████▌    | 627/1120 [08:33<06:24,  1.28it/s] 56%|█████▌    | 628/1120 [08:34<06:24,  1.28it/s] 56%|█████▌    | 629/1120 [08:35<06:22,  1.29it/s] 56%|█████▋    | 630/1120 [08:36<06:21,  1.28it/s]                                                   56%|█████▋    | 630/1120 [08:36<06:21,  1.28it/s] 56%|█████▋    | 631/1120 [08:36<06:19,  1.29it/s] 56%|█████▋    | 632/1120 [08:37<06:17,  1.29it/s] 57%|█████▋    | 633/1120 [08:38<06:15,  1.30it/s] 57%|█████▋    | 634/1120 [08:39<06:15,  1.30it/s] 57%|█████▋    | 635/1120 [08:39<06:15,  1.29it/s] 57%|█████▋    | 636/1120 [08:40<06:15,  1.29it/s] 57%|█████▋    | 637/1120 [08:41<06:13,  1.29it/s] 57%|█████▋    | 638/1120 [08:42<06:13,  1.29it/s] 57%|█████▋    | 639/1120 [08:42<06:13,  1.29it/s] 57%|█████▋    | 640/1120 [08:43<06:11,  1.29it/s]                                                   57%|█████▋    | 640/1120 [08:43<06:11,  1.29it/s]{'eval_loss': 0.21621286869049072, 'eval_runtime': 0.8942, 'eval_samples_per_second': 111.828, 'eval_steps_per_second': 14.538, 'epoch': 5.33}
{'loss': 0.0212, 'learning_rate': 0.00014299065420560745, 'epoch': 5.42}
{'loss': 0.0489, 'learning_rate': 0.00014018691588785044, 'epoch': 5.51}
{'loss': 0.0213, 'learning_rate': 0.00013738317757009343, 'epoch': 5.6}
{'loss': 0.0641, 'learning_rate': 0.00013457943925233642, 'epoch': 5.69}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.48it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.97it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.24it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.86it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.62it/s][A                                                  
                                               [A 57%|█████▋    | 640/1120 [08:44<06:11,  1.29it/s]
100%|██████████| 13/13 [00:00<00:00, 15.62it/s][A
                                               [A 57%|█████▋    | 641/1120 [08:45<08:35,  1.08s/it] 57%|█████▋    | 642/1120 [08:46<07:52,  1.01it/s] 57%|█████▋    | 643/1120 [08:47<07:20,  1.08it/s] 57%|█████▊    | 644/1120 [08:47<06:58,  1.14it/s] 58%|█████▊    | 645/1120 [08:48<06:44,  1.17it/s] 58%|█████▊    | 646/1120 [08:49<06:32,  1.21it/s] 58%|█████▊    | 647/1120 [08:50<06:25,  1.23it/s] 58%|█████▊    | 648/1120 [08:50<06:19,  1.24it/s] 58%|█████▊    | 649/1120 [08:51<06:14,  1.26it/s] 58%|█████▊    | 650/1120 [08:52<06:13,  1.26it/s]                                                   58%|█████▊    | 650/1120 [08:52<06:13,  1.26it/s] 58%|█████▊    | 651/1120 [08:53<06:10,  1.27it/s] 58%|█████▊    | 652/1120 [08:54<06:09,  1.27it/s] 58%|█████▊    | 653/1120 [08:54<06:06,  1.27it/s] 58%|█████▊    | 654/1120 [08:55<06:03,  1.28it/s] 58%|█████▊    | 655/1120 [08:56<06:02,  1.28it/s] 59%|█████▊    | 656/1120 [08:57<06:01,  1.28it/s] 59%|█████▊    | 657/1120 [08:58<06:01,  1.28it/s] 59%|█████▉    | 658/1120 [08:58<05:58,  1.29it/s] 59%|█████▉    | 659/1120 [08:59<05:57,  1.29it/s] 59%|█████▉    | 660/1120 [09:00<06:07,  1.25it/s]                                                   59%|█████▉    | 660/1120 [09:00<06:07,  1.25it/s] 59%|█████▉    | 661/1120 [09:01<06:11,  1.24it/s] 59%|█████▉    | 662/1120 [09:02<06:11,  1.23it/s] 59%|█████▉    | 663/1120 [09:02<06:04,  1.25it/s] 59%|█████▉    | 664/1120 [09:03<06:01,  1.26it/s] 59%|█████▉    | 665/1120 [09:04<06:01,  1.26it/s] 59%|█████▉    | 666/1120 [09:05<05:59,  1.26it/s] 60%|█████▉    | 667/1120 [09:06<06:02,  1.25it/s] 60%|█████▉    | 668/1120 [09:06<06:00,  1.25it/s] 60%|█████▉    | 669/1120 [09:07<06:00,  1.25it/s] 60%|█████▉    | 670/1120 [09:08<05:59,  1.25it/s]                                                   60%|█████▉    | 670/1120 [09:08<05:59,  1.25it/s] 60%|█████▉    | 671/1120 [09:09<05:55,  1.26it/s] 60%|██████    | 672/1120 [09:09<05:57,  1.25it/s] 60%|██████    | 673/1120 [09:10<05:55,  1.26it/s] 60%|██████    | 674/1120 [09:11<05:55,  1.26it/s] 60%|██████    | 675/1120 [09:12<05:55,  1.25it/s] 60%|██████    | 676/1120 [09:13<05:51,  1.26it/s] 60%|██████    | 677/1120 [09:13<05:52,  1.26it/s] 61%|██████    | 678/1120 [09:14<05:50,  1.26it/s] 61%|██████    | 679/1120 [09:15<05:51,  1.25it/s] 61%|██████    | 680/1120 [09:16<05:53,  1.24it/s]                                                   61%|██████    | 680/1120 [09:16<05:53,  1.24it/s]{'eval_loss': 0.255003422498703, 'eval_runtime': 0.8793, 'eval_samples_per_second': 113.723, 'eval_steps_per_second': 14.784, 'epoch': 5.69}
{'loss': 0.0426, 'learning_rate': 0.0001317757009345794, 'epoch': 5.78}
{'loss': 0.0338, 'learning_rate': 0.0001289719626168224, 'epoch': 5.87}
{'loss': 0.0188, 'learning_rate': 0.0001261682242990654, 'epoch': 5.96}
{'loss': 0.0534, 'learning_rate': 0.00012336448598130838, 'epoch': 6.04}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.62it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.58it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.97it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.65it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.41it/s][A                                                  
                                               [A 61%|██████    | 680/1120 [09:17<05:53,  1.24it/s]
100%|██████████| 13/13 [00:00<00:00, 15.41it/s][A
                                               [A 61%|██████    | 681/1120 [09:18<08:06,  1.11s/it] 61%|██████    | 682/1120 [09:19<07:25,  1.02s/it] 61%|██████    | 683/1120 [09:19<06:56,  1.05it/s] 61%|██████    | 684/1120 [09:20<06:38,  1.10it/s] 61%|██████    | 685/1120 [09:21<06:22,  1.14it/s] 61%|██████▏   | 686/1120 [09:22<06:10,  1.17it/s] 61%|██████▏   | 687/1120 [09:23<06:02,  1.19it/s] 61%|██████▏   | 688/1120 [09:23<05:57,  1.21it/s] 62%|██████▏   | 689/1120 [09:24<05:52,  1.22it/s] 62%|██████▏   | 690/1120 [09:25<05:48,  1.23it/s]                                                   62%|██████▏   | 690/1120 [09:25<05:48,  1.23it/s] 62%|██████▏   | 691/1120 [09:26<05:45,  1.24it/s] 62%|██████▏   | 692/1120 [09:27<05:44,  1.24it/s] 62%|██████▏   | 693/1120 [09:27<05:43,  1.24it/s] 62%|██████▏   | 694/1120 [09:28<05:40,  1.25it/s] 62%|██████▏   | 695/1120 [09:29<05:39,  1.25it/s] 62%|██████▏   | 696/1120 [09:30<05:40,  1.25it/s] 62%|██████▏   | 697/1120 [09:31<05:38,  1.25it/s] 62%|██████▏   | 698/1120 [09:31<05:36,  1.25it/s] 62%|██████▏   | 699/1120 [09:32<05:35,  1.25it/s] 62%|██████▎   | 700/1120 [09:33<05:33,  1.26it/s]                                                   62%|██████▎   | 700/1120 [09:33<05:33,  1.26it/s] 63%|██████▎   | 701/1120 [09:34<05:34,  1.25it/s] 63%|██████▎   | 702/1120 [09:34<05:32,  1.26it/s] 63%|██████▎   | 703/1120 [09:35<05:32,  1.25it/s] 63%|██████▎   | 704/1120 [09:36<05:32,  1.25it/s] 63%|██████▎   | 705/1120 [09:37<05:29,  1.26it/s] 63%|██████▎   | 706/1120 [09:38<05:31,  1.25it/s] 63%|██████▎   | 707/1120 [09:38<05:30,  1.25it/s] 63%|██████▎   | 708/1120 [09:39<05:28,  1.25it/s] 63%|██████▎   | 709/1120 [09:40<05:28,  1.25it/s] 63%|██████▎   | 710/1120 [09:41<05:23,  1.27it/s]                                                   63%|██████▎   | 710/1120 [09:41<05:23,  1.27it/s] 63%|██████▎   | 711/1120 [09:42<05:25,  1.26it/s] 64%|██████▎   | 712/1120 [09:42<05:24,  1.26it/s] 64%|██████▎   | 713/1120 [09:43<05:22,  1.26it/s] 64%|██████▍   | 714/1120 [09:44<05:22,  1.26it/s] 64%|██████▍   | 715/1120 [09:45<05:19,  1.27it/s] 64%|██████▍   | 716/1120 [09:46<05:18,  1.27it/s] 64%|██████▍   | 717/1120 [09:46<05:17,  1.27it/s] 64%|██████▍   | 718/1120 [09:47<05:16,  1.27it/s] 64%|██████▍   | 719/1120 [09:48<05:16,  1.27it/s] 64%|██████▍   | 720/1120 [09:49<05:13,  1.27it/s]                                                   64%|██████▍   | 720/1120 [09:49<05:13,  1.27it/s]{'eval_loss': 0.21589761972427368, 'eval_runtime': 0.8935, 'eval_samples_per_second': 111.919, 'eval_steps_per_second': 14.549, 'epoch': 6.04}
{'loss': 0.0256, 'learning_rate': 0.00012056074766355139, 'epoch': 6.13}
{'loss': 0.0267, 'learning_rate': 0.00011775700934579438, 'epoch': 6.22}
{'loss': 0.04, 'learning_rate': 0.00011495327102803737, 'epoch': 6.31}
{'loss': 0.0715, 'learning_rate': 0.00011214953271028036, 'epoch': 6.4}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.74it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.57it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.90it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.43it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.25it/s][A                                                  
                                               [A 64%|██████▍   | 720/1120 [09:50<05:13,  1.27it/s]
100%|██████████| 13/13 [00:00<00:00, 15.25it/s][A
                                               [A 64%|██████▍   | 721/1120 [09:51<07:16,  1.09s/it] 64%|██████▍   | 722/1120 [09:51<06:38,  1.00s/it] 65%|██████▍   | 723/1120 [09:52<06:12,  1.07it/s] 65%|██████▍   | 724/1120 [09:53<05:52,  1.12it/s] 65%|██████▍   | 725/1120 [09:54<05:43,  1.15it/s] 65%|██████▍   | 726/1120 [09:55<05:37,  1.17it/s] 65%|██████▍   | 727/1120 [09:55<05:28,  1.20it/s] 65%|██████▌   | 728/1120 [09:56<05:24,  1.21it/s] 65%|██████▌   | 729/1120 [09:57<05:17,  1.23it/s] 65%|██████▌   | 730/1120 [09:58<05:17,  1.23it/s]                                                   65%|██████▌   | 730/1120 [09:58<05:17,  1.23it/s] 65%|██████▌   | 731/1120 [09:59<05:16,  1.23it/s] 65%|██████▌   | 732/1120 [09:59<05:13,  1.24it/s] 65%|██████▌   | 733/1120 [10:00<05:15,  1.23it/s] 66%|██████▌   | 734/1120 [10:01<05:12,  1.24it/s] 66%|██████▌   | 735/1120 [10:02<05:13,  1.23it/s] 66%|██████▌   | 736/1120 [10:03<05:10,  1.24it/s] 66%|██████▌   | 737/1120 [10:03<05:10,  1.23it/s] 66%|██████▌   | 738/1120 [10:04<05:08,  1.24it/s] 66%|██████▌   | 739/1120 [10:05<05:05,  1.25it/s] 66%|██████▌   | 740/1120 [10:06<05:05,  1.24it/s]                                                   66%|██████▌   | 740/1120 [10:06<05:05,  1.24it/s] 66%|██████▌   | 741/1120 [10:07<05:08,  1.23it/s] 66%|██████▋   | 742/1120 [10:07<05:07,  1.23it/s] 66%|██████▋   | 743/1120 [10:08<05:06,  1.23it/s] 66%|██████▋   | 744/1120 [10:09<05:03,  1.24it/s] 67%|██████▋   | 745/1120 [10:10<05:04,  1.23it/s] 67%|██████▋   | 746/1120 [10:11<05:03,  1.23it/s] 67%|██████▋   | 747/1120 [10:12<05:03,  1.23it/s] 67%|██████▋   | 748/1120 [10:12<05:03,  1.22it/s] 67%|██████▋   | 749/1120 [10:13<05:01,  1.23it/s] 67%|██████▋   | 750/1120 [10:14<05:02,  1.22it/s]                                                   67%|██████▋   | 750/1120 [10:14<05:02,  1.22it/s] 67%|██████▋   | 751/1120 [10:15<04:59,  1.23it/s] 67%|██████▋   | 752/1120 [10:16<04:59,  1.23it/s] 67%|██████▋   | 753/1120 [10:16<04:59,  1.22it/s] 67%|██████▋   | 754/1120 [10:17<04:58,  1.23it/s] 67%|██████▋   | 755/1120 [10:18<04:56,  1.23it/s] 68%|██████▊   | 756/1120 [10:19<04:57,  1.22it/s] 68%|██████▊   | 757/1120 [10:20<04:58,  1.22it/s] 68%|██████▊   | 758/1120 [10:21<04:58,  1.21it/s] 68%|██████▊   | 759/1120 [10:21<04:57,  1.21it/s] 68%|██████▊   | 760/1120 [10:22<04:57,  1.21it/s]                                                   68%|██████▊   | 760/1120 [10:22<04:57,  1.21it/s]{'eval_loss': 0.21182456612586975, 'eval_runtime': 0.8968, 'eval_samples_per_second': 111.507, 'eval_steps_per_second': 14.496, 'epoch': 6.4}
{'loss': 0.0225, 'learning_rate': 0.00010934579439252335, 'epoch': 6.49}
{'loss': 0.024, 'learning_rate': 0.00010654205607476634, 'epoch': 6.58}
{'loss': 0.0294, 'learning_rate': 0.00010373831775700933, 'epoch': 6.67}
{'loss': 0.0445, 'learning_rate': 0.00010093457943925232, 'epoch': 6.76}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.97it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.10it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.13it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.74it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.40it/s][A                                                  
                                               [A 68%|██████▊   | 760/1120 [10:23<04:57,  1.21it/s]
100%|██████████| 13/13 [00:00<00:00, 15.40it/s][A
                                               [A 68%|██████▊   | 761/1120 [10:24<06:44,  1.13s/it] 68%|██████▊   | 762/1120 [10:25<06:12,  1.04s/it] 68%|██████▊   | 763/1120 [10:26<05:47,  1.03it/s] 68%|██████▊   | 764/1120 [10:26<05:31,  1.07it/s] 68%|██████▊   | 765/1120 [10:27<05:17,  1.12it/s] 68%|██████▊   | 766/1120 [10:28<05:09,  1.14it/s] 68%|██████▊   | 767/1120 [10:29<05:01,  1.17it/s] 69%|██████▊   | 768/1120 [10:30<04:55,  1.19it/s] 69%|██████▊   | 769/1120 [10:31<04:52,  1.20it/s] 69%|██████▉   | 770/1120 [10:31<04:46,  1.22it/s]                                                   69%|██████▉   | 770/1120 [10:31<04:46,  1.22it/s] 69%|██████▉   | 771/1120 [10:32<04:44,  1.23it/s] 69%|██████▉   | 772/1120 [10:33<04:41,  1.24it/s] 69%|██████▉   | 773/1120 [10:34<04:42,  1.23it/s] 69%|██████▉   | 774/1120 [10:35<04:45,  1.21it/s] 69%|██████▉   | 775/1120 [10:35<04:49,  1.19it/s] 69%|██████▉   | 776/1120 [10:36<04:45,  1.20it/s] 69%|██████▉   | 777/1120 [10:37<04:43,  1.21it/s] 69%|██████▉   | 778/1120 [10:38<04:48,  1.19it/s] 70%|██████▉   | 779/1120 [10:39<04:49,  1.18it/s] 70%|██████▉   | 780/1120 [10:40<04:51,  1.17it/s]                                                   70%|██████▉   | 780/1120 [10:40<04:51,  1.17it/s] 70%|██████▉   | 781/1120 [10:41<04:51,  1.16it/s] 70%|██████▉   | 782/1120 [10:41<04:51,  1.16it/s] 70%|██████▉   | 783/1120 [10:42<04:51,  1.16it/s] 70%|███████   | 784/1120 [10:43<04:49,  1.16it/s] 70%|███████   | 785/1120 [10:44<04:50,  1.15it/s] 70%|███████   | 786/1120 [10:45<04:40,  1.19it/s] 70%|███████   | 787/1120 [10:46<04:32,  1.22it/s] 70%|███████   | 788/1120 [10:46<04:25,  1.25it/s] 70%|███████   | 789/1120 [10:47<04:29,  1.23it/s] 71%|███████   | 790/1120 [10:48<04:25,  1.24it/s]                                                   71%|███████   | 790/1120 [10:48<04:25,  1.24it/s] 71%|███████   | 791/1120 [10:49<04:17,  1.28it/s] 71%|███████   | 792/1120 [10:49<04:12,  1.30it/s] 71%|███████   | 793/1120 [10:50<04:07,  1.32it/s] 71%|███████   | 794/1120 [10:51<04:04,  1.33it/s] 71%|███████   | 795/1120 [10:52<04:03,  1.34it/s] 71%|███████   | 796/1120 [10:52<04:01,  1.34it/s] 71%|███████   | 797/1120 [10:53<03:59,  1.35it/s] 71%|███████▏  | 798/1120 [10:54<03:57,  1.35it/s] 71%|███████▏  | 799/1120 [10:55<03:56,  1.36it/s] 71%|███████▏  | 800/1120 [10:55<03:54,  1.36it/s]                                                   71%|███████▏  | 800/1120 [10:55<03:54,  1.36it/s]{'eval_loss': 0.25266528129577637, 'eval_runtime': 0.8866, 'eval_samples_per_second': 112.791, 'eval_steps_per_second': 14.663, 'epoch': 6.76}
{'loss': 0.0457, 'learning_rate': 9.813084112149531e-05, 'epoch': 6.84}
{'loss': 0.1238, 'learning_rate': 9.53271028037383e-05, 'epoch': 6.93}
{'loss': 0.0242, 'learning_rate': 9.25233644859813e-05, 'epoch': 7.02}
{'loss': 0.0435, 'learning_rate': 8.971962616822429e-05, 'epoch': 7.11}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.92it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.21it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.45it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.01it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.78it/s][A                                                  
                                               [A 71%|███████▏  | 800/1120 [10:56<03:54,  1.36it/s]
100%|██████████| 13/13 [00:00<00:00, 14.78it/s][A
                                               [A 72%|███████▏  | 801/1120 [10:57<05:35,  1.05s/it] 72%|███████▏  | 802/1120 [10:58<05:04,  1.04it/s] 72%|███████▏  | 803/1120 [10:59<04:43,  1.12it/s] 72%|███████▏  | 804/1120 [10:59<04:27,  1.18it/s] 72%|███████▏  | 805/1120 [11:00<04:17,  1.22it/s] 72%|███████▏  | 806/1120 [11:01<04:08,  1.27it/s] 72%|███████▏  | 807/1120 [11:02<04:02,  1.29it/s] 72%|███████▏  | 808/1120 [11:02<03:58,  1.31it/s] 72%|███████▏  | 809/1120 [11:03<03:54,  1.33it/s] 72%|███████▏  | 810/1120 [11:04<03:52,  1.34it/s]                                                   72%|███████▏  | 810/1120 [11:04<03:52,  1.34it/s] 72%|███████▏  | 811/1120 [11:05<03:49,  1.35it/s] 72%|███████▎  | 812/1120 [11:05<03:47,  1.35it/s] 73%|███████▎  | 813/1120 [11:06<03:46,  1.36it/s] 73%|███████▎  | 814/1120 [11:07<03:45,  1.36it/s] 73%|███████▎  | 815/1120 [11:07<03:44,  1.36it/s] 73%|███████▎  | 816/1120 [11:08<03:43,  1.36it/s] 73%|███████▎  | 817/1120 [11:09<03:43,  1.35it/s] 73%|███████▎  | 818/1120 [11:10<03:43,  1.35it/s] 73%|███████▎  | 819/1120 [11:10<03:41,  1.36it/s] 73%|███████▎  | 820/1120 [11:11<03:40,  1.36it/s]                                                   73%|███████▎  | 820/1120 [11:11<03:40,  1.36it/s] 73%|███████▎  | 821/1120 [11:12<03:39,  1.36it/s] 73%|███████▎  | 822/1120 [11:13<03:38,  1.36it/s] 73%|███████▎  | 823/1120 [11:13<03:38,  1.36it/s] 74%|███████▎  | 824/1120 [11:14<03:36,  1.37it/s] 74%|███████▎  | 825/1120 [11:15<03:35,  1.37it/s] 74%|███████▍  | 826/1120 [11:16<03:36,  1.36it/s] 74%|███████▍  | 827/1120 [11:16<03:35,  1.36it/s] 74%|███████▍  | 828/1120 [11:17<03:35,  1.36it/s] 74%|███████▍  | 829/1120 [11:18<03:35,  1.35it/s] 74%|███████▍  | 830/1120 [11:19<03:35,  1.35it/s]                                                   74%|███████▍  | 830/1120 [11:19<03:35,  1.35it/s] 74%|███████▍  | 831/1120 [11:19<03:35,  1.34it/s] 74%|███████▍  | 832/1120 [11:20<03:35,  1.34it/s] 74%|███████▍  | 833/1120 [11:21<03:34,  1.34it/s] 74%|███████▍  | 834/1120 [11:22<03:33,  1.34it/s] 75%|███████▍  | 835/1120 [11:22<03:32,  1.34it/s] 75%|███████▍  | 836/1120 [11:23<03:31,  1.34it/s] 75%|███████▍  | 837/1120 [11:24<03:32,  1.33it/s] 75%|███████▍  | 838/1120 [11:24<03:31,  1.33it/s] 75%|███████▍  | 839/1120 [11:25<03:30,  1.34it/s] 75%|███████▌  | 840/1120 [11:26<03:28,  1.34it/s]                                                   75%|███████▌  | 840/1120 [11:26<03:28,  1.34it/s]{'eval_loss': 0.2264719009399414, 'eval_runtime': 0.9237, 'eval_samples_per_second': 108.265, 'eval_steps_per_second': 14.074, 'epoch': 7.11}
{'loss': 0.024, 'learning_rate': 8.691588785046728e-05, 'epoch': 7.2}
{'loss': 0.0198, 'learning_rate': 8.411214953271027e-05, 'epoch': 7.29}
{'loss': 0.0406, 'learning_rate': 8.130841121495326e-05, 'epoch': 7.38}
{'loss': 0.0617, 'learning_rate': 7.850467289719625e-05, 'epoch': 7.47}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.08it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.44it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.60it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.08it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.82it/s][A                                                  
                                               [A 75%|███████▌  | 840/1120 [11:27<03:28,  1.34it/s]
100%|██████████| 13/13 [00:00<00:00, 14.82it/s][A
                                               [A 75%|███████▌  | 841/1120 [11:28<04:54,  1.06s/it] 75%|███████▌  | 842/1120 [11:29<04:27,  1.04it/s] 75%|███████▌  | 843/1120 [11:29<04:08,  1.12it/s] 75%|███████▌  | 844/1120 [11:30<03:54,  1.18it/s] 75%|███████▌  | 845/1120 [11:31<03:44,  1.22it/s] 76%|███████▌  | 846/1120 [11:31<03:37,  1.26it/s] 76%|███████▌  | 847/1120 [11:32<03:32,  1.28it/s] 76%|███████▌  | 848/1120 [11:33<03:29,  1.30it/s] 76%|███████▌  | 849/1120 [11:34<03:26,  1.31it/s] 76%|███████▌  | 850/1120 [11:34<03:24,  1.32it/s]                                                   76%|███████▌  | 850/1120 [11:34<03:24,  1.32it/s] 76%|███████▌  | 851/1120 [11:35<03:22,  1.33it/s] 76%|███████▌  | 852/1120 [11:36<03:21,  1.33it/s] 76%|███████▌  | 853/1120 [11:37<03:20,  1.33it/s] 76%|███████▋  | 854/1120 [11:37<03:19,  1.33it/s] 76%|███████▋  | 855/1120 [11:38<03:18,  1.33it/s] 76%|███████▋  | 856/1120 [11:39<03:18,  1.33it/s] 77%|███████▋  | 857/1120 [11:40<03:16,  1.34it/s] 77%|███████▋  | 858/1120 [11:40<03:15,  1.34it/s] 77%|███████▋  | 859/1120 [11:41<03:13,  1.35it/s] 77%|███████▋  | 860/1120 [11:42<03:13,  1.34it/s]                                                   77%|███████▋  | 860/1120 [11:42<03:13,  1.34it/s] 77%|███████▋  | 861/1120 [11:43<03:12,  1.34it/s] 77%|███████▋  | 862/1120 [11:43<03:12,  1.34it/s] 77%|███████▋  | 863/1120 [11:44<03:11,  1.34it/s] 77%|███████▋  | 864/1120 [11:45<03:10,  1.34it/s] 77%|███████▋  | 865/1120 [11:46<03:10,  1.34it/s] 77%|███████▋  | 866/1120 [11:46<03:09,  1.34it/s] 77%|███████▋  | 867/1120 [11:47<03:08,  1.34it/s] 78%|███████▊  | 868/1120 [11:48<03:09,  1.33it/s] 78%|███████▊  | 869/1120 [11:49<03:08,  1.33it/s] 78%|███████▊  | 870/1120 [11:49<03:07,  1.33it/s]                                                   78%|███████▊  | 870/1120 [11:49<03:07,  1.33it/s] 78%|███████▊  | 871/1120 [11:50<03:06,  1.34it/s] 78%|███████▊  | 872/1120 [11:51<03:05,  1.34it/s] 78%|███████▊  | 873/1120 [11:52<03:04,  1.34it/s] 78%|███████▊  | 874/1120 [11:52<03:03,  1.34it/s] 78%|███████▊  | 875/1120 [11:53<03:02,  1.34it/s] 78%|███████▊  | 876/1120 [11:54<03:01,  1.34it/s] 78%|███████▊  | 877/1120 [11:55<03:00,  1.34it/s] 78%|███████▊  | 878/1120 [11:55<03:00,  1.34it/s] 78%|███████▊  | 879/1120 [11:56<02:59,  1.34it/s] 79%|███████▊  | 880/1120 [11:57<02:59,  1.34it/s]                                                   79%|███████▊  | 880/1120 [11:57<02:59,  1.34it/s]{'eval_loss': 0.22971786558628082, 'eval_runtime': 0.92, 'eval_samples_per_second': 108.696, 'eval_steps_per_second': 14.131, 'epoch': 7.47}
{'loss': 0.0124, 'learning_rate': 7.570093457943924e-05, 'epoch': 7.56}
{'loss': 0.0291, 'learning_rate': 7.289719626168223e-05, 'epoch': 7.64}
{'loss': 0.0316, 'learning_rate': 7.009345794392522e-05, 'epoch': 7.73}
{'loss': 0.0243, 'learning_rate': 6.728971962616821e-05, 'epoch': 7.82}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.02it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.30it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.43it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.97it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.64it/s][A                                                  
                                               [A 79%|███████▊  | 880/1120 [11:58<02:59,  1.34it/s]
100%|██████████| 13/13 [00:00<00:00, 14.64it/s][A
                                               [A 79%|███████▊  | 881/1120 [11:59<04:15,  1.07s/it] 79%|███████▉  | 882/1120 [11:59<03:52,  1.02it/s] 79%|███████▉  | 883/1120 [12:00<03:35,  1.10it/s] 79%|███████▉  | 884/1120 [12:01<03:23,  1.16it/s] 79%|███████▉  | 885/1120 [12:02<03:15,  1.20it/s] 79%|███████▉  | 886/1120 [12:02<03:08,  1.24it/s] 79%|███████▉  | 887/1120 [12:03<03:03,  1.27it/s] 79%|███████▉  | 888/1120 [12:04<03:00,  1.29it/s] 79%|███████▉  | 889/1120 [12:05<02:57,  1.30it/s] 79%|███████▉  | 890/1120 [12:05<02:55,  1.31it/s]                                                   79%|███████▉  | 890/1120 [12:05<02:55,  1.31it/s] 80%|███████▉  | 891/1120 [12:06<02:53,  1.32it/s] 80%|███████▉  | 892/1120 [12:07<02:52,  1.32it/s] 80%|███████▉  | 893/1120 [12:08<02:52,  1.32it/s] 80%|███████▉  | 894/1120 [12:08<02:50,  1.33it/s] 80%|███████▉  | 895/1120 [12:09<02:49,  1.33it/s] 80%|████████  | 896/1120 [12:10<02:47,  1.33it/s] 80%|████████  | 897/1120 [12:11<02:46,  1.34it/s] 80%|████████  | 898/1120 [12:11<02:45,  1.34it/s] 80%|████████  | 899/1120 [12:12<02:44,  1.34it/s] 80%|████████  | 900/1120 [12:13<02:43,  1.34it/s]                                                   80%|████████  | 900/1120 [12:13<02:43,  1.34it/s] 80%|████████  | 901/1120 [12:14<02:42,  1.35it/s] 81%|████████  | 902/1120 [12:14<02:40,  1.35it/s] 81%|████████  | 903/1120 [12:15<02:39,  1.36it/s] 81%|████████  | 904/1120 [12:16<02:38,  1.36it/s] 81%|████████  | 905/1120 [12:17<02:38,  1.36it/s] 81%|████████  | 906/1120 [12:17<02:37,  1.36it/s] 81%|████████  | 907/1120 [12:18<02:36,  1.36it/s] 81%|████████  | 908/1120 [12:19<02:35,  1.36it/s] 81%|████████  | 909/1120 [12:20<02:35,  1.36it/s] 81%|████████▏ | 910/1120 [12:20<02:34,  1.36it/s]                                                   81%|████████▏ | 910/1120 [12:20<02:34,  1.36it/s] 81%|████████▏ | 911/1120 [12:21<02:33,  1.36it/s] 81%|████████▏ | 912/1120 [12:22<02:32,  1.37it/s] 82%|████████▏ | 913/1120 [12:22<02:31,  1.37it/s] 82%|████████▏ | 914/1120 [12:23<02:30,  1.37it/s] 82%|████████▏ | 915/1120 [12:24<02:30,  1.36it/s] 82%|████████▏ | 916/1120 [12:25<02:29,  1.36it/s] 82%|████████▏ | 917/1120 [12:25<02:28,  1.36it/s] 82%|████████▏ | 918/1120 [12:26<02:28,  1.36it/s] 82%|████████▏ | 919/1120 [12:27<02:27,  1.37it/s] 82%|████████▏ | 920/1120 [12:28<02:26,  1.36it/s]                                                   82%|████████▏ | 920/1120 [12:28<02:26,  1.36it/s]{'eval_loss': 0.2474704384803772, 'eval_runtime': 0.9286, 'eval_samples_per_second': 107.689, 'eval_steps_per_second': 14.0, 'epoch': 7.82}
{'loss': 0.028, 'learning_rate': 6.44859813084112e-05, 'epoch': 7.91}
{'loss': 0.0105, 'learning_rate': 6.168224299065419e-05, 'epoch': 8.0}
{'loss': 0.0208, 'learning_rate': 5.887850467289719e-05, 'epoch': 8.09}
{'loss': 0.0171, 'learning_rate': 5.607476635514018e-05, 'epoch': 8.18}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.05it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.46it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.60it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.15it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.82it/s][A                                                  
                                               [A 82%|████████▏ | 920/1120 [12:29<02:26,  1.36it/s]
100%|██████████| 13/13 [00:00<00:00, 14.82it/s][A
                                               [A 82%|████████▏ | 921/1120 [12:29<03:34,  1.08s/it] 82%|████████▏ | 922/1120 [12:30<03:13,  1.02it/s] 82%|████████▏ | 923/1120 [12:31<02:57,  1.11it/s] 82%|████████▎ | 924/1120 [12:32<02:46,  1.18it/s] 83%|████████▎ | 925/1120 [12:32<02:39,  1.23it/s] 83%|████████▎ | 926/1120 [12:33<02:33,  1.27it/s] 83%|████████▎ | 927/1120 [12:34<02:28,  1.30it/s] 83%|████████▎ | 928/1120 [12:35<02:26,  1.31it/s] 83%|████████▎ | 929/1120 [12:35<02:23,  1.33it/s] 83%|████████▎ | 930/1120 [12:36<02:22,  1.34it/s]                                                   83%|████████▎ | 930/1120 [12:36<02:22,  1.34it/s] 83%|████████▎ | 931/1120 [12:37<02:20,  1.35it/s] 83%|████████▎ | 932/1120 [12:38<02:19,  1.35it/s] 83%|████████▎ | 933/1120 [12:38<02:17,  1.36it/s] 83%|████████▎ | 934/1120 [12:39<02:16,  1.36it/s] 83%|████████▎ | 935/1120 [12:40<02:16,  1.35it/s] 84%|████████▎ | 936/1120 [12:40<02:15,  1.35it/s] 84%|████████▎ | 937/1120 [12:41<02:15,  1.35it/s] 84%|████████▍ | 938/1120 [12:42<02:14,  1.36it/s] 84%|████████▍ | 939/1120 [12:43<02:13,  1.36it/s] 84%|████████▍ | 940/1120 [12:43<02:12,  1.36it/s]                                                   84%|████████▍ | 940/1120 [12:43<02:12,  1.36it/s] 84%|████████▍ | 941/1120 [12:44<02:11,  1.36it/s] 84%|████████▍ | 942/1120 [12:45<02:10,  1.36it/s] 84%|████████▍ | 943/1120 [12:46<02:09,  1.36it/s] 84%|████████▍ | 944/1120 [12:46<02:09,  1.36it/s] 84%|████████▍ | 945/1120 [12:47<02:08,  1.36it/s] 84%|████████▍ | 946/1120 [12:48<02:08,  1.36it/s] 85%|████████▍ | 947/1120 [12:49<02:07,  1.36it/s] 85%|████████▍ | 948/1120 [12:49<02:06,  1.36it/s] 85%|████████▍ | 949/1120 [12:50<02:06,  1.35it/s] 85%|████████▍ | 950/1120 [12:51<02:06,  1.35it/s]                                                   85%|████████▍ | 950/1120 [12:51<02:06,  1.35it/s] 85%|████████▍ | 951/1120 [12:52<02:05,  1.35it/s] 85%|████████▌ | 952/1120 [12:52<02:04,  1.35it/s] 85%|████████▌ | 953/1120 [12:53<02:03,  1.35it/s] 85%|████████▌ | 954/1120 [12:54<02:02,  1.36it/s] 85%|████████▌ | 955/1120 [12:54<02:02,  1.35it/s] 85%|████████▌ | 956/1120 [12:55<02:01,  1.35it/s] 85%|████████▌ | 957/1120 [12:56<02:01,  1.34it/s] 86%|████████▌ | 958/1120 [12:57<02:00,  1.35it/s] 86%|████████▌ | 959/1120 [12:57<01:59,  1.34it/s] 86%|████████▌ | 960/1120 [12:58<01:58,  1.35it/s]                                                   86%|████████▌ | 960/1120 [12:58<01:58,  1.35it/s]{'eval_loss': 0.25398606061935425, 'eval_runtime': 0.9194, 'eval_samples_per_second': 108.766, 'eval_steps_per_second': 14.14, 'epoch': 8.18}
{'loss': 0.0188, 'learning_rate': 5.327102803738317e-05, 'epoch': 8.27}
{'loss': 0.0119, 'learning_rate': 5.046728971962616e-05, 'epoch': 8.36}
{'loss': 0.0201, 'learning_rate': 4.766355140186915e-05, 'epoch': 8.44}
{'loss': 0.0521, 'learning_rate': 4.485981308411214e-05, 'epoch': 8.53}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.09it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.32it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.41it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.98it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.63it/s][A                                                  
                                               [A 86%|████████▌ | 960/1120 [12:59<01:58,  1.35it/s]
100%|██████████| 13/13 [00:00<00:00, 14.63it/s][A
                                               [A 86%|████████▌ | 961/1120 [13:00<02:49,  1.06s/it] 86%|████████▌ | 962/1120 [13:01<02:32,  1.04it/s] 86%|████████▌ | 963/1120 [13:02<02:21,  1.11it/s] 86%|████████▌ | 964/1120 [13:02<02:12,  1.17it/s] 86%|████████▌ | 965/1120 [13:03<02:06,  1.22it/s] 86%|████████▋ | 966/1120 [13:04<02:02,  1.26it/s] 86%|████████▋ | 967/1120 [13:04<01:59,  1.29it/s] 86%|████████▋ | 968/1120 [13:05<01:56,  1.30it/s] 87%|████████▋ | 969/1120 [13:06<01:54,  1.32it/s] 87%|████████▋ | 970/1120 [13:07<01:53,  1.32it/s]                                                   87%|████████▋ | 970/1120 [13:07<01:53,  1.32it/s] 87%|████████▋ | 971/1120 [13:07<01:51,  1.33it/s] 87%|████████▋ | 972/1120 [13:08<01:50,  1.34it/s] 87%|████████▋ | 973/1120 [13:09<01:49,  1.34it/s] 87%|████████▋ | 974/1120 [13:10<01:49,  1.33it/s] 87%|████████▋ | 975/1120 [13:10<01:49,  1.33it/s] 87%|████████▋ | 976/1120 [13:11<01:47,  1.33it/s] 87%|████████▋ | 977/1120 [13:12<01:46,  1.34it/s] 87%|████████▋ | 978/1120 [13:13<01:45,  1.34it/s] 87%|████████▋ | 979/1120 [13:13<01:45,  1.34it/s] 88%|████████▊ | 980/1120 [13:14<01:44,  1.34it/s]                                                   88%|████████▊ | 980/1120 [13:14<01:44,  1.34it/s] 88%|████████▊ | 981/1120 [13:15<01:44,  1.34it/s] 88%|████████▊ | 982/1120 [13:16<01:43,  1.34it/s] 88%|████████▊ | 983/1120 [13:16<01:42,  1.34it/s] 88%|████████▊ | 984/1120 [13:17<01:41,  1.34it/s] 88%|████████▊ | 985/1120 [13:18<01:41,  1.33it/s] 88%|████████▊ | 986/1120 [13:19<01:40,  1.34it/s] 88%|████████▊ | 987/1120 [13:19<01:39,  1.33it/s] 88%|████████▊ | 988/1120 [13:20<01:39,  1.33it/s] 88%|████████▊ | 989/1120 [13:21<01:38,  1.33it/s] 88%|████████▊ | 990/1120 [13:22<01:37,  1.33it/s]                                                   88%|████████▊ | 990/1120 [13:22<01:37,  1.33it/s] 88%|████████▊ | 991/1120 [13:22<01:36,  1.34it/s] 89%|████████▊ | 992/1120 [13:23<01:35,  1.34it/s] 89%|████████▊ | 993/1120 [13:24<01:35,  1.33it/s] 89%|████████▉ | 994/1120 [13:25<01:34,  1.34it/s] 89%|████████▉ | 995/1120 [13:25<01:33,  1.34it/s] 89%|████████▉ | 996/1120 [13:26<01:32,  1.34it/s] 89%|████████▉ | 997/1120 [13:27<01:31,  1.34it/s] 89%|████████▉ | 998/1120 [13:28<01:30,  1.34it/s] 89%|████████▉ | 999/1120 [13:28<01:29,  1.35it/s] 89%|████████▉ | 1000/1120 [13:29<01:29,  1.35it/s]                                                    89%|████████▉ | 1000/1120 [13:29<01:29,  1.35it/s]{'eval_loss': 0.24836109578609467, 'eval_runtime': 0.9293, 'eval_samples_per_second': 107.61, 'eval_steps_per_second': 13.989, 'epoch': 8.53}
{'loss': 0.0401, 'learning_rate': 4.2056074766355134e-05, 'epoch': 8.62}
{'loss': 0.0266, 'learning_rate': 3.9252336448598124e-05, 'epoch': 8.71}
{'loss': 0.0211, 'learning_rate': 3.6448598130841115e-05, 'epoch': 8.8}
{'loss': 0.0319, 'learning_rate': 3.3644859813084105e-05, 'epoch': 8.89}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.66it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.97it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.19it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.66it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.33it/s][A                                                   
                                               [A 89%|████████▉ | 1000/1120 [13:30<01:29,  1.35it/s]
100%|██████████| 13/13 [00:00<00:00, 14.33it/s][A
                                               [A 89%|████████▉ | 1001/1120 [13:31<02:06,  1.06s/it] 89%|████████▉ | 1002/1120 [13:32<01:54,  1.03it/s] 90%|████████▉ | 1003/1120 [13:32<01:45,  1.11it/s] 90%|████████▉ | 1004/1120 [13:33<01:39,  1.17it/s] 90%|████████▉ | 1005/1120 [13:34<01:34,  1.22it/s] 90%|████████▉ | 1006/1120 [13:35<01:30,  1.25it/s] 90%|████████▉ | 1007/1120 [13:35<01:28,  1.28it/s] 90%|█████████ | 1008/1120 [13:36<01:26,  1.29it/s] 90%|█████████ | 1009/1120 [13:37<01:25,  1.30it/s] 90%|█████████ | 1010/1120 [13:38<01:23,  1.32it/s]                                                    90%|█████████ | 1010/1120 [13:38<01:23,  1.32it/s] 90%|█████████ | 1011/1120 [13:38<01:22,  1.33it/s] 90%|█████████ | 1012/1120 [13:39<01:21,  1.33it/s] 90%|█████████ | 1013/1120 [13:40<01:20,  1.33it/s] 91%|█████████ | 1014/1120 [13:41<01:19,  1.34it/s] 91%|█████████ | 1015/1120 [13:41<01:19,  1.33it/s] 91%|█████████ | 1016/1120 [13:42<01:18,  1.33it/s] 91%|█████████ | 1017/1120 [13:43<01:17,  1.33it/s] 91%|█████████ | 1018/1120 [13:44<01:16,  1.34it/s] 91%|█████████ | 1019/1120 [13:44<01:15,  1.34it/s] 91%|█████████ | 1020/1120 [13:45<01:14,  1.34it/s]                                                    91%|█████████ | 1020/1120 [13:45<01:14,  1.34it/s] 91%|█████████ | 1021/1120 [13:46<01:13,  1.34it/s] 91%|█████████▏| 1022/1120 [13:47<01:13,  1.33it/s] 91%|█████████▏| 1023/1120 [13:47<01:12,  1.33it/s] 91%|█████████▏| 1024/1120 [13:48<01:11,  1.34it/s] 92%|█████████▏| 1025/1120 [13:49<01:10,  1.34it/s] 92%|█████████▏| 1026/1120 [13:50<01:10,  1.34it/s] 92%|█████████▏| 1027/1120 [13:50<01:09,  1.34it/s] 92%|█████████▏| 1028/1120 [13:51<01:08,  1.35it/s] 92%|█████████▏| 1029/1120 [13:52<01:07,  1.35it/s] 92%|█████████▏| 1030/1120 [13:53<01:06,  1.35it/s]                                                    92%|█████████▏| 1030/1120 [13:53<01:06,  1.35it/s] 92%|█████████▏| 1031/1120 [13:53<01:05,  1.35it/s] 92%|█████████▏| 1032/1120 [13:54<01:05,  1.35it/s] 92%|█████████▏| 1033/1120 [13:55<01:04,  1.35it/s] 92%|█████████▏| 1034/1120 [13:55<01:03,  1.35it/s] 92%|█████████▏| 1035/1120 [13:56<01:02,  1.35it/s] 92%|█████████▎| 1036/1120 [13:57<01:02,  1.35it/s] 93%|█████████▎| 1037/1120 [13:58<01:01,  1.35it/s] 93%|█████████▎| 1038/1120 [13:58<01:00,  1.35it/s] 93%|█████████▎| 1039/1120 [13:59<01:00,  1.35it/s] 93%|█████████▎| 1040/1120 [14:00<00:59,  1.34it/s]                                                    93%|█████████▎| 1040/1120 [14:00<00:59,  1.34it/s]{'eval_loss': 0.25245437026023865, 'eval_runtime': 0.9471, 'eval_samples_per_second': 105.582, 'eval_steps_per_second': 13.726, 'epoch': 8.89}
{'loss': 0.0221, 'learning_rate': 3.0841121495327096e-05, 'epoch': 8.98}
{'loss': 0.0392, 'learning_rate': 2.803738317757009e-05, 'epoch': 9.07}
{'loss': 0.0323, 'learning_rate': 2.523364485981308e-05, 'epoch': 9.16}
{'loss': 0.0143, 'learning_rate': 2.242990654205607e-05, 'epoch': 9.24}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.98it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.29it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.39it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.94it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.61it/s][A                                                   
                                               [A 93%|█████████▎| 1040/1120 [14:01<00:59,  1.34it/s]
100%|██████████| 13/13 [00:00<00:00, 14.61it/s][A
                                               [A 93%|█████████▎| 1041/1120 [14:02<01:23,  1.06s/it] 93%|█████████▎| 1042/1120 [14:02<01:15,  1.04it/s] 93%|█████████▎| 1043/1120 [14:03<01:09,  1.11it/s] 93%|█████████▎| 1044/1120 [14:04<01:04,  1.17it/s] 93%|█████████▎| 1045/1120 [14:05<01:01,  1.22it/s] 93%|█████████▎| 1046/1120 [14:05<00:59,  1.25it/s] 93%|█████████▎| 1047/1120 [14:06<00:56,  1.28it/s] 94%|█████████▎| 1048/1120 [14:07<00:55,  1.30it/s] 94%|█████████▎| 1049/1120 [14:08<00:53,  1.32it/s] 94%|█████████▍| 1050/1120 [14:08<00:52,  1.33it/s]                                                    94%|█████████▍| 1050/1120 [14:08<00:52,  1.33it/s] 94%|█████████▍| 1051/1120 [14:09<00:51,  1.34it/s] 94%|█████████▍| 1052/1120 [14:10<00:50,  1.33it/s] 94%|█████████▍| 1053/1120 [14:11<00:49,  1.34it/s] 94%|█████████▍| 1054/1120 [14:11<00:48,  1.35it/s] 94%|█████████▍| 1055/1120 [14:12<00:48,  1.35it/s] 94%|█████████▍| 1056/1120 [14:13<00:47,  1.35it/s] 94%|█████████▍| 1057/1120 [14:14<00:46,  1.35it/s] 94%|█████████▍| 1058/1120 [14:14<00:45,  1.35it/s] 95%|█████████▍| 1059/1120 [14:15<00:45,  1.35it/s] 95%|█████████▍| 1060/1120 [14:16<00:44,  1.36it/s]                                                    95%|█████████▍| 1060/1120 [14:16<00:44,  1.36it/s] 95%|█████████▍| 1061/1120 [14:17<00:43,  1.35it/s] 95%|█████████▍| 1062/1120 [14:17<00:43,  1.35it/s] 95%|█████████▍| 1063/1120 [14:18<00:42,  1.34it/s] 95%|█████████▌| 1064/1120 [14:19<00:41,  1.35it/s] 95%|█████████▌| 1065/1120 [14:20<00:40,  1.35it/s] 95%|█████████▌| 1066/1120 [14:20<00:39,  1.35it/s] 95%|█████████▌| 1067/1120 [14:21<00:39,  1.35it/s] 95%|█████████▌| 1068/1120 [14:22<00:38,  1.35it/s] 95%|█████████▌| 1069/1120 [14:22<00:37,  1.35it/s] 96%|█████████▌| 1070/1120 [14:23<00:37,  1.35it/s]                                                    96%|█████████▌| 1070/1120 [14:23<00:37,  1.35it/s] 96%|█████████▌| 1071/1120 [14:24<00:36,  1.35it/s] 96%|█████████▌| 1072/1120 [14:25<00:35,  1.35it/s] 96%|█████████▌| 1073/1120 [14:25<00:34,  1.35it/s] 96%|█████████▌| 1074/1120 [14:26<00:34,  1.35it/s] 96%|█████████▌| 1075/1120 [14:27<00:33,  1.35it/s] 96%|█████████▌| 1076/1120 [14:28<00:32,  1.35it/s] 96%|█████████▌| 1077/1120 [14:28<00:31,  1.35it/s] 96%|█████████▋| 1078/1120 [14:29<00:30,  1.36it/s] 96%|█████████▋| 1079/1120 [14:30<00:30,  1.35it/s] 96%|█████████▋| 1080/1120 [14:31<00:29,  1.35it/s]                                                    96%|█████████▋| 1080/1120 [14:31<00:29,  1.35it/s]{'eval_loss': 0.2512553036212921, 'eval_runtime': 0.9308, 'eval_samples_per_second': 107.436, 'eval_steps_per_second': 13.967, 'epoch': 9.24}
{'loss': 0.0206, 'learning_rate': 1.9626168224299062e-05, 'epoch': 9.33}
{'loss': 0.0438, 'learning_rate': 1.6822429906542053e-05, 'epoch': 9.42}
{'loss': 0.0124, 'learning_rate': 1.4018691588785045e-05, 'epoch': 9.51}
{'loss': 0.0064, 'learning_rate': 1.1214953271028036e-05, 'epoch': 9.6}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.82it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.23it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.40it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.91it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.54it/s][A                                                   
                                               [A 96%|█████████▋| 1080/1120 [14:32<00:29,  1.35it/s]
100%|██████████| 13/13 [00:00<00:00, 14.54it/s][A
                                               [A 97%|█████████▋| 1081/1120 [14:32<00:41,  1.06s/it] 97%|█████████▋| 1082/1120 [14:33<00:37,  1.02it/s] 97%|█████████▋| 1083/1120 [14:34<00:34,  1.09it/s] 97%|█████████▋| 1084/1120 [14:35<00:31,  1.15it/s] 97%|█████████▋| 1085/1120 [14:35<00:28,  1.22it/s] 97%|█████████▋| 1086/1120 [14:36<00:26,  1.28it/s] 97%|█████████▋| 1087/1120 [14:37<00:25,  1.31it/s] 97%|█████████▋| 1088/1120 [14:38<00:24,  1.30it/s] 97%|█████████▋| 1089/1120 [14:38<00:23,  1.30it/s] 97%|█████████▋| 1090/1120 [14:39<00:23,  1.30it/s]                                                    97%|█████████▋| 1090/1120 [14:39<00:23,  1.30it/s] 97%|█████████▋| 1091/1120 [14:40<00:22,  1.30it/s] 98%|█████████▊| 1092/1120 [14:41<00:21,  1.30it/s] 98%|█████████▊| 1093/1120 [14:41<00:20,  1.30it/s] 98%|█████████▊| 1094/1120 [14:42<00:19,  1.30it/s] 98%|█████████▊| 1095/1120 [14:43<00:19,  1.30it/s] 98%|█████████▊| 1096/1120 [14:44<00:18,  1.30it/s] 98%|█████████▊| 1097/1120 [14:45<00:17,  1.30it/s] 98%|█████████▊| 1098/1120 [14:45<00:16,  1.31it/s] 98%|█████████▊| 1099/1120 [14:46<00:15,  1.31it/s] 98%|█████████▊| 1100/1120 [14:47<00:15,  1.28it/s]                                                    98%|█████████▊| 1100/1120 [14:47<00:15,  1.28it/s] 98%|█████████▊| 1101/1120 [14:48<00:15,  1.25it/s] 98%|█████████▊| 1102/1120 [14:49<00:14,  1.24it/s] 98%|█████████▊| 1103/1120 [14:49<00:13,  1.24it/s] 99%|█████████▊| 1104/1120 [14:50<00:12,  1.24it/s] 99%|█████████▊| 1105/1120 [14:51<00:12,  1.24it/s] 99%|█████████▉| 1106/1120 [14:52<00:11,  1.24it/s] 99%|█████████▉| 1107/1120 [14:53<00:10,  1.24it/s] 99%|█████████▉| 1108/1120 [14:53<00:09,  1.24it/s] 99%|█████████▉| 1109/1120 [14:54<00:08,  1.24it/s] 99%|█████████▉| 1110/1120 [14:55<00:08,  1.24it/s]                                                    99%|█████████▉| 1110/1120 [14:55<00:08,  1.24it/s] 99%|█████████▉| 1111/1120 [14:56<00:07,  1.24it/s] 99%|█████████▉| 1112/1120 [14:57<00:06,  1.24it/s] 99%|█████████▉| 1113/1120 [14:57<00:05,  1.24it/s] 99%|█████████▉| 1114/1120 [14:58<00:04,  1.24it/s]100%|█████████▉| 1115/1120 [14:59<00:04,  1.25it/s]100%|█████████▉| 1116/1120 [15:00<00:03,  1.28it/s]100%|█████████▉| 1117/1120 [15:00<00:02,  1.30it/s]100%|█████████▉| 1118/1120 [15:01<00:01,  1.31it/s]100%|█████████▉| 1119/1120 [15:02<00:00,  1.32it/s]100%|██████████| 1120/1120 [15:03<00:00,  1.33it/s]                                                   100%|██████████| 1120/1120 [15:03<00:00,  1.33it/s]{'eval_loss': 0.2477337121963501, 'eval_runtime': 0.9334, 'eval_samples_per_second': 107.13, 'eval_steps_per_second': 13.927, 'epoch': 9.6}
{'loss': 0.014, 'learning_rate': 8.411214953271026e-06, 'epoch': 9.69}
{'loss': 0.0235, 'learning_rate': 5.607476635514018e-06, 'epoch': 9.78}
{'loss': 0.0098, 'learning_rate': 2.803738317757009e-06, 'epoch': 9.87}
{'loss': 0.0152, 'learning_rate': 0.0, 'epoch': 9.96}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.96it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.41it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.56it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.09it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.77it/s][A                                                   
                                               [A100%|██████████| 1120/1120 [15:04<00:00,  1.33it/s]
100%|██████████| 13/13 [00:00<00:00, 14.77it/s][A
                                               [AThere were missing keys in the checkpoint model loaded: ['base_model.model.shared.weight', 'base_model.model.encoder.embed_tokens.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.encoder.block.0.layer.0.layer_norm.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.0.layer.1.layer_norm.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.1.layer.0.layer_norm.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.1.layer.1.layer_norm.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.2.layer.0.layer_norm.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.2.layer.1.layer_norm.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.3.layer.0.layer_norm.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.3.layer.1.layer_norm.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.4.layer.0.layer_norm.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.4.layer.1.layer_norm.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.5.layer.0.layer_norm.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.5.layer.1.layer_norm.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.6.layer.0.layer_norm.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.6.layer.1.layer_norm.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.7.layer.0.layer_norm.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.7.layer.1.layer_norm.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.8.layer.0.layer_norm.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.8.layer.1.layer_norm.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.9.layer.0.layer_norm.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.9.layer.1.layer_norm.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.10.layer.0.layer_norm.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.10.layer.1.layer_norm.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.11.layer.0.layer_norm.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.11.layer.1.layer_norm.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.12.layer.0.layer_norm.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.12.layer.1.layer_norm.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.13.layer.0.layer_norm.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.13.layer.1.layer_norm.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.14.layer.0.layer_norm.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.14.layer.1.layer_norm.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.15.layer.0.layer_norm.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.15.layer.1.layer_norm.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.16.layer.0.layer_norm.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.16.layer.1.layer_norm.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.17.layer.0.layer_norm.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.17.layer.1.layer_norm.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.18.layer.0.layer_norm.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.18.layer.1.layer_norm.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.19.layer.0.layer_norm.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.19.layer.1.layer_norm.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.20.layer.0.layer_norm.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.20.layer.1.layer_norm.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.21.layer.0.layer_norm.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.21.layer.1.layer_norm.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.22.layer.0.layer_norm.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.22.layer.1.layer_norm.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.23.layer.0.layer_norm.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.23.layer.1.layer_norm.weight', 'base_model.model.encoder.final_layer_norm.weight', 'base_model.model.decoder.embed_tokens.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.decoder.block.0.layer.0.layer_norm.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.0.layer.1.layer_norm.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.0.layer.2.layer_norm.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.1.layer.0.layer_norm.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.1.layer.1.layer_norm.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.1.layer.2.layer_norm.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.2.layer.0.layer_norm.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.2.layer.1.layer_norm.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.2.layer.2.layer_norm.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.3.layer.0.layer_norm.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.3.layer.1.layer_norm.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.3.layer.2.layer_norm.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.4.layer.0.layer_norm.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.4.layer.1.layer_norm.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.4.layer.2.layer_norm.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.5.layer.0.layer_norm.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.5.layer.1.layer_norm.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.5.layer.2.layer_norm.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.6.layer.0.layer_norm.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.6.layer.1.layer_norm.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.6.layer.2.layer_norm.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.7.layer.0.layer_norm.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.7.layer.1.layer_norm.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.7.layer.2.layer_norm.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.8.layer.0.layer_norm.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.8.layer.1.layer_norm.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.8.layer.2.layer_norm.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.9.layer.0.layer_norm.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.9.layer.1.layer_norm.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.9.layer.2.layer_norm.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.10.layer.0.layer_norm.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.10.layer.1.layer_norm.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.10.layer.2.layer_norm.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.11.layer.0.layer_norm.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.11.layer.1.layer_norm.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.11.layer.2.layer_norm.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.12.layer.0.layer_norm.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.12.layer.1.layer_norm.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.12.layer.2.layer_norm.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.13.layer.0.layer_norm.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.13.layer.1.layer_norm.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.13.layer.2.layer_norm.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.14.layer.0.layer_norm.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.14.layer.1.layer_norm.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.14.layer.2.layer_norm.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.15.layer.0.layer_norm.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.15.layer.1.layer_norm.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.15.layer.2.layer_norm.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.16.layer.0.layer_norm.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.16.layer.1.layer_norm.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.16.layer.2.layer_norm.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.17.layer.0.layer_norm.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.17.layer.1.layer_norm.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.17.layer.2.layer_norm.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.18.layer.0.layer_norm.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.18.layer.1.layer_norm.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.18.layer.2.layer_norm.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.19.layer.0.layer_norm.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.19.layer.1.layer_norm.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.19.layer.2.layer_norm.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.20.layer.0.layer_norm.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.20.layer.1.layer_norm.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.20.layer.2.layer_norm.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.21.layer.0.layer_norm.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.21.layer.1.layer_norm.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.21.layer.2.layer_norm.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.22.layer.0.layer_norm.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.22.layer.1.layer_norm.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.22.layer.2.layer_norm.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.23.layer.0.layer_norm.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.23.layer.1.layer_norm.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.23.layer.2.layer_norm.weight', 'base_model.model.decoder.final_layer_norm.weight', 'base_model.model.lm_head.weight'].
There were unexpected keys in the checkpoint model loaded: ['base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.weight'].
                                                   100%|██████████| 1120/1120 [15:04<00:00,  1.33it/s]100%|██████████| 1120/1120 [15:04<00:00,  1.24it/s]
{'eval_loss': 0.2495322972536087, 'eval_runtime': 0.9223, 'eval_samples_per_second': 108.422, 'eval_steps_per_second': 14.095, 'epoch': 9.96}
{'train_runtime': 904.3998, 'train_samples_per_second': 9.951, 'train_steps_per_second': 1.238, 'train_loss': 0.15213827739602753, 'epoch': 9.96}

 If there's a warning about missing keys above, please disregard :)
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 8
micro_batch_size: 2
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: cb... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/1-cb
current data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 772.43it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 933.10it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Loading cached split indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3c0acee40c86feef.arrow and /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-d23b1e6e693671dd.arrow
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-23ddd5122a88e27d.arrow
Loading cached processed dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-ced4ed8bc63afeb3.arrow
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-0e9e2f72300277a7.arrow
Loading cached processed dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-33933896df254f7b.arrow
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-de27b9beee362d07.arrow
Loading cached processed dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-16be677b454dc479.arrow
总样本数：1000, 选择的样本数量：20
lora_weights: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/0-mnli

pre-trained model's BOS EOS and PAD token id: None 1 0  => It should be 1,2,none
continual fine tune lora!
trainable params: 2359296 || all params: 740027392 || trainable%: 0.31881198257050464
训练数据总量：225
验证数据总量：25
memory data loader 2
  0%|          | 0/280 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/280 [00:01<07:32,  1.62s/it]  1%|          | 2/280 [00:02<05:23,  1.16s/it]  1%|          | 3/280 [00:03<04:43,  1.02s/it]  1%|▏         | 4/280 [00:04<04:21,  1.05it/s]  2%|▏         | 5/280 [00:05<04:33,  1.00it/s]  2%|▏         | 6/280 [00:06<04:18,  1.06it/s]  2%|▎         | 7/280 [00:06<04:08,  1.10it/s]  3%|▎         | 8/280 [00:07<04:01,  1.13it/s]  3%|▎         | 9/280 [00:08<04:16,  1.06it/s]  4%|▎         | 10/280 [00:09<04:07,  1.09it/s]                                                  4%|▎         | 10/280 [00:09<04:07,  1.09it/s]  4%|▍         | 11/280 [00:10<04:00,  1.12it/s]  4%|▍         | 12/280 [00:11<03:56,  1.13it/s]  5%|▍         | 13/280 [00:12<04:11,  1.06it/s]  5%|▌         | 14/280 [00:13<04:05,  1.09it/s]  5%|▌         | 15/280 [00:14<03:58,  1.11it/s]  6%|▌         | 16/280 [00:15<03:52,  1.13it/s]  6%|▌         | 17/280 [00:16<04:08,  1.06it/s]  6%|▋         | 18/280 [00:16<04:00,  1.09it/s]  7%|▋         | 19/280 [00:17<03:54,  1.11it/s]  7%|▋         | 20/280 [00:18<03:51,  1.12it/s]                                                  7%|▋         | 20/280 [00:18<03:51,  1.12it/s]  8%|▊         | 21/280 [00:19<04:07,  1.05it/s]  8%|▊         | 22/280 [00:20<03:59,  1.08it/s]  8%|▊         | 23/280 [00:21<03:56,  1.09it/s]  9%|▊         | 24/280 [00:22<03:50,  1.11it/s]  9%|▉         | 25/280 [00:23<04:05,  1.04it/s]  9%|▉         | 26/280 [00:24<03:56,  1.08it/s] 10%|▉         | 27/280 [00:25<03:50,  1.10it/s] 10%|█         | 28/280 [00:26<03:45,  1.12it/s] 10%|█         | 29/280 [00:27<03:57,  1.06it/s] 11%|█         | 30/280 [00:28<03:50,  1.09it/s]                                                 11%|█         | 30/280 [00:28<03:50,  1.09it/s] 11%|█         | 31/280 [00:28<03:43,  1.11it/s] 11%|█▏        | 32/280 [00:29<03:39,  1.13it/s] 12%|█▏        | 33/280 [00:30<03:52,  1.06it/s] 12%|█▏        | 34/280 [00:31<03:45,  1.09it/s] 12%|█▎        | 35/280 [00:32<03:39,  1.11it/s] 13%|█▎        | 36/280 [00:33<03:36,  1.13it/s] 13%|█▎        | 37/280 [00:34<03:49,  1.06it/s] 14%|█▎        | 38/280 [00:35<03:43,  1.08it/s] 14%|█▍        | 39/280 [00:36<03:37,  1.11it/s] 14%|█▍        | 40/280 [00:37<03:32,  1.13it/s]                                                 14%|█▍        | 40/280 [00:37<03:32,  1.13it/s]外层迭代结束！
外层迭代结束！
{'loss': 0.2178, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.35}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0885, 'learning_rate': 0.00011999999999999999, 'epoch': 0.71}
外层迭代结束！
外层迭代结束！
{'loss': 0.1029, 'learning_rate': 0.00017999999999999998, 'epoch': 1.06}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0685, 'learning_rate': 0.00023999999999999998, 'epoch': 1.42}

  0%|          | 0/4 [00:00<?, ?it/s][A
 75%|███████▌  | 3/4 [00:00<00:00, 18.84it/s][A                                                
                                             [A 14%|█▍        | 40/280 [00:37<03:32,  1.13it/s]
100%|██████████| 4/4 [00:00<00:00, 18.84it/s][A
                                             [A 15%|█▍        | 41/280 [00:38<04:23,  1.10s/it] 15%|█▌        | 42/280 [00:39<04:05,  1.03s/it] 15%|█▌        | 43/280 [00:40<03:51,  1.03it/s] 16%|█▌        | 44/280 [00:41<03:42,  1.06it/s] 16%|█▌        | 45/280 [00:42<03:51,  1.02it/s] 16%|█▋        | 46/280 [00:43<03:41,  1.06it/s] 17%|█▋        | 47/280 [00:43<03:33,  1.09it/s] 17%|█▋        | 48/280 [00:44<03:27,  1.12it/s] 18%|█▊        | 49/280 [00:45<03:40,  1.05it/s] 18%|█▊        | 50/280 [00:46<03:32,  1.08it/s]                                                 18%|█▊        | 50/280 [00:46<03:32,  1.08it/s] 18%|█▊        | 51/280 [00:47<03:27,  1.11it/s] 19%|█▊        | 52/280 [00:48<03:22,  1.12it/s] 19%|█▉        | 53/280 [00:49<03:34,  1.06it/s] 19%|█▉        | 54/280 [00:50<03:27,  1.09it/s] 20%|█▉        | 55/280 [00:51<03:22,  1.11it/s] 20%|██        | 56/280 [00:52<03:18,  1.13it/s] 20%|██        | 57/280 [00:53<03:30,  1.06it/s] 21%|██        | 58/280 [00:54<03:23,  1.09it/s] 21%|██        | 59/280 [00:54<03:18,  1.11it/s] 21%|██▏       | 60/280 [00:55<03:15,  1.12it/s]                                                 21%|██▏       | 60/280 [00:56<03:15,  1.12it/s] 22%|██▏       | 61/280 [00:56<03:28,  1.05it/s] 22%|██▏       | 62/280 [00:57<03:20,  1.08it/s] 22%|██▎       | 63/280 [00:58<03:16,  1.11it/s] 23%|██▎       | 64/280 [00:59<03:12,  1.12it/s] 23%|██▎       | 65/280 [01:00<03:23,  1.06it/s] 24%|██▎       | 66/280 [01:01<03:17,  1.08it/s] 24%|██▍       | 67/280 [01:02<03:12,  1.11it/s] 24%|██▍       | 68/280 [01:03<03:08,  1.13it/s] 25%|██▍       | 69/280 [01:04<03:19,  1.06it/s] 25%|██▌       | 70/280 [01:05<03:12,  1.09it/s]                                                 25%|██▌       | 70/280 [01:05<03:12,  1.09it/s] 25%|██▌       | 71/280 [01:05<03:08,  1.11it/s] 26%|██▌       | 72/280 [01:06<03:04,  1.13it/s] 26%|██▌       | 73/280 [01:07<03:16,  1.06it/s] 26%|██▋       | 74/280 [01:08<03:09,  1.09it/s] 27%|██▋       | 75/280 [01:09<03:04,  1.11it/s] 27%|██▋       | 76/280 [01:10<03:00,  1.13it/s] 28%|██▊       | 77/280 [01:11<03:12,  1.05it/s] 28%|██▊       | 78/280 [01:12<03:05,  1.09it/s] 28%|██▊       | 79/280 [01:13<03:01,  1.11it/s] 29%|██▊       | 80/280 [01:14<02:57,  1.13it/s]                                                 29%|██▊       | 80/280 [01:14<02:57,  1.13it/s]{'eval_loss': 0.16574998199939728, 'eval_runtime': 0.3071, 'eval_samples_per_second': 81.405, 'eval_steps_per_second': 13.025, 'epoch': 1.42}
外层迭代结束！
外层迭代结束！
{'loss': 0.0587, 'learning_rate': 0.0003, 'epoch': 1.77}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0586, 'learning_rate': 0.0002869565217391304, 'epoch': 2.12}
外层迭代结束！
外层迭代结束！
{'loss': 0.096, 'learning_rate': 0.00027391304347826085, 'epoch': 2.48}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0803, 'learning_rate': 0.0002608695652173913, 'epoch': 2.83}

  0%|          | 0/4 [00:00<?, ?it/s][A
 75%|███████▌  | 3/4 [00:00<00:00, 18.85it/s][A                                                
                                             [A 29%|██▊       | 80/280 [01:14<02:57,  1.13it/s]
100%|██████████| 4/4 [00:00<00:00, 18.85it/s][A
                                             [A 29%|██▉       | 81/280 [01:15<03:35,  1.08s/it] 29%|██▉       | 82/280 [01:16<03:21,  1.02s/it] 30%|██▉       | 83/280 [01:17<03:10,  1.03it/s] 30%|███       | 84/280 [01:18<03:03,  1.07it/s] 30%|███       | 85/280 [01:19<03:11,  1.02it/s] 31%|███       | 86/280 [01:20<03:02,  1.06it/s] 31%|███       | 87/280 [01:20<02:56,  1.09it/s] 31%|███▏      | 88/280 [01:21<02:52,  1.11it/s] 32%|███▏      | 89/280 [01:22<03:01,  1.05it/s] 32%|███▏      | 90/280 [01:23<02:55,  1.09it/s]                                                 32%|███▏      | 90/280 [01:23<02:55,  1.09it/s] 32%|███▎      | 91/280 [01:24<02:49,  1.11it/s] 33%|███▎      | 92/280 [01:25<02:46,  1.13it/s] 33%|███▎      | 93/280 [01:26<02:56,  1.06it/s] 34%|███▎      | 94/280 [01:27<02:50,  1.09it/s] 34%|███▍      | 95/280 [01:28<02:46,  1.11it/s] 34%|███▍      | 96/280 [01:29<02:42,  1.13it/s] 35%|███▍      | 97/280 [01:30<02:52,  1.06it/s] 35%|███▌      | 98/280 [01:31<02:46,  1.10it/s] 35%|███▌      | 99/280 [01:31<02:42,  1.12it/s] 36%|███▌      | 100/280 [01:32<02:39,  1.13it/s]                                                  36%|███▌      | 100/280 [01:32<02:39,  1.13it/s] 36%|███▌      | 101/280 [01:33<02:48,  1.06it/s] 36%|███▋      | 102/280 [01:34<02:42,  1.09it/s] 37%|███▋      | 103/280 [01:35<02:38,  1.12it/s] 37%|███▋      | 104/280 [01:36<02:34,  1.14it/s] 38%|███▊      | 105/280 [01:37<02:44,  1.06it/s] 38%|███▊      | 106/280 [01:38<02:39,  1.09it/s] 38%|███▊      | 107/280 [01:39<02:34,  1.12it/s] 39%|███▊      | 108/280 [01:39<02:31,  1.14it/s] 39%|███▉      | 109/280 [01:41<02:40,  1.07it/s] 39%|███▉      | 110/280 [01:41<02:35,  1.09it/s]                                                  39%|███▉      | 110/280 [01:41<02:35,  1.09it/s] 40%|███▉      | 111/280 [01:42<02:30,  1.12it/s] 40%|████      | 112/280 [01:43<02:27,  1.14it/s] 40%|████      | 113/280 [01:44<02:36,  1.07it/s] 41%|████      | 114/280 [01:45<02:31,  1.10it/s] 41%|████      | 115/280 [01:46<02:26,  1.12it/s] 41%|████▏     | 116/280 [01:47<02:24,  1.14it/s] 42%|████▏     | 117/280 [01:48<02:32,  1.07it/s] 42%|████▏     | 118/280 [01:49<02:27,  1.10it/s] 42%|████▎     | 119/280 [01:49<02:23,  1.12it/s] 43%|████▎     | 120/280 [01:50<02:20,  1.14it/s]                                                  43%|████▎     | 120/280 [01:51<02:20,  1.14it/s]{'eval_loss': 0.12937861680984497, 'eval_runtime': 0.3086, 'eval_samples_per_second': 81.012, 'eval_steps_per_second': 12.962, 'epoch': 2.83}
外层迭代结束！
外层迭代结束！
{'loss': 0.044, 'learning_rate': 0.0002478260869565217, 'epoch': 3.19}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.048, 'learning_rate': 0.00023478260869565215, 'epoch': 3.54}
外层迭代结束！
外层迭代结束！
{'loss': 0.0078, 'learning_rate': 0.00022173913043478256, 'epoch': 3.89}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0109, 'learning_rate': 0.00020869565217391303, 'epoch': 4.25}

  0%|          | 0/4 [00:00<?, ?it/s][A
 75%|███████▌  | 3/4 [00:00<00:00, 18.60it/s][A                                                 
                                             [A 43%|████▎     | 120/280 [01:51<02:20,  1.14it/s]
100%|██████████| 4/4 [00:00<00:00, 18.60it/s][A
                                             [A 43%|████▎     | 121/280 [01:52<02:57,  1.12s/it] 44%|████▎     | 122/280 [01:53<02:44,  1.04s/it] 44%|████▍     | 123/280 [01:54<02:34,  1.02it/s] 44%|████▍     | 124/280 [01:55<02:26,  1.06it/s] 45%|████▍     | 125/280 [01:56<02:32,  1.02it/s] 45%|████▌     | 126/280 [01:57<02:24,  1.06it/s] 45%|████▌     | 127/280 [01:57<02:20,  1.09it/s] 46%|████▌     | 128/280 [01:58<02:16,  1.11it/s] 46%|████▌     | 129/280 [01:59<02:24,  1.04it/s] 46%|████▋     | 130/280 [02:00<02:18,  1.08it/s]                                                  46%|████▋     | 130/280 [02:00<02:18,  1.08it/s] 47%|████▋     | 131/280 [02:01<02:14,  1.11it/s] 47%|████▋     | 132/280 [02:02<02:10,  1.13it/s] 48%|████▊     | 133/280 [02:03<02:18,  1.06it/s] 48%|████▊     | 134/280 [02:04<02:13,  1.10it/s] 48%|████▊     | 135/280 [02:05<02:09,  1.12it/s] 49%|████▊     | 136/280 [02:05<02:06,  1.14it/s] 49%|████▉     | 137/280 [02:07<02:14,  1.06it/s] 49%|████▉     | 138/280 [02:07<02:10,  1.09it/s] 50%|████▉     | 139/280 [02:08<02:06,  1.11it/s] 50%|█████     | 140/280 [02:09<02:04,  1.12it/s]                                                  50%|█████     | 140/280 [02:09<02:04,  1.12it/s] 50%|█████     | 141/280 [02:10<02:13,  1.04it/s] 51%|█████     | 142/280 [02:11<02:08,  1.07it/s] 51%|█████     | 143/280 [02:12<02:04,  1.10it/s] 51%|█████▏    | 144/280 [02:13<02:00,  1.12it/s] 52%|█████▏    | 145/280 [02:14<02:07,  1.06it/s] 52%|█████▏    | 146/280 [02:15<02:02,  1.09it/s] 52%|█████▎    | 147/280 [02:16<01:58,  1.12it/s] 53%|█████▎    | 148/280 [02:16<01:55,  1.15it/s] 53%|█████▎    | 149/280 [02:17<02:02,  1.07it/s] 54%|█████▎    | 150/280 [02:18<01:58,  1.10it/s]                                                  54%|█████▎    | 150/280 [02:18<01:58,  1.10it/s] 54%|█████▍    | 151/280 [02:19<01:54,  1.13it/s] 54%|█████▍    | 152/280 [02:20<01:51,  1.15it/s] 55%|█████▍    | 153/280 [02:21<01:58,  1.07it/s] 55%|█████▌    | 154/280 [02:22<01:53,  1.11it/s] 55%|█████▌    | 155/280 [02:23<01:50,  1.13it/s] 56%|█████▌    | 156/280 [02:24<01:47,  1.15it/s] 56%|█████▌    | 157/280 [02:25<01:53,  1.08it/s] 56%|█████▋    | 158/280 [02:25<01:49,  1.11it/s] 57%|█████▋    | 159/280 [02:26<01:46,  1.13it/s] 57%|█████▋    | 160/280 [02:27<01:44,  1.15it/s]                                                  57%|█████▋    | 160/280 [02:27<01:44,  1.15it/s]{'eval_loss': 0.08435586839914322, 'eval_runtime': 0.3116, 'eval_samples_per_second': 80.224, 'eval_steps_per_second': 12.836, 'epoch': 4.25}
外层迭代结束！
外层迭代结束！
{'loss': 0.0137, 'learning_rate': 0.00019565217391304346, 'epoch': 4.6}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0222, 'learning_rate': 0.0001826086956521739, 'epoch': 4.96}
外层迭代结束！
外层迭代结束！
{'loss': 0.0028, 'learning_rate': 0.00016956521739130433, 'epoch': 5.31}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0112, 'learning_rate': 0.00015652173913043477, 'epoch': 5.66}

  0%|          | 0/4 [00:00<?, ?it/s][A
 75%|███████▌  | 3/4 [00:00<00:00, 19.06it/s][A                                                 
                                             [A 57%|█████▋    | 160/280 [02:28<01:44,  1.15it/s]
100%|██████████| 4/4 [00:00<00:00, 19.06it/s][A
                                             [A 57%|█████▊    | 161/280 [02:29<02:06,  1.06s/it] 58%|█████▊    | 162/280 [02:30<01:57,  1.00it/s] 58%|█████▊    | 163/280 [02:30<01:51,  1.05it/s] 59%|█████▊    | 164/280 [02:31<01:46,  1.09it/s] 59%|█████▉    | 165/280 [02:32<01:50,  1.04it/s] 59%|█████▉    | 166/280 [02:33<01:45,  1.08it/s] 60%|█████▉    | 167/280 [02:34<01:41,  1.11it/s] 60%|██████    | 168/280 [02:35<01:39,  1.13it/s] 60%|██████    | 169/280 [02:36<01:44,  1.06it/s] 61%|██████    | 170/280 [02:37<01:40,  1.10it/s]                                                  61%|██████    | 170/280 [02:37<01:40,  1.10it/s] 61%|██████    | 171/280 [02:38<01:37,  1.12it/s] 61%|██████▏   | 172/280 [02:38<01:34,  1.14it/s] 62%|██████▏   | 173/280 [02:39<01:40,  1.07it/s] 62%|██████▏   | 174/280 [02:40<01:36,  1.10it/s] 62%|██████▎   | 175/280 [02:41<01:33,  1.12it/s] 63%|██████▎   | 176/280 [02:42<01:31,  1.14it/s] 63%|██████▎   | 177/280 [02:43<01:36,  1.07it/s] 64%|██████▎   | 178/280 [02:44<01:32,  1.10it/s] 64%|██████▍   | 179/280 [02:45<01:29,  1.13it/s] 64%|██████▍   | 180/280 [02:46<01:27,  1.15it/s]                                                  64%|██████▍   | 180/280 [02:46<01:27,  1.15it/s] 65%|██████▍   | 181/280 [02:47<01:32,  1.07it/s] 65%|██████▌   | 182/280 [02:48<01:28,  1.11it/s] 65%|██████▌   | 183/280 [02:48<01:26,  1.13it/s] 66%|██████▌   | 184/280 [02:49<01:23,  1.14it/s] 66%|██████▌   | 185/280 [02:50<01:28,  1.07it/s] 66%|██████▋   | 186/280 [02:51<01:25,  1.10it/s] 67%|██████▋   | 187/280 [02:52<01:22,  1.12it/s] 67%|██████▋   | 188/280 [02:53<01:20,  1.14it/s] 68%|██████▊   | 189/280 [02:54<01:25,  1.06it/s] 68%|██████▊   | 190/280 [02:55<01:21,  1.10it/s]                                                  68%|██████▊   | 190/280 [02:55<01:21,  1.10it/s] 68%|██████▊   | 191/280 [02:56<01:19,  1.13it/s] 69%|██████▊   | 192/280 [02:56<01:16,  1.14it/s] 69%|██████▉   | 193/280 [02:58<01:21,  1.07it/s] 69%|██████▉   | 194/280 [02:58<01:18,  1.10it/s] 70%|██████▉   | 195/280 [02:59<01:15,  1.12it/s] 70%|███████   | 196/280 [03:00<01:13,  1.14it/s] 70%|███████   | 197/280 [03:01<01:17,  1.07it/s] 71%|███████   | 198/280 [03:02<01:14,  1.10it/s] 71%|███████   | 199/280 [03:03<01:11,  1.13it/s] 71%|███████▏  | 200/280 [03:04<01:09,  1.14it/s]                                                  71%|███████▏  | 200/280 [03:04<01:09,  1.14it/s]{'eval_loss': 0.08899226039648056, 'eval_runtime': 0.3055, 'eval_samples_per_second': 81.825, 'eval_steps_per_second': 13.092, 'epoch': 5.66}
外层迭代结束！
外层迭代结束！
{'loss': 0.0061, 'learning_rate': 0.0001434782608695652, 'epoch': 6.02}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.004, 'learning_rate': 0.00013043478260869564, 'epoch': 6.37}
外层迭代结束！
外层迭代结束！
{'loss': 0.0351, 'learning_rate': 0.00011739130434782608, 'epoch': 6.73}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0013, 'learning_rate': 0.00010434782608695651, 'epoch': 7.08}

  0%|          | 0/4 [00:00<?, ?it/s][A
 75%|███████▌  | 3/4 [00:00<00:00, 18.80it/s][A                                                 
                                             [A 71%|███████▏  | 200/280 [03:04<01:09,  1.14it/s]
100%|██████████| 4/4 [00:00<00:00, 18.80it/s][A
                                             [A 72%|███████▏  | 201/280 [03:05<01:25,  1.08s/it] 72%|███████▏  | 202/280 [03:06<01:20,  1.04s/it] 72%|███████▎  | 203/280 [03:07<01:15,  1.02it/s] 73%|███████▎  | 204/280 [03:08<01:11,  1.07it/s] 73%|███████▎  | 205/280 [03:09<01:13,  1.02it/s] 74%|███████▎  | 206/280 [03:10<01:09,  1.06it/s] 74%|███████▍  | 207/280 [03:11<01:06,  1.10it/s] 74%|███████▍  | 208/280 [03:11<01:04,  1.12it/s] 75%|███████▍  | 209/280 [03:13<01:07,  1.06it/s] 75%|███████▌  | 210/280 [03:13<01:04,  1.09it/s]                                                  75%|███████▌  | 210/280 [03:13<01:04,  1.09it/s] 75%|███████▌  | 211/280 [03:14<01:01,  1.12it/s] 76%|███████▌  | 212/280 [03:15<00:59,  1.14it/s] 76%|███████▌  | 213/280 [03:16<01:02,  1.07it/s] 76%|███████▋  | 214/280 [03:17<00:59,  1.10it/s] 77%|███████▋  | 215/280 [03:18<00:57,  1.13it/s] 77%|███████▋  | 216/280 [03:19<00:56,  1.14it/s] 78%|███████▊  | 217/280 [03:20<00:58,  1.07it/s] 78%|███████▊  | 218/280 [03:21<00:56,  1.10it/s] 78%|███████▊  | 219/280 [03:21<00:54,  1.13it/s] 79%|███████▊  | 220/280 [03:22<00:52,  1.15it/s]                                                  79%|███████▊  | 220/280 [03:22<00:52,  1.15it/s] 79%|███████▉  | 221/280 [03:23<00:55,  1.07it/s] 79%|███████▉  | 222/280 [03:24<00:52,  1.10it/s] 80%|███████▉  | 223/280 [03:25<00:50,  1.13it/s] 80%|████████  | 224/280 [03:26<00:48,  1.14it/s] 80%|████████  | 225/280 [03:27<00:51,  1.07it/s] 81%|████████  | 226/280 [03:28<00:48,  1.10it/s] 81%|████████  | 227/280 [03:29<00:47,  1.13it/s] 81%|████████▏ | 228/280 [03:29<00:45,  1.14it/s] 82%|████████▏ | 229/280 [03:31<00:47,  1.07it/s] 82%|████████▏ | 230/280 [03:31<00:45,  1.10it/s]                                                  82%|████████▏ | 230/280 [03:31<00:45,  1.10it/s] 82%|████████▎ | 231/280 [03:32<00:43,  1.13it/s] 83%|████████▎ | 232/280 [03:33<00:41,  1.14it/s] 83%|████████▎ | 233/280 [03:34<00:43,  1.08it/s] 84%|████████▎ | 234/280 [03:35<00:40,  1.15it/s] 84%|████████▍ | 235/280 [03:36<00:37,  1.19it/s] 84%|████████▍ | 236/280 [03:36<00:35,  1.24it/s] 85%|████████▍ | 237/280 [03:37<00:36,  1.17it/s] 85%|████████▌ | 238/280 [03:38<00:34,  1.21it/s] 85%|████████▌ | 239/280 [03:39<00:32,  1.25it/s] 86%|████████▌ | 240/280 [03:40<00:31,  1.27it/s]                                                  86%|████████▌ | 240/280 [03:40<00:31,  1.27it/s]{'eval_loss': 0.07780592143535614, 'eval_runtime': 0.3044, 'eval_samples_per_second': 82.12, 'eval_steps_per_second': 13.139, 'epoch': 7.08}
外层迭代结束！
外层迭代结束！
{'loss': 0.0005, 'learning_rate': 9.130434782608695e-05, 'epoch': 7.43}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0051, 'learning_rate': 7.826086956521738e-05, 'epoch': 7.79}
外层迭代结束！
外层迭代结束！
{'loss': 0.0015, 'learning_rate': 6.521739130434782e-05, 'epoch': 8.14}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0004, 'learning_rate': 5.2173913043478256e-05, 'epoch': 8.5}

  0%|          | 0/4 [00:00<?, ?it/s][A
 75%|███████▌  | 3/4 [00:00<00:00, 19.02it/s][A                                                 
                                             [A 86%|████████▌ | 240/280 [03:40<00:31,  1.27it/s]
100%|██████████| 4/4 [00:00<00:00, 19.02it/s][A
                                             [A 86%|████████▌ | 241/280 [03:41<00:37,  1.04it/s] 86%|████████▋ | 242/280 [03:42<00:34,  1.10it/s] 87%|████████▋ | 243/280 [03:43<00:32,  1.15it/s] 87%|████████▋ | 244/280 [03:43<00:30,  1.18it/s] 88%|████████▊ | 245/280 [03:44<00:30,  1.14it/s] 88%|████████▊ | 246/280 [03:45<00:28,  1.19it/s] 88%|████████▊ | 247/280 [03:46<00:26,  1.23it/s] 89%|████████▊ | 248/280 [03:46<00:25,  1.26it/s] 89%|████████▉ | 249/280 [03:47<00:26,  1.18it/s] 89%|████████▉ | 250/280 [03:48<00:24,  1.22it/s]                                                  89%|████████▉ | 250/280 [03:48<00:24,  1.22it/s] 90%|████████▉ | 251/280 [03:49<00:23,  1.25it/s] 90%|█████████ | 252/280 [03:50<00:21,  1.28it/s] 90%|█████████ | 253/280 [03:51<00:22,  1.19it/s] 91%|█████████ | 254/280 [03:51<00:21,  1.23it/s] 91%|█████████ | 255/280 [03:52<00:19,  1.27it/s] 91%|█████████▏| 256/280 [03:53<00:18,  1.28it/s] 92%|█████████▏| 257/280 [03:54<00:19,  1.20it/s] 92%|█████████▏| 258/280 [03:55<00:17,  1.24it/s] 92%|█████████▎| 259/280 [03:55<00:16,  1.27it/s] 93%|█████████▎| 260/280 [03:56<00:15,  1.28it/s]                                                  93%|█████████▎| 260/280 [03:56<00:15,  1.28it/s] 93%|█████████▎| 261/280 [03:57<00:15,  1.20it/s] 94%|█████████▎| 262/280 [03:58<00:14,  1.24it/s] 94%|█████████▍| 263/280 [03:59<00:13,  1.26it/s] 94%|█████████▍| 264/280 [03:59<00:12,  1.28it/s] 95%|█████████▍| 265/280 [04:00<00:12,  1.20it/s] 95%|█████████▌| 266/280 [04:01<00:11,  1.24it/s] 95%|█████████▌| 267/280 [04:02<00:10,  1.27it/s] 96%|█████████▌| 268/280 [04:03<00:09,  1.29it/s] 96%|█████████▌| 269/280 [04:04<00:09,  1.20it/s] 96%|█████████▋| 270/280 [04:04<00:08,  1.24it/s]                                                  96%|█████████▋| 270/280 [04:04<00:08,  1.24it/s] 97%|█████████▋| 271/280 [04:05<00:07,  1.26it/s] 97%|█████████▋| 272/280 [04:06<00:06,  1.28it/s] 98%|█████████▊| 273/280 [04:07<00:05,  1.20it/s] 98%|█████████▊| 274/280 [04:07<00:04,  1.24it/s] 98%|█████████▊| 275/280 [04:08<00:03,  1.27it/s] 99%|█████████▊| 276/280 [04:09<00:03,  1.29it/s] 99%|█████████▉| 277/280 [04:10<00:02,  1.20it/s] 99%|█████████▉| 278/280 [04:11<00:01,  1.24it/s]100%|█████████▉| 279/280 [04:11<00:00,  1.27it/s]100%|██████████| 280/280 [04:12<00:00,  1.29it/s]                                                 100%|██████████| 280/280 [04:12<00:00,  1.29it/s]{'eval_loss': 0.0784015953540802, 'eval_runtime': 0.3024, 'eval_samples_per_second': 82.665, 'eval_steps_per_second': 13.226, 'epoch': 8.5}
外层迭代结束！
外层迭代结束！
{'loss': 0.006, 'learning_rate': 3.913043478260869e-05, 'epoch': 8.85}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0011, 'learning_rate': 2.6086956521739128e-05, 'epoch': 9.2}
外层迭代结束！
外层迭代结束！
{'loss': 0.0028, 'learning_rate': 1.3043478260869564e-05, 'epoch': 9.56}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0074, 'learning_rate': 0.0, 'epoch': 9.91}

  0%|          | 0/4 [00:00<?, ?it/s][A
 75%|███████▌  | 3/4 [00:00<00:00, 19.05it/s][A                                                 
                                             [A100%|██████████| 280/280 [04:13<00:00,  1.29it/s]
100%|██████████| 4/4 [00:00<00:00, 19.05it/s][A
                                             [AThere were missing keys in the checkpoint model loaded: ['base_model.model.shared.weight', 'base_model.model.encoder.embed_tokens.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.encoder.block.0.layer.0.layer_norm.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.0.layer.1.layer_norm.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.1.layer.0.layer_norm.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.1.layer.1.layer_norm.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.2.layer.0.layer_norm.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.2.layer.1.layer_norm.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.3.layer.0.layer_norm.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.3.layer.1.layer_norm.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.4.layer.0.layer_norm.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.4.layer.1.layer_norm.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.5.layer.0.layer_norm.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.5.layer.1.layer_norm.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.6.layer.0.layer_norm.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.6.layer.1.layer_norm.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.7.layer.0.layer_norm.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.7.layer.1.layer_norm.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.8.layer.0.layer_norm.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.8.layer.1.layer_norm.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.9.layer.0.layer_norm.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.9.layer.1.layer_norm.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.10.layer.0.layer_norm.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.10.layer.1.layer_norm.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.11.layer.0.layer_norm.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.11.layer.1.layer_norm.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.12.layer.0.layer_norm.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.12.layer.1.layer_norm.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.13.layer.0.layer_norm.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.13.layer.1.layer_norm.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.14.layer.0.layer_norm.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.14.layer.1.layer_norm.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.15.layer.0.layer_norm.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.15.layer.1.layer_norm.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.16.layer.0.layer_norm.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.16.layer.1.layer_norm.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.17.layer.0.layer_norm.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.17.layer.1.layer_norm.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.18.layer.0.layer_norm.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.18.layer.1.layer_norm.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.19.layer.0.layer_norm.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.19.layer.1.layer_norm.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.20.layer.0.layer_norm.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.20.layer.1.layer_norm.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.21.layer.0.layer_norm.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.21.layer.1.layer_norm.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.22.layer.0.layer_norm.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.22.layer.1.layer_norm.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.23.layer.0.layer_norm.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.23.layer.1.layer_norm.weight', 'base_model.model.encoder.final_layer_norm.weight', 'base_model.model.decoder.embed_tokens.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.decoder.block.0.layer.0.layer_norm.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.0.layer.1.layer_norm.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.0.layer.2.layer_norm.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.1.layer.0.layer_norm.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.1.layer.1.layer_norm.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.1.layer.2.layer_norm.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.2.layer.0.layer_norm.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.2.layer.1.layer_norm.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.2.layer.2.layer_norm.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.3.layer.0.layer_norm.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.3.layer.1.layer_norm.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.3.layer.2.layer_norm.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.4.layer.0.layer_norm.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.4.layer.1.layer_norm.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.4.layer.2.layer_norm.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.5.layer.0.layer_norm.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.5.layer.1.layer_norm.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.5.layer.2.layer_norm.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.6.layer.0.layer_norm.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.6.layer.1.layer_norm.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.6.layer.2.layer_norm.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.7.layer.0.layer_norm.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.7.layer.1.layer_norm.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.7.layer.2.layer_norm.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.8.layer.0.layer_norm.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.8.layer.1.layer_norm.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.8.layer.2.layer_norm.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.9.layer.0.layer_norm.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.9.layer.1.layer_norm.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.9.layer.2.layer_norm.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.10.layer.0.layer_norm.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.10.layer.1.layer_norm.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.10.layer.2.layer_norm.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.11.layer.0.layer_norm.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.11.layer.1.layer_norm.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.11.layer.2.layer_norm.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.12.layer.0.layer_norm.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.12.layer.1.layer_norm.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.12.layer.2.layer_norm.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.13.layer.0.layer_norm.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.13.layer.1.layer_norm.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.13.layer.2.layer_norm.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.14.layer.0.layer_norm.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.14.layer.1.layer_norm.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.14.layer.2.layer_norm.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.15.layer.0.layer_norm.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.15.layer.1.layer_norm.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.15.layer.2.layer_norm.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.16.layer.0.layer_norm.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.16.layer.1.layer_norm.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.16.layer.2.layer_norm.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.17.layer.0.layer_norm.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.17.layer.1.layer_norm.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.17.layer.2.layer_norm.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.18.layer.0.layer_norm.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.18.layer.1.layer_norm.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.18.layer.2.layer_norm.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.19.layer.0.layer_norm.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.19.layer.1.layer_norm.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.19.layer.2.layer_norm.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.20.layer.0.layer_norm.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.20.layer.1.layer_norm.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.20.layer.2.layer_norm.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.21.layer.0.layer_norm.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.21.layer.1.layer_norm.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.21.layer.2.layer_norm.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.22.layer.0.layer_norm.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.22.layer.1.layer_norm.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.22.layer.2.layer_norm.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.23.layer.0.layer_norm.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.23.layer.1.layer_norm.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.23.layer.2.layer_norm.weight', 'base_model.model.decoder.final_layer_norm.weight', 'base_model.model.lm_head.weight'].
There were unexpected keys in the checkpoint model loaded: ['base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.weight'].
                                                 100%|██████████| 280/280 [04:13<00:00,  1.29it/s]100%|██████████| 280/280 [04:13<00:00,  1.10it/s]
{'eval_loss': 0.07554620504379272, 'eval_runtime': 0.3024, 'eval_samples_per_second': 82.683, 'eval_steps_per_second': 13.229, 'epoch': 9.91}
{'train_runtime': 253.4276, 'train_samples_per_second': 8.878, 'train_steps_per_second': 1.105, 'train_loss': 0.03583098101662472, 'epoch': 9.91}

 If there's a warning about missing keys above, please disregard :)
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 8
micro_batch_size: 2
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: wic... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/2-wic
current data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 806.13it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 251.11it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 961.56it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Loading cached split indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-a4418f5f3b211a2e.arrow and /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-b03e7ee572f872c5.arrow
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-b47bd8361486d675.arrow
Loading cached processed dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-548b9e4b6bda8fe3.arrow
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-c2c8333eedaacee6.arrow
总样本数：250, 选择的样本数量：5
lora_weights: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/1-cb

pre-trained model's BOS EOS and PAD token id: None 1 0  => It should be 1,2,none
continual fine tune lora!
trainable params: 2359296 || all params: 740027392 || trainable%: 0.31881198257050464
训练数据总量：900
验证数据总量：100
Map:   0%|          | 0/100 [00:00<?, ? examples/s]/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3597: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  "`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your "
                                                   Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b8af281327a3c26.arrow
Loading cached processed dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-837c542572d29396.arrow
memory data loader 2
  0%|          | 0/1120 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/1120 [00:01<27:02,  1.45s/it]  0%|          | 2/1120 [00:02<19:05,  1.02s/it]  0%|          | 3/1120 [00:02<16:31,  1.13it/s]  0%|          | 4/1120 [00:03<15:16,  1.22it/s]  0%|          | 5/1120 [00:04<15:58,  1.16it/s]  1%|          | 6/1120 [00:05<15:20,  1.21it/s]  1%|          | 7/1120 [00:06<14:41,  1.26it/s]  1%|          | 8/1120 [00:06<14:18,  1.30it/s]  1%|          | 9/1120 [00:07<15:30,  1.19it/s]  1%|          | 10/1120 [00:08<14:53,  1.24it/s]                                                   1%|          | 10/1120 [00:08<14:53,  1.24it/s]  1%|          | 11/1120 [00:09<14:27,  1.28it/s]  1%|          | 12/1120 [00:09<14:09,  1.30it/s]  1%|          | 13/1120 [00:10<15:07,  1.22it/s]  1%|▏         | 14/1120 [00:11<14:36,  1.26it/s]  1%|▏         | 15/1120 [00:12<14:17,  1.29it/s]  1%|▏         | 16/1120 [00:13<14:06,  1.30it/s]  2%|▏         | 17/1120 [00:14<15:11,  1.21it/s]  2%|▏         | 18/1120 [00:14<14:40,  1.25it/s]  2%|▏         | 19/1120 [00:15<14:17,  1.28it/s]  2%|▏         | 20/1120 [00:16<14:04,  1.30it/s]                                                   2%|▏         | 20/1120 [00:16<14:04,  1.30it/s]  2%|▏         | 21/1120 [00:17<15:03,  1.22it/s]  2%|▏         | 22/1120 [00:17<14:39,  1.25it/s]  2%|▏         | 23/1120 [00:18<14:19,  1.28it/s]  2%|▏         | 24/1120 [00:19<14:01,  1.30it/s]  2%|▏         | 25/1120 [00:20<15:00,  1.22it/s]  2%|▏         | 26/1120 [00:21<14:31,  1.26it/s]  2%|▏         | 27/1120 [00:21<14:11,  1.28it/s]  2%|▎         | 28/1120 [00:22<13:58,  1.30it/s]  3%|▎         | 29/1120 [00:23<14:55,  1.22it/s]  3%|▎         | 30/1120 [00:24<14:27,  1.26it/s]                                                   3%|▎         | 30/1120 [00:24<14:27,  1.26it/s]  3%|▎         | 31/1120 [00:25<14:07,  1.28it/s]  3%|▎         | 32/1120 [00:25<13:53,  1.31it/s]  3%|▎         | 33/1120 [00:26<14:52,  1.22it/s]  3%|▎         | 34/1120 [00:27<14:24,  1.26it/s]  3%|▎         | 35/1120 [00:28<14:05,  1.28it/s]  3%|▎         | 36/1120 [00:28<13:53,  1.30it/s]  3%|▎         | 37/1120 [00:29<14:49,  1.22it/s]  3%|▎         | 38/1120 [00:30<14:26,  1.25it/s]  3%|▎         | 39/1120 [00:31<14:10,  1.27it/s]  4%|▎         | 40/1120 [00:32<13:54,  1.29it/s]                                                   4%|▎         | 40/1120 [00:32<13:54,  1.29it/s]外层迭代结束！
外层迭代结束！
{'loss': 7.1518, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.09}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 4.7495, 'learning_rate': 0.00011999999999999999, 'epoch': 0.18}
外层迭代结束！
外层迭代结束！
{'loss': 3.0657, 'learning_rate': 0.00017999999999999998, 'epoch': 0.27}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3515, 'learning_rate': 0.00023999999999999998, 'epoch': 0.36}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.39it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.75it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 14.82it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.45it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.15it/s][A                                                 
                                               [A  4%|▎         | 40/1120 [00:33<13:54,  1.29it/s]
100%|██████████| 13/13 [00:00<00:00, 14.15it/s][A
                                               [A  4%|▎         | 41/1120 [00:34<20:49,  1.16s/it]  4%|▍         | 42/1120 [00:34<18:34,  1.03s/it]  4%|▍         | 43/1120 [00:35<17:04,  1.05it/s]  4%|▍         | 44/1120 [00:36<15:56,  1.12it/s]  4%|▍         | 45/1120 [00:37<16:16,  1.10it/s]  4%|▍         | 46/1120 [00:38<15:24,  1.16it/s]  4%|▍         | 47/1120 [00:38<14:47,  1.21it/s]  4%|▍         | 48/1120 [00:39<14:19,  1.25it/s]  4%|▍         | 49/1120 [00:40<15:07,  1.18it/s]  4%|▍         | 50/1120 [00:41<14:33,  1.22it/s]                                                   4%|▍         | 50/1120 [00:41<14:33,  1.22it/s]  5%|▍         | 51/1120 [00:42<14:09,  1.26it/s]  5%|▍         | 52/1120 [00:42<13:55,  1.28it/s]  5%|▍         | 53/1120 [00:43<14:47,  1.20it/s]  5%|▍         | 54/1120 [00:44<14:17,  1.24it/s]  5%|▍         | 55/1120 [00:45<13:56,  1.27it/s]  5%|▌         | 56/1120 [00:45<13:41,  1.30it/s]  5%|▌         | 57/1120 [00:46<14:41,  1.21it/s]  5%|▌         | 58/1120 [00:47<14:14,  1.24it/s]  5%|▌         | 59/1120 [00:48<13:54,  1.27it/s]  5%|▌         | 60/1120 [00:49<13:39,  1.29it/s]                                                   5%|▌         | 60/1120 [00:49<13:39,  1.29it/s]  5%|▌         | 61/1120 [00:50<14:34,  1.21it/s]  6%|▌         | 62/1120 [00:50<14:09,  1.24it/s]  6%|▌         | 63/1120 [00:51<13:48,  1.28it/s]  6%|▌         | 64/1120 [00:52<13:38,  1.29it/s]  6%|▌         | 65/1120 [00:53<14:38,  1.20it/s]  6%|▌         | 66/1120 [00:54<14:08,  1.24it/s]  6%|▌         | 67/1120 [00:54<13:51,  1.27it/s]  6%|▌         | 68/1120 [00:55<13:37,  1.29it/s]  6%|▌         | 69/1120 [00:56<14:31,  1.21it/s]  6%|▋         | 70/1120 [00:57<14:03,  1.24it/s]                                                   6%|▋         | 70/1120 [00:57<14:03,  1.24it/s]  6%|▋         | 71/1120 [00:58<13:45,  1.27it/s]  6%|▋         | 72/1120 [00:58<13:33,  1.29it/s]  7%|▋         | 73/1120 [00:59<14:30,  1.20it/s]  7%|▋         | 74/1120 [01:00<14:02,  1.24it/s]  7%|▋         | 75/1120 [01:01<13:42,  1.27it/s]  7%|▋         | 76/1120 [01:01<13:29,  1.29it/s]  7%|▋         | 77/1120 [01:02<14:24,  1.21it/s]  7%|▋         | 78/1120 [01:03<13:56,  1.25it/s]  7%|▋         | 79/1120 [01:04<13:35,  1.28it/s]  7%|▋         | 80/1120 [01:05<13:19,  1.30it/s]                                                   7%|▋         | 80/1120 [01:05<13:19,  1.30it/s]{'eval_loss': 0.27794989943504333, 'eval_runtime': 0.9584, 'eval_samples_per_second': 104.344, 'eval_steps_per_second': 13.565, 'epoch': 0.36}
外层迭代结束！
外层迭代结束！
{'loss': 0.2775, 'learning_rate': 0.0003, 'epoch': 0.44}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3065, 'learning_rate': 0.00029719626168224294, 'epoch': 0.53}
外层迭代结束！
外层迭代结束！
{'loss': 0.2677, 'learning_rate': 0.00029439252336448596, 'epoch': 0.62}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.278, 'learning_rate': 0.0002915887850467289, 'epoch': 0.71}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.89it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.03it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.05it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.60it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.33it/s][A                                                 
                                               [A  7%|▋         | 80/1120 [01:06<13:19,  1.30it/s]
100%|██████████| 13/13 [00:00<00:00, 14.33it/s][A
                                               [A  7%|▋         | 81/1120 [01:07<19:49,  1.15s/it]  7%|▋         | 82/1120 [01:07<17:44,  1.03s/it]  7%|▋         | 83/1120 [01:08<16:17,  1.06it/s]  8%|▊         | 84/1120 [01:09<15:14,  1.13it/s]  8%|▊         | 85/1120 [01:10<15:33,  1.11it/s]  8%|▊         | 86/1120 [01:11<14:47,  1.17it/s]  8%|▊         | 87/1120 [01:11<14:11,  1.21it/s]  8%|▊         | 88/1120 [01:12<13:45,  1.25it/s]  8%|▊         | 89/1120 [01:13<14:34,  1.18it/s]  8%|▊         | 90/1120 [01:14<14:03,  1.22it/s]                                                   8%|▊         | 90/1120 [01:14<14:03,  1.22it/s]  8%|▊         | 91/1120 [01:15<13:39,  1.26it/s]  8%|▊         | 92/1120 [01:15<13:25,  1.28it/s]  8%|▊         | 93/1120 [01:16<14:15,  1.20it/s]  8%|▊         | 94/1120 [01:17<13:53,  1.23it/s]  8%|▊         | 95/1120 [01:18<13:32,  1.26it/s]  9%|▊         | 96/1120 [01:19<13:16,  1.29it/s]  9%|▊         | 97/1120 [01:20<14:22,  1.19it/s]  9%|▉         | 98/1120 [01:20<13:52,  1.23it/s]  9%|▉         | 99/1120 [01:21<13:31,  1.26it/s]  9%|▉         | 100/1120 [01:22<13:16,  1.28it/s]                                                    9%|▉         | 100/1120 [01:22<13:16,  1.28it/s]  9%|▉         | 101/1120 [01:23<14:09,  1.20it/s]  9%|▉         | 102/1120 [01:23<13:40,  1.24it/s]  9%|▉         | 103/1120 [01:24<13:21,  1.27it/s]  9%|▉         | 104/1120 [01:25<13:12,  1.28it/s]  9%|▉         | 105/1120 [01:26<14:05,  1.20it/s]  9%|▉         | 106/1120 [01:27<13:38,  1.24it/s] 10%|▉         | 107/1120 [01:27<13:22,  1.26it/s] 10%|▉         | 108/1120 [01:28<13:07,  1.29it/s] 10%|▉         | 109/1120 [01:29<13:58,  1.21it/s] 10%|▉         | 110/1120 [01:30<13:37,  1.24it/s]                                                   10%|▉         | 110/1120 [01:30<13:37,  1.24it/s] 10%|▉         | 111/1120 [01:31<13:16,  1.27it/s] 10%|█         | 112/1120 [01:31<13:03,  1.29it/s] 10%|█         | 113/1120 [01:32<14:00,  1.20it/s] 10%|█         | 114/1120 [01:33<13:32,  1.24it/s] 10%|█         | 115/1120 [01:34<13:12,  1.27it/s] 10%|█         | 116/1120 [01:35<13:01,  1.28it/s] 10%|█         | 117/1120 [01:36<13:53,  1.20it/s] 11%|█         | 118/1120 [01:36<13:25,  1.24it/s] 11%|█         | 119/1120 [01:37<13:17,  1.26it/s] 11%|█         | 120/1120 [01:38<13:00,  1.28it/s]                                                   11%|█         | 120/1120 [01:38<13:00,  1.28it/s]{'eval_loss': 0.2661708891391754, 'eval_runtime': 0.9461, 'eval_samples_per_second': 105.696, 'eval_steps_per_second': 13.741, 'epoch': 0.71}
外层迭代结束！
外层迭代结束！
{'loss': 0.2993, 'learning_rate': 0.00028878504672897194, 'epoch': 0.8}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2568, 'learning_rate': 0.0002859813084112149, 'epoch': 0.89}
外层迭代结束！
外层迭代结束！
{'loss': 0.2452, 'learning_rate': 0.0002831775700934579, 'epoch': 0.98}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2764, 'learning_rate': 0.0002803738317757009, 'epoch': 1.07}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.42it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.99it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.14it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.60it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.26it/s][A                                                  
                                               [A 11%|█         | 120/1120 [01:39<13:00,  1.28it/s]
100%|██████████| 13/13 [00:00<00:00, 14.26it/s][A
                                               [A 11%|█         | 121/1120 [01:40<19:12,  1.15s/it] 11%|█         | 122/1120 [01:41<17:11,  1.03s/it] 11%|█         | 123/1120 [01:41<15:49,  1.05it/s] 11%|█         | 124/1120 [01:42<14:45,  1.12it/s] 11%|█         | 125/1120 [01:43<15:06,  1.10it/s] 11%|█▏        | 126/1120 [01:44<14:16,  1.16it/s] 11%|█▏        | 127/1120 [01:45<13:42,  1.21it/s] 11%|█▏        | 128/1120 [01:45<13:17,  1.24it/s] 12%|█▏        | 129/1120 [01:46<14:02,  1.18it/s] 12%|█▏        | 130/1120 [01:47<13:34,  1.22it/s]                                                   12%|█▏        | 130/1120 [01:47<13:34,  1.22it/s] 12%|█▏        | 131/1120 [01:48<13:10,  1.25it/s] 12%|█▏        | 132/1120 [01:48<12:55,  1.27it/s] 12%|█▏        | 133/1120 [01:49<13:46,  1.19it/s] 12%|█▏        | 134/1120 [01:50<13:17,  1.24it/s] 12%|█▏        | 135/1120 [01:51<12:58,  1.27it/s] 12%|█▏        | 136/1120 [01:52<12:44,  1.29it/s] 12%|█▏        | 137/1120 [01:53<13:38,  1.20it/s] 12%|█▏        | 138/1120 [01:53<13:13,  1.24it/s] 12%|█▏        | 139/1120 [01:54<12:53,  1.27it/s] 12%|█▎        | 140/1120 [01:55<12:39,  1.29it/s]                                                   12%|█▎        | 140/1120 [01:55<12:39,  1.29it/s] 13%|█▎        | 141/1120 [01:56<13:34,  1.20it/s] 13%|█▎        | 142/1120 [01:57<13:06,  1.24it/s] 13%|█▎        | 143/1120 [01:57<12:49,  1.27it/s] 13%|█▎        | 144/1120 [01:58<12:36,  1.29it/s] 13%|█▎        | 145/1120 [01:59<13:33,  1.20it/s] 13%|█▎        | 146/1120 [02:00<13:11,  1.23it/s] 13%|█▎        | 147/1120 [02:01<12:49,  1.27it/s] 13%|█▎        | 148/1120 [02:01<12:34,  1.29it/s] 13%|█▎        | 149/1120 [02:02<13:22,  1.21it/s] 13%|█▎        | 150/1120 [02:03<12:58,  1.25it/s]                                                   13%|█▎        | 150/1120 [02:03<12:58,  1.25it/s] 13%|█▎        | 151/1120 [02:04<12:39,  1.28it/s] 14%|█▎        | 152/1120 [02:04<12:26,  1.30it/s] 14%|█▎        | 153/1120 [02:05<13:17,  1.21it/s] 14%|█▍        | 154/1120 [02:06<12:51,  1.25it/s] 14%|█▍        | 155/1120 [02:07<12:34,  1.28it/s] 14%|█▍        | 156/1120 [02:08<12:24,  1.29it/s] 14%|█▍        | 157/1120 [02:09<13:13,  1.21it/s] 14%|█▍        | 158/1120 [02:09<12:50,  1.25it/s] 14%|█▍        | 159/1120 [02:10<12:31,  1.28it/s] 14%|█▍        | 160/1120 [02:11<12:20,  1.30it/s]                                                   14%|█▍        | 160/1120 [02:11<12:20,  1.30it/s]{'eval_loss': 0.22453255951404572, 'eval_runtime': 0.9492, 'eval_samples_per_second': 105.348, 'eval_steps_per_second': 13.695, 'epoch': 1.07}
外层迭代结束！
外层迭代结束！
{'loss': 0.2461, 'learning_rate': 0.0002775700934579439, 'epoch': 1.16}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2258, 'learning_rate': 0.00027476635514018686, 'epoch': 1.24}
外层迭代结束！
外层迭代结束！
{'loss': 0.2285, 'learning_rate': 0.0002719626168224299, 'epoch': 1.33}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2325, 'learning_rate': 0.00026915887850467284, 'epoch': 1.42}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.40it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.01it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.13it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.64it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.35it/s][A                                                  
                                               [A 14%|█▍        | 160/1120 [02:12<12:20,  1.30it/s]
100%|██████████| 13/13 [00:00<00:00, 14.35it/s][A
                                               [A 14%|█▍        | 161/1120 [02:13<18:36,  1.16s/it] 14%|█▍        | 162/1120 [02:14<16:38,  1.04s/it] 15%|█▍        | 163/1120 [02:14<15:12,  1.05it/s] 15%|█▍        | 164/1120 [02:15<14:14,  1.12it/s] 15%|█▍        | 165/1120 [02:16<14:28,  1.10it/s] 15%|█▍        | 166/1120 [02:17<13:42,  1.16it/s] 15%|█▍        | 167/1120 [02:18<13:08,  1.21it/s] 15%|█▌        | 168/1120 [02:18<12:42,  1.25it/s] 15%|█▌        | 169/1120 [02:19<13:25,  1.18it/s] 15%|█▌        | 170/1120 [02:20<12:54,  1.23it/s]                                                   15%|█▌        | 170/1120 [02:20<12:54,  1.23it/s] 15%|█▌        | 171/1120 [02:21<12:32,  1.26it/s] 15%|█▌        | 172/1120 [02:22<12:18,  1.28it/s] 15%|█▌        | 173/1120 [02:22<13:05,  1.21it/s] 16%|█▌        | 174/1120 [02:23<12:39,  1.25it/s] 16%|█▌        | 175/1120 [02:24<12:22,  1.27it/s] 16%|█▌        | 176/1120 [02:25<12:09,  1.29it/s] 16%|█▌        | 177/1120 [02:26<12:56,  1.21it/s] 16%|█▌        | 178/1120 [02:26<12:31,  1.25it/s] 16%|█▌        | 179/1120 [02:27<12:14,  1.28it/s] 16%|█▌        | 180/1120 [02:28<12:04,  1.30it/s]                                                   16%|█▌        | 180/1120 [02:28<12:04,  1.30it/s] 16%|█▌        | 181/1120 [02:29<12:54,  1.21it/s] 16%|█▋        | 182/1120 [02:30<12:30,  1.25it/s] 16%|█▋        | 183/1120 [02:30<12:15,  1.27it/s] 16%|█▋        | 184/1120 [02:31<12:04,  1.29it/s] 17%|█▋        | 185/1120 [02:32<12:53,  1.21it/s] 17%|█▋        | 186/1120 [02:33<12:29,  1.25it/s] 17%|█▋        | 187/1120 [02:34<12:11,  1.28it/s] 17%|█▋        | 188/1120 [02:34<11:59,  1.29it/s] 17%|█▋        | 189/1120 [02:35<12:48,  1.21it/s] 17%|█▋        | 190/1120 [02:36<12:23,  1.25it/s]                                                   17%|█▋        | 190/1120 [02:36<12:23,  1.25it/s] 17%|█▋        | 191/1120 [02:37<12:06,  1.28it/s] 17%|█▋        | 192/1120 [02:37<11:53,  1.30it/s] 17%|█▋        | 193/1120 [02:38<12:40,  1.22it/s] 17%|█▋        | 194/1120 [02:39<12:20,  1.25it/s] 17%|█▋        | 195/1120 [02:40<12:02,  1.28it/s] 18%|█▊        | 196/1120 [02:41<11:50,  1.30it/s] 18%|█▊        | 197/1120 [02:42<12:39,  1.22it/s] 18%|█▊        | 198/1120 [02:42<12:17,  1.25it/s] 18%|█▊        | 199/1120 [02:43<12:00,  1.28it/s] 18%|█▊        | 200/1120 [02:44<11:49,  1.30it/s]                                                   18%|█▊        | 200/1120 [02:44<11:49,  1.30it/s]{'eval_loss': 0.20876285433769226, 'eval_runtime': 0.9465, 'eval_samples_per_second': 105.652, 'eval_steps_per_second': 13.735, 'epoch': 1.42}
外层迭代结束！
外层迭代结束！
{'loss': 0.2485, 'learning_rate': 0.00026635514018691586, 'epoch': 1.51}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2092, 'learning_rate': 0.0002635514018691588, 'epoch': 1.6}
外层迭代结束！
外层迭代结束！
{'loss': 0.2672, 'learning_rate': 0.00026074766355140184, 'epoch': 1.69}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2306, 'learning_rate': 0.0002579439252336448, 'epoch': 1.78}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.76it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.11it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.21it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.73it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.41it/s][A                                                  
                                               [A 18%|█▊        | 200/1120 [02:45<11:49,  1.30it/s]
100%|██████████| 13/13 [00:00<00:00, 14.41it/s][A
                                               [A 18%|█▊        | 201/1120 [02:46<17:31,  1.14s/it] 18%|█▊        | 202/1120 [02:47<15:39,  1.02s/it] 18%|█▊        | 203/1120 [02:47<14:21,  1.06it/s] 18%|█▊        | 204/1120 [02:48<13:25,  1.14it/s] 18%|█▊        | 205/1120 [02:49<13:44,  1.11it/s] 18%|█▊        | 206/1120 [02:50<13:00,  1.17it/s] 18%|█▊        | 207/1120 [02:50<12:28,  1.22it/s] 19%|█▊        | 208/1120 [02:51<12:06,  1.26it/s] 19%|█▊        | 209/1120 [02:52<12:49,  1.18it/s] 19%|█▉        | 210/1120 [02:53<12:20,  1.23it/s]                                                   19%|█▉        | 210/1120 [02:53<12:20,  1.23it/s] 19%|█▉        | 211/1120 [02:54<12:00,  1.26it/s] 19%|█▉        | 212/1120 [02:54<11:45,  1.29it/s] 19%|█▉        | 213/1120 [02:55<12:31,  1.21it/s] 19%|█▉        | 214/1120 [02:56<12:05,  1.25it/s] 19%|█▉        | 215/1120 [02:57<11:47,  1.28it/s] 19%|█▉        | 216/1120 [02:58<11:34,  1.30it/s] 19%|█▉        | 217/1120 [02:58<12:23,  1.22it/s] 19%|█▉        | 218/1120 [02:59<12:00,  1.25it/s] 20%|█▉        | 219/1120 [03:00<11:43,  1.28it/s] 20%|█▉        | 220/1120 [03:01<11:31,  1.30it/s]                                                   20%|█▉        | 220/1120 [03:01<11:31,  1.30it/s] 20%|█▉        | 221/1120 [03:02<12:18,  1.22it/s] 20%|█▉        | 222/1120 [03:02<12:00,  1.25it/s] 20%|█▉        | 223/1120 [03:03<11:45,  1.27it/s] 20%|██        | 224/1120 [03:04<11:34,  1.29it/s] 20%|██        | 225/1120 [03:05<12:23,  1.20it/s] 20%|██        | 226/1120 [03:06<12:00,  1.24it/s] 20%|██        | 227/1120 [03:06<11:43,  1.27it/s] 20%|██        | 228/1120 [03:07<11:35,  1.28it/s] 20%|██        | 229/1120 [03:08<12:29,  1.19it/s] 21%|██        | 230/1120 [03:09<12:09,  1.22it/s]                                                   21%|██        | 230/1120 [03:09<12:09,  1.22it/s] 21%|██        | 231/1120 [03:10<11:51,  1.25it/s] 21%|██        | 232/1120 [03:10<11:45,  1.26it/s] 21%|██        | 233/1120 [03:11<12:32,  1.18it/s] 21%|██        | 234/1120 [03:12<12:12,  1.21it/s] 21%|██        | 235/1120 [03:13<11:59,  1.23it/s] 21%|██        | 236/1120 [03:14<11:48,  1.25it/s] 21%|██        | 237/1120 [03:15<12:33,  1.17it/s] 21%|██▏       | 238/1120 [03:15<12:03,  1.22it/s] 21%|██▏       | 239/1120 [03:16<11:43,  1.25it/s] 21%|██▏       | 240/1120 [03:17<11:29,  1.28it/s]                                                   21%|██▏       | 240/1120 [03:17<11:29,  1.28it/s]{'eval_loss': 0.20800931751728058, 'eval_runtime': 0.9413, 'eval_samples_per_second': 106.234, 'eval_steps_per_second': 13.81, 'epoch': 1.78}
外层迭代结束！
外层迭代结束！
{'loss': 0.2476, 'learning_rate': 0.0002551401869158878, 'epoch': 1.87}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2332, 'learning_rate': 0.0002523364485981308, 'epoch': 1.96}
外层迭代结束！
外层迭代结束！
{'loss': 0.2084, 'learning_rate': 0.0002495327102803738, 'epoch': 2.04}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1987, 'learning_rate': 0.00024672897196261677, 'epoch': 2.13}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.62it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.09it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.20it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.72it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.39it/s][A                                                  
                                               [A 21%|██▏       | 240/1120 [03:18<11:29,  1.28it/s]
100%|██████████| 13/13 [00:00<00:00, 14.39it/s][A
                                               [A 22%|██▏       | 241/1120 [03:19<17:05,  1.17s/it] 22%|██▏       | 242/1120 [03:20<15:13,  1.04s/it] 22%|██▏       | 243/1120 [03:21<13:58,  1.05it/s] 22%|██▏       | 244/1120 [03:21<13:04,  1.12it/s] 22%|██▏       | 245/1120 [03:22<13:21,  1.09it/s] 22%|██▏       | 246/1120 [03:23<12:42,  1.15it/s] 22%|██▏       | 247/1120 [03:24<12:12,  1.19it/s] 22%|██▏       | 248/1120 [03:25<11:49,  1.23it/s] 22%|██▏       | 249/1120 [03:25<12:27,  1.16it/s] 22%|██▏       | 250/1120 [03:26<11:59,  1.21it/s]                                                   22%|██▏       | 250/1120 [03:26<11:59,  1.21it/s] 22%|██▏       | 251/1120 [03:27<11:40,  1.24it/s] 22%|██▎       | 252/1120 [03:28<11:26,  1.27it/s] 23%|██▎       | 253/1120 [03:29<12:09,  1.19it/s] 23%|██▎       | 254/1120 [03:29<11:44,  1.23it/s] 23%|██▎       | 255/1120 [03:30<11:29,  1.25it/s] 23%|██▎       | 256/1120 [03:31<11:22,  1.27it/s] 23%|██▎       | 257/1120 [03:32<12:04,  1.19it/s] 23%|██▎       | 258/1120 [03:33<11:43,  1.23it/s] 23%|██▎       | 259/1120 [03:33<11:25,  1.26it/s] 23%|██▎       | 260/1120 [03:34<11:13,  1.28it/s]                                                   23%|██▎       | 260/1120 [03:34<11:13,  1.28it/s] 23%|██▎       | 261/1120 [03:35<12:00,  1.19it/s] 23%|██▎       | 262/1120 [03:36<11:36,  1.23it/s] 23%|██▎       | 263/1120 [03:37<11:22,  1.26it/s] 24%|██▎       | 264/1120 [03:37<11:09,  1.28it/s] 24%|██▎       | 265/1120 [03:38<11:52,  1.20it/s] 24%|██▍       | 266/1120 [03:39<11:29,  1.24it/s] 24%|██▍       | 267/1120 [03:40<11:14,  1.27it/s] 24%|██▍       | 268/1120 [03:41<11:04,  1.28it/s] 24%|██▍       | 269/1120 [03:42<11:50,  1.20it/s] 24%|██▍       | 270/1120 [03:42<11:31,  1.23it/s]                                                   24%|██▍       | 270/1120 [03:42<11:31,  1.23it/s] 24%|██▍       | 271/1120 [03:43<11:15,  1.26it/s] 24%|██▍       | 272/1120 [03:44<11:01,  1.28it/s] 24%|██▍       | 273/1120 [03:45<11:49,  1.19it/s] 24%|██▍       | 274/1120 [03:46<11:27,  1.23it/s] 25%|██▍       | 275/1120 [03:46<11:10,  1.26it/s] 25%|██▍       | 276/1120 [03:47<10:59,  1.28it/s] 25%|██▍       | 277/1120 [03:48<11:44,  1.20it/s] 25%|██▍       | 278/1120 [03:49<11:23,  1.23it/s] 25%|██▍       | 279/1120 [03:50<11:06,  1.26it/s] 25%|██▌       | 280/1120 [03:50<10:53,  1.29it/s]                                                   25%|██▌       | 280/1120 [03:50<10:53,  1.29it/s]{'eval_loss': 0.22180423140525818, 'eval_runtime': 0.9427, 'eval_samples_per_second': 106.076, 'eval_steps_per_second': 13.79, 'epoch': 2.13}
外层迭代结束！
外层迭代结束！
{'loss': 0.2002, 'learning_rate': 0.0002439252336448598, 'epoch': 2.22}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1871, 'learning_rate': 0.00024112149532710278, 'epoch': 2.31}
外层迭代结束！
外层迭代结束！
{'loss': 0.1842, 'learning_rate': 0.00023831775700934577, 'epoch': 2.4}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2486, 'learning_rate': 0.00023551401869158876, 'epoch': 2.49}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.56it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.99it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.15it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.66it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.35it/s][A                                                  
                                               [A 25%|██▌       | 280/1120 [03:51<10:53,  1.29it/s]
100%|██████████| 13/13 [00:00<00:00, 14.35it/s][A
                                               [A 25%|██▌       | 281/1120 [03:52<16:07,  1.15s/it] 25%|██▌       | 282/1120 [03:53<14:26,  1.03s/it] 25%|██▌       | 283/1120 [03:54<13:14,  1.05it/s] 25%|██▌       | 284/1120 [03:55<12:21,  1.13it/s] 25%|██▌       | 285/1120 [03:56<12:35,  1.11it/s] 26%|██▌       | 286/1120 [03:56<11:54,  1.17it/s] 26%|██▌       | 287/1120 [03:57<11:24,  1.22it/s] 26%|██▌       | 288/1120 [03:58<11:03,  1.25it/s] 26%|██▌       | 289/1120 [03:59<11:42,  1.18it/s] 26%|██▌       | 290/1120 [03:59<11:18,  1.22it/s]                                                   26%|██▌       | 290/1120 [03:59<11:18,  1.22it/s] 26%|██▌       | 291/1120 [04:00<10:58,  1.26it/s] 26%|██▌       | 292/1120 [04:01<10:45,  1.28it/s] 26%|██▌       | 293/1120 [04:02<11:27,  1.20it/s] 26%|██▋       | 294/1120 [04:03<11:06,  1.24it/s] 26%|██▋       | 295/1120 [04:03<10:49,  1.27it/s] 26%|██▋       | 296/1120 [04:04<10:37,  1.29it/s] 27%|██▋       | 297/1120 [04:05<11:22,  1.21it/s] 27%|██▋       | 298/1120 [04:06<10:59,  1.25it/s] 27%|██▋       | 299/1120 [04:07<10:45,  1.27it/s] 27%|██▋       | 300/1120 [04:07<10:35,  1.29it/s]                                                   27%|██▋       | 300/1120 [04:08<10:35,  1.29it/s] 27%|██▋       | 301/1120 [04:08<11:17,  1.21it/s] 27%|██▋       | 302/1120 [04:09<10:54,  1.25it/s] 27%|██▋       | 303/1120 [04:10<10:40,  1.28it/s] 27%|██▋       | 304/1120 [04:10<10:30,  1.29it/s] 27%|██▋       | 305/1120 [04:11<11:09,  1.22it/s] 27%|██▋       | 306/1120 [04:12<10:49,  1.25it/s] 27%|██▋       | 307/1120 [04:13<10:38,  1.27it/s] 28%|██▊       | 308/1120 [04:14<10:27,  1.29it/s] 28%|██▊       | 309/1120 [04:15<11:09,  1.21it/s] 28%|██▊       | 310/1120 [04:15<10:46,  1.25it/s]                                                   28%|██▊       | 310/1120 [04:15<10:46,  1.25it/s] 28%|██▊       | 311/1120 [04:16<10:30,  1.28it/s] 28%|██▊       | 312/1120 [04:17<10:20,  1.30it/s] 28%|██▊       | 313/1120 [04:18<11:04,  1.21it/s] 28%|██▊       | 314/1120 [04:19<10:43,  1.25it/s] 28%|██▊       | 315/1120 [04:19<10:27,  1.28it/s] 28%|██▊       | 316/1120 [04:20<10:17,  1.30it/s] 28%|██▊       | 317/1120 [04:21<11:00,  1.22it/s] 28%|██▊       | 318/1120 [04:22<10:38,  1.26it/s] 28%|██▊       | 319/1120 [04:22<10:24,  1.28it/s] 29%|██▊       | 320/1120 [04:23<10:13,  1.30it/s]                                                   29%|██▊       | 320/1120 [04:23<10:13,  1.30it/s]{'eval_loss': 0.21676774322986603, 'eval_runtime': 0.9459, 'eval_samples_per_second': 105.724, 'eval_steps_per_second': 13.744, 'epoch': 2.49}
外层迭代结束！
外层迭代结束！
{'loss': 0.1624, 'learning_rate': 0.00023271028037383175, 'epoch': 2.58}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.215, 'learning_rate': 0.00022990654205607474, 'epoch': 2.67}
外层迭代结束！
外层迭代结束！
{'loss': 0.2574, 'learning_rate': 0.00022710280373831773, 'epoch': 2.76}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2118, 'learning_rate': 0.00022429906542056072, 'epoch': 2.84}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.89it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.25it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.29it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.72it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.43it/s][A                                                  
                                               [A 29%|██▊       | 320/1120 [04:24<10:13,  1.30it/s]
100%|██████████| 13/13 [00:00<00:00, 14.43it/s][A
                                               [A 29%|██▊       | 321/1120 [04:25<15:11,  1.14s/it] 29%|██▉       | 322/1120 [04:26<13:35,  1.02s/it] 29%|██▉       | 323/1120 [04:27<12:26,  1.07it/s] 29%|██▉       | 324/1120 [04:27<11:40,  1.14it/s] 29%|██▉       | 325/1120 [04:28<11:55,  1.11it/s] 29%|██▉       | 326/1120 [04:29<11:16,  1.17it/s] 29%|██▉       | 327/1120 [04:30<10:48,  1.22it/s] 29%|██▉       | 328/1120 [04:31<10:34,  1.25it/s] 29%|██▉       | 329/1120 [04:32<11:12,  1.18it/s] 29%|██▉       | 330/1120 [04:32<10:48,  1.22it/s]                                                   29%|██▉       | 330/1120 [04:32<10:48,  1.22it/s] 30%|██▉       | 331/1120 [04:33<10:29,  1.25it/s] 30%|██▉       | 332/1120 [04:34<10:16,  1.28it/s] 30%|██▉       | 333/1120 [04:35<10:54,  1.20it/s] 30%|██▉       | 334/1120 [04:35<10:33,  1.24it/s] 30%|██▉       | 335/1120 [04:36<10:17,  1.27it/s] 30%|███       | 336/1120 [04:37<10:07,  1.29it/s] 30%|███       | 337/1120 [04:38<10:46,  1.21it/s] 30%|███       | 338/1120 [04:39<10:27,  1.25it/s] 30%|███       | 339/1120 [04:39<10:13,  1.27it/s] 30%|███       | 340/1120 [04:40<10:03,  1.29it/s]                                                   30%|███       | 340/1120 [04:40<10:03,  1.29it/s] 30%|███       | 341/1120 [04:41<10:43,  1.21it/s] 31%|███       | 342/1120 [04:42<10:23,  1.25it/s] 31%|███       | 343/1120 [04:43<10:08,  1.28it/s] 31%|███       | 344/1120 [04:43<09:58,  1.30it/s] 31%|███       | 345/1120 [04:44<10:40,  1.21it/s] 31%|███       | 346/1120 [04:45<10:19,  1.25it/s] 31%|███       | 347/1120 [04:46<10:06,  1.27it/s] 31%|███       | 348/1120 [04:47<09:56,  1.29it/s] 31%|███       | 349/1120 [04:47<10:39,  1.20it/s] 31%|███▏      | 350/1120 [04:48<10:20,  1.24it/s]                                                   31%|███▏      | 350/1120 [04:48<10:20,  1.24it/s] 31%|███▏      | 351/1120 [04:49<10:06,  1.27it/s] 31%|███▏      | 352/1120 [04:50<09:55,  1.29it/s] 32%|███▏      | 353/1120 [04:51<10:53,  1.17it/s] 32%|███▏      | 354/1120 [04:52<10:49,  1.18it/s] 32%|███▏      | 355/1120 [04:52<10:50,  1.18it/s] 32%|███▏      | 356/1120 [04:53<10:49,  1.18it/s] 32%|███▏      | 357/1120 [04:54<11:42,  1.09it/s] 32%|███▏      | 358/1120 [04:55<11:22,  1.12it/s] 32%|███▏      | 359/1120 [04:56<11:09,  1.14it/s] 32%|███▏      | 360/1120 [04:57<11:00,  1.15it/s]                                                   32%|███▏      | 360/1120 [04:57<11:00,  1.15it/s]{'eval_loss': 0.20749643445014954, 'eval_runtime': 0.9395, 'eval_samples_per_second': 106.435, 'eval_steps_per_second': 13.837, 'epoch': 2.84}
外层迭代结束！
外层迭代结束！
{'loss': 0.2317, 'learning_rate': 0.0002214953271028037, 'epoch': 2.93}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2225, 'learning_rate': 0.0002186915887850467, 'epoch': 3.02}
外层迭代结束！
外层迭代结束！
{'loss': 0.2155, 'learning_rate': 0.0002158878504672897, 'epoch': 3.11}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2123, 'learning_rate': 0.00021308411214953268, 'epoch': 3.2}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 17.12it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 13.81it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 12.79it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 12.28it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 11.97it/s][A
100%|██████████| 13/13 [00:01<00:00, 11.86it/s][A                                                  
                                               [A 32%|███▏      | 360/1120 [04:58<11:00,  1.15it/s]
100%|██████████| 13/13 [00:01<00:00, 11.86it/s][A
                                               [A 32%|███▏      | 361/1120 [04:59<16:39,  1.32s/it] 32%|███▏      | 362/1120 [05:00<14:50,  1.17s/it] 32%|███▏      | 363/1120 [05:01<13:32,  1.07s/it] 32%|███▎      | 364/1120 [05:02<12:37,  1.00s/it] 33%|███▎      | 365/1120 [05:03<12:55,  1.03s/it] 33%|███▎      | 366/1120 [05:04<12:15,  1.03it/s] 33%|███▎      | 367/1120 [05:05<11:44,  1.07it/s] 33%|███▎      | 368/1120 [05:05<11:21,  1.10it/s] 33%|███▎      | 369/1120 [05:07<12:00,  1.04it/s] 33%|███▎      | 370/1120 [05:07<11:35,  1.08it/s]                                                   33%|███▎      | 370/1120 [05:07<11:35,  1.08it/s] 33%|███▎      | 371/1120 [05:08<11:15,  1.11it/s] 33%|███▎      | 372/1120 [05:09<10:59,  1.13it/s] 33%|███▎      | 373/1120 [05:10<11:43,  1.06it/s] 33%|███▎      | 374/1120 [05:11<11:20,  1.10it/s] 33%|███▎      | 375/1120 [05:12<11:04,  1.12it/s] 34%|███▎      | 376/1120 [05:13<10:56,  1.13it/s] 34%|███▎      | 377/1120 [05:14<11:38,  1.06it/s] 34%|███▍      | 378/1120 [05:15<11:16,  1.10it/s] 34%|███▍      | 379/1120 [05:15<11:01,  1.12it/s] 34%|███▍      | 380/1120 [05:16<10:49,  1.14it/s]                                                   34%|███▍      | 380/1120 [05:17<10:49,  1.14it/s] 34%|███▍      | 381/1120 [05:17<11:32,  1.07it/s] 34%|███▍      | 382/1120 [05:18<11:10,  1.10it/s] 34%|███▍      | 383/1120 [05:19<10:55,  1.12it/s] 34%|███▍      | 384/1120 [05:20<10:45,  1.14it/s] 34%|███▍      | 385/1120 [05:21<11:32,  1.06it/s] 34%|███▍      | 386/1120 [05:22<11:08,  1.10it/s] 35%|███▍      | 387/1120 [05:23<10:53,  1.12it/s] 35%|███▍      | 388/1120 [05:24<10:41,  1.14it/s] 35%|███▍      | 389/1120 [05:25<11:25,  1.07it/s] 35%|███▍      | 390/1120 [05:25<11:02,  1.10it/s]                                                   35%|███▍      | 390/1120 [05:25<11:02,  1.10it/s] 35%|███▍      | 391/1120 [05:26<10:49,  1.12it/s] 35%|███▌      | 392/1120 [05:27<10:35,  1.15it/s] 35%|███▌      | 393/1120 [05:28<11:21,  1.07it/s] 35%|███▌      | 394/1120 [05:29<10:57,  1.10it/s] 35%|███▌      | 395/1120 [05:30<10:41,  1.13it/s] 35%|███▌      | 396/1120 [05:31<10:32,  1.14it/s] 35%|███▌      | 397/1120 [05:32<11:17,  1.07it/s] 36%|███▌      | 398/1120 [05:33<10:56,  1.10it/s] 36%|███▌      | 399/1120 [05:33<10:39,  1.13it/s] 36%|███▌      | 400/1120 [05:34<10:28,  1.14it/s]                                                   36%|███▌      | 400/1120 [05:35<10:28,  1.14it/s]{'eval_loss': 0.20585229992866516, 'eval_runtime': 1.1355, 'eval_samples_per_second': 88.067, 'eval_steps_per_second': 11.449, 'epoch': 3.2}
外层迭代结束！
外层迭代结束！
{'loss': 0.1874, 'learning_rate': 0.00021028037383177567, 'epoch': 3.29}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2103, 'learning_rate': 0.00020747663551401867, 'epoch': 3.38}
外层迭代结束！
外层迭代结束！
{'loss': 0.1919, 'learning_rate': 0.00020467289719626166, 'epoch': 3.47}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1742, 'learning_rate': 0.00020186915887850465, 'epoch': 3.56}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 17.18it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 13.79it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 12.70it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 12.14it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 11.84it/s][A
100%|██████████| 13/13 [00:01<00:00, 11.74it/s][A                                                  
                                               [A 36%|███▌      | 400/1120 [05:36<10:28,  1.14it/s]
100%|██████████| 13/13 [00:01<00:00, 11.74it/s][A
                                               [A 36%|███▌      | 401/1120 [05:37<15:54,  1.33s/it] 36%|███▌      | 402/1120 [05:38<14:08,  1.18s/it] 36%|███▌      | 403/1120 [05:38<12:53,  1.08s/it] 36%|███▌      | 404/1120 [05:39<12:01,  1.01s/it] 36%|███▌      | 405/1120 [05:40<12:17,  1.03s/it] 36%|███▋      | 406/1120 [05:41<11:35,  1.03it/s] 36%|███▋      | 407/1120 [05:42<11:04,  1.07it/s] 36%|███▋      | 408/1120 [05:43<10:44,  1.11it/s] 37%|███▋      | 409/1120 [05:44<11:22,  1.04it/s] 37%|███▋      | 410/1120 [05:45<10:53,  1.09it/s]                                                   37%|███▋      | 410/1120 [05:45<10:53,  1.09it/s] 37%|███▋      | 411/1120 [05:46<10:39,  1.11it/s] 37%|███▋      | 412/1120 [05:46<10:25,  1.13it/s] 37%|███▋      | 413/1120 [05:48<11:13,  1.05it/s] 37%|███▋      | 414/1120 [05:48<10:50,  1.09it/s] 37%|███▋      | 415/1120 [05:49<10:35,  1.11it/s] 37%|███▋      | 416/1120 [05:50<10:25,  1.13it/s] 37%|███▋      | 417/1120 [05:51<11:07,  1.05it/s] 37%|███▋      | 418/1120 [05:52<10:46,  1.09it/s] 37%|███▋      | 419/1120 [05:53<10:31,  1.11it/s] 38%|███▊      | 420/1120 [05:54<10:20,  1.13it/s]                                                   38%|███▊      | 420/1120 [05:54<10:20,  1.13it/s] 38%|███▊      | 421/1120 [05:55<11:02,  1.05it/s] 38%|███▊      | 422/1120 [05:56<10:40,  1.09it/s] 38%|███▊      | 423/1120 [05:57<10:23,  1.12it/s] 38%|███▊      | 424/1120 [05:57<10:12,  1.14it/s] 38%|███▊      | 425/1120 [05:58<10:55,  1.06it/s] 38%|███▊      | 426/1120 [05:59<10:33,  1.10it/s] 38%|███▊      | 427/1120 [06:00<10:16,  1.12it/s] 38%|███▊      | 428/1120 [06:01<10:07,  1.14it/s] 38%|███▊      | 429/1120 [06:02<10:49,  1.06it/s] 38%|███▊      | 430/1120 [06:03<10:28,  1.10it/s]                                                   38%|███▊      | 430/1120 [06:03<10:28,  1.10it/s] 38%|███▊      | 431/1120 [06:04<10:13,  1.12it/s] 39%|███▊      | 432/1120 [06:05<10:03,  1.14it/s] 39%|███▊      | 433/1120 [06:06<10:46,  1.06it/s] 39%|███▉      | 434/1120 [06:07<10:25,  1.10it/s] 39%|███▉      | 435/1120 [06:07<10:10,  1.12it/s] 39%|███▉      | 436/1120 [06:08<10:01,  1.14it/s] 39%|███▉      | 437/1120 [06:09<10:43,  1.06it/s] 39%|███▉      | 438/1120 [06:10<10:23,  1.09it/s] 39%|███▉      | 439/1120 [06:11<10:10,  1.12it/s] 39%|███▉      | 440/1120 [06:12<09:59,  1.13it/s]                                                   39%|███▉      | 440/1120 [06:12<09:59,  1.13it/s]{'eval_loss': 0.20575712621212006, 'eval_runtime': 1.1456, 'eval_samples_per_second': 87.288, 'eval_steps_per_second': 11.347, 'epoch': 3.56}
外层迭代结束！
外层迭代结束！
{'loss': 0.177, 'learning_rate': 0.00019906542056074764, 'epoch': 3.64}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1522, 'learning_rate': 0.00019626168224299063, 'epoch': 3.73}
外层迭代结束！
外层迭代结束！
{'loss': 0.1956, 'learning_rate': 0.00019345794392523362, 'epoch': 3.82}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1739, 'learning_rate': 0.0001906542056074766, 'epoch': 3.91}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 15.98it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 13.27it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 12.43it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 12.00it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 11.77it/s][A
100%|██████████| 13/13 [00:01<00:00, 11.60it/s][A                                                  
                                               [A 39%|███▉      | 440/1120 [06:13<09:59,  1.13it/s]
100%|██████████| 13/13 [00:01<00:00, 11.60it/s][A
                                               [A 39%|███▉      | 441/1120 [06:14<15:07,  1.34s/it] 39%|███▉      | 442/1120 [06:15<13:27,  1.19s/it] 40%|███▉      | 443/1120 [06:16<12:12,  1.08s/it] 40%|███▉      | 444/1120 [06:17<11:24,  1.01s/it] 40%|███▉      | 445/1120 [06:18<11:40,  1.04s/it] 40%|███▉      | 446/1120 [06:19<11:01,  1.02it/s] 40%|███▉      | 447/1120 [06:20<10:33,  1.06it/s] 40%|████      | 448/1120 [06:20<10:16,  1.09it/s] 40%|████      | 449/1120 [06:22<10:52,  1.03it/s] 40%|████      | 450/1120 [06:22<10:26,  1.07it/s]                                                   40%|████      | 450/1120 [06:22<10:26,  1.07it/s] 40%|████      | 451/1120 [06:23<10:10,  1.10it/s] 40%|████      | 452/1120 [06:24<09:55,  1.12it/s] 40%|████      | 453/1120 [06:25<10:32,  1.05it/s] 41%|████      | 454/1120 [06:26<10:14,  1.08it/s] 41%|████      | 455/1120 [06:27<09:56,  1.11it/s] 41%|████      | 456/1120 [06:28<09:49,  1.13it/s] 41%|████      | 457/1120 [06:29<10:27,  1.06it/s] 41%|████      | 458/1120 [06:30<10:10,  1.08it/s] 41%|████      | 459/1120 [06:31<09:58,  1.10it/s] 41%|████      | 460/1120 [06:31<09:49,  1.12it/s]                                                   41%|████      | 460/1120 [06:32<09:49,  1.12it/s] 41%|████      | 461/1120 [06:33<10:35,  1.04it/s] 41%|████▏     | 462/1120 [06:33<10:11,  1.08it/s] 41%|████▏     | 463/1120 [06:34<09:54,  1.11it/s] 41%|████▏     | 464/1120 [06:35<09:41,  1.13it/s] 42%|████▏     | 465/1120 [06:36<10:22,  1.05it/s] 42%|████▏     | 466/1120 [06:37<10:01,  1.09it/s] 42%|████▏     | 467/1120 [06:38<09:49,  1.11it/s] 42%|████▏     | 468/1120 [06:39<09:38,  1.13it/s] 42%|████▏     | 469/1120 [06:40<10:16,  1.06it/s] 42%|████▏     | 470/1120 [06:41<09:58,  1.09it/s]                                                   42%|████▏     | 470/1120 [06:41<09:58,  1.09it/s] 42%|████▏     | 471/1120 [06:42<09:44,  1.11it/s] 42%|████▏     | 472/1120 [06:42<09:35,  1.13it/s] 42%|████▏     | 473/1120 [06:44<10:17,  1.05it/s] 42%|████▏     | 474/1120 [06:44<09:54,  1.09it/s] 42%|████▏     | 475/1120 [06:45<09:38,  1.11it/s] 42%|████▎     | 476/1120 [06:46<09:31,  1.13it/s] 43%|████▎     | 477/1120 [06:47<10:05,  1.06it/s] 43%|████▎     | 478/1120 [06:48<09:48,  1.09it/s] 43%|████▎     | 479/1120 [06:49<09:34,  1.12it/s] 43%|████▎     | 480/1120 [06:50<09:22,  1.14it/s]                                                   43%|████▎     | 480/1120 [06:50<09:22,  1.14it/s]{'eval_loss': 0.2824445068836212, 'eval_runtime': 1.1646, 'eval_samples_per_second': 85.868, 'eval_steps_per_second': 11.163, 'epoch': 3.91}
外层迭代结束！
外层迭代结束！
{'loss': 0.1444, 'learning_rate': 0.0001878504672897196, 'epoch': 4.0}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1553, 'learning_rate': 0.0001850467289719626, 'epoch': 4.09}
外层迭代结束！
外层迭代结束！
{'loss': 0.1812, 'learning_rate': 0.00018224299065420558, 'epoch': 4.18}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1393, 'learning_rate': 0.00017943925233644857, 'epoch': 4.27}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 16.58it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 13.53it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 12.62it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 12.07it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 11.83it/s][A
100%|██████████| 13/13 [00:01<00:00, 11.68it/s][A                                                  
                                               [A 43%|████▎     | 480/1120 [06:51<09:22,  1.14it/s]
100%|██████████| 13/13 [00:01<00:00, 11.68it/s][A
                                               [A 43%|████▎     | 481/1120 [06:52<14:10,  1.33s/it] 43%|████▎     | 482/1120 [06:53<12:37,  1.19s/it] 43%|████▎     | 483/1120 [06:54<11:29,  1.08s/it] 43%|████▎     | 484/1120 [06:55<10:41,  1.01s/it] 43%|████▎     | 485/1120 [06:56<10:53,  1.03s/it] 43%|████▎     | 486/1120 [06:57<10:16,  1.03it/s] 43%|████▎     | 487/1120 [06:57<09:44,  1.08it/s] 44%|████▎     | 488/1120 [06:58<09:11,  1.15it/s] 44%|████▎     | 489/1120 [06:59<09:25,  1.12it/s] 44%|████▍     | 490/1120 [07:00<08:55,  1.18it/s]                                                   44%|████▍     | 490/1120 [07:00<08:55,  1.18it/s] 44%|████▍     | 491/1120 [07:01<08:33,  1.22it/s] 44%|████▍     | 492/1120 [07:01<08:17,  1.26it/s] 44%|████▍     | 493/1120 [07:02<08:46,  1.19it/s] 44%|████▍     | 494/1120 [07:03<08:27,  1.23it/s] 44%|████▍     | 495/1120 [07:04<08:13,  1.27it/s] 44%|████▍     | 496/1120 [07:04<08:02,  1.29it/s] 44%|████▍     | 497/1120 [07:05<08:33,  1.21it/s] 44%|████▍     | 498/1120 [07:06<08:16,  1.25it/s] 45%|████▍     | 499/1120 [07:07<08:03,  1.28it/s] 45%|████▍     | 500/1120 [07:08<07:54,  1.31it/s]                                                   45%|████▍     | 500/1120 [07:08<07:54,  1.31it/s] 45%|████▍     | 501/1120 [07:09<08:26,  1.22it/s] 45%|████▍     | 502/1120 [07:09<08:09,  1.26it/s] 45%|████▍     | 503/1120 [07:10<07:58,  1.29it/s] 45%|████▌     | 504/1120 [07:11<07:51,  1.31it/s] 45%|████▌     | 505/1120 [07:12<08:23,  1.22it/s] 45%|████▌     | 506/1120 [07:12<08:10,  1.25it/s] 45%|████▌     | 507/1120 [07:13<07:58,  1.28it/s] 45%|████▌     | 508/1120 [07:14<07:50,  1.30it/s] 45%|████▌     | 509/1120 [07:15<08:21,  1.22it/s] 46%|████▌     | 510/1120 [07:16<08:06,  1.25it/s]                                                   46%|████▌     | 510/1120 [07:16<08:06,  1.25it/s] 46%|████▌     | 511/1120 [07:16<07:54,  1.28it/s] 46%|████▌     | 512/1120 [07:17<07:44,  1.31it/s] 46%|████▌     | 513/1120 [07:18<08:17,  1.22it/s] 46%|████▌     | 514/1120 [07:19<08:01,  1.26it/s] 46%|████▌     | 515/1120 [07:20<07:49,  1.29it/s] 46%|████▌     | 516/1120 [07:20<07:43,  1.30it/s] 46%|████▌     | 517/1120 [07:21<08:14,  1.22it/s] 46%|████▋     | 518/1120 [07:22<07:58,  1.26it/s] 46%|████▋     | 519/1120 [07:23<07:47,  1.29it/s] 46%|████▋     | 520/1120 [07:23<07:39,  1.30it/s]                                                   46%|████▋     | 520/1120 [07:24<07:39,  1.30it/s]{'eval_loss': 0.25948336720466614, 'eval_runtime': 1.1534, 'eval_samples_per_second': 86.701, 'eval_steps_per_second': 11.271, 'epoch': 4.27}
外层迭代结束！
外层迭代结束！
{'loss': 0.1258, 'learning_rate': 0.00017663551401869156, 'epoch': 4.36}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.149, 'learning_rate': 0.00017383177570093455, 'epoch': 4.44}
外层迭代结束！
外层迭代结束！
{'loss': 0.1847, 'learning_rate': 0.00017102803738317754, 'epoch': 4.53}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2142, 'learning_rate': 0.00016822429906542053, 'epoch': 4.62}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.89it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 16.42it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 15.36it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 14.83it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 14.52it/s][A
100%|██████████| 13/13 [00:00<00:00, 14.34it/s][A                                                  
                                               [A 46%|████▋     | 520/1120 [07:25<07:39,  1.30it/s]
100%|██████████| 13/13 [00:00<00:00, 14.34it/s][A
                                               [A 47%|████▋     | 521/1120 [07:25<11:21,  1.14s/it] 47%|████▋     | 522/1120 [07:26<10:11,  1.02s/it] 47%|████▋     | 523/1120 [07:27<09:20,  1.07it/s] 47%|████▋     | 524/1120 [07:28<08:44,  1.14it/s] 47%|████▋     | 525/1120 [07:29<08:55,  1.11it/s] 47%|████▋     | 526/1120 [07:29<08:26,  1.17it/s] 47%|████▋     | 527/1120 [07:30<08:06,  1.22it/s] 47%|████▋     | 528/1120 [07:31<07:50,  1.26it/s] 47%|████▋     | 529/1120 [07:32<08:16,  1.19it/s] 47%|████▋     | 530/1120 [07:33<07:58,  1.23it/s]                                                   47%|████▋     | 530/1120 [07:33<07:58,  1.23it/s] 47%|████▋     | 531/1120 [07:33<07:44,  1.27it/s] 48%|████▊     | 532/1120 [07:34<07:35,  1.29it/s] 48%|████▊     | 533/1120 [07:35<08:03,  1.21it/s] 48%|████▊     | 534/1120 [07:36<07:46,  1.26it/s] 48%|████▊     | 535/1120 [07:36<07:34,  1.29it/s] 48%|████▊     | 536/1120 [07:37<07:25,  1.31it/s] 48%|████▊     | 537/1120 [07:38<07:54,  1.23it/s] 48%|████▊     | 538/1120 [07:39<07:39,  1.27it/s] 48%|████▊     | 539/1120 [07:40<07:29,  1.29it/s] 48%|████▊     | 540/1120 [07:40<07:21,  1.31it/s]                                                   48%|████▊     | 540/1120 [07:40<07:21,  1.31it/s] 48%|████▊     | 541/1120 [07:41<07:51,  1.23it/s] 48%|████▊     | 542/1120 [07:42<07:35,  1.27it/s] 48%|████▊     | 543/1120 [07:43<07:25,  1.30it/s] 49%|████▊     | 544/1120 [07:43<07:18,  1.31it/s] 49%|████▊     | 545/1120 [07:44<07:47,  1.23it/s] 49%|████▉     | 546/1120 [07:45<07:32,  1.27it/s] 49%|████▉     | 547/1120 [07:46<07:22,  1.30it/s] 49%|████▉     | 548/1120 [07:47<07:14,  1.32it/s] 49%|████▉     | 549/1120 [07:47<07:42,  1.23it/s] 49%|████▉     | 550/1120 [07:48<07:25,  1.28it/s]                                                   49%|████▉     | 550/1120 [07:48<07:25,  1.28it/s] 49%|████▉     | 551/1120 [07:49<07:17,  1.30it/s] 49%|████▉     | 552/1120 [07:50<07:09,  1.32it/s] 49%|████▉     | 553/1120 [07:51<07:40,  1.23it/s] 49%|████▉     | 554/1120 [07:51<07:26,  1.27it/s] 50%|████▉     | 555/1120 [07:52<07:16,  1.30it/s] 50%|████▉     | 556/1120 [07:53<07:09,  1.31it/s] 50%|████▉     | 557/1120 [07:54<07:38,  1.23it/s] 50%|████▉     | 558/1120 [07:54<07:23,  1.27it/s] 50%|████▉     | 559/1120 [07:55<07:13,  1.29it/s] 50%|█████     | 560/1120 [07:56<07:07,  1.31it/s]                                                   50%|█████     | 560/1120 [07:56<07:07,  1.31it/s]{'eval_loss': 0.24142619967460632, 'eval_runtime': 0.9425, 'eval_samples_per_second': 106.103, 'eval_steps_per_second': 13.793, 'epoch': 4.62}
外层迭代结束！
外层迭代结束！
{'loss': 0.0898, 'learning_rate': 0.00016542056074766352, 'epoch': 4.71}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1386, 'learning_rate': 0.00016261682242990652, 'epoch': 4.8}
外层迭代结束！
外层迭代结束！
{'loss': 0.1911, 'learning_rate': 0.0001598130841121495, 'epoch': 4.89}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1676, 'learning_rate': 0.0001570093457943925, 'epoch': 4.98}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.24it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.53it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.59it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.10it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.81it/s][A                                                  
                                               [A 50%|█████     | 560/1120 [07:57<07:07,  1.31it/s]
100%|██████████| 13/13 [00:00<00:00, 14.81it/s][A
                                               [A 50%|█████     | 561/1120 [07:58<10:30,  1.13s/it] 50%|█████     | 562/1120 [07:59<09:23,  1.01s/it] 50%|█████     | 563/1120 [07:59<08:35,  1.08it/s] 50%|█████     | 564/1120 [08:00<08:04,  1.15it/s] 50%|█████     | 565/1120 [08:01<08:14,  1.12it/s] 51%|█████     | 566/1120 [08:02<07:46,  1.19it/s] 51%|█████     | 567/1120 [08:03<07:28,  1.23it/s] 51%|█████     | 568/1120 [08:03<07:14,  1.27it/s] 51%|█████     | 569/1120 [08:04<07:39,  1.20it/s] 51%|█████     | 570/1120 [08:05<07:21,  1.25it/s]                                                   51%|█████     | 570/1120 [08:05<07:21,  1.25it/s] 51%|█████     | 571/1120 [08:06<07:09,  1.28it/s] 51%|█████     | 572/1120 [08:06<07:01,  1.30it/s] 51%|█████     | 573/1120 [08:07<07:28,  1.22it/s] 51%|█████▏    | 574/1120 [08:08<07:15,  1.25it/s] 51%|█████▏    | 575/1120 [08:09<07:04,  1.28it/s] 51%|█████▏    | 576/1120 [08:10<06:56,  1.30it/s] 52%|█████▏    | 577/1120 [08:10<07:24,  1.22it/s] 52%|█████▏    | 578/1120 [08:11<07:09,  1.26it/s] 52%|█████▏    | 579/1120 [08:12<07:00,  1.29it/s] 52%|█████▏    | 580/1120 [08:13<06:54,  1.30it/s]                                                   52%|█████▏    | 580/1120 [08:13<06:54,  1.30it/s] 52%|█████▏    | 581/1120 [08:14<07:24,  1.21it/s] 52%|█████▏    | 582/1120 [08:14<07:08,  1.25it/s] 52%|█████▏    | 583/1120 [08:15<06:58,  1.28it/s] 52%|█████▏    | 584/1120 [08:16<06:50,  1.31it/s] 52%|█████▏    | 585/1120 [08:17<07:17,  1.22it/s] 52%|█████▏    | 586/1120 [08:18<07:03,  1.26it/s] 52%|█████▏    | 587/1120 [08:18<06:53,  1.29it/s] 52%|█████▎    | 588/1120 [08:19<06:45,  1.31it/s] 53%|█████▎    | 589/1120 [08:20<07:14,  1.22it/s] 53%|█████▎    | 590/1120 [08:21<06:59,  1.26it/s]                                                   53%|█████▎    | 590/1120 [08:21<06:59,  1.26it/s] 53%|█████▎    | 591/1120 [08:21<06:50,  1.29it/s] 53%|█████▎    | 592/1120 [08:22<06:43,  1.31it/s] 53%|█████▎    | 593/1120 [08:23<07:11,  1.22it/s] 53%|█████▎    | 594/1120 [08:24<06:58,  1.26it/s] 53%|█████▎    | 595/1120 [08:25<06:47,  1.29it/s] 53%|█████▎    | 596/1120 [08:25<06:40,  1.31it/s] 53%|█████▎    | 597/1120 [08:26<07:07,  1.22it/s] 53%|█████▎    | 598/1120 [08:27<06:54,  1.26it/s] 53%|█████▎    | 599/1120 [08:28<06:45,  1.28it/s] 54%|█████▎    | 600/1120 [08:28<06:39,  1.30it/s]                                                   54%|█████▎    | 600/1120 [08:29<06:39,  1.30it/s]{'eval_loss': 0.24963568150997162, 'eval_runtime': 0.9171, 'eval_samples_per_second': 109.034, 'eval_steps_per_second': 14.174, 'epoch': 4.98}
外层迭代结束！
外层迭代结束！
{'loss': 0.1184, 'learning_rate': 0.0001542056074766355, 'epoch': 5.07}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1544, 'learning_rate': 0.00015140186915887848, 'epoch': 5.16}
外层迭代结束！
外层迭代结束！
{'loss': 0.1423, 'learning_rate': 0.00014859813084112147, 'epoch': 5.24}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1889, 'learning_rate': 0.00014579439252336446, 'epoch': 5.33}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.74it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.20it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.28it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.83it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.41it/s][A                                                  
                                               [A 54%|█████▎    | 600/1120 [08:30<06:39,  1.30it/s]
100%|██████████| 13/13 [00:00<00:00, 14.41it/s][A
                                               [A 54%|█████▎    | 601/1120 [08:31<09:55,  1.15s/it] 54%|█████▍    | 602/1120 [08:31<08:51,  1.03s/it] 54%|█████▍    | 603/1120 [08:32<08:05,  1.06it/s] 54%|█████▍    | 604/1120 [08:33<07:36,  1.13it/s] 54%|█████▍    | 605/1120 [08:34<07:48,  1.10it/s] 54%|█████▍    | 606/1120 [08:34<07:25,  1.15it/s] 54%|█████▍    | 607/1120 [08:35<07:05,  1.20it/s] 54%|█████▍    | 608/1120 [08:36<06:51,  1.25it/s] 54%|█████▍    | 609/1120 [08:37<07:13,  1.18it/s] 54%|█████▍    | 610/1120 [08:38<06:58,  1.22it/s]                                                   54%|█████▍    | 610/1120 [08:38<06:58,  1.22it/s] 55%|█████▍    | 611/1120 [08:38<06:47,  1.25it/s] 55%|█████▍    | 612/1120 [08:39<06:38,  1.27it/s] 55%|█████▍    | 613/1120 [08:40<07:02,  1.20it/s] 55%|█████▍    | 614/1120 [08:41<06:49,  1.23it/s] 55%|█████▍    | 615/1120 [08:42<06:39,  1.26it/s] 55%|█████▌    | 616/1120 [08:42<06:30,  1.29it/s] 55%|█████▌    | 617/1120 [08:43<06:57,  1.21it/s] 55%|█████▌    | 618/1120 [08:44<06:44,  1.24it/s] 55%|█████▌    | 619/1120 [08:45<06:36,  1.26it/s] 55%|█████▌    | 620/1120 [08:46<06:29,  1.28it/s]                                                   55%|█████▌    | 620/1120 [08:46<06:29,  1.28it/s] 55%|█████▌    | 621/1120 [08:47<06:54,  1.21it/s] 56%|█████▌    | 622/1120 [08:47<06:40,  1.24it/s] 56%|█████▌    | 623/1120 [08:48<06:31,  1.27it/s] 56%|█████▌    | 624/1120 [08:49<06:23,  1.29it/s] 56%|█████▌    | 625/1120 [08:50<06:49,  1.21it/s] 56%|█████▌    | 626/1120 [08:50<06:36,  1.24it/s] 56%|█████▌    | 627/1120 [08:51<06:27,  1.27it/s] 56%|█████▌    | 628/1120 [08:52<06:20,  1.29it/s] 56%|█████▌    | 629/1120 [08:53<06:46,  1.21it/s] 56%|█████▋    | 630/1120 [08:54<06:33,  1.25it/s]                                                   56%|█████▋    | 630/1120 [08:54<06:33,  1.25it/s] 56%|█████▋    | 631/1120 [08:54<06:22,  1.28it/s] 56%|█████▋    | 632/1120 [08:55<06:17,  1.29it/s] 57%|█████▋    | 633/1120 [08:56<06:43,  1.21it/s] 57%|█████▋    | 634/1120 [08:57<06:30,  1.24it/s] 57%|█████▋    | 635/1120 [08:58<06:22,  1.27it/s] 57%|█████▋    | 636/1120 [08:58<06:14,  1.29it/s] 57%|█████▋    | 637/1120 [08:59<06:38,  1.21it/s] 57%|█████▋    | 638/1120 [09:00<06:25,  1.25it/s] 57%|█████▋    | 639/1120 [09:01<06:16,  1.28it/s] 57%|█████▋    | 640/1120 [09:02<06:10,  1.29it/s]                                                   57%|█████▋    | 640/1120 [09:02<06:10,  1.29it/s]{'eval_loss': 0.3408900499343872, 'eval_runtime': 0.94, 'eval_samples_per_second': 106.381, 'eval_steps_per_second': 13.83, 'epoch': 5.33}
外层迭代结束！
外层迭代结束！
{'loss': 0.1821, 'learning_rate': 0.00014299065420560745, 'epoch': 5.42}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1308, 'learning_rate': 0.00014018691588785044, 'epoch': 5.51}
外层迭代结束！
外层迭代结束！
{'loss': 0.1125, 'learning_rate': 0.00013738317757009343, 'epoch': 5.6}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1209, 'learning_rate': 0.00013457943925233642, 'epoch': 5.69}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.99it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.32it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.27it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.71it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.26it/s][A                                                  
                                               [A 57%|█████▋    | 640/1120 [09:03<06:10,  1.29it/s]
100%|██████████| 13/13 [00:00<00:00, 14.26it/s][A
                                               [A 57%|█████▋    | 641/1120 [09:04<09:13,  1.15s/it] 57%|█████▋    | 642/1120 [09:04<08:13,  1.03s/it] 57%|█████▋    | 643/1120 [09:05<07:33,  1.05it/s] 57%|█████▊    | 644/1120 [09:06<07:06,  1.12it/s] 58%|█████▊    | 645/1120 [09:07<07:17,  1.09it/s] 58%|█████▊    | 646/1120 [09:08<06:54,  1.14it/s] 58%|█████▊    | 647/1120 [09:08<06:39,  1.19it/s] 58%|█████▊    | 648/1120 [09:09<06:30,  1.21it/s] 58%|█████▊    | 649/1120 [09:10<06:54,  1.14it/s] 58%|█████▊    | 650/1120 [09:11<06:40,  1.17it/s]                                                   58%|█████▊    | 650/1120 [09:11<06:40,  1.17it/s] 58%|█████▊    | 651/1120 [09:12<06:31,  1.20it/s] 58%|█████▊    | 652/1120 [09:13<06:24,  1.22it/s] 58%|█████▊    | 653/1120 [09:14<06:50,  1.14it/s] 58%|█████▊    | 654/1120 [09:14<06:33,  1.19it/s] 58%|█████▊    | 655/1120 [09:15<06:25,  1.21it/s] 59%|█████▊    | 656/1120 [09:16<06:21,  1.22it/s] 59%|█████▊    | 657/1120 [09:17<06:42,  1.15it/s] 59%|█████▉    | 658/1120 [09:18<06:27,  1.19it/s] 59%|█████▉    | 659/1120 [09:18<06:13,  1.23it/s] 59%|█████▉    | 660/1120 [09:19<06:06,  1.25it/s]                                                   59%|█████▉    | 660/1120 [09:19<06:06,  1.25it/s] 59%|█████▉    | 661/1120 [09:20<06:28,  1.18it/s] 59%|█████▉    | 662/1120 [09:21<06:15,  1.22it/s] 59%|█████▉    | 663/1120 [09:22<06:07,  1.24it/s] 59%|█████▉    | 664/1120 [09:22<05:58,  1.27it/s] 59%|█████▉    | 665/1120 [09:23<06:24,  1.18it/s] 59%|█████▉    | 666/1120 [09:24<06:11,  1.22it/s] 60%|█████▉    | 667/1120 [09:25<06:02,  1.25it/s] 60%|█████▉    | 668/1120 [09:26<05:57,  1.26it/s] 60%|█████▉    | 669/1120 [09:27<06:20,  1.18it/s] 60%|█████▉    | 670/1120 [09:27<06:09,  1.22it/s]                                                   60%|█████▉    | 670/1120 [09:27<06:09,  1.22it/s] 60%|█████▉    | 671/1120 [09:28<06:00,  1.25it/s] 60%|██████    | 672/1120 [09:29<05:54,  1.26it/s] 60%|██████    | 673/1120 [09:30<06:17,  1.18it/s] 60%|██████    | 674/1120 [09:31<06:07,  1.21it/s] 60%|██████    | 675/1120 [09:31<05:58,  1.24it/s] 60%|██████    | 676/1120 [09:32<05:50,  1.27it/s] 60%|██████    | 677/1120 [09:33<06:13,  1.19it/s] 61%|██████    | 678/1120 [09:34<06:00,  1.23it/s] 61%|██████    | 679/1120 [09:35<05:50,  1.26it/s] 61%|██████    | 680/1120 [09:35<05:44,  1.28it/s]                                                   61%|██████    | 680/1120 [09:36<05:44,  1.28it/s]{'eval_loss': 0.2779264450073242, 'eval_runtime': 0.9434, 'eval_samples_per_second': 106.002, 'eval_steps_per_second': 13.78, 'epoch': 5.69}
外层迭代结束！
外层迭代结束！
{'loss': 0.1168, 'learning_rate': 0.0001317757009345794, 'epoch': 5.78}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.138, 'learning_rate': 0.0001289719626168224, 'epoch': 5.87}
外层迭代结束！
外层迭代结束！
{'loss': 0.143, 'learning_rate': 0.0001261682242990654, 'epoch': 5.96}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1026, 'learning_rate': 0.00012336448598130838, 'epoch': 6.04}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.40it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.02it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.05it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.54it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.23it/s][A                                                  
                                               [A 61%|██████    | 680/1120 [09:37<05:44,  1.28it/s]
100%|██████████| 13/13 [00:00<00:00, 14.23it/s][A
                                               [A 61%|██████    | 681/1120 [09:37<08:29,  1.16s/it] 61%|██████    | 682/1120 [09:38<07:34,  1.04s/it] 61%|██████    | 683/1120 [09:39<06:56,  1.05it/s] 61%|██████    | 684/1120 [09:40<06:29,  1.12it/s] 61%|██████    | 685/1120 [09:41<06:35,  1.10it/s] 61%|██████▏   | 686/1120 [09:41<06:15,  1.16it/s] 61%|██████▏   | 687/1120 [09:42<05:59,  1.20it/s] 61%|██████▏   | 688/1120 [09:43<05:48,  1.24it/s] 62%|██████▏   | 689/1120 [09:44<06:12,  1.16it/s] 62%|██████▏   | 690/1120 [09:45<05:58,  1.20it/s]                                                   62%|██████▏   | 690/1120 [09:45<05:58,  1.20it/s] 62%|██████▏   | 691/1120 [09:45<05:42,  1.25it/s] 62%|██████▏   | 692/1120 [09:46<05:32,  1.29it/s] 62%|██████▏   | 693/1120 [09:47<05:49,  1.22it/s] 62%|██████▏   | 694/1120 [09:48<05:35,  1.27it/s] 62%|██████▏   | 695/1120 [09:48<05:23,  1.31it/s] 62%|██████▏   | 696/1120 [09:49<05:16,  1.34it/s] 62%|██████▏   | 697/1120 [09:50<05:37,  1.25it/s] 62%|██████▏   | 698/1120 [09:51<05:22,  1.31it/s] 62%|██████▏   | 699/1120 [09:51<05:15,  1.33it/s] 62%|██████▎   | 700/1120 [09:52<05:08,  1.36it/s]                                                   62%|██████▎   | 700/1120 [09:52<05:08,  1.36it/s] 63%|██████▎   | 701/1120 [09:53<05:29,  1.27it/s] 63%|██████▎   | 702/1120 [09:54<05:18,  1.31it/s] 63%|██████▎   | 703/1120 [09:54<05:10,  1.35it/s] 63%|██████▎   | 704/1120 [09:55<05:05,  1.36it/s] 63%|██████▎   | 705/1120 [09:56<05:26,  1.27it/s] 63%|██████▎   | 706/1120 [09:57<05:15,  1.31it/s] 63%|██████▎   | 707/1120 [09:58<05:10,  1.33it/s] 63%|██████▎   | 708/1120 [09:58<05:09,  1.33it/s] 63%|██████▎   | 709/1120 [09:59<05:29,  1.25it/s] 63%|██████▎   | 710/1120 [10:00<05:17,  1.29it/s]                                                   63%|██████▎   | 710/1120 [10:00<05:17,  1.29it/s] 63%|██████▎   | 711/1120 [10:01<05:06,  1.33it/s] 64%|██████▎   | 712/1120 [10:01<05:02,  1.35it/s] 64%|██████▎   | 713/1120 [10:02<05:23,  1.26it/s] 64%|██████▍   | 714/1120 [10:03<05:13,  1.29it/s] 64%|██████▍   | 715/1120 [10:04<05:05,  1.33it/s] 64%|██████▍   | 716/1120 [10:04<04:57,  1.36it/s] 64%|██████▍   | 717/1120 [10:05<05:18,  1.27it/s] 64%|██████▍   | 718/1120 [10:06<05:08,  1.30it/s] 64%|██████▍   | 719/1120 [10:07<04:58,  1.34it/s] 64%|██████▍   | 720/1120 [10:07<04:56,  1.35it/s]                                                   64%|██████▍   | 720/1120 [10:08<04:56,  1.35it/s]{'eval_loss': 0.3026098906993866, 'eval_runtime': 0.9538, 'eval_samples_per_second': 104.848, 'eval_steps_per_second': 13.63, 'epoch': 6.04}
外层迭代结束！
外层迭代结束！
{'loss': 0.1243, 'learning_rate': 0.00012056074766355139, 'epoch': 6.13}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.14, 'learning_rate': 0.00011775700934579438, 'epoch': 6.22}
外层迭代结束！
外层迭代结束！
{'loss': 0.1099, 'learning_rate': 0.00011495327102803737, 'epoch': 6.31}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0999, 'learning_rate': 0.00011214953271028036, 'epoch': 6.4}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.93it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 16.65it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 15.81it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 15.34it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 15.10it/s][A
100%|██████████| 13/13 [00:00<00:00, 15.03it/s][A                                                  
                                               [A 64%|██████▍   | 720/1120 [10:09<04:56,  1.35it/s]
100%|██████████| 13/13 [00:00<00:00, 15.03it/s][A
                                               [A 64%|██████▍   | 721/1120 [10:09<07:22,  1.11s/it] 64%|██████▍   | 722/1120 [10:10<06:35,  1.01it/s] 65%|██████▍   | 723/1120 [10:11<05:58,  1.11it/s] 65%|██████▍   | 724/1120 [10:12<05:37,  1.17it/s] 65%|██████▍   | 725/1120 [10:12<05:46,  1.14it/s] 65%|██████▍   | 726/1120 [10:13<05:27,  1.20it/s] 65%|██████▍   | 727/1120 [10:14<05:12,  1.26it/s] 65%|██████▌   | 728/1120 [10:15<05:00,  1.31it/s] 65%|██████▌   | 729/1120 [10:16<05:18,  1.23it/s] 65%|██████▌   | 730/1120 [10:16<05:07,  1.27it/s]                                                   65%|██████▌   | 730/1120 [10:16<05:07,  1.27it/s] 65%|██████▌   | 731/1120 [10:17<04:55,  1.31it/s] 65%|██████▌   | 732/1120 [10:18<04:51,  1.33it/s] 65%|██████▌   | 733/1120 [10:19<05:10,  1.25it/s] 66%|██████▌   | 734/1120 [10:19<04:59,  1.29it/s] 66%|██████▌   | 735/1120 [10:20<04:51,  1.32it/s] 66%|██████▌   | 736/1120 [10:21<04:43,  1.35it/s] 66%|██████▌   | 737/1120 [10:22<05:04,  1.26it/s] 66%|██████▌   | 738/1120 [10:22<04:55,  1.29it/s] 66%|██████▌   | 739/1120 [10:23<04:46,  1.33it/s] 66%|██████▌   | 740/1120 [10:24<04:41,  1.35it/s]                                                   66%|██████▌   | 740/1120 [10:24<04:41,  1.35it/s] 66%|██████▌   | 741/1120 [10:25<05:00,  1.26it/s] 66%|██████▋   | 742/1120 [10:25<04:52,  1.29it/s] 66%|██████▋   | 743/1120 [10:26<04:46,  1.32it/s] 66%|██████▋   | 744/1120 [10:27<04:39,  1.34it/s] 67%|██████▋   | 745/1120 [10:28<05:01,  1.24it/s] 67%|██████▋   | 746/1120 [10:29<04:51,  1.28it/s] 67%|██████▋   | 747/1120 [10:29<04:42,  1.32it/s] 67%|██████▋   | 748/1120 [10:30<04:40,  1.33it/s] 67%|██████▋   | 749/1120 [10:31<04:58,  1.24it/s] 67%|██████▋   | 750/1120 [10:32<04:48,  1.28it/s]                                                   67%|██████▋   | 750/1120 [10:32<04:48,  1.28it/s] 67%|██████▋   | 751/1120 [10:32<04:42,  1.30it/s] 67%|██████▋   | 752/1120 [10:33<04:35,  1.34it/s] 67%|██████▋   | 753/1120 [10:34<04:54,  1.25it/s] 67%|██████▋   | 754/1120 [10:35<04:43,  1.29it/s] 67%|██████▋   | 755/1120 [10:35<04:35,  1.32it/s] 68%|██████▊   | 756/1120 [10:36<04:30,  1.34it/s] 68%|██████▊   | 757/1120 [10:37<04:47,  1.26it/s] 68%|██████▊   | 758/1120 [10:38<04:39,  1.30it/s] 68%|██████▊   | 759/1120 [10:39<04:33,  1.32it/s] 68%|██████▊   | 760/1120 [10:39<04:26,  1.35it/s]                                                   68%|██████▊   | 760/1120 [10:39<04:26,  1.35it/s]{'eval_loss': 0.33733001351356506, 'eval_runtime': 0.911, 'eval_samples_per_second': 109.77, 'eval_steps_per_second': 14.27, 'epoch': 6.4}
外层迭代结束！
外层迭代结束！
{'loss': 0.1065, 'learning_rate': 0.00010934579439252335, 'epoch': 6.49}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1179, 'learning_rate': 0.00010654205607476634, 'epoch': 6.58}
外层迭代结束！
外层迭代结束！
{'loss': 0.121, 'learning_rate': 0.00010373831775700933, 'epoch': 6.67}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1521, 'learning_rate': 0.00010093457943925232, 'epoch': 6.76}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.64it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.17it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.43it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.02it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.69it/s][A                                                  
                                               [A 68%|██████▊   | 760/1120 [10:40<04:26,  1.35it/s]
100%|██████████| 13/13 [00:00<00:00, 14.69it/s][A
                                               [A 68%|██████▊   | 761/1120 [10:41<06:48,  1.14s/it] 68%|██████▊   | 762/1120 [10:42<06:04,  1.02s/it] 68%|██████▊   | 763/1120 [10:43<05:31,  1.08it/s] 68%|██████▊   | 764/1120 [10:43<05:06,  1.16it/s] 68%|██████▊   | 765/1120 [10:44<05:12,  1.13it/s] 68%|██████▊   | 766/1120 [10:45<04:54,  1.20it/s] 68%|██████▊   | 767/1120 [10:46<04:42,  1.25it/s] 69%|██████▊   | 768/1120 [10:47<04:34,  1.28it/s] 69%|██████▊   | 769/1120 [10:47<04:46,  1.23it/s] 69%|██████▉   | 770/1120 [10:48<04:37,  1.26it/s]                                                   69%|██████▉   | 770/1120 [10:48<04:37,  1.26it/s] 69%|██████▉   | 771/1120 [10:49<04:28,  1.30it/s] 69%|██████▉   | 772/1120 [10:50<04:21,  1.33it/s] 69%|██████▉   | 773/1120 [10:51<04:39,  1.24it/s] 69%|██████▉   | 774/1120 [10:51<04:27,  1.29it/s] 69%|██████▉   | 775/1120 [10:52<04:22,  1.31it/s] 69%|██████▉   | 776/1120 [10:53<04:22,  1.31it/s] 69%|██████▉   | 777/1120 [10:54<04:43,  1.21it/s] 69%|██████▉   | 778/1120 [10:54<04:33,  1.25it/s] 70%|██████▉   | 779/1120 [10:55<04:23,  1.29it/s] 70%|██████▉   | 780/1120 [10:56<04:19,  1.31it/s]                                                   70%|██████▉   | 780/1120 [10:56<04:19,  1.31it/s] 70%|██████▉   | 781/1120 [10:57<04:34,  1.23it/s] 70%|██████▉   | 782/1120 [10:58<04:23,  1.28it/s] 70%|██████▉   | 783/1120 [10:58<04:17,  1.31it/s] 70%|███████   | 784/1120 [10:59<04:11,  1.34it/s] 70%|███████   | 785/1120 [11:00<04:28,  1.25it/s] 70%|███████   | 786/1120 [11:01<04:20,  1.28it/s] 70%|███████   | 787/1120 [11:01<04:10,  1.33it/s] 70%|███████   | 788/1120 [11:02<04:06,  1.35it/s] 70%|███████   | 789/1120 [11:03<04:23,  1.26it/s] 71%|███████   | 790/1120 [11:04<04:14,  1.30it/s]                                                   71%|███████   | 790/1120 [11:04<04:14,  1.30it/s] 71%|███████   | 791/1120 [11:04<04:09,  1.32it/s] 71%|███████   | 792/1120 [11:05<04:04,  1.34it/s] 71%|███████   | 793/1120 [11:06<04:19,  1.26it/s] 71%|███████   | 794/1120 [11:07<04:12,  1.29it/s] 71%|███████   | 795/1120 [11:07<04:04,  1.33it/s] 71%|███████   | 796/1120 [11:08<04:01,  1.34it/s] 71%|███████   | 797/1120 [11:09<04:16,  1.26it/s] 71%|███████▏  | 798/1120 [11:10<04:08,  1.30it/s] 71%|███████▏  | 799/1120 [11:11<04:01,  1.33it/s] 71%|███████▏  | 800/1120 [11:11<03:57,  1.35it/s]                                                   71%|███████▏  | 800/1120 [11:11<03:57,  1.35it/s]{'eval_loss': 0.3126286268234253, 'eval_runtime': 0.9347, 'eval_samples_per_second': 106.988, 'eval_steps_per_second': 13.908, 'epoch': 6.76}
外层迭代结束！
外层迭代结束！
{'loss': 0.1182, 'learning_rate': 9.813084112149531e-05, 'epoch': 6.84}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1648, 'learning_rate': 9.53271028037383e-05, 'epoch': 6.93}
外层迭代结束！
外层迭代结束！
{'loss': 0.1324, 'learning_rate': 9.25233644859813e-05, 'epoch': 7.02}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1169, 'learning_rate': 8.971962616822429e-05, 'epoch': 7.11}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.95it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.19it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.46it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.01it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.70it/s][A                                                  
                                               [A 71%|███████▏  | 800/1120 [11:12<03:57,  1.35it/s]
100%|██████████| 13/13 [00:00<00:00, 14.70it/s][A
                                               [A 72%|███████▏  | 801/1120 [11:13<05:55,  1.11s/it] 72%|███████▏  | 802/1120 [11:14<05:16,  1.01it/s] 72%|███████▏  | 803/1120 [11:15<04:48,  1.10it/s] 72%|███████▏  | 804/1120 [11:15<04:27,  1.18it/s] 72%|███████▏  | 805/1120 [11:16<04:32,  1.16it/s] 72%|███████▏  | 806/1120 [11:17<04:17,  1.22it/s] 72%|███████▏  | 807/1120 [11:18<04:04,  1.28it/s] 72%|███████▏  | 808/1120 [11:18<03:59,  1.30it/s] 72%|███████▏  | 809/1120 [11:19<04:12,  1.23it/s] 72%|███████▏  | 810/1120 [11:20<04:02,  1.28it/s]                                                   72%|███████▏  | 810/1120 [11:20<04:02,  1.28it/s] 72%|███████▏  | 811/1120 [11:21<03:55,  1.31it/s] 72%|███████▎  | 812/1120 [11:21<03:50,  1.33it/s] 73%|███████▎  | 813/1120 [11:22<04:07,  1.24it/s] 73%|███████▎  | 814/1120 [11:23<03:57,  1.29it/s] 73%|███████▎  | 815/1120 [11:24<03:50,  1.32it/s] 73%|███████▎  | 816/1120 [11:25<03:44,  1.35it/s] 73%|███████▎  | 817/1120 [11:25<03:59,  1.27it/s] 73%|███████▎  | 818/1120 [11:26<03:51,  1.30it/s] 73%|███████▎  | 819/1120 [11:27<03:45,  1.33it/s] 73%|███████▎  | 820/1120 [11:28<03:41,  1.36it/s]                                                   73%|███████▎  | 820/1120 [11:28<03:41,  1.36it/s] 73%|███████▎  | 821/1120 [11:28<03:56,  1.26it/s] 73%|███████▎  | 822/1120 [11:29<03:48,  1.31it/s] 73%|███████▎  | 823/1120 [11:30<03:41,  1.34it/s] 74%|███████▎  | 824/1120 [11:31<03:38,  1.35it/s] 74%|███████▎  | 825/1120 [11:32<03:53,  1.26it/s] 74%|███████▍  | 826/1120 [11:32<03:45,  1.30it/s] 74%|███████▍  | 827/1120 [11:33<03:41,  1.32it/s] 74%|███████▍  | 828/1120 [11:34<03:34,  1.36it/s] 74%|███████▍  | 829/1120 [11:35<03:51,  1.25it/s] 74%|███████▍  | 830/1120 [11:35<03:54,  1.24it/s]                                                   74%|███████▍  | 830/1120 [11:35<03:54,  1.24it/s] 74%|███████▍  | 831/1120 [11:36<03:54,  1.23it/s] 74%|███████▍  | 832/1120 [11:37<03:54,  1.23it/s] 74%|███████▍  | 833/1120 [11:38<04:13,  1.13it/s] 74%|███████▍  | 834/1120 [11:39<04:07,  1.16it/s] 75%|███████▍  | 835/1120 [11:40<03:59,  1.19it/s] 75%|███████▍  | 836/1120 [11:41<03:57,  1.20it/s] 75%|███████▍  | 837/1120 [11:42<04:13,  1.11it/s] 75%|███████▍  | 838/1120 [11:42<04:06,  1.14it/s] 75%|███████▍  | 839/1120 [11:43<04:01,  1.16it/s] 75%|███████▌  | 840/1120 [11:44<03:54,  1.19it/s]                                                   75%|███████▌  | 840/1120 [11:44<03:54,  1.19it/s]{'eval_loss': 0.3065846562385559, 'eval_runtime': 0.9314, 'eval_samples_per_second': 107.363, 'eval_steps_per_second': 13.957, 'epoch': 7.11}
外层迭代结束！
外层迭代结束！
{'loss': 0.1017, 'learning_rate': 8.691588785046728e-05, 'epoch': 7.2}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0791, 'learning_rate': 8.411214953271027e-05, 'epoch': 7.29}
外层迭代结束！
外层迭代结束！
{'loss': 0.0839, 'learning_rate': 8.130841121495326e-05, 'epoch': 7.38}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1283, 'learning_rate': 7.850467289719625e-05, 'epoch': 7.47}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.02it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.52it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.59it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.02it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.54it/s][A                                                  
                                               [A 75%|███████▌  | 840/1120 [11:45<03:54,  1.19it/s]
100%|██████████| 13/13 [00:00<00:00, 14.54it/s][A
                                               [A 75%|███████▌  | 841/1120 [11:46<05:38,  1.21s/it] 75%|███████▌  | 842/1120 [11:47<05:04,  1.09s/it] 75%|███████▌  | 843/1120 [11:48<04:39,  1.01s/it] 75%|███████▌  | 844/1120 [11:49<04:23,  1.05it/s] 75%|███████▌  | 845/1120 [11:50<04:30,  1.02it/s] 76%|███████▌  | 846/1120 [11:50<04:15,  1.07it/s] 76%|███████▌  | 847/1120 [11:51<04:07,  1.10it/s] 76%|███████▌  | 848/1120 [11:52<03:56,  1.15it/s] 76%|███████▌  | 849/1120 [11:53<04:10,  1.08it/s] 76%|███████▌  | 850/1120 [11:54<03:58,  1.13it/s]                                                   76%|███████▌  | 850/1120 [11:54<03:58,  1.13it/s] 76%|███████▌  | 851/1120 [11:55<03:51,  1.16it/s] 76%|███████▌  | 852/1120 [11:55<03:46,  1.18it/s] 76%|███████▌  | 853/1120 [11:57<04:02,  1.10it/s] 76%|███████▋  | 854/1120 [11:57<03:55,  1.13it/s] 76%|███████▋  | 855/1120 [11:58<03:48,  1.16it/s] 76%|███████▋  | 856/1120 [11:59<03:42,  1.18it/s] 77%|███████▋  | 857/1120 [12:00<03:56,  1.11it/s] 77%|███████▋  | 858/1120 [12:01<03:49,  1.14it/s] 77%|███████▋  | 859/1120 [12:02<03:44,  1.16it/s] 77%|███████▋  | 860/1120 [12:02<03:40,  1.18it/s]                                                   77%|███████▋  | 860/1120 [12:03<03:40,  1.18it/s] 77%|███████▋  | 861/1120 [12:04<03:53,  1.11it/s] 77%|███████▋  | 862/1120 [12:04<03:44,  1.15it/s] 77%|███████▋  | 863/1120 [12:05<03:39,  1.17it/s] 77%|███████▋  | 864/1120 [12:06<03:33,  1.20it/s] 77%|███████▋  | 865/1120 [12:07<03:47,  1.12it/s] 77%|███████▋  | 866/1120 [12:08<03:39,  1.16it/s] 77%|███████▋  | 867/1120 [12:09<03:34,  1.18it/s] 78%|███████▊  | 868/1120 [12:09<03:30,  1.19it/s] 78%|███████▊  | 869/1120 [12:10<03:43,  1.12it/s] 78%|███████▊  | 870/1120 [12:11<03:36,  1.16it/s]                                                   78%|███████▊  | 870/1120 [12:11<03:36,  1.16it/s] 78%|███████▊  | 871/1120 [12:12<03:30,  1.18it/s] 78%|███████▊  | 872/1120 [12:13<03:28,  1.19it/s] 78%|███████▊  | 873/1120 [12:14<03:40,  1.12it/s] 78%|███████▊  | 874/1120 [12:15<03:31,  1.16it/s] 78%|███████▊  | 875/1120 [12:15<03:25,  1.19it/s] 78%|███████▊  | 876/1120 [12:16<03:20,  1.21it/s] 78%|███████▊  | 877/1120 [12:17<03:33,  1.14it/s] 78%|███████▊  | 878/1120 [12:18<03:25,  1.18it/s] 78%|███████▊  | 879/1120 [12:19<03:19,  1.21it/s] 79%|███████▊  | 880/1120 [12:20<03:15,  1.23it/s]                                                   79%|███████▊  | 880/1120 [12:20<03:15,  1.23it/s]{'eval_loss': 0.3582673668861389, 'eval_runtime': 0.9253, 'eval_samples_per_second': 108.076, 'eval_steps_per_second': 14.05, 'epoch': 7.47}
外层迭代结束！
外层迭代结束！
{'loss': 0.1259, 'learning_rate': 7.570093457943924e-05, 'epoch': 7.56}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0936, 'learning_rate': 7.289719626168223e-05, 'epoch': 7.64}
外层迭代结束！
外层迭代结束！
{'loss': 0.1457, 'learning_rate': 7.009345794392522e-05, 'epoch': 7.73}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0955, 'learning_rate': 6.728971962616821e-05, 'epoch': 7.82}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.55it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.86it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.87it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.33it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.07it/s][A                                                  
                                               [A 79%|███████▊  | 880/1120 [12:21<03:15,  1.23it/s]
100%|██████████| 13/13 [00:00<00:00, 15.07it/s][A
                                               [A 79%|███████▊  | 881/1120 [12:22<04:43,  1.18s/it] 79%|███████▉  | 882/1120 [12:22<04:14,  1.07s/it] 79%|███████▉  | 883/1120 [12:23<03:52,  1.02it/s] 79%|███████▉  | 884/1120 [12:24<03:37,  1.09it/s] 79%|███████▉  | 885/1120 [12:25<03:41,  1.06it/s] 79%|███████▉  | 886/1120 [12:26<03:29,  1.12it/s] 79%|███████▉  | 887/1120 [12:27<03:20,  1.16it/s] 79%|███████▉  | 888/1120 [12:27<03:15,  1.19it/s] 79%|███████▉  | 889/1120 [12:28<03:24,  1.13it/s] 79%|███████▉  | 890/1120 [12:29<03:17,  1.17it/s]                                                   79%|███████▉  | 890/1120 [12:29<03:17,  1.17it/s] 80%|███████▉  | 891/1120 [12:30<03:10,  1.20it/s] 80%|███████▉  | 892/1120 [12:31<03:08,  1.21it/s] 80%|███████▉  | 893/1120 [12:32<03:20,  1.13it/s] 80%|███████▉  | 894/1120 [12:33<03:16,  1.15it/s] 80%|███████▉  | 895/1120 [12:33<03:10,  1.18it/s] 80%|████████  | 896/1120 [12:34<03:05,  1.21it/s] 80%|████████  | 897/1120 [12:35<03:16,  1.14it/s] 80%|████████  | 898/1120 [12:36<03:08,  1.18it/s] 80%|████████  | 899/1120 [12:37<03:02,  1.21it/s] 80%|████████  | 900/1120 [12:37<02:59,  1.23it/s]                                                   80%|████████  | 900/1120 [12:38<02:59,  1.23it/s] 80%|████████  | 901/1120 [12:38<03:10,  1.15it/s] 81%|████████  | 902/1120 [12:39<03:03,  1.19it/s] 81%|████████  | 903/1120 [12:40<02:58,  1.21it/s] 81%|████████  | 904/1120 [12:41<02:55,  1.23it/s] 81%|████████  | 905/1120 [12:42<03:07,  1.15it/s] 81%|████████  | 906/1120 [12:43<03:01,  1.18it/s] 81%|████████  | 907/1120 [12:43<02:56,  1.21it/s] 81%|████████  | 908/1120 [12:44<02:53,  1.22it/s] 81%|████████  | 909/1120 [12:45<03:04,  1.15it/s] 81%|████████▏ | 910/1120 [12:46<02:57,  1.18it/s]                                                   81%|████████▏ | 910/1120 [12:46<02:57,  1.18it/s] 81%|████████▏ | 911/1120 [12:47<02:52,  1.21it/s] 81%|████████▏ | 912/1120 [12:47<02:48,  1.23it/s] 82%|████████▏ | 913/1120 [12:48<02:58,  1.16it/s] 82%|████████▏ | 914/1120 [12:49<02:53,  1.19it/s] 82%|████████▏ | 915/1120 [12:50<02:48,  1.22it/s] 82%|████████▏ | 916/1120 [12:51<02:45,  1.23it/s] 82%|████████▏ | 917/1120 [12:52<02:55,  1.16it/s] 82%|████████▏ | 918/1120 [12:53<02:49,  1.19it/s] 82%|████████▏ | 919/1120 [12:53<02:45,  1.21it/s] 82%|████████▏ | 920/1120 [12:54<02:42,  1.23it/s]                                                   82%|████████▏ | 920/1120 [12:54<02:42,  1.23it/s]{'eval_loss': 0.32842332124710083, 'eval_runtime': 0.903, 'eval_samples_per_second': 110.748, 'eval_steps_per_second': 14.397, 'epoch': 7.82}
外层迭代结束！
外层迭代结束！
{'loss': 0.0911, 'learning_rate': 6.44859813084112e-05, 'epoch': 7.91}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1462, 'learning_rate': 6.168224299065419e-05, 'epoch': 8.0}
外层迭代结束！
外层迭代结束！
{'loss': 0.1119, 'learning_rate': 5.887850467289719e-05, 'epoch': 8.09}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0632, 'learning_rate': 5.607476635514018e-05, 'epoch': 8.18}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.85it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.96it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.03it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.50it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.19it/s][A                                                  
                                               [A 82%|████████▏ | 920/1120 [12:55<02:42,  1.23it/s]
100%|██████████| 13/13 [00:00<00:00, 15.19it/s][A
                                               [A 82%|████████▏ | 921/1120 [12:56<03:53,  1.17s/it] 82%|████████▏ | 922/1120 [12:57<03:28,  1.05s/it] 82%|████████▏ | 923/1120 [12:58<03:11,  1.03it/s] 82%|████████▎ | 924/1120 [12:59<02:58,  1.10it/s] 83%|████████▎ | 925/1120 [12:59<03:02,  1.07it/s] 83%|████████▎ | 926/1120 [13:00<02:52,  1.13it/s] 83%|████████▎ | 927/1120 [13:01<02:45,  1.17it/s] 83%|████████▎ | 928/1120 [13:02<02:40,  1.20it/s] 83%|████████▎ | 929/1120 [13:03<02:49,  1.13it/s] 83%|████████▎ | 930/1120 [13:04<02:42,  1.17it/s]                                                   83%|████████▎ | 930/1120 [13:04<02:42,  1.17it/s] 83%|████████▎ | 931/1120 [13:04<02:37,  1.20it/s] 83%|████████▎ | 932/1120 [13:05<02:34,  1.22it/s] 83%|████████▎ | 933/1120 [13:06<02:43,  1.14it/s] 83%|████████▎ | 934/1120 [13:07<02:37,  1.18it/s] 83%|████████▎ | 935/1120 [13:08<02:33,  1.21it/s] 84%|████████▎ | 936/1120 [13:09<02:30,  1.22it/s] 84%|████████▎ | 937/1120 [13:10<02:39,  1.15it/s] 84%|████████▍ | 938/1120 [13:10<02:33,  1.18it/s] 84%|████████▍ | 939/1120 [13:11<02:30,  1.20it/s] 84%|████████▍ | 940/1120 [13:12<02:27,  1.22it/s]                                                   84%|████████▍ | 940/1120 [13:12<02:27,  1.22it/s] 84%|████████▍ | 941/1120 [13:13<02:37,  1.14it/s] 84%|████████▍ | 942/1120 [13:14<02:31,  1.18it/s] 84%|████████▍ | 943/1120 [13:15<02:26,  1.21it/s] 84%|████████▍ | 944/1120 [13:15<02:23,  1.22it/s] 84%|████████▍ | 945/1120 [13:16<02:33,  1.14it/s] 84%|████████▍ | 946/1120 [13:17<02:27,  1.18it/s] 85%|████████▍ | 947/1120 [13:18<02:23,  1.21it/s] 85%|████████▍ | 948/1120 [13:19<02:20,  1.23it/s] 85%|████████▍ | 949/1120 [13:20<02:29,  1.15it/s] 85%|████████▍ | 950/1120 [13:20<02:23,  1.19it/s]                                                   85%|████████▍ | 950/1120 [13:20<02:23,  1.19it/s] 85%|████████▍ | 951/1120 [13:21<02:19,  1.21it/s] 85%|████████▌ | 952/1120 [13:22<02:16,  1.23it/s] 85%|████████▌ | 953/1120 [13:23<02:25,  1.15it/s] 85%|████████▌ | 954/1120 [13:24<02:20,  1.18it/s] 85%|████████▌ | 955/1120 [13:25<02:16,  1.21it/s] 85%|████████▌ | 956/1120 [13:25<02:13,  1.23it/s] 85%|████████▌ | 957/1120 [13:26<02:21,  1.15it/s] 86%|████████▌ | 958/1120 [13:27<02:16,  1.19it/s] 86%|████████▌ | 959/1120 [13:28<02:13,  1.21it/s] 86%|████████▌ | 960/1120 [13:29<02:11,  1.22it/s]                                                   86%|████████▌ | 960/1120 [13:29<02:11,  1.22it/s]{'eval_loss': 0.3477199077606201, 'eval_runtime': 0.8941, 'eval_samples_per_second': 111.848, 'eval_steps_per_second': 14.54, 'epoch': 8.18}
外层迭代结束！
外层迭代结束！
{'loss': 0.0992, 'learning_rate': 5.327102803738317e-05, 'epoch': 8.27}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0718, 'learning_rate': 5.046728971962616e-05, 'epoch': 8.36}
外层迭代结束！
外层迭代结束！
{'loss': 0.0661, 'learning_rate': 4.766355140186915e-05, 'epoch': 8.44}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0909, 'learning_rate': 4.485981308411214e-05, 'epoch': 8.53}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.01it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.53it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.37it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.88it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.70it/s][A                                                  
                                               [A 86%|████████▌ | 960/1120 [13:30<02:11,  1.22it/s]
100%|██████████| 13/13 [00:00<00:00, 14.70it/s][A
                                               [A 86%|████████▌ | 961/1120 [13:31<03:11,  1.20s/it] 86%|████████▌ | 962/1120 [13:32<02:51,  1.09s/it] 86%|████████▌ | 963/1120 [13:32<02:37,  1.00s/it] 86%|████████▌ | 964/1120 [13:33<02:27,  1.06it/s] 86%|████████▌ | 965/1120 [13:34<02:30,  1.03it/s] 86%|████████▋ | 966/1120 [13:35<02:21,  1.09it/s] 86%|████████▋ | 967/1120 [13:36<02:14,  1.14it/s] 86%|████████▋ | 968/1120 [13:37<02:09,  1.18it/s] 87%|████████▋ | 969/1120 [13:38<02:14,  1.12it/s] 87%|████████▋ | 970/1120 [13:38<02:08,  1.17it/s]                                                   87%|████████▋ | 970/1120 [13:38<02:08,  1.17it/s] 87%|████████▋ | 971/1120 [13:39<02:04,  1.20it/s] 87%|████████▋ | 972/1120 [13:40<02:01,  1.22it/s] 87%|████████▋ | 973/1120 [13:41<02:08,  1.15it/s] 87%|████████▋ | 974/1120 [13:42<02:03,  1.19it/s] 87%|████████▋ | 975/1120 [13:43<01:59,  1.21it/s] 87%|████████▋ | 976/1120 [13:43<01:56,  1.23it/s] 87%|████████▋ | 977/1120 [13:44<02:04,  1.15it/s] 87%|████████▋ | 978/1120 [13:45<01:59,  1.19it/s] 87%|████████▋ | 979/1120 [13:46<01:55,  1.22it/s] 88%|████████▊ | 980/1120 [13:47<01:53,  1.23it/s]                                                   88%|████████▊ | 980/1120 [13:47<01:53,  1.23it/s] 88%|████████▊ | 981/1120 [13:48<02:00,  1.15it/s] 88%|████████▊ | 982/1120 [13:48<01:56,  1.18it/s] 88%|████████▊ | 983/1120 [13:49<01:53,  1.21it/s] 88%|████████▊ | 984/1120 [13:50<01:51,  1.22it/s] 88%|████████▊ | 985/1120 [13:51<01:58,  1.14it/s] 88%|████████▊ | 986/1120 [13:52<01:53,  1.18it/s] 88%|████████▊ | 987/1120 [13:53<01:51,  1.20it/s] 88%|████████▊ | 988/1120 [13:53<01:48,  1.22it/s] 88%|████████▊ | 989/1120 [13:54<01:54,  1.14it/s] 88%|████████▊ | 990/1120 [13:55<01:50,  1.17it/s]                                                   88%|████████▊ | 990/1120 [13:55<01:50,  1.17it/s] 88%|████████▊ | 991/1120 [13:56<01:47,  1.20it/s] 89%|████████▊ | 992/1120 [13:57<01:44,  1.23it/s] 89%|████████▊ | 993/1120 [13:58<01:50,  1.15it/s] 89%|████████▉ | 994/1120 [13:59<01:46,  1.19it/s] 89%|████████▉ | 995/1120 [13:59<01:44,  1.20it/s] 89%|████████▉ | 996/1120 [14:00<01:41,  1.22it/s] 89%|████████▉ | 997/1120 [14:01<01:47,  1.14it/s] 89%|████████▉ | 998/1120 [14:02<01:43,  1.18it/s] 89%|████████▉ | 999/1120 [14:03<01:40,  1.20it/s] 89%|████████▉ | 1000/1120 [14:04<01:38,  1.22it/s]                                                    89%|████████▉ | 1000/1120 [14:04<01:38,  1.22it/s]{'eval_loss': 0.3800164759159088, 'eval_runtime': 0.9221, 'eval_samples_per_second': 108.451, 'eval_steps_per_second': 14.099, 'epoch': 8.53}
外层迭代结束！
外层迭代结束！
{'loss': 0.1193, 'learning_rate': 4.2056074766355134e-05, 'epoch': 8.62}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0634, 'learning_rate': 3.9252336448598124e-05, 'epoch': 8.71}
外层迭代结束！
外层迭代结束！
{'loss': 0.0835, 'learning_rate': 3.6448598130841115e-05, 'epoch': 8.8}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0814, 'learning_rate': 3.3644859813084105e-05, 'epoch': 8.89}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.41it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.65it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.78it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.24it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.93it/s][A                                                   
                                               [A 89%|████████▉ | 1000/1120 [14:05<01:38,  1.22it/s]
100%|██████████| 13/13 [00:00<00:00, 14.93it/s][A
                                               [A 89%|████████▉ | 1001/1120 [14:06<02:21,  1.19s/it] 89%|████████▉ | 1002/1120 [14:06<02:06,  1.07s/it] 90%|████████▉ | 1003/1120 [14:07<01:55,  1.01it/s] 90%|████████▉ | 1004/1120 [14:08<01:47,  1.08it/s] 90%|████████▉ | 1005/1120 [14:09<01:49,  1.05it/s] 90%|████████▉ | 1006/1120 [14:10<01:42,  1.11it/s] 90%|████████▉ | 1007/1120 [14:11<01:38,  1.15it/s] 90%|█████████ | 1008/1120 [14:11<01:34,  1.19it/s] 90%|█████████ | 1009/1120 [14:12<01:39,  1.11it/s] 90%|█████████ | 1010/1120 [14:13<01:35,  1.15it/s]                                                    90%|█████████ | 1010/1120 [14:13<01:35,  1.15it/s] 90%|█████████ | 1011/1120 [14:14<01:32,  1.18it/s] 90%|█████████ | 1012/1120 [14:15<01:29,  1.20it/s] 90%|█████████ | 1013/1120 [14:16<01:34,  1.13it/s] 91%|█████████ | 1014/1120 [14:17<01:30,  1.17it/s] 91%|█████████ | 1015/1120 [14:17<01:27,  1.20it/s] 91%|█████████ | 1016/1120 [14:18<01:24,  1.22it/s] 91%|█████████ | 1017/1120 [14:19<01:29,  1.15it/s] 91%|█████████ | 1018/1120 [14:20<01:26,  1.17it/s] 91%|█████████ | 1019/1120 [14:21<01:24,  1.20it/s] 91%|█████████ | 1020/1120 [14:21<01:22,  1.22it/s]                                                    91%|█████████ | 1020/1120 [14:22<01:22,  1.22it/s] 91%|█████████ | 1021/1120 [14:23<01:26,  1.14it/s] 91%|█████████▏| 1022/1120 [14:23<01:23,  1.17it/s] 91%|█████████▏| 1023/1120 [14:24<01:19,  1.23it/s] 91%|█████████▏| 1024/1120 [14:25<01:14,  1.28it/s] 92%|█████████▏| 1025/1120 [14:26<01:17,  1.22it/s] 92%|█████████▏| 1026/1120 [14:26<01:14,  1.27it/s] 92%|█████████▏| 1027/1120 [14:27<01:11,  1.31it/s] 92%|█████████▏| 1028/1120 [14:28<01:08,  1.33it/s] 92%|█████████▏| 1029/1120 [14:29<01:12,  1.25it/s] 92%|█████████▏| 1030/1120 [14:29<01:09,  1.29it/s]                                                    92%|█████████▏| 1030/1120 [14:29<01:09,  1.29it/s] 92%|█████████▏| 1031/1120 [14:30<01:07,  1.32it/s] 92%|█████████▏| 1032/1120 [14:31<01:05,  1.35it/s] 92%|█████████▏| 1033/1120 [14:32<01:09,  1.25it/s] 92%|█████████▏| 1034/1120 [14:32<01:06,  1.29it/s] 92%|█████████▏| 1035/1120 [14:33<01:04,  1.31it/s] 92%|█████████▎| 1036/1120 [14:34<01:02,  1.33it/s] 93%|█████████▎| 1037/1120 [14:35<01:06,  1.26it/s] 93%|█████████▎| 1038/1120 [14:36<01:03,  1.29it/s] 93%|█████████▎| 1039/1120 [14:36<01:01,  1.31it/s] 93%|█████████▎| 1040/1120 [14:37<00:59,  1.34it/s]                                                    93%|█████████▎| 1040/1120 [14:37<00:59,  1.34it/s]{'eval_loss': 0.3862508535385132, 'eval_runtime': 0.9096, 'eval_samples_per_second': 109.939, 'eval_steps_per_second': 14.292, 'epoch': 8.89}
外层迭代结束！
外层迭代结束！
{'loss': 0.0894, 'learning_rate': 3.0841121495327096e-05, 'epoch': 8.98}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0504, 'learning_rate': 2.803738317757009e-05, 'epoch': 9.07}
外层迭代结束！
外层迭代结束！
{'loss': 0.0735, 'learning_rate': 2.523364485981308e-05, 'epoch': 9.16}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1216, 'learning_rate': 2.242990654205607e-05, 'epoch': 9.24}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.10it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.47it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.50it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.89it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.58it/s][A                                                   
                                               [A 93%|█████████▎| 1040/1120 [14:38<00:59,  1.34it/s]
100%|██████████| 13/13 [00:00<00:00, 14.58it/s][A
                                               [A 93%|█████████▎| 1041/1120 [14:39<01:28,  1.12s/it] 93%|█████████▎| 1042/1120 [14:40<01:18,  1.00s/it] 93%|█████████▎| 1043/1120 [14:40<01:10,  1.09it/s] 93%|█████████▎| 1044/1120 [14:41<01:05,  1.16it/s] 93%|█████████▎| 1045/1120 [14:42<01:05,  1.14it/s] 93%|█████████▎| 1046/1120 [14:43<01:00,  1.22it/s] 93%|█████████▎| 1047/1120 [14:44<00:58,  1.26it/s] 94%|█████████▎| 1048/1120 [14:44<00:55,  1.30it/s] 94%|█████████▎| 1049/1120 [14:45<00:57,  1.23it/s] 94%|█████████▍| 1050/1120 [14:46<00:54,  1.27it/s]                                                    94%|█████████▍| 1050/1120 [14:46<00:54,  1.27it/s] 94%|█████████▍| 1051/1120 [14:47<00:52,  1.31it/s] 94%|█████████▍| 1052/1120 [14:47<00:50,  1.34it/s] 94%|█████████▍| 1053/1120 [14:48<00:53,  1.25it/s] 94%|█████████▍| 1054/1120 [14:49<00:50,  1.30it/s] 94%|█████████▍| 1055/1120 [14:50<00:49,  1.32it/s] 94%|█████████▍| 1056/1120 [14:50<00:47,  1.35it/s] 94%|█████████▍| 1057/1120 [14:51<00:49,  1.26it/s] 94%|█████████▍| 1058/1120 [14:52<00:47,  1.30it/s] 95%|█████████▍| 1059/1120 [14:53<00:45,  1.33it/s] 95%|█████████▍| 1060/1120 [14:53<00:44,  1.35it/s]                                                    95%|█████████▍| 1060/1120 [14:54<00:44,  1.35it/s] 95%|█████████▍| 1061/1120 [14:54<00:46,  1.26it/s] 95%|█████████▍| 1062/1120 [14:55<00:44,  1.30it/s] 95%|█████████▍| 1063/1120 [14:56<00:42,  1.33it/s] 95%|█████████▌| 1064/1120 [14:56<00:41,  1.35it/s] 95%|█████████▌| 1065/1120 [14:57<00:43,  1.25it/s] 95%|█████████▌| 1066/1120 [14:58<00:41,  1.29it/s] 95%|█████████▌| 1067/1120 [14:59<00:39,  1.33it/s] 95%|█████████▌| 1068/1120 [15:00<00:38,  1.34it/s] 95%|█████████▌| 1069/1120 [15:00<00:40,  1.26it/s] 96%|█████████▌| 1070/1120 [15:01<00:38,  1.29it/s]                                                    96%|█████████▌| 1070/1120 [15:01<00:38,  1.29it/s] 96%|█████████▌| 1071/1120 [15:02<00:37,  1.32it/s] 96%|█████████▌| 1072/1120 [15:03<00:35,  1.33it/s] 96%|█████████▌| 1073/1120 [15:04<00:37,  1.24it/s] 96%|█████████▌| 1074/1120 [15:04<00:35,  1.28it/s] 96%|█████████▌| 1075/1120 [15:05<00:33,  1.33it/s] 96%|█████████▌| 1076/1120 [15:06<00:32,  1.34it/s] 96%|█████████▌| 1077/1120 [15:07<00:34,  1.25it/s] 96%|█████████▋| 1078/1120 [15:07<00:32,  1.29it/s] 96%|█████████▋| 1079/1120 [15:08<00:31,  1.32it/s] 96%|█████████▋| 1080/1120 [15:09<00:29,  1.36it/s]                                                    96%|█████████▋| 1080/1120 [15:09<00:29,  1.36it/s]{'eval_loss': 0.38563430309295654, 'eval_runtime': 0.9276, 'eval_samples_per_second': 107.804, 'eval_steps_per_second': 14.014, 'epoch': 9.24}
外层迭代结束！
外层迭代结束！
{'loss': 0.0735, 'learning_rate': 1.9626168224299062e-05, 'epoch': 9.33}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0804, 'learning_rate': 1.6822429906542053e-05, 'epoch': 9.42}
外层迭代结束！
外层迭代结束！
{'loss': 0.1087, 'learning_rate': 1.4018691588785045e-05, 'epoch': 9.51}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1295, 'learning_rate': 1.1214953271028036e-05, 'epoch': 9.6}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.24it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.30it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.54it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.10it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.86it/s][A                                                   
                                               [A 96%|█████████▋| 1080/1120 [15:10<00:29,  1.36it/s]
100%|██████████| 13/13 [00:00<00:00, 14.86it/s][A
                                               [A 97%|█████████▋| 1081/1120 [15:11<00:42,  1.10s/it] 97%|█████████▋| 1082/1120 [15:11<00:37,  1.01it/s] 97%|█████████▋| 1083/1120 [15:12<00:33,  1.10it/s] 97%|█████████▋| 1084/1120 [15:13<00:30,  1.18it/s] 97%|█████████▋| 1085/1120 [15:14<00:30,  1.15it/s] 97%|█████████▋| 1086/1120 [15:14<00:27,  1.22it/s] 97%|█████████▋| 1087/1120 [15:15<00:25,  1.28it/s] 97%|█████████▋| 1088/1120 [15:16<00:24,  1.31it/s] 97%|█████████▋| 1089/1120 [15:17<00:24,  1.24it/s] 97%|█████████▋| 1090/1120 [15:18<00:23,  1.28it/s]                                                    97%|█████████▋| 1090/1120 [15:18<00:23,  1.28it/s] 97%|█████████▋| 1091/1120 [15:18<00:22,  1.31it/s] 98%|█████████▊| 1092/1120 [15:19<00:20,  1.35it/s] 98%|█████████▊| 1093/1120 [15:20<00:21,  1.26it/s] 98%|█████████▊| 1094/1120 [15:21<00:20,  1.30it/s] 98%|█████████▊| 1095/1120 [15:21<00:18,  1.34it/s] 98%|█████████▊| 1096/1120 [15:22<00:17,  1.35it/s] 98%|█████████▊| 1097/1120 [15:23<00:18,  1.26it/s] 98%|█████████▊| 1098/1120 [15:24<00:16,  1.30it/s] 98%|█████████▊| 1099/1120 [15:24<00:15,  1.32it/s] 98%|█████████▊| 1100/1120 [15:25<00:14,  1.35it/s]                                                    98%|█████████▊| 1100/1120 [15:25<00:14,  1.35it/s] 98%|█████████▊| 1101/1120 [15:26<00:15,  1.26it/s] 98%|█████████▊| 1102/1120 [15:27<00:13,  1.29it/s] 98%|█████████▊| 1103/1120 [15:27<00:12,  1.32it/s] 99%|█████████▊| 1104/1120 [15:28<00:11,  1.34it/s] 99%|█████████▊| 1105/1120 [15:29<00:11,  1.26it/s] 99%|█████████▉| 1106/1120 [15:30<00:10,  1.29it/s] 99%|█████████▉| 1107/1120 [15:31<00:09,  1.31it/s] 99%|█████████▉| 1108/1120 [15:31<00:08,  1.35it/s] 99%|█████████▉| 1109/1120 [15:32<00:08,  1.25it/s] 99%|█████████▉| 1110/1120 [15:33<00:07,  1.28it/s]                                                    99%|█████████▉| 1110/1120 [15:33<00:07,  1.28it/s] 99%|█████████▉| 1111/1120 [15:34<00:06,  1.31it/s] 99%|█████████▉| 1112/1120 [15:34<00:06,  1.32it/s] 99%|█████████▉| 1113/1120 [15:35<00:05,  1.20it/s] 99%|█████████▉| 1114/1120 [15:36<00:04,  1.21it/s]100%|█████████▉| 1115/1120 [15:37<00:04,  1.21it/s]100%|█████████▉| 1116/1120 [15:38<00:03,  1.22it/s]100%|█████████▉| 1117/1120 [15:39<00:02,  1.13it/s]100%|█████████▉| 1118/1120 [15:40<00:01,  1.16it/s]100%|█████████▉| 1119/1120 [15:40<00:00,  1.17it/s]100%|██████████| 1120/1120 [15:41<00:00,  1.20it/s]                                                   100%|██████████| 1120/1120 [15:41<00:00,  1.20it/s]{'eval_loss': 0.3762947916984558, 'eval_runtime': 0.923, 'eval_samples_per_second': 108.347, 'eval_steps_per_second': 14.085, 'epoch': 9.6}
外层迭代结束！
外层迭代结束！
{'loss': 0.14, 'learning_rate': 8.411214953271026e-06, 'epoch': 9.69}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0993, 'learning_rate': 5.607476635514018e-06, 'epoch': 9.78}
外层迭代结束！
外层迭代结束！
{'loss': 0.0665, 'learning_rate': 2.803738317757009e-06, 'epoch': 9.87}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0838, 'learning_rate': 0.0, 'epoch': 9.96}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.01it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.56it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.60it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.00it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.57it/s][A                                                   
                                               [A100%|██████████| 1120/1120 [15:42<00:00,  1.20it/s]
100%|██████████| 13/13 [00:00<00:00, 14.57it/s][A
                                               [AThere were missing keys in the checkpoint model loaded: ['base_model.model.shared.weight', 'base_model.model.encoder.embed_tokens.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.encoder.block.0.layer.0.layer_norm.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.0.layer.1.layer_norm.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.1.layer.0.layer_norm.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.1.layer.1.layer_norm.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.2.layer.0.layer_norm.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.2.layer.1.layer_norm.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.3.layer.0.layer_norm.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.3.layer.1.layer_norm.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.4.layer.0.layer_norm.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.4.layer.1.layer_norm.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.5.layer.0.layer_norm.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.5.layer.1.layer_norm.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.6.layer.0.layer_norm.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.6.layer.1.layer_norm.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.7.layer.0.layer_norm.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.7.layer.1.layer_norm.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.8.layer.0.layer_norm.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.8.layer.1.layer_norm.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.9.layer.0.layer_norm.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.9.layer.1.layer_norm.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.10.layer.0.layer_norm.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.10.layer.1.layer_norm.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.11.layer.0.layer_norm.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.11.layer.1.layer_norm.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.12.layer.0.layer_norm.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.12.layer.1.layer_norm.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.13.layer.0.layer_norm.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.13.layer.1.layer_norm.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.14.layer.0.layer_norm.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.14.layer.1.layer_norm.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.15.layer.0.layer_norm.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.15.layer.1.layer_norm.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.16.layer.0.layer_norm.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.16.layer.1.layer_norm.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.17.layer.0.layer_norm.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.17.layer.1.layer_norm.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.18.layer.0.layer_norm.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.18.layer.1.layer_norm.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.19.layer.0.layer_norm.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.19.layer.1.layer_norm.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.20.layer.0.layer_norm.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.20.layer.1.layer_norm.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.21.layer.0.layer_norm.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.21.layer.1.layer_norm.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.22.layer.0.layer_norm.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.22.layer.1.layer_norm.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.23.layer.0.layer_norm.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.23.layer.1.layer_norm.weight', 'base_model.model.encoder.final_layer_norm.weight', 'base_model.model.decoder.embed_tokens.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.decoder.block.0.layer.0.layer_norm.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.0.layer.1.layer_norm.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.0.layer.2.layer_norm.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.1.layer.0.layer_norm.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.1.layer.1.layer_norm.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.1.layer.2.layer_norm.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.2.layer.0.layer_norm.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.2.layer.1.layer_norm.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.2.layer.2.layer_norm.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.3.layer.0.layer_norm.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.3.layer.1.layer_norm.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.3.layer.2.layer_norm.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.4.layer.0.layer_norm.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.4.layer.1.layer_norm.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.4.layer.2.layer_norm.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.5.layer.0.layer_norm.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.5.layer.1.layer_norm.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.5.layer.2.layer_norm.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.6.layer.0.layer_norm.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.6.layer.1.layer_norm.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.6.layer.2.layer_norm.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.7.layer.0.layer_norm.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.7.layer.1.layer_norm.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.7.layer.2.layer_norm.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.8.layer.0.layer_norm.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.8.layer.1.layer_norm.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.8.layer.2.layer_norm.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.9.layer.0.layer_norm.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.9.layer.1.layer_norm.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.9.layer.2.layer_norm.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.10.layer.0.layer_norm.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.10.layer.1.layer_norm.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.10.layer.2.layer_norm.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.11.layer.0.layer_norm.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.11.layer.1.layer_norm.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.11.layer.2.layer_norm.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.12.layer.0.layer_norm.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.12.layer.1.layer_norm.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.12.layer.2.layer_norm.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.13.layer.0.layer_norm.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.13.layer.1.layer_norm.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.13.layer.2.layer_norm.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.14.layer.0.layer_norm.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.14.layer.1.layer_norm.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.14.layer.2.layer_norm.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.15.layer.0.layer_norm.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.15.layer.1.layer_norm.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.15.layer.2.layer_norm.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.16.layer.0.layer_norm.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.16.layer.1.layer_norm.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.16.layer.2.layer_norm.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.17.layer.0.layer_norm.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.17.layer.1.layer_norm.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.17.layer.2.layer_norm.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.18.layer.0.layer_norm.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.18.layer.1.layer_norm.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.18.layer.2.layer_norm.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.19.layer.0.layer_norm.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.19.layer.1.layer_norm.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.19.layer.2.layer_norm.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.20.layer.0.layer_norm.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.20.layer.1.layer_norm.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.20.layer.2.layer_norm.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.21.layer.0.layer_norm.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.21.layer.1.layer_norm.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.21.layer.2.layer_norm.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.22.layer.0.layer_norm.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.22.layer.1.layer_norm.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.22.layer.2.layer_norm.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.23.layer.0.layer_norm.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.23.layer.1.layer_norm.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.23.layer.2.layer_norm.weight', 'base_model.model.decoder.final_layer_norm.weight', 'base_model.model.lm_head.weight'].
There were unexpected keys in the checkpoint model loaded: ['base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.weight'].
                                                   100%|██████████| 1120/1120 [15:43<00:00,  1.20it/s]100%|██████████| 1120/1120 [15:43<00:00,  1.19it/s]
{'eval_loss': 0.37375161051750183, 'eval_runtime': 0.9294, 'eval_samples_per_second': 107.597, 'eval_steps_per_second': 13.988, 'epoch': 9.96}
{'train_runtime': 943.172, 'train_samples_per_second': 9.542, 'train_steps_per_second': 1.187, 'train_loss': 0.28935334405728746, 'epoch': 9.96}

 If there's a warning about missing keys above, please disregard :)
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 8
micro_batch_size: 2
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: copa... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/3-copa
current data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 863.38it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 641.72it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 954.99it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 639.77it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Loading cached split indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-0fb90895d5797280.arrow and /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-6965e73c9435ab1e.arrow
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-a7714f0148da569c.arrow
Loading cached processed dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-c1e36c3e73c1bdf4.arrow
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-e621ec9957376d77.arrow
总样本数：1000, 选择的样本数量：20
lora_weights: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/2-wic

pre-trained model's BOS EOS and PAD token id: None 1 0  => It should be 1,2,none
continual fine tune lora!
trainable params: 2359296 || all params: 740027392 || trainable%: 0.31881198257050464
训练数据总量：360
验证数据总量：40
Map:   0%|          | 0/40 [00:00<?, ? examples/s]/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3597: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  "`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your "
                                                  Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-48eadb8d40f4f4b8.arrow
Loading cached processed dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-6c43ccacea1ed131.arrow
memory data loader 2
  0%|          | 0/450 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/450 [00:01<10:25,  1.39s/it]  0%|          | 2/450 [00:02<07:21,  1.01it/s]  1%|          | 3/450 [00:02<06:22,  1.17it/s]  1%|          | 4/450 [00:03<05:53,  1.26it/s]  1%|          | 5/450 [00:04<06:18,  1.17it/s]  1%|▏         | 6/450 [00:05<05:54,  1.25it/s]  2%|▏         | 7/450 [00:05<05:42,  1.29it/s]  2%|▏         | 8/450 [00:06<05:35,  1.32it/s]  2%|▏         | 9/450 [00:07<05:53,  1.25it/s]  2%|▏         | 10/450 [00:08<05:41,  1.29it/s]                                                  2%|▏         | 10/450 [00:08<05:41,  1.29it/s]  2%|▏         | 11/450 [00:08<05:31,  1.32it/s]  3%|▎         | 12/450 [00:09<05:23,  1.36it/s]  3%|▎         | 13/450 [00:10<05:44,  1.27it/s]  3%|▎         | 14/450 [00:11<05:32,  1.31it/s]  3%|▎         | 15/450 [00:11<05:24,  1.34it/s]  4%|▎         | 16/450 [00:12<05:20,  1.36it/s]  4%|▍         | 17/450 [00:13<05:43,  1.26it/s]  4%|▍         | 18/450 [00:14<05:43,  1.26it/s]  4%|▍         | 19/450 [00:15<05:39,  1.27it/s]  4%|▍         | 20/450 [00:15<05:30,  1.30it/s]                                                  4%|▍         | 20/450 [00:16<05:30,  1.30it/s]  5%|▍         | 21/450 [00:16<05:49,  1.23it/s]  5%|▍         | 22/450 [00:17<05:33,  1.28it/s]  5%|▌         | 23/450 [00:18<05:24,  1.31it/s]  5%|▌         | 24/450 [00:18<05:17,  1.34it/s]  6%|▌         | 25/450 [00:19<05:37,  1.26it/s]  6%|▌         | 26/450 [00:20<05:25,  1.30it/s]  6%|▌         | 27/450 [00:21<05:17,  1.33it/s]  6%|▌         | 28/450 [00:21<05:10,  1.36it/s]  6%|▋         | 29/450 [00:22<05:31,  1.27it/s]  7%|▋         | 30/450 [00:23<05:18,  1.32it/s]                                                  7%|▋         | 30/450 [00:23<05:18,  1.32it/s]  7%|▋         | 31/450 [00:24<05:14,  1.33it/s]  7%|▋         | 32/450 [00:24<05:09,  1.35it/s]  7%|▋         | 33/450 [00:25<05:28,  1.27it/s]  8%|▊         | 34/450 [00:26<05:17,  1.31it/s]  8%|▊         | 35/450 [00:27<05:08,  1.34it/s]  8%|▊         | 36/450 [00:27<05:03,  1.36it/s]  8%|▊         | 37/450 [00:28<05:25,  1.27it/s]  8%|▊         | 38/450 [00:29<05:14,  1.31it/s]  9%|▊         | 39/450 [00:30<05:08,  1.33it/s]  9%|▉         | 40/450 [00:31<05:04,  1.34it/s]                                                  9%|▉         | 40/450 [00:31<05:04,  1.34it/s]外层迭代结束！
外层迭代结束！
{'loss': 6.0366, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.22}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 4.2167, 'learning_rate': 0.00011999999999999999, 'epoch': 0.44}
外层迭代结束！
外层迭代结束！
{'loss': 1.3679, 'learning_rate': 0.00017999999999999998, 'epoch': 0.67}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.4998, 'learning_rate': 0.00023999999999999998, 'epoch': 0.89}

  0%|          | 0/5 [00:00<?, ?it/s][A
 60%|██████    | 3/5 [00:00<00:00, 22.00it/s][A                                                
                                             [A  9%|▉         | 40/450 [00:31<05:04,  1.34it/s]
100%|██████████| 5/5 [00:00<00:00, 22.00it/s][A
                                             [A  9%|▉         | 41/450 [00:32<06:23,  1.07it/s]  9%|▉         | 42/450 [00:33<05:56,  1.14it/s] 10%|▉         | 43/450 [00:33<05:36,  1.21it/s] 10%|▉         | 44/450 [00:34<05:21,  1.26it/s] 10%|█         | 45/450 [00:35<05:33,  1.21it/s] 10%|█         | 46/450 [00:36<05:17,  1.27it/s] 10%|█         | 47/450 [00:36<05:06,  1.32it/s] 11%|█         | 48/450 [00:37<04:58,  1.35it/s] 11%|█         | 49/450 [00:38<05:16,  1.27it/s] 11%|█         | 50/450 [00:39<05:06,  1.31it/s]                                                 11%|█         | 50/450 [00:39<05:06,  1.31it/s] 11%|█▏        | 51/450 [00:39<04:57,  1.34it/s] 12%|█▏        | 52/450 [00:40<04:50,  1.37it/s] 12%|█▏        | 53/450 [00:41<05:09,  1.28it/s] 12%|█▏        | 54/450 [00:42<04:59,  1.32it/s] 12%|█▏        | 55/450 [00:42<04:51,  1.36it/s] 12%|█▏        | 56/450 [00:43<04:46,  1.37it/s] 13%|█▎        | 57/450 [00:44<05:06,  1.28it/s] 13%|█▎        | 58/450 [00:45<04:56,  1.32it/s] 13%|█▎        | 59/450 [00:45<04:48,  1.36it/s] 13%|█▎        | 60/450 [00:46<04:42,  1.38it/s]                                                 13%|█▎        | 60/450 [00:46<04:42,  1.38it/s] 14%|█▎        | 61/450 [00:47<05:01,  1.29it/s] 14%|█▍        | 62/450 [00:48<04:51,  1.33it/s] 14%|█▍        | 63/450 [00:48<04:46,  1.35it/s] 14%|█▍        | 64/450 [00:49<04:43,  1.36it/s] 14%|█▍        | 65/450 [00:50<05:01,  1.28it/s] 15%|█▍        | 66/450 [00:51<04:52,  1.31it/s] 15%|█▍        | 67/450 [00:51<04:45,  1.34it/s] 15%|█▌        | 68/450 [00:52<04:39,  1.37it/s] 15%|█▌        | 69/450 [00:53<04:55,  1.29it/s] 16%|█▌        | 70/450 [00:54<04:47,  1.32it/s]                                                 16%|█▌        | 70/450 [00:54<04:47,  1.32it/s] 16%|█▌        | 71/450 [00:54<04:40,  1.35it/s] 16%|█▌        | 72/450 [00:55<04:35,  1.37it/s] 16%|█▌        | 73/450 [00:56<04:57,  1.27it/s] 16%|█▋        | 74/450 [00:57<04:48,  1.30it/s] 17%|█▋        | 75/450 [00:57<04:43,  1.32it/s] 17%|█▋        | 76/450 [00:58<04:41,  1.33it/s] 17%|█▋        | 77/450 [00:59<04:58,  1.25it/s] 17%|█▋        | 78/450 [01:00<04:50,  1.28it/s] 18%|█▊        | 79/450 [01:01<04:42,  1.31it/s] 18%|█▊        | 80/450 [01:01<04:35,  1.34it/s]                                                 18%|█▊        | 80/450 [01:02<04:35,  1.34it/s]{'eval_loss': 0.39603108167648315, 'eval_runtime': 0.351, 'eval_samples_per_second': 113.973, 'eval_steps_per_second': 14.247, 'epoch': 0.89}
外层迭代结束！
外层迭代结束！
{'loss': 0.4149, 'learning_rate': 0.0003, 'epoch': 1.11}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.393, 'learning_rate': 0.00029249999999999995, 'epoch': 1.33}
外层迭代结束！
外层迭代结束！
{'loss': 0.4555, 'learning_rate': 0.000285, 'epoch': 1.56}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.4503, 'learning_rate': 0.00027749999999999997, 'epoch': 1.78}

  0%|          | 0/5 [00:00<?, ?it/s][A
 60%|██████    | 3/5 [00:00<00:00, 20.86it/s][A                                                
                                             [A 18%|█▊        | 80/450 [01:02<04:35,  1.34it/s]
100%|██████████| 5/5 [00:00<00:00, 20.86it/s][A
                                             [A 18%|█▊        | 81/450 [01:03<05:49,  1.06it/s] 18%|█▊        | 82/450 [01:03<05:24,  1.13it/s] 18%|█▊        | 83/450 [01:04<05:08,  1.19it/s] 19%|█▊        | 84/450 [01:05<04:52,  1.25it/s] 19%|█▉        | 85/450 [01:06<05:03,  1.20it/s] 19%|█▉        | 86/450 [01:07<04:48,  1.26it/s] 19%|█▉        | 87/450 [01:07<04:36,  1.31it/s] 20%|█▉        | 88/450 [01:08<04:32,  1.33it/s] 20%|█▉        | 89/450 [01:09<04:49,  1.25it/s] 20%|██        | 90/450 [01:10<04:38,  1.29it/s]                                                 20%|██        | 90/450 [01:10<04:38,  1.29it/s] 20%|██        | 91/450 [01:10<04:31,  1.32it/s] 20%|██        | 92/450 [01:11<04:24,  1.35it/s] 21%|██        | 93/450 [01:12<04:44,  1.26it/s] 21%|██        | 94/450 [01:13<04:35,  1.29it/s] 21%|██        | 95/450 [01:13<04:26,  1.33it/s] 21%|██▏       | 96/450 [01:14<04:25,  1.33it/s] 22%|██▏       | 97/450 [01:15<04:41,  1.26it/s] 22%|██▏       | 98/450 [01:16<04:32,  1.29it/s] 22%|██▏       | 99/450 [01:16<04:23,  1.33it/s] 22%|██▏       | 100/450 [01:17<04:17,  1.36it/s]                                                  22%|██▏       | 100/450 [01:17<04:17,  1.36it/s] 22%|██▏       | 101/450 [01:18<04:34,  1.27it/s] 23%|██▎       | 102/450 [01:19<04:24,  1.32it/s] 23%|██▎       | 103/450 [01:19<04:16,  1.35it/s] 23%|██▎       | 104/450 [01:20<04:12,  1.37it/s] 23%|██▎       | 105/450 [01:21<04:28,  1.29it/s] 24%|██▎       | 106/450 [01:22<04:19,  1.33it/s] 24%|██▍       | 107/450 [01:22<04:12,  1.36it/s] 24%|██▍       | 108/450 [01:23<04:09,  1.37it/s] 24%|██▍       | 109/450 [01:24<04:24,  1.29it/s] 24%|██▍       | 110/450 [01:25<04:15,  1.33it/s]                                                  24%|██▍       | 110/450 [01:25<04:15,  1.33it/s] 25%|██▍       | 111/450 [01:25<04:08,  1.36it/s] 25%|██▍       | 112/450 [01:26<04:03,  1.39it/s] 25%|██▌       | 113/450 [01:27<04:20,  1.29it/s] 25%|██▌       | 114/450 [01:28<04:12,  1.33it/s] 26%|██▌       | 115/450 [01:28<04:05,  1.36it/s] 26%|██▌       | 116/450 [01:29<04:03,  1.37it/s] 26%|██▌       | 117/450 [01:30<04:20,  1.28it/s] 26%|██▌       | 118/450 [01:31<04:13,  1.31it/s] 26%|██▋       | 119/450 [01:31<04:06,  1.34it/s] 27%|██▋       | 120/450 [01:32<04:02,  1.36it/s]                                                  27%|██▋       | 120/450 [01:32<04:02,  1.36it/s]{'eval_loss': 0.37871119379997253, 'eval_runtime': 0.3608, 'eval_samples_per_second': 110.867, 'eval_steps_per_second': 13.858, 'epoch': 1.78}
外层迭代结束！
外层迭代结束！
{'loss': 0.3997, 'learning_rate': 0.00027, 'epoch': 2.0}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3871, 'learning_rate': 0.0002625, 'epoch': 2.22}
外层迭代结束！
外层迭代结束！
{'loss': 0.4014, 'learning_rate': 0.00025499999999999996, 'epoch': 2.44}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3756, 'learning_rate': 0.00024749999999999994, 'epoch': 2.67}

  0%|          | 0/5 [00:00<?, ?it/s][A
 60%|██████    | 3/5 [00:00<00:00, 20.74it/s][A                                                 
                                             [A 27%|██▋       | 120/450 [01:33<04:02,  1.36it/s]
100%|██████████| 5/5 [00:00<00:00, 20.74it/s][A
                                             [A 27%|██▋       | 121/450 [01:34<05:09,  1.06it/s] 27%|██▋       | 122/450 [01:34<04:49,  1.13it/s] 27%|██▋       | 123/450 [01:35<04:31,  1.20it/s] 28%|██▊       | 124/450 [01:36<04:17,  1.26it/s] 28%|██▊       | 125/450 [01:37<04:27,  1.21it/s] 28%|██▊       | 126/450 [01:37<04:13,  1.28it/s] 28%|██▊       | 127/450 [01:38<04:05,  1.31it/s] 28%|██▊       | 128/450 [01:39<04:00,  1.34it/s] 29%|██▊       | 129/450 [01:40<04:12,  1.27it/s] 29%|██▉       | 130/450 [01:40<04:04,  1.31it/s]                                                  29%|██▉       | 130/450 [01:40<04:04,  1.31it/s] 29%|██▉       | 131/450 [01:41<03:57,  1.34it/s] 29%|██▉       | 132/450 [01:42<03:52,  1.37it/s] 30%|██▉       | 133/450 [01:43<04:08,  1.27it/s] 30%|██▉       | 134/450 [01:43<03:58,  1.32it/s] 30%|███       | 135/450 [01:44<03:53,  1.35it/s] 30%|███       | 136/450 [01:45<03:50,  1.36it/s] 30%|███       | 137/450 [01:46<04:05,  1.27it/s] 31%|███       | 138/450 [01:46<03:56,  1.32it/s] 31%|███       | 139/450 [01:47<03:54,  1.33it/s] 31%|███       | 140/450 [01:48<03:51,  1.34it/s]                                                  31%|███       | 140/450 [01:48<03:51,  1.34it/s] 31%|███▏      | 141/450 [01:49<04:07,  1.25it/s] 32%|███▏      | 142/450 [01:49<03:56,  1.30it/s] 32%|███▏      | 143/450 [01:50<03:51,  1.32it/s] 32%|███▏      | 144/450 [01:51<03:47,  1.34it/s] 32%|███▏      | 145/450 [01:52<04:01,  1.26it/s] 32%|███▏      | 146/450 [01:52<03:52,  1.31it/s] 33%|███▎      | 147/450 [01:53<03:46,  1.34it/s] 33%|███▎      | 148/450 [01:54<03:42,  1.36it/s] 33%|███▎      | 149/450 [01:55<03:57,  1.27it/s] 33%|███▎      | 150/450 [01:55<03:48,  1.31it/s]                                                  33%|███▎      | 150/450 [01:55<03:48,  1.31it/s] 34%|███▎      | 151/450 [01:56<03:44,  1.33it/s] 34%|███▍      | 152/450 [01:57<03:40,  1.35it/s] 34%|███▍      | 153/450 [01:58<03:55,  1.26it/s] 34%|███▍      | 154/450 [01:59<03:46,  1.30it/s] 34%|███▍      | 155/450 [01:59<03:40,  1.34it/s] 35%|███▍      | 156/450 [02:00<03:37,  1.35it/s] 35%|███▍      | 157/450 [02:01<03:51,  1.27it/s] 35%|███▌      | 158/450 [02:02<03:42,  1.31it/s] 35%|███▌      | 159/450 [02:02<03:36,  1.34it/s] 36%|███▌      | 160/450 [02:03<03:33,  1.36it/s]                                                  36%|███▌      | 160/450 [02:03<03:33,  1.36it/s]{'eval_loss': 0.3576285243034363, 'eval_runtime': 0.3587, 'eval_samples_per_second': 111.525, 'eval_steps_per_second': 13.941, 'epoch': 2.67}
外层迭代结束！
外层迭代结束！
{'loss': 0.368, 'learning_rate': 0.00023999999999999998, 'epoch': 2.89}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3897, 'learning_rate': 0.00023249999999999999, 'epoch': 3.11}
外层迭代结束！
外层迭代结束！
{'loss': 0.3702, 'learning_rate': 0.000225, 'epoch': 3.33}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.4095, 'learning_rate': 0.00021749999999999997, 'epoch': 3.56}

  0%|          | 0/5 [00:00<?, ?it/s][A
 60%|██████    | 3/5 [00:00<00:00, 21.78it/s][A                                                 
                                             [A 36%|███▌      | 160/450 [02:04<03:33,  1.36it/s]
100%|██████████| 5/5 [00:00<00:00, 21.78it/s][A
                                             [A 36%|███▌      | 161/450 [02:04<04:28,  1.08it/s] 36%|███▌      | 162/450 [02:05<04:10,  1.15it/s] 36%|███▌      | 163/450 [02:06<03:56,  1.22it/s] 36%|███▋      | 164/450 [02:07<03:45,  1.27it/s] 37%|███▋      | 165/450 [02:07<03:54,  1.22it/s] 37%|███▋      | 166/450 [02:08<03:46,  1.25it/s] 37%|███▋      | 167/450 [02:09<03:38,  1.29it/s] 37%|███▋      | 168/450 [02:10<03:33,  1.32it/s] 38%|███▊      | 169/450 [02:11<03:46,  1.24it/s] 38%|███▊      | 170/450 [02:11<03:37,  1.29it/s]                                                  38%|███▊      | 170/450 [02:11<03:37,  1.29it/s] 38%|███▊      | 171/450 [02:12<03:31,  1.32it/s] 38%|███▊      | 172/450 [02:13<03:27,  1.34it/s] 38%|███▊      | 173/450 [02:14<03:40,  1.26it/s] 39%|███▊      | 174/450 [02:14<03:34,  1.29it/s] 39%|███▉      | 175/450 [02:15<03:28,  1.32it/s] 39%|███▉      | 176/450 [02:16<03:24,  1.34it/s] 39%|███▉      | 177/450 [02:17<03:37,  1.25it/s] 40%|███▉      | 178/450 [02:17<03:28,  1.31it/s] 40%|███▉      | 179/450 [02:18<03:24,  1.32it/s] 40%|████      | 180/450 [02:19<03:21,  1.34it/s]                                                  40%|████      | 180/450 [02:19<03:21,  1.34it/s] 40%|████      | 181/450 [02:20<03:34,  1.25it/s] 40%|████      | 182/450 [02:20<03:26,  1.30it/s] 41%|████      | 183/450 [02:21<03:21,  1.32it/s] 41%|████      | 184/450 [02:22<03:17,  1.35it/s] 41%|████      | 185/450 [02:23<03:31,  1.25it/s] 41%|████▏     | 186/450 [02:23<03:23,  1.30it/s] 42%|████▏     | 187/450 [02:24<03:20,  1.31it/s] 42%|████▏     | 188/450 [02:25<03:17,  1.33it/s] 42%|████▏     | 189/450 [02:26<03:29,  1.25it/s] 42%|████▏     | 190/450 [02:27<03:21,  1.29it/s]                                                  42%|████▏     | 190/450 [02:27<03:21,  1.29it/s] 42%|████▏     | 191/450 [02:27<03:15,  1.33it/s] 43%|████▎     | 192/450 [02:28<03:11,  1.34it/s] 43%|████▎     | 193/450 [02:29<03:26,  1.25it/s] 43%|████▎     | 194/450 [02:30<03:22,  1.27it/s] 43%|████▎     | 195/450 [02:30<03:18,  1.29it/s] 44%|████▎     | 196/450 [02:31<03:11,  1.33it/s] 44%|████▍     | 197/450 [02:32<03:21,  1.25it/s] 44%|████▍     | 198/450 [02:33<03:15,  1.29it/s] 44%|████▍     | 199/450 [02:33<03:08,  1.33it/s] 44%|████▍     | 200/450 [02:34<03:06,  1.34it/s]                                                  44%|████▍     | 200/450 [02:34<03:06,  1.34it/s]{'eval_loss': 0.33439332246780396, 'eval_runtime': 0.3527, 'eval_samples_per_second': 113.395, 'eval_steps_per_second': 14.174, 'epoch': 3.56}
外层迭代结束！
外层迭代结束！
{'loss': 0.3805, 'learning_rate': 0.00020999999999999998, 'epoch': 3.78}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.348, 'learning_rate': 0.0002025, 'epoch': 4.0}
外层迭代结束！
外层迭代结束！
{'loss': 0.3795, 'learning_rate': 0.000195, 'epoch': 4.22}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3545, 'learning_rate': 0.00018749999999999998, 'epoch': 4.44}

  0%|          | 0/5 [00:00<?, ?it/s][A
 60%|██████    | 3/5 [00:00<00:00, 20.26it/s][A                                                 
                                             [A 44%|████▍     | 200/450 [02:35<03:06,  1.34it/s]
100%|██████████| 5/5 [00:00<00:00, 20.26it/s][A
                                             [A 45%|████▍     | 201/450 [02:36<03:54,  1.06it/s] 45%|████▍     | 202/450 [02:36<03:37,  1.14it/s] 45%|████▌     | 203/450 [02:37<03:25,  1.20it/s] 45%|████▌     | 204/450 [02:38<03:15,  1.26it/s] 46%|████▌     | 205/450 [02:39<03:25,  1.19it/s] 46%|████▌     | 206/450 [02:39<03:13,  1.26it/s] 46%|████▌     | 207/450 [02:40<03:08,  1.29it/s] 46%|████▌     | 208/450 [02:41<03:05,  1.30it/s] 46%|████▋     | 209/450 [02:42<03:15,  1.23it/s] 47%|████▋     | 210/450 [02:43<03:08,  1.27it/s]                                                  47%|████▋     | 210/450 [02:43<03:08,  1.27it/s] 47%|████▋     | 211/450 [02:43<03:02,  1.31it/s] 47%|████▋     | 212/450 [02:44<02:58,  1.33it/s] 47%|████▋     | 213/450 [02:45<03:10,  1.24it/s] 48%|████▊     | 214/450 [02:46<03:01,  1.30it/s] 48%|████▊     | 215/450 [02:46<02:58,  1.32it/s] 48%|████▊     | 216/450 [02:47<02:55,  1.34it/s] 48%|████▊     | 217/450 [02:48<03:05,  1.26it/s] 48%|████▊     | 218/450 [02:49<02:59,  1.29it/s] 49%|████▊     | 219/450 [02:49<02:53,  1.33it/s] 49%|████▉     | 220/450 [02:50<02:50,  1.35it/s]                                                  49%|████▉     | 220/450 [02:50<02:50,  1.35it/s] 49%|████▉     | 221/450 [02:51<03:02,  1.26it/s] 49%|████▉     | 222/450 [02:52<02:54,  1.30it/s] 50%|████▉     | 223/450 [02:52<02:50,  1.33it/s] 50%|████▉     | 224/450 [02:53<02:46,  1.36it/s] 50%|█████     | 225/450 [02:54<02:56,  1.27it/s] 50%|█████     | 226/450 [02:55<02:51,  1.31it/s] 50%|█████     | 227/450 [02:55<02:45,  1.35it/s] 51%|█████     | 228/450 [02:56<02:43,  1.36it/s] 51%|█████     | 229/450 [02:57<02:53,  1.27it/s] 51%|█████     | 230/450 [02:58<02:47,  1.32it/s]                                                  51%|█████     | 230/450 [02:58<02:47,  1.32it/s] 51%|█████▏    | 231/450 [02:58<02:43,  1.34it/s] 52%|█████▏    | 232/450 [02:59<02:40,  1.35it/s] 52%|█████▏    | 233/450 [03:00<02:51,  1.26it/s] 52%|█████▏    | 234/450 [03:01<02:47,  1.29it/s] 52%|█████▏    | 235/450 [03:02<02:41,  1.33it/s] 52%|█████▏    | 236/450 [03:02<02:38,  1.35it/s] 53%|█████▎    | 237/450 [03:03<02:49,  1.26it/s] 53%|█████▎    | 238/450 [03:04<02:42,  1.30it/s] 53%|█████▎    | 239/450 [03:05<02:39,  1.32it/s] 53%|█████▎    | 240/450 [03:05<02:36,  1.35it/s]                                                  53%|█████▎    | 240/450 [03:06<02:36,  1.35it/s]{'eval_loss': 0.3222760260105133, 'eval_runtime': 0.3657, 'eval_samples_per_second': 109.381, 'eval_steps_per_second': 13.673, 'epoch': 4.44}
外层迭代结束！
外层迭代结束！
{'loss': 0.3428, 'learning_rate': 0.00017999999999999998, 'epoch': 4.67}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3332, 'learning_rate': 0.00017249999999999996, 'epoch': 4.89}
外层迭代结束！
外层迭代结束！
{'loss': 0.3589, 'learning_rate': 0.000165, 'epoch': 5.11}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3766, 'learning_rate': 0.00015749999999999998, 'epoch': 5.33}

  0%|          | 0/5 [00:00<?, ?it/s][A
 60%|██████    | 3/5 [00:00<00:00, 21.71it/s][A                                                 
                                             [A 53%|█████▎    | 240/450 [03:06<02:36,  1.35it/s]
100%|██████████| 5/5 [00:00<00:00, 21.71it/s][A
                                             [A 54%|█████▎    | 241/450 [03:07<03:15,  1.07it/s] 54%|█████▍    | 242/450 [03:07<03:01,  1.15it/s] 54%|█████▍    | 243/450 [03:08<02:51,  1.21it/s] 54%|█████▍    | 244/450 [03:09<02:44,  1.25it/s] 54%|█████▍    | 245/450 [03:10<02:50,  1.20it/s] 55%|█████▍    | 246/450 [03:11<02:42,  1.25it/s] 55%|█████▍    | 247/450 [03:11<02:37,  1.29it/s] 55%|█████▌    | 248/450 [03:12<02:33,  1.32it/s] 55%|█████▌    | 249/450 [03:13<02:42,  1.24it/s] 56%|█████▌    | 250/450 [03:14<02:34,  1.30it/s]                                                  56%|█████▌    | 250/450 [03:14<02:34,  1.30it/s] 56%|█████▌    | 251/450 [03:14<02:32,  1.31it/s] 56%|█████▌    | 252/450 [03:15<02:30,  1.32it/s] 56%|█████▌    | 253/450 [03:16<02:39,  1.24it/s] 56%|█████▋    | 254/450 [03:17<02:33,  1.28it/s] 57%|█████▋    | 255/450 [03:17<02:31,  1.29it/s] 57%|█████▋    | 256/450 [03:18<02:30,  1.29it/s] 57%|█████▋    | 257/450 [03:19<02:40,  1.20it/s] 57%|█████▋    | 258/450 [03:20<02:32,  1.26it/s] 58%|█████▊    | 259/450 [03:21<02:27,  1.30it/s] 58%|█████▊    | 260/450 [03:21<02:23,  1.33it/s]                                                  58%|█████▊    | 260/450 [03:22<02:23,  1.33it/s] 58%|█████▊    | 261/450 [03:22<02:32,  1.24it/s] 58%|█████▊    | 262/450 [03:23<02:28,  1.27it/s] 58%|█████▊    | 263/450 [03:24<02:22,  1.32it/s] 59%|█████▊    | 264/450 [03:24<02:20,  1.33it/s] 59%|█████▉    | 265/450 [03:25<02:27,  1.25it/s] 59%|█████▉    | 266/450 [03:26<02:22,  1.29it/s] 59%|█████▉    | 267/450 [03:27<02:19,  1.31it/s] 60%|█████▉    | 268/450 [03:27<02:15,  1.35it/s] 60%|█████▉    | 269/450 [03:28<02:23,  1.26it/s] 60%|██████    | 270/450 [03:29<02:18,  1.30it/s]                                                  60%|██████    | 270/450 [03:29<02:18,  1.30it/s] 60%|██████    | 271/450 [03:30<02:14,  1.33it/s] 60%|██████    | 272/450 [03:31<02:12,  1.35it/s] 61%|██████    | 273/450 [03:31<02:20,  1.26it/s] 61%|██████    | 274/450 [03:32<02:15,  1.29it/s] 61%|██████    | 275/450 [03:33<02:13,  1.31it/s] 61%|██████▏   | 276/450 [03:34<02:09,  1.34it/s] 62%|██████▏   | 277/450 [03:35<02:18,  1.25it/s] 62%|██████▏   | 278/450 [03:35<02:12,  1.30it/s] 62%|██████▏   | 279/450 [03:36<02:09,  1.32it/s] 62%|██████▏   | 280/450 [03:37<02:06,  1.35it/s]                                                  62%|██████▏   | 280/450 [03:37<02:06,  1.35it/s]{'eval_loss': 0.31456929445266724, 'eval_runtime': 0.3647, 'eval_samples_per_second': 109.685, 'eval_steps_per_second': 13.711, 'epoch': 5.33}
外层迭代结束！
外层迭代结束！
{'loss': 0.3768, 'learning_rate': 0.00015, 'epoch': 5.56}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3567, 'learning_rate': 0.0001425, 'epoch': 5.78}
外层迭代结束！
外层迭代结束！
{'loss': 0.3189, 'learning_rate': 0.000135, 'epoch': 6.0}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3586, 'learning_rate': 0.00012749999999999998, 'epoch': 6.22}

  0%|          | 0/5 [00:00<?, ?it/s][A
 60%|██████    | 3/5 [00:00<00:00, 21.80it/s][A                                                 
                                             [A 62%|██████▏   | 280/450 [03:37<02:06,  1.35it/s]
100%|██████████| 5/5 [00:00<00:00, 21.80it/s][A
                                             [A 62%|██████▏   | 281/450 [03:38<02:38,  1.06it/s] 63%|██████▎   | 282/450 [03:39<02:27,  1.14it/s] 63%|██████▎   | 283/450 [03:40<02:17,  1.22it/s] 63%|██████▎   | 284/450 [03:40<02:12,  1.26it/s] 63%|██████▎   | 285/450 [03:41<02:17,  1.20it/s] 64%|██████▎   | 286/450 [03:42<02:10,  1.25it/s] 64%|██████▍   | 287/450 [03:43<02:05,  1.29it/s] 64%|██████▍   | 288/450 [03:43<02:02,  1.33it/s] 64%|██████▍   | 289/450 [03:44<02:08,  1.25it/s] 64%|██████▍   | 290/450 [03:45<02:03,  1.29it/s]                                                  64%|██████▍   | 290/450 [03:45<02:03,  1.29it/s] 65%|██████▍   | 291/450 [03:46<01:59,  1.33it/s] 65%|██████▍   | 292/450 [03:46<01:57,  1.34it/s] 65%|██████▌   | 293/450 [03:47<02:04,  1.26it/s] 65%|██████▌   | 294/450 [03:48<02:00,  1.30it/s] 66%|██████▌   | 295/450 [03:49<01:56,  1.33it/s] 66%|██████▌   | 296/450 [03:49<01:53,  1.36it/s] 66%|██████▌   | 297/450 [03:50<02:01,  1.26it/s] 66%|██████▌   | 298/450 [03:51<01:57,  1.29it/s] 66%|██████▋   | 299/450 [03:52<01:53,  1.33it/s] 67%|██████▋   | 300/450 [03:52<01:51,  1.34it/s]                                                  67%|██████▋   | 300/450 [03:53<01:51,  1.34it/s] 67%|██████▋   | 301/450 [03:53<01:58,  1.26it/s] 67%|██████▋   | 302/450 [03:54<01:54,  1.30it/s] 67%|██████▋   | 303/450 [03:55<01:51,  1.32it/s] 68%|██████▊   | 304/450 [03:56<01:47,  1.36it/s] 68%|██████▊   | 305/450 [03:56<01:54,  1.26it/s] 68%|██████▊   | 306/450 [03:57<01:50,  1.30it/s] 68%|██████▊   | 307/450 [03:58<01:48,  1.32it/s] 68%|██████▊   | 308/450 [03:59<01:46,  1.34it/s] 69%|██████▊   | 309/450 [04:00<01:51,  1.26it/s] 69%|██████▉   | 310/450 [04:00<01:48,  1.29it/s]                                                  69%|██████▉   | 310/450 [04:00<01:48,  1.29it/s] 69%|██████▉   | 311/450 [04:01<01:45,  1.32it/s] 69%|██████▉   | 312/450 [04:02<01:41,  1.36it/s] 70%|██████▉   | 313/450 [04:03<01:48,  1.26it/s] 70%|██████▉   | 314/450 [04:03<01:44,  1.30it/s] 70%|███████   | 315/450 [04:04<01:41,  1.33it/s] 70%|███████   | 316/450 [04:05<01:38,  1.36it/s] 70%|███████   | 317/450 [04:06<01:44,  1.27it/s] 71%|███████   | 318/450 [04:06<01:40,  1.31it/s] 71%|███████   | 319/450 [04:07<01:38,  1.33it/s] 71%|███████   | 320/450 [04:08<01:34,  1.37it/s]                                                  71%|███████   | 320/450 [04:08<01:34,  1.37it/s]{'eval_loss': 0.26679569482803345, 'eval_runtime': 0.3501, 'eval_samples_per_second': 114.264, 'eval_steps_per_second': 14.283, 'epoch': 6.22}
外层迭代结束！
外层迭代结束！
{'loss': 0.2929, 'learning_rate': 0.00011999999999999999, 'epoch': 6.44}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.328, 'learning_rate': 0.0001125, 'epoch': 6.67}
外层迭代结束！
外层迭代结束！
{'loss': 0.3026, 'learning_rate': 0.00010499999999999999, 'epoch': 6.89}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3121, 'learning_rate': 9.75e-05, 'epoch': 7.11}

  0%|          | 0/5 [00:00<?, ?it/s][A
 60%|██████    | 3/5 [00:00<00:00, 21.43it/s][A                                                 
                                             [A 71%|███████   | 320/450 [04:08<01:34,  1.37it/s]
100%|██████████| 5/5 [00:00<00:00, 21.43it/s][A
                                             [A 71%|███████▏  | 321/450 [04:09<02:00,  1.07it/s] 72%|███████▏  | 322/450 [04:10<01:49,  1.16it/s] 72%|███████▏  | 323/450 [04:11<01:44,  1.22it/s] 72%|███████▏  | 324/450 [04:11<01:40,  1.26it/s] 72%|███████▏  | 325/450 [04:12<01:43,  1.20it/s] 72%|███████▏  | 326/450 [04:13<01:39,  1.24it/s] 73%|███████▎  | 327/450 [04:14<01:34,  1.30it/s] 73%|███████▎  | 328/450 [04:14<01:32,  1.31it/s] 73%|███████▎  | 329/450 [04:15<01:38,  1.23it/s] 73%|███████▎  | 330/450 [04:16<01:33,  1.28it/s]                                                  73%|███████▎  | 330/450 [04:16<01:33,  1.28it/s] 74%|███████▎  | 331/450 [04:17<01:30,  1.32it/s] 74%|███████▍  | 332/450 [04:17<01:27,  1.35it/s] 74%|███████▍  | 333/450 [04:18<01:33,  1.26it/s] 74%|███████▍  | 334/450 [04:19<01:29,  1.29it/s] 74%|███████▍  | 335/450 [04:20<01:25,  1.34it/s] 75%|███████▍  | 336/450 [04:20<01:24,  1.35it/s] 75%|███████▍  | 337/450 [04:21<01:29,  1.26it/s] 75%|███████▌  | 338/450 [04:22<01:25,  1.30it/s] 75%|███████▌  | 339/450 [04:23<01:23,  1.33it/s] 76%|███████▌  | 340/450 [04:23<01:21,  1.35it/s]                                                  76%|███████▌  | 340/450 [04:24<01:21,  1.35it/s] 76%|███████▌  | 341/450 [04:24<01:26,  1.26it/s] 76%|███████▌  | 342/450 [04:25<01:23,  1.30it/s] 76%|███████▌  | 343/450 [04:26<01:19,  1.34it/s] 76%|███████▋  | 344/450 [04:27<01:18,  1.36it/s] 77%|███████▋  | 345/450 [04:27<01:22,  1.27it/s] 77%|███████▋  | 346/450 [04:28<01:19,  1.31it/s] 77%|███████▋  | 347/450 [04:29<01:16,  1.34it/s] 77%|███████▋  | 348/450 [04:30<01:14,  1.36it/s] 78%|███████▊  | 349/450 [04:30<01:18,  1.28it/s] 78%|███████▊  | 350/450 [04:31<01:16,  1.31it/s]                                                  78%|███████▊  | 350/450 [04:31<01:16,  1.31it/s] 78%|███████▊  | 351/450 [04:32<01:13,  1.35it/s] 78%|███████▊  | 352/450 [04:33<01:12,  1.36it/s] 78%|███████▊  | 353/450 [04:33<01:16,  1.27it/s] 79%|███████▊  | 354/450 [04:34<01:13,  1.31it/s] 79%|███████▉  | 355/450 [04:35<01:10,  1.36it/s] 79%|███████▉  | 356/450 [04:36<01:07,  1.38it/s] 79%|███████▉  | 357/450 [04:36<01:11,  1.29it/s] 80%|███████▉  | 358/450 [04:37<01:08,  1.34it/s] 80%|███████▉  | 359/450 [04:38<01:06,  1.36it/s] 80%|████████  | 360/450 [04:39<01:04,  1.39it/s]                                                  80%|████████  | 360/450 [04:39<01:04,  1.39it/s]{'eval_loss': 0.20060022175312042, 'eval_runtime': 0.3591, 'eval_samples_per_second': 111.376, 'eval_steps_per_second': 13.922, 'epoch': 7.11}
外层迭代结束！
外层迭代结束！
{'loss': 0.2832, 'learning_rate': 8.999999999999999e-05, 'epoch': 7.33}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3152, 'learning_rate': 8.25e-05, 'epoch': 7.56}
外层迭代结束！
外层迭代结束！
{'loss': 0.2919, 'learning_rate': 7.5e-05, 'epoch': 7.78}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2988, 'learning_rate': 6.75e-05, 'epoch': 8.0}

  0%|          | 0/5 [00:00<?, ?it/s][A
 60%|██████    | 3/5 [00:00<00:00, 21.56it/s][A                                                 
                                             [A 80%|████████  | 360/450 [04:39<01:04,  1.39it/s]
100%|██████████| 5/5 [00:00<00:00, 21.56it/s][A
                                             [A 80%|████████  | 361/450 [04:40<01:21,  1.10it/s] 80%|████████  | 362/450 [04:41<01:14,  1.18it/s] 81%|████████  | 363/450 [04:41<01:09,  1.25it/s] 81%|████████  | 364/450 [04:42<01:06,  1.30it/s] 81%|████████  | 365/450 [04:43<01:08,  1.24it/s] 81%|████████▏ | 366/450 [04:44<01:04,  1.29it/s] 82%|████████▏ | 367/450 [04:44<01:02,  1.33it/s] 82%|████████▏ | 368/450 [04:45<00:59,  1.37it/s] 82%|████████▏ | 369/450 [04:46<01:02,  1.29it/s] 82%|████████▏ | 370/450 [04:47<01:00,  1.33it/s]                                                  82%|████████▏ | 370/450 [04:47<01:00,  1.33it/s] 82%|████████▏ | 371/450 [04:47<00:58,  1.35it/s] 83%|████████▎ | 372/450 [04:48<00:56,  1.38it/s] 83%|████████▎ | 373/450 [04:49<00:59,  1.29it/s] 83%|████████▎ | 374/450 [04:50<00:57,  1.33it/s] 83%|████████▎ | 375/450 [04:50<00:54,  1.37it/s] 84%|████████▎ | 376/450 [04:51<00:53,  1.39it/s] 84%|████████▍ | 377/450 [04:52<00:56,  1.29it/s] 84%|████████▍ | 378/450 [04:53<00:54,  1.32it/s] 84%|████████▍ | 379/450 [04:53<00:52,  1.36it/s] 84%|████████▍ | 380/450 [04:54<00:50,  1.38it/s]                                                  84%|████████▍ | 380/450 [04:54<00:50,  1.38it/s] 85%|████████▍ | 381/450 [04:55<00:53,  1.28it/s] 85%|████████▍ | 382/450 [04:55<00:51,  1.33it/s] 85%|████████▌ | 383/450 [04:56<00:49,  1.36it/s] 85%|████████▌ | 384/450 [04:57<00:47,  1.38it/s] 86%|████████▌ | 385/450 [04:58<00:50,  1.29it/s] 86%|████████▌ | 386/450 [04:58<00:48,  1.32it/s] 86%|████████▌ | 387/450 [04:59<00:46,  1.35it/s] 86%|████████▌ | 388/450 [05:00<00:45,  1.37it/s] 86%|████████▋ | 389/450 [05:01<00:47,  1.29it/s] 87%|████████▋ | 390/450 [05:01<00:45,  1.32it/s]                                                  87%|████████▋ | 390/450 [05:01<00:45,  1.32it/s] 87%|████████▋ | 391/450 [05:02<00:43,  1.35it/s] 87%|████████▋ | 392/450 [05:03<00:42,  1.36it/s] 87%|████████▋ | 393/450 [05:04<00:44,  1.27it/s] 88%|████████▊ | 394/450 [05:05<00:42,  1.30it/s] 88%|████████▊ | 395/450 [05:05<00:41,  1.33it/s] 88%|████████▊ | 396/450 [05:06<00:39,  1.36it/s] 88%|████████▊ | 397/450 [05:07<00:41,  1.26it/s] 88%|████████▊ | 398/450 [05:08<00:39,  1.30it/s] 89%|████████▊ | 399/450 [05:08<00:38,  1.33it/s] 89%|████████▉ | 400/450 [05:09<00:37,  1.35it/s]                                                  89%|████████▉ | 400/450 [05:09<00:37,  1.35it/s]{'eval_loss': 0.17632544040679932, 'eval_runtime': 0.3486, 'eval_samples_per_second': 114.733, 'eval_steps_per_second': 14.342, 'epoch': 8.0}
外层迭代结束！
外层迭代结束！
{'loss': 0.2907, 'learning_rate': 5.9999999999999995e-05, 'epoch': 8.22}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2711, 'learning_rate': 5.2499999999999995e-05, 'epoch': 8.44}
外层迭代结束！
外层迭代结束！
{'loss': 0.3461, 'learning_rate': 4.4999999999999996e-05, 'epoch': 8.67}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2875, 'learning_rate': 3.75e-05, 'epoch': 8.89}

  0%|          | 0/5 [00:00<?, ?it/s][A
 60%|██████    | 3/5 [00:00<00:00, 21.63it/s][A                                                 
                                             [A 89%|████████▉ | 400/450 [05:10<00:37,  1.35it/s]
100%|██████████| 5/5 [00:00<00:00, 21.63it/s][A
                                             [A 89%|████████▉ | 401/450 [05:10<00:46,  1.07it/s] 89%|████████▉ | 402/450 [05:11<00:42,  1.14it/s] 90%|████████▉ | 403/450 [05:12<00:38,  1.21it/s] 90%|████████▉ | 404/450 [05:13<00:36,  1.26it/s] 90%|█████████ | 405/450 [05:13<00:37,  1.21it/s] 90%|█████████ | 406/450 [05:14<00:35,  1.25it/s] 90%|█████████ | 407/450 [05:15<00:33,  1.29it/s] 91%|█████████ | 408/450 [05:16<00:31,  1.33it/s] 91%|█████████ | 409/450 [05:17<00:32,  1.24it/s] 91%|█████████ | 410/450 [05:17<00:31,  1.29it/s]                                                  91%|█████████ | 410/450 [05:17<00:31,  1.29it/s] 91%|█████████▏| 411/450 [05:18<00:29,  1.32it/s] 92%|█████████▏| 412/450 [05:19<00:28,  1.34it/s] 92%|█████████▏| 413/450 [05:20<00:29,  1.26it/s] 92%|█████████▏| 414/450 [05:20<00:27,  1.30it/s] 92%|█████████▏| 415/450 [05:21<00:26,  1.33it/s] 92%|█████████▏| 416/450 [05:22<00:25,  1.35it/s] 93%|█████████▎| 417/450 [05:23<00:26,  1.26it/s] 93%|█████████▎| 418/450 [05:23<00:24,  1.30it/s] 93%|█████████▎| 419/450 [05:24<00:23,  1.33it/s] 93%|█████████▎| 420/450 [05:25<00:22,  1.35it/s]                                                  93%|█████████▎| 420/450 [05:25<00:22,  1.35it/s] 94%|█████████▎| 421/450 [05:26<00:22,  1.27it/s] 94%|█████████▍| 422/450 [05:26<00:21,  1.30it/s] 94%|█████████▍| 423/450 [05:27<00:20,  1.33it/s] 94%|█████████▍| 424/450 [05:28<00:19,  1.36it/s] 94%|█████████▍| 425/450 [05:29<00:19,  1.26it/s] 95%|█████████▍| 426/450 [05:29<00:18,  1.30it/s] 95%|█████████▍| 427/450 [05:30<00:17,  1.34it/s] 95%|█████████▌| 428/450 [05:31<00:16,  1.36it/s] 95%|█████████▌| 429/450 [05:32<00:16,  1.27it/s] 96%|█████████▌| 430/450 [05:33<00:15,  1.30it/s]                                                  96%|█████████▌| 430/450 [05:33<00:15,  1.30it/s] 96%|█████████▌| 431/450 [05:33<00:14,  1.33it/s] 96%|█████████▌| 432/450 [05:34<00:13,  1.35it/s] 96%|█████████▌| 433/450 [05:35<00:13,  1.26it/s] 96%|█████████▋| 434/450 [05:36<00:12,  1.30it/s] 97%|█████████▋| 435/450 [05:36<00:11,  1.33it/s] 97%|█████████▋| 436/450 [05:37<00:10,  1.35it/s] 97%|█████████▋| 437/450 [05:38<00:10,  1.27it/s] 97%|█████████▋| 438/450 [05:39<00:09,  1.30it/s] 98%|█████████▊| 439/450 [05:39<00:08,  1.33it/s] 98%|█████████▊| 440/450 [05:40<00:07,  1.36it/s]                                                  98%|█████████▊| 440/450 [05:40<00:07,  1.36it/s]{'eval_loss': 0.1787700653076172, 'eval_runtime': 0.3493, 'eval_samples_per_second': 114.525, 'eval_steps_per_second': 14.316, 'epoch': 8.89}
外层迭代结束！
外层迭代结束！
{'loss': 0.2551, 'learning_rate': 2.9999999999999997e-05, 'epoch': 9.11}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2606, 'learning_rate': 2.2499999999999998e-05, 'epoch': 9.33}
外层迭代结束！
外层迭代结束！
{'loss': 0.2837, 'learning_rate': 1.4999999999999999e-05, 'epoch': 9.56}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.245, 'learning_rate': 7.499999999999999e-06, 'epoch': 9.78}

  0%|          | 0/5 [00:00<?, ?it/s][A
 60%|██████    | 3/5 [00:00<00:00, 21.29it/s][A                                                 
                                             [A 98%|█████████▊| 440/450 [05:41<00:07,  1.36it/s]
100%|██████████| 5/5 [00:00<00:00, 21.29it/s][A
                                             [A 98%|█████████▊| 441/450 [05:41<00:08,  1.07it/s] 98%|█████████▊| 442/450 [05:42<00:06,  1.15it/s] 98%|█████████▊| 443/450 [05:43<00:05,  1.21it/s] 99%|█████████▊| 444/450 [05:44<00:04,  1.26it/s] 99%|█████████▉| 445/450 [05:44<00:04,  1.20it/s] 99%|█████████▉| 446/450 [05:45<00:03,  1.26it/s] 99%|█████████▉| 447/450 [05:46<00:02,  1.31it/s]100%|█████████▉| 448/450 [05:47<00:01,  1.33it/s]100%|█████████▉| 449/450 [05:48<00:00,  1.25it/s]100%|██████████| 450/450 [05:48<00:00,  1.30it/s]                                                 100%|██████████| 450/450 [05:48<00:00,  1.30it/s]There were missing keys in the checkpoint model loaded: ['base_model.model.shared.weight', 'base_model.model.encoder.embed_tokens.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.encoder.block.0.layer.0.layer_norm.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.0.layer.1.layer_norm.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.1.layer.0.layer_norm.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.1.layer.1.layer_norm.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.2.layer.0.layer_norm.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.2.layer.1.layer_norm.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.3.layer.0.layer_norm.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.3.layer.1.layer_norm.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.4.layer.0.layer_norm.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.4.layer.1.layer_norm.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.5.layer.0.layer_norm.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.5.layer.1.layer_norm.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.6.layer.0.layer_norm.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.6.layer.1.layer_norm.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.7.layer.0.layer_norm.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.7.layer.1.layer_norm.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.8.layer.0.layer_norm.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.8.layer.1.layer_norm.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.9.layer.0.layer_norm.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.9.layer.1.layer_norm.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.10.layer.0.layer_norm.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.10.layer.1.layer_norm.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.11.layer.0.layer_norm.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.11.layer.1.layer_norm.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.12.layer.0.layer_norm.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.12.layer.1.layer_norm.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.13.layer.0.layer_norm.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.13.layer.1.layer_norm.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.14.layer.0.layer_norm.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.14.layer.1.layer_norm.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.15.layer.0.layer_norm.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.15.layer.1.layer_norm.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.16.layer.0.layer_norm.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.16.layer.1.layer_norm.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.17.layer.0.layer_norm.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.17.layer.1.layer_norm.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.18.layer.0.layer_norm.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.18.layer.1.layer_norm.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.19.layer.0.layer_norm.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.19.layer.1.layer_norm.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.20.layer.0.layer_norm.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.20.layer.1.layer_norm.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.21.layer.0.layer_norm.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.21.layer.1.layer_norm.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.22.layer.0.layer_norm.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.22.layer.1.layer_norm.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.23.layer.0.layer_norm.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.23.layer.1.layer_norm.weight', 'base_model.model.encoder.final_layer_norm.weight', 'base_model.model.decoder.embed_tokens.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.decoder.block.0.layer.0.layer_norm.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.0.layer.1.layer_norm.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.0.layer.2.layer_norm.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.1.layer.0.layer_norm.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.1.layer.1.layer_norm.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.1.layer.2.layer_norm.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.2.layer.0.layer_norm.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.2.layer.1.layer_norm.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.2.layer.2.layer_norm.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.3.layer.0.layer_norm.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.3.layer.1.layer_norm.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.3.layer.2.layer_norm.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.4.layer.0.layer_norm.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.4.layer.1.layer_norm.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.4.layer.2.layer_norm.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.5.layer.0.layer_norm.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.5.layer.1.layer_norm.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.5.layer.2.layer_norm.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.6.layer.0.layer_norm.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.6.layer.1.layer_norm.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.6.layer.2.layer_norm.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.7.layer.0.layer_norm.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.7.layer.1.layer_norm.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.7.layer.2.layer_norm.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.8.layer.0.layer_norm.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.8.layer.1.layer_norm.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.8.layer.2.layer_norm.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.9.layer.0.layer_norm.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.9.layer.1.layer_norm.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.9.layer.2.layer_norm.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.10.layer.0.layer_norm.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.10.layer.1.layer_norm.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.10.layer.2.layer_norm.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.11.layer.0.layer_norm.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.11.layer.1.layer_norm.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.11.layer.2.layer_norm.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.12.layer.0.layer_norm.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.12.layer.1.layer_norm.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.12.layer.2.layer_norm.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.13.layer.0.layer_norm.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.13.layer.1.layer_norm.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.13.layer.2.layer_norm.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.14.layer.0.layer_norm.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.14.layer.1.layer_norm.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.14.layer.2.layer_norm.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.15.layer.0.layer_norm.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.15.layer.1.layer_norm.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.15.layer.2.layer_norm.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.16.layer.0.layer_norm.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.16.layer.1.layer_norm.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.16.layer.2.layer_norm.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.17.layer.0.layer_norm.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.17.layer.1.layer_norm.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.17.layer.2.layer_norm.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.18.layer.0.layer_norm.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.18.layer.1.layer_norm.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.18.layer.2.layer_norm.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.19.layer.0.layer_norm.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.19.layer.1.layer_norm.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.19.layer.2.layer_norm.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.20.layer.0.layer_norm.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.20.layer.1.layer_norm.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.20.layer.2.layer_norm.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.21.layer.0.layer_norm.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.21.layer.1.layer_norm.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.21.layer.2.layer_norm.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.22.layer.0.layer_norm.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.22.layer.1.layer_norm.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.22.layer.2.layer_norm.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.23.layer.0.layer_norm.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.23.layer.1.layer_norm.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.23.layer.2.layer_norm.weight', 'base_model.model.decoder.final_layer_norm.weight', 'base_model.model.lm_head.weight'].
There were unexpected keys in the checkpoint model loaded: ['base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.weight'].
                                                 100%|██████████| 450/450 [05:48<00:00,  1.30it/s]100%|██████████| 450/450 [05:48<00:00,  1.29it/s]
{'eval_loss': 0.1709907054901123, 'eval_runtime': 0.3571, 'eval_samples_per_second': 112.002, 'eval_steps_per_second': 14.0, 'epoch': 9.78}
外层迭代结束！
外层迭代结束！
{'loss': 0.2791, 'learning_rate': 0.0, 'epoch': 10.0}
{'train_runtime': 348.8898, 'train_samples_per_second': 10.318, 'train_steps_per_second': 1.29, 'train_loss': 0.5814346615473429, 'epoch': 10.0}

 If there's a warning about missing keys above, please disregard :)
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 8
micro_batch_size: 2
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: qqp... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/4-qqp
current data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 842.74it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 1005.35it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 455.75it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 785.16it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 921.42it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Loading cached split indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-f5ed842584b86aa9.arrow and /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-4a955c721c6ef99e.arrow
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-76794074a9c389d3.arrow
Loading cached processed dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-aa7b9de312b74ce6.arrow
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-9c4b977ad1bc5fd5.arrow
总样本数：400, 选择的样本数量：8
lora_weights: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/3-copa

pre-trained model's BOS EOS and PAD token id: None 1 0  => It should be 1,2,none
continual fine tune lora!
trainable params: 2359296 || all params: 740027392 || trainable%: 0.31881198257050464
训练数据总量：900
验证数据总量：100
Map:   0%|          | 0/100 [00:00<?, ? examples/s]/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3597: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  "`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your "
                                                   Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-e82c0e8ff8c2624d.arrow
Loading cached processed dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-dadb16c085e62834.arrow
memory data loader 2
  0%|          | 0/1120 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/1120 [00:01<28:17,  1.52s/it]  0%|          | 2/1120 [00:02<20:16,  1.09s/it]  0%|          | 3/1120 [00:03<17:40,  1.05it/s]  0%|          | 4/1120 [00:03<16:25,  1.13it/s]  0%|          | 5/1120 [00:04<17:24,  1.07it/s]  1%|          | 6/1120 [00:05<16:10,  1.15it/s]  1%|          | 7/1120 [00:06<15:32,  1.19it/s]  1%|          | 8/1120 [00:07<15:06,  1.23it/s]  1%|          | 9/1120 [00:08<16:08,  1.15it/s]  1%|          | 10/1120 [00:08<15:34,  1.19it/s]                                                   1%|          | 10/1120 [00:08<15:34,  1.19it/s]  1%|          | 11/1120 [00:09<15:10,  1.22it/s]  1%|          | 12/1120 [00:10<14:59,  1.23it/s]  1%|          | 13/1120 [00:11<15:59,  1.15it/s]  1%|▏         | 14/1120 [00:12<15:27,  1.19it/s]  1%|▏         | 15/1120 [00:13<15:03,  1.22it/s]  1%|▏         | 16/1120 [00:13<14:44,  1.25it/s]  2%|▏         | 17/1120 [00:14<15:53,  1.16it/s]  2%|▏         | 18/1120 [00:15<15:23,  1.19it/s]  2%|▏         | 19/1120 [00:16<15:06,  1.21it/s]  2%|▏         | 20/1120 [00:17<14:55,  1.23it/s]                                                   2%|▏         | 20/1120 [00:17<14:55,  1.23it/s]  2%|▏         | 21/1120 [00:18<15:52,  1.15it/s]  2%|▏         | 22/1120 [00:18<15:22,  1.19it/s]  2%|▏         | 23/1120 [00:19<14:59,  1.22it/s]  2%|▏         | 24/1120 [00:20<14:48,  1.23it/s]  2%|▏         | 25/1120 [00:21<15:47,  1.16it/s]  2%|▏         | 26/1120 [00:22<15:20,  1.19it/s]  2%|▏         | 27/1120 [00:23<14:59,  1.22it/s]  2%|▎         | 28/1120 [00:23<14:38,  1.24it/s]  3%|▎         | 29/1120 [00:24<15:42,  1.16it/s]  3%|▎         | 30/1120 [00:25<15:17,  1.19it/s]                                                   3%|▎         | 30/1120 [00:25<15:17,  1.19it/s]  3%|▎         | 31/1120 [00:26<14:59,  1.21it/s]  3%|▎         | 32/1120 [00:27<14:47,  1.23it/s]  3%|▎         | 33/1120 [00:28<16:09,  1.12it/s]  3%|▎         | 34/1120 [00:29<15:42,  1.15it/s]  3%|▎         | 35/1120 [00:29<15:22,  1.18it/s]  3%|▎         | 36/1120 [00:30<15:20,  1.18it/s]  3%|▎         | 37/1120 [00:31<16:16,  1.11it/s]  3%|▎         | 38/1120 [00:32<15:33,  1.16it/s]  3%|▎         | 39/1120 [00:33<15:07,  1.19it/s]  4%|▎         | 40/1120 [00:34<14:53,  1.21it/s]                                                   4%|▎         | 40/1120 [00:34<14:53,  1.21it/s]外层迭代结束！
外层迭代结束！
{'loss': 2.7064, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.09}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.9323, 'learning_rate': 0.00011999999999999999, 'epoch': 0.18}
外层迭代结束！
外层迭代结束！
{'loss': 0.2601, 'learning_rate': 0.00017999999999999998, 'epoch': 0.27}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3263, 'learning_rate': 0.00023999999999999998, 'epoch': 0.36}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.92it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 16.22it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 14.90it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 14.17it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 14.01it/s][A
100%|██████████| 13/13 [00:00<00:00, 13.88it/s][A                                                 
                                               [A  4%|▎         | 40/1120 [00:35<14:53,  1.21it/s]
100%|██████████| 13/13 [00:00<00:00, 13.88it/s][A
                                               [A  4%|▎         | 41/1120 [00:36<21:54,  1.22s/it]  4%|▍         | 42/1120 [00:37<19:37,  1.09s/it]  4%|▍         | 43/1120 [00:37<17:59,  1.00s/it]  4%|▍         | 44/1120 [00:38<16:55,  1.06it/s]  4%|▍         | 45/1120 [00:39<17:19,  1.03it/s]  4%|▍         | 46/1120 [00:40<16:18,  1.10it/s]  4%|▍         | 47/1120 [00:41<15:41,  1.14it/s]  4%|▍         | 48/1120 [00:42<15:13,  1.17it/s]  4%|▍         | 49/1120 [00:43<15:58,  1.12it/s]  4%|▍         | 50/1120 [00:43<15:23,  1.16it/s]                                                   4%|▍         | 50/1120 [00:43<15:23,  1.16it/s]  5%|▍         | 51/1120 [00:44<14:52,  1.20it/s]  5%|▍         | 52/1120 [00:45<14:30,  1.23it/s]  5%|▍         | 53/1120 [00:46<15:28,  1.15it/s]  5%|▍         | 54/1120 [00:47<14:56,  1.19it/s]  5%|▍         | 55/1120 [00:47<14:37,  1.21it/s]  5%|▌         | 56/1120 [00:48<14:20,  1.24it/s]  5%|▌         | 57/1120 [00:49<15:17,  1.16it/s]  5%|▌         | 58/1120 [00:50<14:51,  1.19it/s]  5%|▌         | 59/1120 [00:51<14:37,  1.21it/s]  5%|▌         | 60/1120 [00:52<14:21,  1.23it/s]                                                   5%|▌         | 60/1120 [00:52<14:21,  1.23it/s]  5%|▌         | 61/1120 [00:53<15:20,  1.15it/s]  6%|▌         | 62/1120 [00:53<14:45,  1.19it/s]  6%|▌         | 63/1120 [00:54<14:26,  1.22it/s]  6%|▌         | 64/1120 [00:55<14:13,  1.24it/s]  6%|▌         | 65/1120 [00:56<15:14,  1.15it/s]  6%|▌         | 66/1120 [00:57<14:47,  1.19it/s]  6%|▌         | 67/1120 [00:57<14:23,  1.22it/s]  6%|▌         | 68/1120 [00:58<14:10,  1.24it/s]  6%|▌         | 69/1120 [00:59<15:08,  1.16it/s]  6%|▋         | 70/1120 [01:00<14:40,  1.19it/s]                                                   6%|▋         | 70/1120 [01:00<14:40,  1.19it/s]  6%|▋         | 71/1120 [01:01<14:19,  1.22it/s]  6%|▋         | 72/1120 [01:02<14:02,  1.24it/s]  7%|▋         | 73/1120 [01:03<15:02,  1.16it/s]  7%|▋         | 74/1120 [01:03<14:34,  1.20it/s]  7%|▋         | 75/1120 [01:04<14:15,  1.22it/s]  7%|▋         | 76/1120 [01:05<14:01,  1.24it/s]  7%|▋         | 77/1120 [01:06<15:00,  1.16it/s]  7%|▋         | 78/1120 [01:07<14:32,  1.19it/s]  7%|▋         | 79/1120 [01:07<14:10,  1.22it/s]  7%|▋         | 80/1120 [01:08<13:57,  1.24it/s]                                                   7%|▋         | 80/1120 [01:08<13:57,  1.24it/s]{'eval_loss': 0.19947710633277893, 'eval_runtime': 0.9744, 'eval_samples_per_second': 102.624, 'eval_steps_per_second': 13.341, 'epoch': 0.36}
外层迭代结束！
外层迭代结束！
{'loss': 0.2855, 'learning_rate': 0.0003, 'epoch': 0.44}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2284, 'learning_rate': 0.00029719626168224294, 'epoch': 0.53}
外层迭代结束！
外层迭代结束！
{'loss': 0.2543, 'learning_rate': 0.00029439252336448596, 'epoch': 0.62}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1719, 'learning_rate': 0.0002915887850467289, 'epoch': 0.71}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.55it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 16.07it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 14.96it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 14.35it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 14.11it/s][A
100%|██████████| 13/13 [00:00<00:00, 13.94it/s][A                                                 
                                               [A  7%|▋         | 80/1120 [01:09<13:57,  1.24it/s]
100%|██████████| 13/13 [00:00<00:00, 13.94it/s][A
                                               [A  7%|▋         | 81/1120 [01:10<20:37,  1.19s/it]  7%|▋         | 82/1120 [01:11<18:28,  1.07s/it]  7%|▋         | 83/1120 [01:12<16:57,  1.02it/s]  8%|▊         | 84/1120 [01:13<15:54,  1.09it/s]  8%|▊         | 85/1120 [01:14<16:11,  1.07it/s]  8%|▊         | 86/1120 [01:14<15:23,  1.12it/s]  8%|▊         | 87/1120 [01:15<14:45,  1.17it/s]  8%|▊         | 88/1120 [01:16<14:17,  1.20it/s]  8%|▊         | 89/1120 [01:17<15:06,  1.14it/s]  8%|▊         | 90/1120 [01:18<14:34,  1.18it/s]                                                   8%|▊         | 90/1120 [01:18<14:34,  1.18it/s]  8%|▊         | 91/1120 [01:18<14:11,  1.21it/s]  8%|▊         | 92/1120 [01:19<13:58,  1.23it/s]  8%|▊         | 93/1120 [01:20<14:52,  1.15it/s]  8%|▊         | 94/1120 [01:21<14:28,  1.18it/s]  8%|▊         | 95/1120 [01:22<14:05,  1.21it/s]  9%|▊         | 96/1120 [01:23<13:50,  1.23it/s]  9%|▊         | 97/1120 [01:24<14:48,  1.15it/s]  9%|▉         | 98/1120 [01:24<14:21,  1.19it/s]  9%|▉         | 99/1120 [01:25<13:59,  1.22it/s]  9%|▉         | 100/1120 [01:26<13:47,  1.23it/s]                                                    9%|▉         | 100/1120 [01:26<13:47,  1.23it/s]  9%|▉         | 101/1120 [01:27<14:46,  1.15it/s]  9%|▉         | 102/1120 [01:28<14:17,  1.19it/s]  9%|▉         | 103/1120 [01:29<13:56,  1.22it/s]  9%|▉         | 104/1120 [01:29<13:42,  1.24it/s]  9%|▉         | 105/1120 [01:30<14:36,  1.16it/s]  9%|▉         | 106/1120 [01:31<14:10,  1.19it/s] 10%|▉         | 107/1120 [01:32<13:49,  1.22it/s] 10%|▉         | 108/1120 [01:33<13:36,  1.24it/s] 10%|▉         | 109/1120 [01:34<14:26,  1.17it/s] 10%|▉         | 110/1120 [01:34<13:58,  1.20it/s]                                                   10%|▉         | 110/1120 [01:34<13:58,  1.20it/s] 10%|▉         | 111/1120 [01:35<13:36,  1.24it/s] 10%|█         | 112/1120 [01:36<13:17,  1.26it/s] 10%|█         | 113/1120 [01:37<14:07,  1.19it/s] 10%|█         | 114/1120 [01:38<13:40,  1.23it/s] 10%|█         | 115/1120 [01:38<13:19,  1.26it/s] 10%|█         | 116/1120 [01:39<13:07,  1.28it/s] 10%|█         | 117/1120 [01:40<14:05,  1.19it/s] 11%|█         | 118/1120 [01:41<13:43,  1.22it/s] 11%|█         | 119/1120 [01:42<13:26,  1.24it/s] 11%|█         | 120/1120 [01:42<13:21,  1.25it/s]                                                   11%|█         | 120/1120 [01:43<13:21,  1.25it/s]{'eval_loss': 0.14659737050533295, 'eval_runtime': 0.9704, 'eval_samples_per_second': 103.051, 'eval_steps_per_second': 13.397, 'epoch': 0.71}
外层迭代结束！
外层迭代结束！
{'loss': 0.2008, 'learning_rate': 0.00028878504672897194, 'epoch': 0.8}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1877, 'learning_rate': 0.0002859813084112149, 'epoch': 0.89}
外层迭代结束！
外层迭代结束！
{'loss': 0.1424, 'learning_rate': 0.0002831775700934579, 'epoch': 0.98}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1456, 'learning_rate': 0.0002803738317757009, 'epoch': 1.07}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.59it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 16.26it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 15.16it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 14.55it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 14.33it/s][A
100%|██████████| 13/13 [00:00<00:00, 14.20it/s][A                                                  
                                               [A 11%|█         | 120/1120 [01:44<13:21,  1.25it/s]
100%|██████████| 13/13 [00:00<00:00, 14.20it/s][A
                                               [A 11%|█         | 121/1120 [01:44<19:38,  1.18s/it] 11%|█         | 122/1120 [01:45<17:35,  1.06s/it] 11%|█         | 123/1120 [01:46<16:08,  1.03it/s] 11%|█         | 124/1120 [01:47<15:05,  1.10it/s] 11%|█         | 125/1120 [01:48<15:27,  1.07it/s] 11%|█▏        | 126/1120 [01:49<14:35,  1.14it/s] 11%|█▏        | 127/1120 [01:49<14:01,  1.18it/s] 11%|█▏        | 128/1120 [01:50<13:38,  1.21it/s] 12%|█▏        | 129/1120 [01:51<14:25,  1.15it/s] 12%|█▏        | 130/1120 [01:52<13:52,  1.19it/s]                                                   12%|█▏        | 130/1120 [01:52<13:52,  1.19it/s] 12%|█▏        | 131/1120 [01:53<13:29,  1.22it/s] 12%|█▏        | 132/1120 [01:53<13:14,  1.24it/s] 12%|█▏        | 133/1120 [01:54<14:03,  1.17it/s] 12%|█▏        | 134/1120 [01:55<13:36,  1.21it/s] 12%|█▏        | 135/1120 [01:56<13:17,  1.23it/s] 12%|█▏        | 136/1120 [01:57<13:02,  1.26it/s] 12%|█▏        | 137/1120 [01:58<13:56,  1.17it/s] 12%|█▏        | 138/1120 [01:58<13:30,  1.21it/s] 12%|█▏        | 139/1120 [01:59<13:10,  1.24it/s] 12%|█▎        | 140/1120 [02:00<12:57,  1.26it/s]                                                   12%|█▎        | 140/1120 [02:00<12:57,  1.26it/s] 13%|█▎        | 141/1120 [02:01<13:51,  1.18it/s] 13%|█▎        | 142/1120 [02:02<13:26,  1.21it/s] 13%|█▎        | 143/1120 [02:02<13:05,  1.24it/s] 13%|█▎        | 144/1120 [02:03<12:52,  1.26it/s] 13%|█▎        | 145/1120 [02:04<13:44,  1.18it/s] 13%|█▎        | 146/1120 [02:05<13:19,  1.22it/s] 13%|█▎        | 147/1120 [02:06<13:02,  1.24it/s] 13%|█▎        | 148/1120 [02:06<12:50,  1.26it/s] 13%|█▎        | 149/1120 [02:07<13:41,  1.18it/s] 13%|█▎        | 150/1120 [02:08<13:15,  1.22it/s]                                                   13%|█▎        | 150/1120 [02:08<13:15,  1.22it/s] 13%|█▎        | 151/1120 [02:09<12:57,  1.25it/s] 14%|█▎        | 152/1120 [02:10<12:48,  1.26it/s] 14%|█▎        | 153/1120 [02:11<13:39,  1.18it/s] 14%|█▍        | 154/1120 [02:11<13:13,  1.22it/s] 14%|█▍        | 155/1120 [02:12<12:55,  1.24it/s] 14%|█▍        | 156/1120 [02:13<12:42,  1.26it/s] 14%|█▍        | 157/1120 [02:14<13:33,  1.18it/s] 14%|█▍        | 158/1120 [02:15<13:07,  1.22it/s] 14%|█▍        | 159/1120 [02:15<12:48,  1.25it/s] 14%|█▍        | 160/1120 [02:16<12:36,  1.27it/s]                                                   14%|█▍        | 160/1120 [02:16<12:36,  1.27it/s]{'eval_loss': 0.11624202877283096, 'eval_runtime': 0.9555, 'eval_samples_per_second': 104.653, 'eval_steps_per_second': 13.605, 'epoch': 1.07}
外层迭代结束！
外层迭代结束！
{'loss': 0.1555, 'learning_rate': 0.0002775700934579439, 'epoch': 1.16}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1131, 'learning_rate': 0.00027476635514018686, 'epoch': 1.24}
外层迭代结束！
外层迭代结束！
{'loss': 0.0982, 'learning_rate': 0.0002719626168224299, 'epoch': 1.33}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1275, 'learning_rate': 0.00026915887850467284, 'epoch': 1.42}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.25it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.90it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.04it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.57it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.28it/s][A                                                  
                                               [A 14%|█▍        | 160/1120 [02:17<12:36,  1.27it/s]
100%|██████████| 13/13 [00:00<00:00, 14.28it/s][A
                                               [A 14%|█▍        | 161/1120 [02:18<18:46,  1.17s/it] 14%|█▍        | 162/1120 [02:19<16:46,  1.05s/it] 15%|█▍        | 163/1120 [02:20<15:21,  1.04it/s] 15%|█▍        | 164/1120 [02:21<14:23,  1.11it/s] 15%|█▍        | 165/1120 [02:22<14:43,  1.08it/s] 15%|█▍        | 166/1120 [02:22<13:54,  1.14it/s] 15%|█▍        | 167/1120 [02:23<13:21,  1.19it/s] 15%|█▌        | 168/1120 [02:24<12:57,  1.22it/s] 15%|█▌        | 169/1120 [02:25<13:40,  1.16it/s] 15%|█▌        | 170/1120 [02:26<13:09,  1.20it/s]                                                   15%|█▌        | 170/1120 [02:26<13:09,  1.20it/s] 15%|█▌        | 171/1120 [02:26<12:58,  1.22it/s] 15%|█▌        | 172/1120 [02:27<12:40,  1.25it/s] 15%|█▌        | 173/1120 [02:28<13:25,  1.18it/s] 16%|█▌        | 174/1120 [02:29<12:58,  1.22it/s] 16%|█▌        | 175/1120 [02:30<12:39,  1.24it/s] 16%|█▌        | 176/1120 [02:30<12:26,  1.27it/s] 16%|█▌        | 177/1120 [02:31<13:16,  1.18it/s] 16%|█▌        | 178/1120 [02:32<12:51,  1.22it/s] 16%|█▌        | 179/1120 [02:33<12:34,  1.25it/s] 16%|█▌        | 180/1120 [02:34<12:24,  1.26it/s]                                                   16%|█▌        | 180/1120 [02:34<12:24,  1.26it/s] 16%|█▌        | 181/1120 [02:35<13:11,  1.19it/s] 16%|█▋        | 182/1120 [02:35<12:49,  1.22it/s] 16%|█▋        | 183/1120 [02:36<12:30,  1.25it/s] 16%|█▋        | 184/1120 [02:37<12:16,  1.27it/s] 17%|█▋        | 185/1120 [02:38<13:07,  1.19it/s] 17%|█▋        | 186/1120 [02:39<12:42,  1.22it/s] 17%|█▋        | 187/1120 [02:39<12:25,  1.25it/s] 17%|█▋        | 188/1120 [02:40<12:12,  1.27it/s] 17%|█▋        | 189/1120 [02:41<13:04,  1.19it/s] 17%|█▋        | 190/1120 [02:42<12:39,  1.22it/s]                                                   17%|█▋        | 190/1120 [02:42<12:39,  1.22it/s] 17%|█▋        | 191/1120 [02:43<12:21,  1.25it/s] 17%|█▋        | 192/1120 [02:43<12:12,  1.27it/s] 17%|█▋        | 193/1120 [02:44<13:01,  1.19it/s] 17%|█▋        | 194/1120 [02:45<12:36,  1.22it/s] 17%|█▋        | 195/1120 [02:46<12:19,  1.25it/s] 18%|█▊        | 196/1120 [02:47<12:06,  1.27it/s] 18%|█▊        | 197/1120 [02:48<12:56,  1.19it/s] 18%|█▊        | 198/1120 [02:48<12:31,  1.23it/s] 18%|█▊        | 199/1120 [02:49<12:15,  1.25it/s] 18%|█▊        | 200/1120 [02:50<12:04,  1.27it/s]                                                   18%|█▊        | 200/1120 [02:50<12:04,  1.27it/s]{'eval_loss': 0.13828860223293304, 'eval_runtime': 0.9532, 'eval_samples_per_second': 104.905, 'eval_steps_per_second': 13.638, 'epoch': 1.42}
外层迭代结束！
外层迭代结束！
{'loss': 0.146, 'learning_rate': 0.00026635514018691586, 'epoch': 1.51}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0998, 'learning_rate': 0.0002635514018691588, 'epoch': 1.6}
外层迭代结束！
外层迭代结束！
{'loss': 0.1216, 'learning_rate': 0.00026074766355140184, 'epoch': 1.69}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0854, 'learning_rate': 0.0002579439252336448, 'epoch': 1.78}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.60it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.93it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.00it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.51it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.22it/s][A                                                  
                                               [A 18%|█▊        | 200/1120 [02:51<12:04,  1.27it/s]
100%|██████████| 13/13 [00:00<00:00, 14.22it/s][A
                                               [A 18%|█▊        | 201/1120 [02:52<17:50,  1.16s/it] 18%|█▊        | 202/1120 [02:53<15:58,  1.04s/it] 18%|█▊        | 203/1120 [02:53<14:39,  1.04it/s] 18%|█▊        | 204/1120 [02:54<13:43,  1.11it/s] 18%|█▊        | 205/1120 [02:55<14:05,  1.08it/s] 18%|█▊        | 206/1120 [02:56<13:18,  1.14it/s] 18%|█▊        | 207/1120 [02:57<12:46,  1.19it/s] 19%|█▊        | 208/1120 [02:57<12:26,  1.22it/s] 19%|█▊        | 209/1120 [02:58<13:07,  1.16it/s] 19%|█▉        | 210/1120 [02:59<12:40,  1.20it/s]                                                   19%|█▉        | 210/1120 [02:59<12:40,  1.20it/s] 19%|█▉        | 211/1120 [03:00<12:20,  1.23it/s] 19%|█▉        | 212/1120 [03:01<12:06,  1.25it/s] 19%|█▉        | 213/1120 [03:02<12:53,  1.17it/s] 19%|█▉        | 214/1120 [03:02<12:28,  1.21it/s] 19%|█▉        | 215/1120 [03:03<12:12,  1.23it/s] 19%|█▉        | 216/1120 [03:04<11:59,  1.26it/s] 19%|█▉        | 217/1120 [03:05<12:46,  1.18it/s] 19%|█▉        | 218/1120 [03:06<12:22,  1.22it/s] 20%|█▉        | 219/1120 [03:06<12:06,  1.24it/s] 20%|█▉        | 220/1120 [03:07<11:54,  1.26it/s]                                                   20%|█▉        | 220/1120 [03:07<11:54,  1.26it/s] 20%|█▉        | 221/1120 [03:08<12:43,  1.18it/s] 20%|█▉        | 222/1120 [03:09<12:20,  1.21it/s] 20%|█▉        | 223/1120 [03:10<12:04,  1.24it/s] 20%|██        | 224/1120 [03:10<11:52,  1.26it/s] 20%|██        | 225/1120 [03:11<12:38,  1.18it/s] 20%|██        | 226/1120 [03:12<12:15,  1.22it/s] 20%|██        | 227/1120 [03:13<11:59,  1.24it/s] 20%|██        | 228/1120 [03:14<11:50,  1.26it/s] 20%|██        | 229/1120 [03:15<12:39,  1.17it/s] 21%|██        | 230/1120 [03:16<12:15,  1.21it/s]                                                   21%|██        | 230/1120 [03:16<12:15,  1.21it/s] 21%|██        | 231/1120 [03:16<11:57,  1.24it/s] 21%|██        | 232/1120 [03:17<11:50,  1.25it/s] 21%|██        | 233/1120 [03:18<12:41,  1.17it/s] 21%|██        | 234/1120 [03:19<12:16,  1.20it/s] 21%|██        | 235/1120 [03:20<11:59,  1.23it/s] 21%|██        | 236/1120 [03:20<11:44,  1.25it/s] 21%|██        | 237/1120 [03:21<12:34,  1.17it/s] 21%|██▏       | 238/1120 [03:22<12:10,  1.21it/s] 21%|██▏       | 239/1120 [03:23<11:55,  1.23it/s] 21%|██▏       | 240/1120 [03:24<11:42,  1.25it/s]                                                   21%|██▏       | 240/1120 [03:24<11:42,  1.25it/s]{'eval_loss': 0.13658130168914795, 'eval_runtime': 0.9539, 'eval_samples_per_second': 104.83, 'eval_steps_per_second': 13.628, 'epoch': 1.78}
外层迭代结束！
外层迭代结束！
{'loss': 0.0996, 'learning_rate': 0.0002551401869158878, 'epoch': 1.87}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1453, 'learning_rate': 0.0002523364485981308, 'epoch': 1.96}
外层迭代结束！
外层迭代结束！
{'loss': 0.0827, 'learning_rate': 0.0002495327102803738, 'epoch': 2.04}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.083, 'learning_rate': 0.00024672897196261677, 'epoch': 2.13}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.06it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.85it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 14.97it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.46it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.20it/s][A                                                  
                                               [A 21%|██▏       | 240/1120 [03:25<11:42,  1.25it/s]
100%|██████████| 13/13 [00:00<00:00, 14.20it/s][A
                                               [A 22%|██▏       | 241/1120 [03:26<17:23,  1.19s/it] 22%|██▏       | 242/1120 [03:27<15:32,  1.06s/it] 22%|██▏       | 243/1120 [03:27<14:14,  1.03it/s] 22%|██▏       | 244/1120 [03:28<13:20,  1.09it/s] 22%|██▏       | 245/1120 [03:29<13:36,  1.07it/s] 22%|██▏       | 246/1120 [03:30<12:54,  1.13it/s] 22%|██▏       | 247/1120 [03:31<12:20,  1.18it/s] 22%|██▏       | 248/1120 [03:31<11:58,  1.21it/s] 22%|██▏       | 249/1120 [03:32<12:37,  1.15it/s] 22%|██▏       | 250/1120 [03:33<12:08,  1.19it/s]                                                   22%|██▏       | 250/1120 [03:33<12:08,  1.19it/s] 22%|██▏       | 251/1120 [03:34<11:46,  1.23it/s] 22%|██▎       | 252/1120 [03:35<11:33,  1.25it/s] 23%|██▎       | 253/1120 [03:36<12:17,  1.17it/s] 23%|██▎       | 254/1120 [03:36<11:54,  1.21it/s] 23%|██▎       | 255/1120 [03:37<11:38,  1.24it/s] 23%|██▎       | 256/1120 [03:38<11:24,  1.26it/s] 23%|██▎       | 257/1120 [03:39<12:09,  1.18it/s] 23%|██▎       | 258/1120 [03:40<11:48,  1.22it/s] 23%|██▎       | 259/1120 [03:40<11:32,  1.24it/s] 23%|██▎       | 260/1120 [03:41<11:20,  1.26it/s]                                                   23%|██▎       | 260/1120 [03:41<11:20,  1.26it/s] 23%|██▎       | 261/1120 [03:42<12:07,  1.18it/s] 23%|██▎       | 262/1120 [03:43<11:46,  1.21it/s] 23%|██▎       | 263/1120 [03:44<11:31,  1.24it/s] 24%|██▎       | 264/1120 [03:44<11:19,  1.26it/s] 24%|██▎       | 265/1120 [03:45<12:07,  1.18it/s] 24%|██▍       | 266/1120 [03:46<11:44,  1.21it/s] 24%|██▍       | 267/1120 [03:47<11:34,  1.23it/s] 24%|██▍       | 268/1120 [03:48<11:21,  1.25it/s] 24%|██▍       | 269/1120 [03:49<12:03,  1.18it/s] 24%|██▍       | 270/1120 [03:49<11:40,  1.21it/s]                                                   24%|██▍       | 270/1120 [03:49<11:40,  1.21it/s] 24%|██▍       | 271/1120 [03:50<11:27,  1.23it/s] 24%|██▍       | 272/1120 [03:51<11:15,  1.26it/s] 24%|██▍       | 273/1120 [03:52<12:00,  1.18it/s] 24%|██▍       | 274/1120 [03:53<11:37,  1.21it/s] 25%|██▍       | 275/1120 [03:53<11:26,  1.23it/s] 25%|██▍       | 276/1120 [03:54<11:16,  1.25it/s] 25%|██▍       | 277/1120 [03:55<12:01,  1.17it/s] 25%|██▍       | 278/1120 [03:56<11:37,  1.21it/s] 25%|██▍       | 279/1120 [03:57<11:24,  1.23it/s] 25%|██▌       | 280/1120 [03:58<11:11,  1.25it/s]                                                   25%|██▌       | 280/1120 [03:58<11:11,  1.25it/s]{'eval_loss': 0.10100841522216797, 'eval_runtime': 0.9609, 'eval_samples_per_second': 104.071, 'eval_steps_per_second': 13.529, 'epoch': 2.13}
外层迭代结束！
外层迭代结束！
{'loss': 0.0907, 'learning_rate': 0.0002439252336448598, 'epoch': 2.22}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1076, 'learning_rate': 0.00024112149532710278, 'epoch': 2.31}
外层迭代结束！
外层迭代结束！
{'loss': 0.1026, 'learning_rate': 0.00023831775700934577, 'epoch': 2.4}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0573, 'learning_rate': 0.00023551401869158876, 'epoch': 2.49}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.76it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.23it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.40it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.79it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.59it/s][A                                                  
                                               [A 25%|██▌       | 280/1120 [03:59<11:11,  1.25it/s]
100%|██████████| 13/13 [00:00<00:00, 14.59it/s][A
                                               [A 25%|██▌       | 281/1120 [04:00<16:17,  1.16s/it] 25%|██▌       | 282/1120 [04:00<14:38,  1.05s/it] 25%|██▌       | 283/1120 [04:01<13:26,  1.04it/s] 25%|██▌       | 284/1120 [04:02<12:31,  1.11it/s] 25%|██▌       | 285/1120 [04:03<12:52,  1.08it/s] 26%|██▌       | 286/1120 [04:04<12:06,  1.15it/s] 26%|██▌       | 287/1120 [04:04<11:42,  1.18it/s] 26%|██▌       | 288/1120 [04:05<11:26,  1.21it/s] 26%|██▌       | 289/1120 [04:06<12:07,  1.14it/s] 26%|██▌       | 290/1120 [04:07<11:41,  1.18it/s]                                                   26%|██▌       | 290/1120 [04:07<11:41,  1.18it/s] 26%|██▌       | 291/1120 [04:08<11:19,  1.22it/s] 26%|██▌       | 292/1120 [04:08<11:05,  1.24it/s] 26%|██▌       | 293/1120 [04:09<11:48,  1.17it/s] 26%|██▋       | 294/1120 [04:10<11:25,  1.21it/s] 26%|██▋       | 295/1120 [04:11<11:12,  1.23it/s] 26%|██▋       | 296/1120 [04:12<10:58,  1.25it/s] 27%|██▋       | 297/1120 [04:13<11:39,  1.18it/s] 27%|██▋       | 298/1120 [04:13<11:18,  1.21it/s] 27%|██▋       | 299/1120 [04:14<11:02,  1.24it/s] 27%|██▋       | 300/1120 [04:15<10:53,  1.26it/s]                                                   27%|██▋       | 300/1120 [04:15<10:53,  1.26it/s] 27%|██▋       | 301/1120 [04:16<11:35,  1.18it/s] 27%|██▋       | 302/1120 [04:17<11:14,  1.21it/s] 27%|██▋       | 303/1120 [04:18<10:59,  1.24it/s] 27%|██▋       | 304/1120 [04:18<10:49,  1.26it/s] 27%|██▋       | 305/1120 [04:19<11:32,  1.18it/s] 27%|██▋       | 306/1120 [04:20<11:10,  1.21it/s] 27%|██▋       | 307/1120 [04:21<10:59,  1.23it/s] 28%|██▊       | 308/1120 [04:22<10:48,  1.25it/s] 28%|██▊       | 309/1120 [04:23<11:30,  1.17it/s] 28%|██▊       | 310/1120 [04:23<11:08,  1.21it/s]                                                   28%|██▊       | 310/1120 [04:23<11:08,  1.21it/s] 28%|██▊       | 311/1120 [04:24<10:53,  1.24it/s] 28%|██▊       | 312/1120 [04:25<10:43,  1.26it/s] 28%|██▊       | 313/1120 [04:26<11:26,  1.17it/s] 28%|██▊       | 314/1120 [04:27<11:06,  1.21it/s] 28%|██▊       | 315/1120 [04:27<10:53,  1.23it/s] 28%|██▊       | 316/1120 [04:28<10:42,  1.25it/s] 28%|██▊       | 317/1120 [04:29<11:26,  1.17it/s] 28%|██▊       | 318/1120 [04:30<11:03,  1.21it/s] 28%|██▊       | 319/1120 [04:31<10:52,  1.23it/s] 29%|██▊       | 320/1120 [04:31<10:41,  1.25it/s]                                                   29%|██▊       | 320/1120 [04:32<10:41,  1.25it/s]{'eval_loss': 0.120510034263134, 'eval_runtime': 0.9331, 'eval_samples_per_second': 107.17, 'eval_steps_per_second': 13.932, 'epoch': 2.49}
外层迭代结束！
外层迭代结束！
{'loss': 0.1134, 'learning_rate': 0.00023271028037383175, 'epoch': 2.58}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.067, 'learning_rate': 0.00022990654205607474, 'epoch': 2.67}
外层迭代结束！
外层迭代结束！
{'loss': 0.0616, 'learning_rate': 0.00022710280373831773, 'epoch': 2.76}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1276, 'learning_rate': 0.00022429906542056072, 'epoch': 2.84}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.16it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.84it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 14.91it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.44it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.14it/s][A                                                  
                                               [A 29%|██▊       | 320/1120 [04:33<10:41,  1.25it/s]
100%|██████████| 13/13 [00:00<00:00, 14.14it/s][A
                                               [A 29%|██▊       | 321/1120 [04:34<15:46,  1.18s/it] 29%|██▉       | 322/1120 [04:34<14:10,  1.07s/it] 29%|██▉       | 323/1120 [04:35<13:01,  1.02it/s] 29%|██▉       | 324/1120 [04:36<12:10,  1.09it/s] 29%|██▉       | 325/1120 [04:37<12:25,  1.07it/s] 29%|██▉       | 326/1120 [04:38<11:44,  1.13it/s] 29%|██▉       | 327/1120 [04:38<11:13,  1.18it/s] 29%|██▉       | 328/1120 [04:39<10:52,  1.21it/s] 29%|██▉       | 329/1120 [04:40<11:28,  1.15it/s] 29%|██▉       | 330/1120 [04:41<11:04,  1.19it/s]                                                   29%|██▉       | 330/1120 [04:41<11:04,  1.19it/s] 30%|██▉       | 331/1120 [04:42<10:45,  1.22it/s] 30%|██▉       | 332/1120 [04:42<10:32,  1.25it/s] 30%|██▉       | 333/1120 [04:43<11:13,  1.17it/s] 30%|██▉       | 334/1120 [04:44<10:50,  1.21it/s] 30%|██▉       | 335/1120 [04:45<10:36,  1.23it/s] 30%|███       | 336/1120 [04:46<10:24,  1.26it/s] 30%|███       | 337/1120 [04:47<11:06,  1.18it/s] 30%|███       | 338/1120 [04:47<10:44,  1.21it/s] 30%|███       | 339/1120 [04:48<10:29,  1.24it/s] 30%|███       | 340/1120 [04:49<10:18,  1.26it/s]                                                   30%|███       | 340/1120 [04:49<10:18,  1.26it/s] 30%|███       | 341/1120 [04:50<11:00,  1.18it/s] 31%|███       | 342/1120 [04:51<10:40,  1.21it/s] 31%|███       | 343/1120 [04:51<10:25,  1.24it/s] 31%|███       | 344/1120 [04:52<10:13,  1.26it/s] 31%|███       | 345/1120 [04:53<10:54,  1.18it/s] 31%|███       | 346/1120 [04:54<10:33,  1.22it/s] 31%|███       | 347/1120 [04:55<10:19,  1.25it/s] 31%|███       | 348/1120 [04:55<10:08,  1.27it/s] 31%|███       | 349/1120 [04:56<10:49,  1.19it/s] 31%|███▏      | 350/1120 [04:57<10:28,  1.22it/s]                                                   31%|███▏      | 350/1120 [04:57<10:28,  1.22it/s] 31%|███▏      | 351/1120 [04:58<10:14,  1.25it/s] 31%|███▏      | 352/1120 [04:59<10:04,  1.27it/s] 32%|███▏      | 353/1120 [05:00<10:45,  1.19it/s] 32%|███▏      | 354/1120 [05:00<10:24,  1.23it/s] 32%|███▏      | 355/1120 [05:01<10:10,  1.25it/s] 32%|███▏      | 356/1120 [05:02<09:59,  1.27it/s] 32%|███▏      | 357/1120 [05:03<10:41,  1.19it/s] 32%|███▏      | 358/1120 [05:04<10:23,  1.22it/s] 32%|███▏      | 359/1120 [05:04<10:08,  1.25it/s] 32%|███▏      | 360/1120 [05:05<09:58,  1.27it/s]                                                   32%|███▏      | 360/1120 [05:05<09:58,  1.27it/s]{'eval_loss': 0.11385311186313629, 'eval_runtime': 0.9606, 'eval_samples_per_second': 104.103, 'eval_steps_per_second': 13.533, 'epoch': 2.84}
外层迭代结束！
外层迭代结束！
{'loss': 0.1024, 'learning_rate': 0.0002214953271028037, 'epoch': 2.93}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0539, 'learning_rate': 0.0002186915887850467, 'epoch': 3.02}
外层迭代结束！
外层迭代结束！
{'loss': 0.0786, 'learning_rate': 0.0002158878504672897, 'epoch': 3.11}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0746, 'learning_rate': 0.00021308411214953268, 'epoch': 3.2}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.63it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.06it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.09it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.58it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.38it/s][A                                                  
                                               [A 32%|███▏      | 360/1120 [05:06<09:58,  1.27it/s]
100%|██████████| 13/13 [00:00<00:00, 14.38it/s][A
                                               [A 32%|███▏      | 361/1120 [05:07<14:42,  1.16s/it] 32%|███▏      | 362/1120 [05:08<13:09,  1.04s/it] 32%|███▏      | 363/1120 [05:09<12:03,  1.05it/s] 32%|███▎      | 364/1120 [05:10<11:18,  1.11it/s] 33%|███▎      | 365/1120 [05:10<11:33,  1.09it/s] 33%|███▎      | 366/1120 [05:11<10:55,  1.15it/s] 33%|███▎      | 367/1120 [05:12<10:32,  1.19it/s] 33%|███▎      | 368/1120 [05:13<10:11,  1.23it/s] 33%|███▎      | 369/1120 [05:14<10:41,  1.17it/s] 33%|███▎      | 370/1120 [05:14<10:16,  1.22it/s]                                                   33%|███▎      | 370/1120 [05:14<10:16,  1.22it/s] 33%|███▎      | 371/1120 [05:15<10:01,  1.24it/s] 33%|███▎      | 372/1120 [05:16<09:50,  1.27it/s] 33%|███▎      | 373/1120 [05:17<10:31,  1.18it/s] 33%|███▎      | 374/1120 [05:18<10:14,  1.21it/s] 33%|███▎      | 375/1120 [05:19<09:59,  1.24it/s] 34%|███▎      | 376/1120 [05:19<09:49,  1.26it/s] 34%|███▎      | 377/1120 [05:20<10:25,  1.19it/s] 34%|███▍      | 378/1120 [05:21<10:08,  1.22it/s] 34%|███▍      | 379/1120 [05:22<09:54,  1.25it/s] 34%|███▍      | 380/1120 [05:23<09:46,  1.26it/s]                                                   34%|███▍      | 380/1120 [05:23<09:46,  1.26it/s] 34%|███▍      | 381/1120 [05:23<10:25,  1.18it/s] 34%|███▍      | 382/1120 [05:24<10:05,  1.22it/s] 34%|███▍      | 383/1120 [05:25<09:51,  1.25it/s] 34%|███▍      | 384/1120 [05:26<09:43,  1.26it/s] 34%|███▍      | 385/1120 [05:27<10:23,  1.18it/s] 34%|███▍      | 386/1120 [05:28<10:08,  1.21it/s] 35%|███▍      | 387/1120 [05:28<09:54,  1.23it/s] 35%|███▍      | 388/1120 [05:29<09:44,  1.25it/s] 35%|███▍      | 389/1120 [05:30<10:18,  1.18it/s] 35%|███▍      | 390/1120 [05:31<09:58,  1.22it/s]                                                   35%|███▍      | 390/1120 [05:31<09:58,  1.22it/s] 35%|███▍      | 391/1120 [05:32<09:47,  1.24it/s] 35%|███▌      | 392/1120 [05:32<09:36,  1.26it/s] 35%|███▌      | 393/1120 [05:33<10:17,  1.18it/s] 35%|███▌      | 394/1120 [05:34<09:58,  1.21it/s] 35%|███▌      | 395/1120 [05:35<09:45,  1.24it/s] 35%|███▌      | 396/1120 [05:36<09:36,  1.26it/s] 35%|███▌      | 397/1120 [05:37<10:16,  1.17it/s] 36%|███▌      | 398/1120 [05:37<09:58,  1.21it/s] 36%|███▌      | 399/1120 [05:38<09:43,  1.24it/s] 36%|███▌      | 400/1120 [05:39<09:35,  1.25it/s]                                                   36%|███▌      | 400/1120 [05:39<09:35,  1.25it/s]{'eval_loss': 0.11325597763061523, 'eval_runtime': 0.9468, 'eval_samples_per_second': 105.622, 'eval_steps_per_second': 13.731, 'epoch': 3.2}
外层迭代结束！
外层迭代结束！
{'loss': 0.0357, 'learning_rate': 0.00021028037383177567, 'epoch': 3.29}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0675, 'learning_rate': 0.00020747663551401867, 'epoch': 3.38}
外层迭代结束！
外层迭代结束！
{'loss': 0.0704, 'learning_rate': 0.00020467289719626166, 'epoch': 3.47}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0451, 'learning_rate': 0.00020186915887850465, 'epoch': 3.56}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.03it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.89it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 14.97it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.49it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.20it/s][A                                                  
                                               [A 36%|███▌      | 400/1120 [05:40<09:35,  1.25it/s]
100%|██████████| 13/13 [00:00<00:00, 14.20it/s][A
                                               [A 36%|███▌      | 401/1120 [05:41<14:33,  1.21s/it] 36%|███▌      | 402/1120 [05:42<13:04,  1.09s/it] 36%|███▌      | 403/1120 [05:43<11:59,  1.00s/it] 36%|███▌      | 404/1120 [05:43<11:12,  1.06it/s] 36%|███▌      | 405/1120 [05:44<11:24,  1.05it/s] 36%|███▋      | 406/1120 [05:45<10:47,  1.10it/s] 36%|███▋      | 407/1120 [05:46<10:21,  1.15it/s] 36%|███▋      | 408/1120 [05:47<10:04,  1.18it/s] 37%|███▋      | 409/1120 [05:48<10:37,  1.12it/s] 37%|███▋      | 410/1120 [05:49<10:15,  1.15it/s]                                                   37%|███▋      | 410/1120 [05:49<10:15,  1.15it/s] 37%|███▋      | 411/1120 [05:49<09:58,  1.18it/s] 37%|███▋      | 412/1120 [05:50<09:48,  1.20it/s] 37%|███▋      | 413/1120 [05:51<10:25,  1.13it/s] 37%|███▋      | 414/1120 [05:52<10:04,  1.17it/s] 37%|███▋      | 415/1120 [05:53<09:47,  1.20it/s] 37%|███▋      | 416/1120 [05:54<09:38,  1.22it/s] 37%|███▋      | 417/1120 [05:55<10:16,  1.14it/s] 37%|███▋      | 418/1120 [05:55<09:57,  1.18it/s] 37%|███▋      | 419/1120 [05:56<09:42,  1.20it/s] 38%|███▊      | 420/1120 [05:57<09:27,  1.23it/s]                                                   38%|███▊      | 420/1120 [05:57<09:27,  1.23it/s] 38%|███▊      | 421/1120 [05:58<10:04,  1.16it/s] 38%|███▊      | 422/1120 [05:59<09:49,  1.18it/s] 38%|███▊      | 423/1120 [06:00<09:33,  1.22it/s] 38%|███▊      | 424/1120 [06:00<09:23,  1.23it/s] 38%|███▊      | 425/1120 [06:01<10:01,  1.16it/s] 38%|███▊      | 426/1120 [06:02<09:41,  1.19it/s] 38%|███▊      | 427/1120 [06:03<09:28,  1.22it/s] 38%|███▊      | 428/1120 [06:04<09:19,  1.24it/s] 38%|███▊      | 429/1120 [06:05<09:54,  1.16it/s] 38%|███▊      | 430/1120 [06:05<09:33,  1.20it/s]                                                   38%|███▊      | 430/1120 [06:05<09:33,  1.20it/s] 38%|███▊      | 431/1120 [06:06<09:19,  1.23it/s] 39%|███▊      | 432/1120 [06:07<09:11,  1.25it/s] 39%|███▊      | 433/1120 [06:08<09:47,  1.17it/s] 39%|███▉      | 434/1120 [06:09<09:32,  1.20it/s] 39%|███▉      | 435/1120 [06:09<09:17,  1.23it/s] 39%|███▉      | 436/1120 [06:10<09:08,  1.25it/s] 39%|███▉      | 437/1120 [06:11<09:48,  1.16it/s] 39%|███▉      | 438/1120 [06:12<09:30,  1.20it/s] 39%|███▉      | 439/1120 [06:13<09:18,  1.22it/s] 39%|███▉      | 440/1120 [06:14<09:07,  1.24it/s]                                                   39%|███▉      | 440/1120 [06:14<09:07,  1.24it/s]{'eval_loss': 0.14639084041118622, 'eval_runtime': 0.959, 'eval_samples_per_second': 104.279, 'eval_steps_per_second': 13.556, 'epoch': 3.56}
外层迭代结束！
外层迭代结束！
{'loss': 0.0962, 'learning_rate': 0.00019906542056074764, 'epoch': 3.64}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0603, 'learning_rate': 0.00019626168224299063, 'epoch': 3.73}
外层迭代结束！
外层迭代结束！
{'loss': 0.0552, 'learning_rate': 0.00019345794392523362, 'epoch': 3.82}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0985, 'learning_rate': 0.0001906542056074766, 'epoch': 3.91}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.18it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.81it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 14.94it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.47it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.11it/s][A                                                  
                                               [A 39%|███▉      | 440/1120 [06:15<09:07,  1.24it/s]
100%|██████████| 13/13 [00:00<00:00, 14.11it/s][A
                                               [A 39%|███▉      | 441/1120 [06:16<13:28,  1.19s/it] 39%|███▉      | 442/1120 [06:16<12:01,  1.06s/it] 40%|███▉      | 443/1120 [06:17<10:59,  1.03it/s] 40%|███▉      | 444/1120 [06:18<10:15,  1.10it/s] 40%|███▉      | 445/1120 [06:19<10:31,  1.07it/s] 40%|███▉      | 446/1120 [06:20<09:56,  1.13it/s] 40%|███▉      | 447/1120 [06:20<09:31,  1.18it/s] 40%|████      | 448/1120 [06:21<09:13,  1.21it/s] 40%|████      | 449/1120 [06:22<09:44,  1.15it/s] 40%|████      | 450/1120 [06:23<09:23,  1.19it/s]                                                   40%|████      | 450/1120 [06:23<09:23,  1.19it/s] 40%|████      | 451/1120 [06:24<09:08,  1.22it/s] 40%|████      | 452/1120 [06:25<08:57,  1.24it/s] 40%|████      | 453/1120 [06:26<09:30,  1.17it/s] 41%|████      | 454/1120 [06:26<09:14,  1.20it/s] 41%|████      | 455/1120 [06:27<09:02,  1.23it/s] 41%|████      | 456/1120 [06:28<08:53,  1.25it/s] 41%|████      | 457/1120 [06:29<09:27,  1.17it/s] 41%|████      | 458/1120 [06:30<09:15,  1.19it/s] 41%|████      | 459/1120 [06:30<09:04,  1.22it/s] 41%|████      | 460/1120 [06:31<08:55,  1.23it/s]                                                   41%|████      | 460/1120 [06:31<08:55,  1.23it/s] 41%|████      | 461/1120 [06:32<09:30,  1.15it/s] 41%|████▏     | 462/1120 [06:33<09:13,  1.19it/s] 41%|████▏     | 463/1120 [06:34<08:59,  1.22it/s] 41%|████▏     | 464/1120 [06:35<08:53,  1.23it/s] 42%|████▏     | 465/1120 [06:36<09:29,  1.15it/s] 42%|████▏     | 466/1120 [06:36<09:11,  1.19it/s] 42%|████▏     | 467/1120 [06:37<08:59,  1.21it/s] 42%|████▏     | 468/1120 [06:38<08:49,  1.23it/s] 42%|████▏     | 469/1120 [06:39<09:21,  1.16it/s] 42%|████▏     | 470/1120 [06:40<09:02,  1.20it/s]                                                   42%|████▏     | 470/1120 [06:40<09:02,  1.20it/s] 42%|████▏     | 471/1120 [06:40<08:49,  1.22it/s] 42%|████▏     | 472/1120 [06:41<08:40,  1.24it/s] 42%|████▏     | 473/1120 [06:42<09:14,  1.17it/s] 42%|████▏     | 474/1120 [06:43<09:00,  1.19it/s] 42%|████▏     | 475/1120 [06:44<08:45,  1.23it/s] 42%|████▎     | 476/1120 [06:44<08:34,  1.25it/s] 43%|████▎     | 477/1120 [06:45<09:06,  1.18it/s] 43%|████▎     | 478/1120 [06:46<08:51,  1.21it/s] 43%|████▎     | 479/1120 [06:47<08:40,  1.23it/s] 43%|████▎     | 480/1120 [06:48<08:28,  1.26it/s]                                                   43%|████▎     | 480/1120 [06:48<08:28,  1.26it/s]{'eval_loss': 0.13345298171043396, 'eval_runtime': 0.9607, 'eval_samples_per_second': 104.088, 'eval_steps_per_second': 13.531, 'epoch': 3.91}
外层迭代结束！
外层迭代结束！
{'loss': 0.0494, 'learning_rate': 0.0001878504672897196, 'epoch': 4.0}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0707, 'learning_rate': 0.0001850467289719626, 'epoch': 4.09}
外层迭代结束！
外层迭代结束！
{'loss': 0.0475, 'learning_rate': 0.00018224299065420558, 'epoch': 4.18}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0289, 'learning_rate': 0.00017943925233644857, 'epoch': 4.27}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.19it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.91it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.01it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.56it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.33it/s][A                                                  
                                               [A 43%|████▎     | 480/1120 [06:49<08:28,  1.26it/s]
100%|██████████| 13/13 [00:00<00:00, 14.33it/s][A
                                               [A 43%|████▎     | 481/1120 [06:50<12:27,  1.17s/it] 43%|████▎     | 482/1120 [06:51<11:08,  1.05s/it] 43%|████▎     | 483/1120 [06:51<10:14,  1.04it/s] 43%|████▎     | 484/1120 [06:52<09:33,  1.11it/s] 43%|████▎     | 485/1120 [06:53<09:46,  1.08it/s] 43%|████▎     | 486/1120 [06:54<09:15,  1.14it/s] 43%|████▎     | 487/1120 [06:55<08:58,  1.18it/s] 44%|████▎     | 488/1120 [06:55<08:41,  1.21it/s] 44%|████▎     | 489/1120 [06:56<09:09,  1.15it/s] 44%|████▍     | 490/1120 [06:57<08:49,  1.19it/s]                                                   44%|████▍     | 490/1120 [06:57<08:49,  1.19it/s] 44%|████▍     | 491/1120 [06:58<08:38,  1.21it/s] 44%|████▍     | 492/1120 [06:59<08:27,  1.24it/s] 44%|████▍     | 493/1120 [07:00<08:58,  1.17it/s] 44%|████▍     | 494/1120 [07:00<08:40,  1.20it/s] 44%|████▍     | 495/1120 [07:01<08:27,  1.23it/s] 44%|████▍     | 496/1120 [07:02<08:18,  1.25it/s] 44%|████▍     | 497/1120 [07:03<08:51,  1.17it/s] 44%|████▍     | 498/1120 [07:04<08:34,  1.21it/s] 45%|████▍     | 499/1120 [07:04<08:19,  1.24it/s] 45%|████▍     | 500/1120 [07:05<08:11,  1.26it/s]                                                   45%|████▍     | 500/1120 [07:05<08:11,  1.26it/s] 45%|████▍     | 501/1120 [07:06<08:44,  1.18it/s] 45%|████▍     | 502/1120 [07:07<08:27,  1.22it/s] 45%|████▍     | 503/1120 [07:08<08:14,  1.25it/s] 45%|████▌     | 504/1120 [07:08<08:05,  1.27it/s] 45%|████▌     | 505/1120 [07:09<08:38,  1.19it/s] 45%|████▌     | 506/1120 [07:10<08:23,  1.22it/s] 45%|████▌     | 507/1120 [07:11<08:12,  1.25it/s] 45%|████▌     | 508/1120 [07:12<08:03,  1.26it/s] 45%|████▌     | 509/1120 [07:13<08:35,  1.19it/s] 46%|████▌     | 510/1120 [07:13<08:19,  1.22it/s]                                                   46%|████▌     | 510/1120 [07:13<08:19,  1.22it/s] 46%|████▌     | 511/1120 [07:14<08:07,  1.25it/s] 46%|████▌     | 512/1120 [07:15<08:01,  1.26it/s] 46%|████▌     | 513/1120 [07:16<08:32,  1.18it/s] 46%|████▌     | 514/1120 [07:17<08:15,  1.22it/s] 46%|████▌     | 515/1120 [07:17<08:03,  1.25it/s] 46%|████▌     | 516/1120 [07:18<07:56,  1.27it/s] 46%|████▌     | 517/1120 [07:19<08:27,  1.19it/s] 46%|████▋     | 518/1120 [07:20<08:11,  1.22it/s] 46%|████▋     | 519/1120 [07:21<08:01,  1.25it/s] 46%|████▋     | 520/1120 [07:21<07:51,  1.27it/s]                                                   46%|████▋     | 520/1120 [07:22<07:51,  1.27it/s]{'eval_loss': 0.13843776285648346, 'eval_runtime': 0.9516, 'eval_samples_per_second': 105.088, 'eval_steps_per_second': 13.661, 'epoch': 4.27}
外层迭代结束！
外层迭代结束！
{'loss': 0.0373, 'learning_rate': 0.00017663551401869156, 'epoch': 4.36}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0377, 'learning_rate': 0.00017383177570093455, 'epoch': 4.44}
外层迭代结束！
外层迭代结束！
{'loss': 0.0663, 'learning_rate': 0.00017102803738317754, 'epoch': 4.53}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0463, 'learning_rate': 0.00016822429906542053, 'epoch': 4.62}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.46it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.13it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.33it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.81it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.53it/s][A                                                  
                                               [A 46%|████▋     | 520/1120 [07:23<07:51,  1.27it/s]
100%|██████████| 13/13 [00:00<00:00, 14.53it/s][A
                                               [A 47%|████▋     | 521/1120 [07:24<11:36,  1.16s/it] 47%|████▋     | 522/1120 [07:24<10:22,  1.04s/it] 47%|████▋     | 523/1120 [07:25<09:30,  1.05it/s] 47%|████▋     | 524/1120 [07:26<08:55,  1.11it/s] 47%|████▋     | 525/1120 [07:27<09:07,  1.09it/s] 47%|████▋     | 526/1120 [07:28<08:37,  1.15it/s] 47%|████▋     | 527/1120 [07:28<08:16,  1.20it/s] 47%|████▋     | 528/1120 [07:29<08:01,  1.23it/s] 47%|████▋     | 529/1120 [07:30<08:29,  1.16it/s] 47%|████▋     | 530/1120 [07:31<08:09,  1.21it/s]                                                   47%|████▋     | 530/1120 [07:31<08:09,  1.21it/s] 47%|████▋     | 531/1120 [07:32<07:55,  1.24it/s] 48%|████▊     | 532/1120 [07:32<07:45,  1.26it/s] 48%|████▊     | 533/1120 [07:33<08:16,  1.18it/s] 48%|████▊     | 534/1120 [07:34<07:59,  1.22it/s] 48%|████▊     | 535/1120 [07:35<07:50,  1.24it/s] 48%|████▊     | 536/1120 [07:36<07:41,  1.26it/s] 48%|████▊     | 537/1120 [07:37<08:13,  1.18it/s] 48%|████▊     | 538/1120 [07:37<07:59,  1.21it/s] 48%|████▊     | 539/1120 [07:38<07:48,  1.24it/s] 48%|████▊     | 540/1120 [07:39<07:38,  1.26it/s]                                                   48%|████▊     | 540/1120 [07:39<07:38,  1.26it/s] 48%|████▊     | 541/1120 [07:40<08:09,  1.18it/s] 48%|████▊     | 542/1120 [07:41<07:55,  1.22it/s] 48%|████▊     | 543/1120 [07:41<07:44,  1.24it/s] 49%|████▊     | 544/1120 [07:42<07:36,  1.26it/s] 49%|████▊     | 545/1120 [07:43<08:07,  1.18it/s] 49%|████▉     | 546/1120 [07:44<07:51,  1.22it/s] 49%|████▉     | 547/1120 [07:45<07:41,  1.24it/s] 49%|████▉     | 548/1120 [07:45<07:33,  1.26it/s] 49%|████▉     | 549/1120 [07:46<08:03,  1.18it/s] 49%|████▉     | 550/1120 [07:47<07:48,  1.22it/s]                                                   49%|████▉     | 550/1120 [07:47<07:48,  1.22it/s] 49%|████▉     | 551/1120 [07:48<07:38,  1.24it/s] 49%|████▉     | 552/1120 [07:49<07:29,  1.26it/s] 49%|████▉     | 553/1120 [07:50<07:59,  1.18it/s] 49%|████▉     | 554/1120 [07:50<07:44,  1.22it/s] 50%|████▉     | 555/1120 [07:51<07:34,  1.24it/s] 50%|████▉     | 556/1120 [07:52<07:26,  1.26it/s] 50%|████▉     | 557/1120 [07:53<07:56,  1.18it/s] 50%|████▉     | 558/1120 [07:54<07:41,  1.22it/s] 50%|████▉     | 559/1120 [07:54<07:30,  1.24it/s] 50%|█████     | 560/1120 [07:55<07:23,  1.26it/s]                                                   50%|█████     | 560/1120 [07:55<07:23,  1.26it/s]{'eval_loss': 0.15291118621826172, 'eval_runtime': 0.9387, 'eval_samples_per_second': 106.529, 'eval_steps_per_second': 13.849, 'epoch': 4.62}
外层迭代结束！
外层迭代结束！
{'loss': 0.0603, 'learning_rate': 0.00016542056074766352, 'epoch': 4.71}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0441, 'learning_rate': 0.00016261682242990652, 'epoch': 4.8}
外层迭代结束！
外层迭代结束！
{'loss': 0.0339, 'learning_rate': 0.0001598130841121495, 'epoch': 4.89}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0315, 'learning_rate': 0.0001570093457943925, 'epoch': 4.98}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.23it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.86it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 14.97it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.48it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.21it/s][A                                                  
                                               [A 50%|█████     | 560/1120 [07:56<07:23,  1.26it/s]
100%|██████████| 13/13 [00:00<00:00, 14.21it/s][A
                                               [A 50%|█████     | 561/1120 [07:57<10:56,  1.18s/it] 50%|█████     | 562/1120 [07:58<09:47,  1.05s/it] 50%|█████     | 563/1120 [07:59<08:58,  1.03it/s] 50%|█████     | 564/1120 [08:00<08:23,  1.10it/s] 50%|█████     | 565/1120 [08:00<08:33,  1.08it/s] 51%|█████     | 566/1120 [08:01<08:06,  1.14it/s] 51%|█████     | 567/1120 [08:02<07:46,  1.19it/s] 51%|█████     | 568/1120 [08:03<07:32,  1.22it/s] 51%|█████     | 569/1120 [08:04<07:56,  1.16it/s] 51%|█████     | 570/1120 [08:05<07:39,  1.20it/s]                                                   51%|█████     | 570/1120 [08:05<07:39,  1.20it/s] 51%|█████     | 571/1120 [08:05<07:26,  1.23it/s] 51%|█████     | 572/1120 [08:06<07:17,  1.25it/s] 51%|█████     | 573/1120 [08:07<07:48,  1.17it/s] 51%|█████▏    | 574/1120 [08:08<07:32,  1.21it/s] 51%|█████▏    | 575/1120 [08:09<07:21,  1.24it/s] 51%|█████▏    | 576/1120 [08:09<07:12,  1.26it/s] 52%|█████▏    | 577/1120 [08:10<07:40,  1.18it/s] 52%|█████▏    | 578/1120 [08:11<07:26,  1.21it/s] 52%|█████▏    | 579/1120 [08:12<07:17,  1.24it/s] 52%|█████▏    | 580/1120 [08:13<07:09,  1.26it/s]                                                   52%|█████▏    | 580/1120 [08:13<07:09,  1.26it/s] 52%|█████▏    | 581/1120 [08:14<07:38,  1.17it/s] 52%|█████▏    | 582/1120 [08:14<07:23,  1.21it/s] 52%|█████▏    | 583/1120 [08:15<07:14,  1.24it/s] 52%|█████▏    | 584/1120 [08:16<07:06,  1.26it/s] 52%|█████▏    | 585/1120 [08:17<07:33,  1.18it/s] 52%|█████▏    | 586/1120 [08:18<07:20,  1.21it/s] 52%|█████▏    | 587/1120 [08:18<07:08,  1.24it/s] 52%|█████▎    | 588/1120 [08:19<07:01,  1.26it/s] 53%|█████▎    | 589/1120 [08:20<07:29,  1.18it/s] 53%|█████▎    | 590/1120 [08:21<07:16,  1.21it/s]                                                   53%|█████▎    | 590/1120 [08:21<07:16,  1.21it/s] 53%|█████▎    | 591/1120 [08:22<07:06,  1.24it/s] 53%|█████▎    | 592/1120 [08:22<07:00,  1.26it/s] 53%|█████▎    | 593/1120 [08:23<07:27,  1.18it/s] 53%|█████▎    | 594/1120 [08:24<07:13,  1.21it/s] 53%|█████▎    | 595/1120 [08:25<07:05,  1.23it/s] 53%|█████▎    | 596/1120 [08:26<07:00,  1.25it/s] 53%|█████▎    | 597/1120 [08:27<07:29,  1.16it/s] 53%|█████▎    | 598/1120 [08:27<07:16,  1.20it/s] 53%|█████▎    | 599/1120 [08:28<07:08,  1.22it/s] 54%|█████▎    | 600/1120 [08:29<07:03,  1.23it/s]                                                   54%|█████▎    | 600/1120 [08:29<07:03,  1.23it/s]{'eval_loss': 0.17365345358848572, 'eval_runtime': 0.9596, 'eval_samples_per_second': 104.209, 'eval_steps_per_second': 13.547, 'epoch': 4.98}
外层迭代结束！
外层迭代结束！
{'loss': 0.0369, 'learning_rate': 0.0001542056074766355, 'epoch': 5.07}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0129, 'learning_rate': 0.00015140186915887848, 'epoch': 5.16}
外层迭代结束！
外层迭代结束！
{'loss': 0.078, 'learning_rate': 0.00014859813084112147, 'epoch': 5.24}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0464, 'learning_rate': 0.00014579439252336446, 'epoch': 5.33}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.76it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 15.73it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 14.90it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 14.51it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 14.21it/s][A
100%|██████████| 13/13 [00:00<00:00, 14.18it/s][A                                                  
                                               [A 54%|█████▎    | 600/1120 [08:30<07:03,  1.23it/s]
100%|██████████| 13/13 [00:00<00:00, 14.18it/s][A
                                               [A 54%|█████▎    | 601/1120 [08:31<10:21,  1.20s/it] 54%|█████▍    | 602/1120 [08:32<09:16,  1.07s/it] 54%|█████▍    | 603/1120 [08:33<08:30,  1.01it/s] 54%|█████▍    | 604/1120 [08:34<07:57,  1.08it/s] 54%|█████▍    | 605/1120 [08:35<08:06,  1.06it/s] 54%|█████▍    | 606/1120 [08:35<07:41,  1.11it/s] 54%|█████▍    | 607/1120 [08:36<07:22,  1.16it/s] 54%|█████▍    | 608/1120 [08:37<07:07,  1.20it/s] 54%|█████▍    | 609/1120 [08:38<07:32,  1.13it/s] 54%|█████▍    | 610/1120 [08:39<07:12,  1.18it/s]                                                   54%|█████▍    | 610/1120 [08:39<07:12,  1.18it/s] 55%|█████▍    | 611/1120 [08:39<07:01,  1.21it/s] 55%|█████▍    | 612/1120 [08:40<06:52,  1.23it/s] 55%|█████▍    | 613/1120 [08:41<07:17,  1.16it/s] 55%|█████▍    | 614/1120 [08:42<07:01,  1.20it/s] 55%|█████▍    | 615/1120 [08:43<06:47,  1.24it/s] 55%|█████▌    | 616/1120 [08:43<06:39,  1.26it/s] 55%|█████▌    | 617/1120 [08:44<07:03,  1.19it/s] 55%|█████▌    | 618/1120 [08:45<06:49,  1.22it/s] 55%|█████▌    | 619/1120 [08:46<06:40,  1.25it/s] 55%|█████▌    | 620/1120 [08:47<06:36,  1.26it/s]                                                   55%|█████▌    | 620/1120 [08:47<06:36,  1.26it/s] 55%|█████▌    | 621/1120 [08:48<07:08,  1.17it/s] 56%|█████▌    | 622/1120 [08:48<06:54,  1.20it/s] 56%|█████▌    | 623/1120 [08:49<06:44,  1.23it/s] 56%|█████▌    | 624/1120 [08:50<06:38,  1.25it/s] 56%|█████▌    | 625/1120 [08:51<07:06,  1.16it/s] 56%|█████▌    | 626/1120 [08:52<06:53,  1.20it/s] 56%|█████▌    | 627/1120 [08:53<06:43,  1.22it/s] 56%|█████▌    | 628/1120 [08:53<06:38,  1.23it/s] 56%|█████▌    | 629/1120 [08:54<07:03,  1.16it/s] 56%|█████▋    | 630/1120 [08:55<06:50,  1.19it/s]                                                   56%|█████▋    | 630/1120 [08:55<06:50,  1.19it/s] 56%|█████▋    | 631/1120 [08:56<06:41,  1.22it/s] 56%|█████▋    | 632/1120 [08:57<06:33,  1.24it/s] 57%|█████▋    | 633/1120 [08:58<07:01,  1.15it/s] 57%|█████▋    | 634/1120 [08:58<06:46,  1.20it/s] 57%|█████▋    | 635/1120 [08:59<06:38,  1.22it/s] 57%|█████▋    | 636/1120 [09:00<06:30,  1.24it/s] 57%|█████▋    | 637/1120 [09:01<06:57,  1.16it/s] 57%|█████▋    | 638/1120 [09:02<06:45,  1.19it/s] 57%|█████▋    | 639/1120 [09:03<06:32,  1.22it/s] 57%|█████▋    | 640/1120 [09:03<06:26,  1.24it/s]                                                   57%|█████▋    | 640/1120 [09:04<06:26,  1.24it/s]{'eval_loss': 0.19891740381717682, 'eval_runtime': 0.9609, 'eval_samples_per_second': 104.071, 'eval_steps_per_second': 13.529, 'epoch': 5.33}
外层迭代结束！
外层迭代结束！
{'loss': 0.0169, 'learning_rate': 0.00014299065420560745, 'epoch': 5.42}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0303, 'learning_rate': 0.00014018691588785044, 'epoch': 5.51}
外层迭代结束！
外层迭代结束！
{'loss': 0.0214, 'learning_rate': 0.00013738317757009343, 'epoch': 5.6}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0289, 'learning_rate': 0.00013457943925233642, 'epoch': 5.69}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.48it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 16.08it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 14.95it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 14.44it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 14.18it/s][A
100%|██████████| 13/13 [00:00<00:00, 14.06it/s][A                                                  
                                               [A 57%|█████▋    | 640/1120 [09:05<06:26,  1.24it/s]
100%|██████████| 13/13 [00:00<00:00, 14.06it/s][A
                                               [A 57%|█████▋    | 641/1120 [09:05<09:35,  1.20s/it] 57%|█████▋    | 642/1120 [09:06<08:38,  1.08s/it] 57%|█████▋    | 643/1120 [09:07<07:58,  1.00s/it] 57%|█████▊    | 644/1120 [09:08<07:29,  1.06it/s] 58%|█████▊    | 645/1120 [09:09<07:38,  1.04it/s] 58%|█████▊    | 646/1120 [09:10<07:13,  1.09it/s] 58%|█████▊    | 647/1120 [09:10<06:54,  1.14it/s] 58%|█████▊    | 648/1120 [09:11<06:44,  1.17it/s] 58%|█████▊    | 649/1120 [09:12<07:06,  1.11it/s] 58%|█████▊    | 650/1120 [09:13<06:52,  1.14it/s]                                                   58%|█████▊    | 650/1120 [09:13<06:52,  1.14it/s] 58%|█████▊    | 651/1120 [09:14<06:44,  1.16it/s] 58%|█████▊    | 652/1120 [09:15<06:36,  1.18it/s] 58%|█████▊    | 653/1120 [09:16<07:03,  1.10it/s] 58%|█████▊    | 654/1120 [09:17<06:44,  1.15it/s] 58%|█████▊    | 655/1120 [09:17<06:36,  1.17it/s] 59%|█████▊    | 656/1120 [09:18<06:28,  1.19it/s] 59%|█████▊    | 657/1120 [09:19<06:53,  1.12it/s] 59%|█████▉    | 658/1120 [09:20<06:38,  1.16it/s] 59%|█████▉    | 659/1120 [09:21<06:26,  1.19it/s] 59%|█████▉    | 660/1120 [09:22<06:20,  1.21it/s]                                                   59%|█████▉    | 660/1120 [09:22<06:20,  1.21it/s] 59%|█████▉    | 661/1120 [09:23<06:45,  1.13it/s] 59%|█████▉    | 662/1120 [09:23<06:31,  1.17it/s] 59%|█████▉    | 663/1120 [09:24<06:22,  1.19it/s] 59%|█████▉    | 664/1120 [09:25<06:17,  1.21it/s] 59%|█████▉    | 665/1120 [09:26<06:42,  1.13it/s] 59%|█████▉    | 666/1120 [09:27<06:28,  1.17it/s] 60%|█████▉    | 667/1120 [09:28<06:19,  1.19it/s] 60%|█████▉    | 668/1120 [09:28<06:13,  1.21it/s] 60%|█████▉    | 669/1120 [09:29<06:36,  1.14it/s] 60%|█████▉    | 670/1120 [09:30<06:24,  1.17it/s]                                                   60%|█████▉    | 670/1120 [09:30<06:24,  1.17it/s] 60%|█████▉    | 671/1120 [09:31<06:16,  1.19it/s] 60%|██████    | 672/1120 [09:32<06:10,  1.21it/s] 60%|██████    | 673/1120 [09:33<06:34,  1.13it/s] 60%|██████    | 674/1120 [09:34<06:21,  1.17it/s] 60%|██████    | 675/1120 [09:34<06:13,  1.19it/s] 60%|██████    | 676/1120 [09:35<06:07,  1.21it/s] 60%|██████    | 677/1120 [09:36<06:30,  1.14it/s] 61%|██████    | 678/1120 [09:37<06:18,  1.17it/s] 61%|██████    | 679/1120 [09:38<06:10,  1.19it/s] 61%|██████    | 680/1120 [09:39<06:04,  1.21it/s]                                                   61%|██████    | 680/1120 [09:39<06:04,  1.21it/s]{'eval_loss': 0.20225049555301666, 'eval_runtime': 0.9654, 'eval_samples_per_second': 103.58, 'eval_steps_per_second': 13.465, 'epoch': 5.69}
外层迭代结束！
外层迭代结束！
{'loss': 0.0238, 'learning_rate': 0.0001317757009345794, 'epoch': 5.78}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0121, 'learning_rate': 0.0001289719626168224, 'epoch': 5.87}
外层迭代结束！
外层迭代结束！
{'loss': 0.0381, 'learning_rate': 0.0001261682242990654, 'epoch': 5.96}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0537, 'learning_rate': 0.00012336448598130838, 'epoch': 6.04}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.62it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.06it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.20it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.69it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.45it/s][A                                                  
                                               [A 61%|██████    | 680/1120 [09:40<06:04,  1.21it/s]
100%|██████████| 13/13 [00:00<00:00, 14.45it/s][A
                                               [A 61%|██████    | 681/1120 [09:41<08:54,  1.22s/it] 61%|██████    | 682/1120 [09:42<07:59,  1.09s/it] 61%|██████    | 683/1120 [09:42<07:18,  1.00s/it] 61%|██████    | 684/1120 [09:43<06:50,  1.06it/s] 61%|██████    | 685/1120 [09:44<06:57,  1.04it/s] 61%|██████▏   | 686/1120 [09:45<06:34,  1.10it/s] 61%|██████▏   | 687/1120 [09:46<06:19,  1.14it/s] 61%|██████▏   | 688/1120 [09:47<06:08,  1.17it/s] 62%|██████▏   | 689/1120 [09:48<06:29,  1.11it/s] 62%|██████▏   | 690/1120 [09:48<06:14,  1.15it/s]                                                   62%|██████▏   | 690/1120 [09:48<06:14,  1.15it/s] 62%|██████▏   | 691/1120 [09:49<06:04,  1.18it/s] 62%|██████▏   | 692/1120 [09:50<05:57,  1.20it/s] 62%|██████▏   | 693/1120 [09:51<06:18,  1.13it/s] 62%|██████▏   | 694/1120 [09:52<06:01,  1.18it/s] 62%|██████▏   | 695/1120 [09:53<05:58,  1.19it/s] 62%|██████▏   | 696/1120 [09:53<05:57,  1.19it/s] 62%|██████▏   | 697/1120 [09:54<06:10,  1.14it/s] 62%|██████▏   | 698/1120 [09:55<05:48,  1.21it/s] 62%|██████▏   | 699/1120 [09:56<05:33,  1.26it/s] 62%|██████▎   | 700/1120 [09:56<05:23,  1.30it/s]                                                   62%|██████▎   | 700/1120 [09:57<05:23,  1.30it/s] 63%|██████▎   | 701/1120 [09:57<05:41,  1.23it/s] 63%|██████▎   | 702/1120 [09:58<05:28,  1.27it/s] 63%|██████▎   | 703/1120 [09:59<05:21,  1.30it/s] 63%|██████▎   | 704/1120 [10:00<05:14,  1.32it/s] 63%|██████▎   | 705/1120 [10:00<05:33,  1.25it/s] 63%|██████▎   | 706/1120 [10:01<05:21,  1.29it/s] 63%|██████▎   | 707/1120 [10:02<05:12,  1.32it/s] 63%|██████▎   | 708/1120 [10:03<05:06,  1.34it/s] 63%|██████▎   | 709/1120 [10:04<05:26,  1.26it/s] 63%|██████▎   | 710/1120 [10:04<05:16,  1.29it/s]                                                   63%|██████▎   | 710/1120 [10:04<05:16,  1.29it/s] 63%|██████▎   | 711/1120 [10:05<05:13,  1.31it/s] 64%|██████▎   | 712/1120 [10:06<05:09,  1.32it/s] 64%|██████▎   | 713/1120 [10:07<05:30,  1.23it/s] 64%|██████▍   | 714/1120 [10:07<05:21,  1.26it/s] 64%|██████▍   | 715/1120 [10:08<05:17,  1.28it/s] 64%|██████▍   | 716/1120 [10:09<05:10,  1.30it/s] 64%|██████▍   | 717/1120 [10:10<05:31,  1.22it/s] 64%|██████▍   | 718/1120 [10:11<05:20,  1.25it/s] 64%|██████▍   | 719/1120 [10:11<05:13,  1.28it/s] 64%|██████▍   | 720/1120 [10:12<05:07,  1.30it/s]                                                   64%|██████▍   | 720/1120 [10:12<05:07,  1.30it/s]{'eval_loss': 0.20666004717350006, 'eval_runtime': 0.9445, 'eval_samples_per_second': 105.877, 'eval_steps_per_second': 13.764, 'epoch': 6.04}
外层迭代结束！
外层迭代结束！
{'loss': 0.0307, 'learning_rate': 0.00012056074766355139, 'epoch': 6.13}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0451, 'learning_rate': 0.00011775700934579438, 'epoch': 6.22}
外层迭代结束！
外层迭代结束！
{'loss': 0.0348, 'learning_rate': 0.00011495327102803737, 'epoch': 6.31}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0436, 'learning_rate': 0.00011214953271028036, 'epoch': 6.4}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.23it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.68it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.84it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.93it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.64it/s][A                                                  
                                               [A 64%|██████▍   | 720/1120 [10:13<05:07,  1.30it/s]
100%|██████████| 13/13 [00:00<00:00, 14.64it/s][A
                                               [A 64%|██████▍   | 721/1120 [10:14<07:43,  1.16s/it] 64%|██████▍   | 722/1120 [10:15<06:50,  1.03s/it] 65%|██████▍   | 723/1120 [10:16<06:17,  1.05it/s] 65%|██████▍   | 724/1120 [10:16<05:51,  1.13it/s] 65%|██████▍   | 725/1120 [10:17<05:57,  1.10it/s] 65%|██████▍   | 726/1120 [10:18<05:38,  1.16it/s] 65%|██████▍   | 727/1120 [10:19<05:20,  1.23it/s] 65%|██████▌   | 728/1120 [10:20<05:13,  1.25it/s] 65%|██████▌   | 729/1120 [10:21<05:29,  1.19it/s] 65%|██████▌   | 730/1120 [10:21<05:18,  1.22it/s]                                                   65%|██████▌   | 730/1120 [10:21<05:18,  1.22it/s] 65%|██████▌   | 731/1120 [10:22<05:10,  1.25it/s] 65%|██████▌   | 732/1120 [10:23<05:02,  1.28it/s] 65%|██████▌   | 733/1120 [10:24<05:21,  1.20it/s] 66%|██████▌   | 734/1120 [10:24<05:10,  1.24it/s] 66%|██████▌   | 735/1120 [10:25<05:03,  1.27it/s] 66%|██████▌   | 736/1120 [10:26<04:59,  1.28it/s] 66%|██████▌   | 737/1120 [10:27<05:16,  1.21it/s] 66%|██████▌   | 738/1120 [10:28<05:06,  1.25it/s] 66%|██████▌   | 739/1120 [10:28<04:58,  1.27it/s] 66%|██████▌   | 740/1120 [10:29<04:52,  1.30it/s]                                                   66%|██████▌   | 740/1120 [10:29<04:52,  1.30it/s] 66%|██████▌   | 741/1120 [10:30<05:14,  1.21it/s] 66%|██████▋   | 742/1120 [10:31<05:01,  1.25it/s] 66%|██████▋   | 743/1120 [10:32<04:54,  1.28it/s] 66%|██████▋   | 744/1120 [10:32<04:49,  1.30it/s] 67%|██████▋   | 745/1120 [10:33<05:10,  1.21it/s] 67%|██████▋   | 746/1120 [10:34<05:00,  1.25it/s] 67%|██████▋   | 747/1120 [10:35<04:52,  1.28it/s] 67%|██████▋   | 748/1120 [10:35<04:45,  1.30it/s] 67%|██████▋   | 749/1120 [10:36<05:03,  1.22it/s] 67%|██████▋   | 750/1120 [10:37<04:52,  1.26it/s]                                                   67%|██████▋   | 750/1120 [10:37<04:52,  1.26it/s] 67%|██████▋   | 751/1120 [10:38<04:47,  1.28it/s] 67%|██████▋   | 752/1120 [10:39<04:41,  1.31it/s] 67%|██████▋   | 753/1120 [10:40<04:59,  1.22it/s] 67%|██████▋   | 754/1120 [10:40<04:51,  1.26it/s] 67%|██████▋   | 755/1120 [10:41<04:40,  1.30it/s] 68%|██████▊   | 756/1120 [10:42<04:35,  1.32it/s] 68%|██████▊   | 757/1120 [10:43<04:52,  1.24it/s] 68%|██████▊   | 758/1120 [10:43<04:44,  1.27it/s] 68%|██████▊   | 759/1120 [10:44<04:38,  1.30it/s] 68%|██████▊   | 760/1120 [10:45<04:33,  1.32it/s]                                                   68%|██████▊   | 760/1120 [10:45<04:33,  1.32it/s]{'eval_loss': 0.22641080617904663, 'eval_runtime': 0.92, 'eval_samples_per_second': 108.691, 'eval_steps_per_second': 14.13, 'epoch': 6.4}
外层迭代结束！
外层迭代结束！
{'loss': 0.0263, 'learning_rate': 0.00010934579439252335, 'epoch': 6.49}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0092, 'learning_rate': 0.00010654205607476634, 'epoch': 6.58}
外层迭代结束！
外层迭代结束！
{'loss': 0.0228, 'learning_rate': 0.00010373831775700933, 'epoch': 6.67}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0049, 'learning_rate': 0.00010093457943925232, 'epoch': 6.76}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.24it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.76it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.81it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.33it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.10it/s][A                                                  
                                               [A 68%|██████▊   | 760/1120 [10:46<04:33,  1.32it/s]
100%|██████████| 13/13 [00:00<00:00, 15.10it/s][A
                                               [A 68%|██████▊   | 761/1120 [10:47<06:44,  1.13s/it] 68%|██████▊   | 762/1120 [10:48<06:01,  1.01s/it] 68%|██████▊   | 763/1120 [10:48<05:30,  1.08it/s] 68%|██████▊   | 764/1120 [10:49<05:08,  1.15it/s] 68%|██████▊   | 765/1120 [10:50<05:13,  1.13it/s] 68%|██████▊   | 766/1120 [10:51<04:55,  1.20it/s] 68%|██████▊   | 767/1120 [10:51<04:43,  1.24it/s] 69%|██████▊   | 768/1120 [10:52<04:34,  1.28it/s] 69%|██████▊   | 769/1120 [10:53<04:48,  1.22it/s] 69%|██████▉   | 770/1120 [10:54<04:37,  1.26it/s]                                                   69%|██████▉   | 770/1120 [10:54<04:37,  1.26it/s] 69%|██████▉   | 771/1120 [10:55<04:30,  1.29it/s] 69%|██████▉   | 772/1120 [10:55<04:23,  1.32it/s] 69%|██████▉   | 773/1120 [10:56<04:41,  1.23it/s] 69%|██████▉   | 774/1120 [10:57<04:31,  1.28it/s] 69%|██████▉   | 775/1120 [10:58<04:24,  1.30it/s] 69%|██████▉   | 776/1120 [10:58<04:19,  1.33it/s] 69%|██████▉   | 777/1120 [10:59<04:36,  1.24it/s] 69%|██████▉   | 778/1120 [11:00<04:28,  1.27it/s] 70%|██████▉   | 779/1120 [11:01<04:22,  1.30it/s] 70%|██████▉   | 780/1120 [11:02<04:17,  1.32it/s]                                                   70%|██████▉   | 780/1120 [11:02<04:17,  1.32it/s] 70%|██████▉   | 781/1120 [11:02<04:35,  1.23it/s] 70%|██████▉   | 782/1120 [11:03<04:27,  1.27it/s] 70%|██████▉   | 783/1120 [11:04<04:21,  1.29it/s] 70%|███████   | 784/1120 [11:05<04:17,  1.30it/s] 70%|███████   | 785/1120 [11:06<04:34,  1.22it/s] 70%|███████   | 786/1120 [11:06<04:26,  1.25it/s] 70%|███████   | 787/1120 [11:07<04:18,  1.29it/s] 70%|███████   | 788/1120 [11:08<04:14,  1.30it/s] 70%|███████   | 789/1120 [11:09<04:32,  1.22it/s] 71%|███████   | 790/1120 [11:10<04:23,  1.25it/s]                                                   71%|███████   | 790/1120 [11:10<04:23,  1.25it/s] 71%|███████   | 791/1120 [11:10<04:16,  1.28it/s] 71%|███████   | 792/1120 [11:11<04:12,  1.30it/s] 71%|███████   | 793/1120 [11:12<04:29,  1.21it/s] 71%|███████   | 794/1120 [11:13<04:21,  1.25it/s] 71%|███████   | 795/1120 [11:13<04:15,  1.27it/s] 71%|███████   | 796/1120 [11:14<04:09,  1.30it/s] 71%|███████   | 797/1120 [11:15<04:24,  1.22it/s] 71%|███████▏  | 798/1120 [11:16<04:16,  1.26it/s] 71%|███████▏  | 799/1120 [11:17<04:10,  1.28it/s] 71%|███████▏  | 800/1120 [11:17<04:04,  1.31it/s]                                                   71%|███████▏  | 800/1120 [11:18<04:04,  1.31it/s]{'eval_loss': 0.2222014218568802, 'eval_runtime': 0.9072, 'eval_samples_per_second': 110.232, 'eval_steps_per_second': 14.33, 'epoch': 6.76}
外层迭代结束！
外层迭代结束！
{'loss': 0.0237, 'learning_rate': 9.813084112149531e-05, 'epoch': 6.84}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0504, 'learning_rate': 9.53271028037383e-05, 'epoch': 6.93}
外层迭代结束！
外层迭代结束！
{'loss': 0.007, 'learning_rate': 9.25233644859813e-05, 'epoch': 7.02}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0343, 'learning_rate': 8.971962616822429e-05, 'epoch': 7.11}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.61it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.42it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.62it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.03it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.68it/s][A                                                  
                                               [A 71%|███████▏  | 800/1120 [11:18<04:04,  1.31it/s]
100%|██████████| 13/13 [00:00<00:00, 14.68it/s][A
                                               [A 72%|███████▏  | 801/1120 [11:19<06:03,  1.14s/it] 72%|███████▏  | 802/1120 [11:20<05:25,  1.02s/it] 72%|███████▏  | 803/1120 [11:21<04:57,  1.07it/s] 72%|███████▏  | 804/1120 [11:22<04:38,  1.14it/s] 72%|███████▏  | 805/1120 [11:23<04:42,  1.11it/s] 72%|███████▏  | 806/1120 [11:23<04:25,  1.18it/s] 72%|███████▏  | 807/1120 [11:24<04:15,  1.22it/s] 72%|███████▏  | 808/1120 [11:25<04:08,  1.26it/s] 72%|███████▏  | 809/1120 [11:26<04:20,  1.19it/s] 72%|███████▏  | 810/1120 [11:26<04:12,  1.23it/s]                                                   72%|███████▏  | 810/1120 [11:26<04:12,  1.23it/s] 72%|███████▏  | 811/1120 [11:27<04:04,  1.26it/s] 72%|███████▎  | 812/1120 [11:28<04:00,  1.28it/s] 73%|███████▎  | 813/1120 [11:29<04:16,  1.20it/s] 73%|███████▎  | 814/1120 [11:30<04:08,  1.23it/s] 73%|███████▎  | 815/1120 [11:30<04:02,  1.26it/s] 73%|███████▎  | 816/1120 [11:31<03:56,  1.29it/s] 73%|███████▎  | 817/1120 [11:32<04:10,  1.21it/s] 73%|███████▎  | 818/1120 [11:33<04:02,  1.25it/s] 73%|███████▎  | 819/1120 [11:34<03:54,  1.28it/s] 73%|███████▎  | 820/1120 [11:34<03:51,  1.30it/s]                                                   73%|███████▎  | 820/1120 [11:35<03:51,  1.30it/s] 73%|███████▎  | 821/1120 [11:35<04:06,  1.21it/s] 73%|███████▎  | 822/1120 [11:36<03:58,  1.25it/s] 73%|███████▎  | 823/1120 [11:37<03:54,  1.27it/s] 74%|███████▎  | 824/1120 [11:37<03:47,  1.30it/s] 74%|███████▎  | 825/1120 [11:38<04:05,  1.20it/s] 74%|███████▍  | 826/1120 [11:39<03:56,  1.24it/s] 74%|███████▍  | 827/1120 [11:40<03:51,  1.27it/s] 74%|███████▍  | 828/1120 [11:41<03:47,  1.28it/s] 74%|███████▍  | 829/1120 [11:42<04:02,  1.20it/s] 74%|███████▍  | 830/1120 [11:42<03:56,  1.23it/s]                                                   74%|███████▍  | 830/1120 [11:42<03:56,  1.23it/s] 74%|███████▍  | 831/1120 [11:43<03:49,  1.26it/s] 74%|███████▍  | 832/1120 [11:44<03:44,  1.28it/s] 74%|███████▍  | 833/1120 [11:45<03:59,  1.20it/s] 74%|███████▍  | 834/1120 [11:46<03:49,  1.25it/s] 75%|███████▍  | 835/1120 [11:46<03:44,  1.27it/s] 75%|███████▍  | 836/1120 [11:47<03:40,  1.29it/s] 75%|███████▍  | 837/1120 [11:48<03:56,  1.20it/s] 75%|███████▍  | 838/1120 [11:49<03:48,  1.23it/s] 75%|███████▍  | 839/1120 [11:50<03:40,  1.27it/s] 75%|███████▌  | 840/1120 [11:50<03:38,  1.28it/s]                                                   75%|███████▌  | 840/1120 [11:51<03:38,  1.28it/s]{'eval_loss': 0.23999574780464172, 'eval_runtime': 0.9269, 'eval_samples_per_second': 107.882, 'eval_steps_per_second': 14.025, 'epoch': 7.11}
外层迭代结束！
外层迭代结束！
{'loss': 0.0156, 'learning_rate': 8.691588785046728e-05, 'epoch': 7.2}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.016, 'learning_rate': 8.411214953271027e-05, 'epoch': 7.29}
外层迭代结束！
外层迭代结束！
{'loss': 0.0327, 'learning_rate': 8.130841121495326e-05, 'epoch': 7.38}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0229, 'learning_rate': 7.850467289719625e-05, 'epoch': 7.47}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.46it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 16.58it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 15.43it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 14.95it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 14.78it/s][A
100%|██████████| 13/13 [00:00<00:00, 14.54it/s][A                                                  
                                               [A 75%|███████▌  | 840/1120 [11:52<03:38,  1.28it/s]
100%|██████████| 13/13 [00:00<00:00, 14.54it/s][A
                                               [A 75%|███████▌  | 841/1120 [11:53<05:31,  1.19s/it] 75%|███████▌  | 842/1120 [11:53<04:54,  1.06s/it] 75%|███████▌  | 843/1120 [11:54<04:29,  1.03it/s] 75%|███████▌  | 844/1120 [11:55<04:11,  1.10it/s] 75%|███████▌  | 845/1120 [11:56<04:13,  1.09it/s] 76%|███████▌  | 846/1120 [11:57<04:00,  1.14it/s] 76%|███████▌  | 847/1120 [11:57<03:50,  1.19it/s] 76%|███████▌  | 848/1120 [11:58<03:41,  1.23it/s] 76%|███████▌  | 849/1120 [11:59<03:51,  1.17it/s] 76%|███████▌  | 850/1120 [12:00<03:39,  1.23it/s]                                                   76%|███████▌  | 850/1120 [12:00<03:39,  1.23it/s] 76%|███████▌  | 851/1120 [12:00<03:33,  1.26it/s] 76%|███████▌  | 852/1120 [12:01<03:28,  1.28it/s] 76%|███████▌  | 853/1120 [12:02<03:40,  1.21it/s] 76%|███████▋  | 854/1120 [12:03<03:33,  1.24it/s] 76%|███████▋  | 855/1120 [12:04<03:26,  1.29it/s] 76%|███████▋  | 856/1120 [12:04<03:22,  1.30it/s] 77%|███████▋  | 857/1120 [12:05<03:35,  1.22it/s] 77%|███████▋  | 858/1120 [12:06<03:27,  1.26it/s] 77%|███████▋  | 859/1120 [12:07<03:22,  1.29it/s] 77%|███████▋  | 860/1120 [12:08<03:20,  1.30it/s]                                                   77%|███████▋  | 860/1120 [12:08<03:20,  1.30it/s] 77%|███████▋  | 861/1120 [12:08<03:34,  1.21it/s] 77%|███████▋  | 862/1120 [12:09<03:27,  1.24it/s] 77%|███████▋  | 863/1120 [12:10<03:20,  1.28it/s] 77%|███████▋  | 864/1120 [12:11<03:17,  1.30it/s] 77%|███████▋  | 865/1120 [12:12<03:28,  1.22it/s] 77%|███████▋  | 866/1120 [12:12<03:22,  1.25it/s] 77%|███████▋  | 867/1120 [12:13<03:17,  1.28it/s] 78%|███████▊  | 868/1120 [12:14<03:11,  1.32it/s] 78%|███████▊  | 869/1120 [12:15<03:25,  1.22it/s] 78%|███████▊  | 870/1120 [12:16<03:19,  1.25it/s]                                                   78%|███████▊  | 870/1120 [12:16<03:19,  1.25it/s] 78%|███████▊  | 871/1120 [12:16<03:14,  1.28it/s] 78%|███████▊  | 872/1120 [12:17<03:11,  1.30it/s] 78%|███████▊  | 873/1120 [12:18<03:21,  1.22it/s] 78%|███████▊  | 874/1120 [12:19<03:16,  1.25it/s] 78%|███████▊  | 875/1120 [12:19<03:10,  1.28it/s] 78%|███████▊  | 876/1120 [12:20<03:06,  1.31it/s] 78%|███████▊  | 877/1120 [12:21<03:19,  1.22it/s] 78%|███████▊  | 878/1120 [12:22<03:10,  1.27it/s] 78%|███████▊  | 879/1120 [12:23<03:06,  1.29it/s] 79%|███████▊  | 880/1120 [12:23<03:02,  1.31it/s]                                                   79%|███████▊  | 880/1120 [12:24<03:02,  1.31it/s]{'eval_loss': 0.23532500863075256, 'eval_runtime': 0.933, 'eval_samples_per_second': 107.185, 'eval_steps_per_second': 13.934, 'epoch': 7.47}
外层迭代结束！
外层迭代结束！
{'loss': 0.0145, 'learning_rate': 7.570093457943924e-05, 'epoch': 7.56}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0161, 'learning_rate': 7.289719626168223e-05, 'epoch': 7.64}
外层迭代结束！
外层迭代结束！
{'loss': 0.0126, 'learning_rate': 7.009345794392522e-05, 'epoch': 7.73}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.031, 'learning_rate': 6.728971962616821e-05, 'epoch': 7.82}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.67it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.76it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.58it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.11it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.91it/s][A                                                  
                                               [A 79%|███████▊  | 880/1120 [12:24<03:02,  1.31it/s]
100%|██████████| 13/13 [00:00<00:00, 14.91it/s][A
                                               [A 79%|███████▊  | 881/1120 [12:25<04:29,  1.13s/it] 79%|███████▉  | 882/1120 [12:26<03:59,  1.01s/it] 79%|███████▉  | 883/1120 [12:27<03:39,  1.08it/s] 79%|███████▉  | 884/1120 [12:27<03:24,  1.15it/s] 79%|███████▉  | 885/1120 [12:28<03:30,  1.12it/s] 79%|███████▉  | 886/1120 [12:29<03:19,  1.18it/s] 79%|███████▉  | 887/1120 [12:30<03:10,  1.22it/s] 79%|███████▉  | 888/1120 [12:31<03:05,  1.25it/s] 79%|███████▉  | 889/1120 [12:32<03:14,  1.19it/s] 79%|███████▉  | 890/1120 [12:32<03:07,  1.23it/s]                                                   79%|███████▉  | 890/1120 [12:32<03:07,  1.23it/s] 80%|███████▉  | 891/1120 [12:33<03:01,  1.26it/s] 80%|███████▉  | 892/1120 [12:34<02:56,  1.29it/s] 80%|███████▉  | 893/1120 [12:35<03:08,  1.21it/s] 80%|███████▉  | 894/1120 [12:36<03:01,  1.25it/s] 80%|███████▉  | 895/1120 [12:36<02:57,  1.27it/s] 80%|████████  | 896/1120 [12:37<02:53,  1.29it/s] 80%|████████  | 897/1120 [12:38<03:03,  1.22it/s] 80%|████████  | 898/1120 [12:39<02:58,  1.24it/s] 80%|████████  | 899/1120 [12:39<02:53,  1.27it/s] 80%|████████  | 900/1120 [12:40<02:49,  1.29it/s]                                                   80%|████████  | 900/1120 [12:40<02:49,  1.29it/s] 80%|████████  | 901/1120 [12:41<03:01,  1.20it/s] 81%|████████  | 902/1120 [12:42<02:54,  1.25it/s] 81%|████████  | 903/1120 [12:43<02:50,  1.28it/s] 81%|████████  | 904/1120 [12:43<02:47,  1.29it/s] 81%|████████  | 905/1120 [12:44<02:57,  1.21it/s] 81%|████████  | 906/1120 [12:45<02:50,  1.25it/s] 81%|████████  | 907/1120 [12:46<02:45,  1.28it/s] 81%|████████  | 908/1120 [12:47<02:43,  1.30it/s] 81%|████████  | 909/1120 [12:48<02:53,  1.22it/s] 81%|████████▏ | 910/1120 [12:48<02:46,  1.26it/s]                                                   81%|████████▏ | 910/1120 [12:48<02:46,  1.26it/s] 81%|████████▏ | 911/1120 [12:49<02:43,  1.28it/s] 81%|████████▏ | 912/1120 [12:50<02:39,  1.31it/s] 82%|████████▏ | 913/1120 [12:51<02:51,  1.20it/s] 82%|████████▏ | 914/1120 [12:51<02:45,  1.24it/s] 82%|████████▏ | 915/1120 [12:52<02:41,  1.27it/s] 82%|████████▏ | 916/1120 [12:53<02:37,  1.29it/s] 82%|████████▏ | 917/1120 [12:54<02:47,  1.21it/s] 82%|████████▏ | 918/1120 [12:55<02:42,  1.24it/s] 82%|████████▏ | 919/1120 [12:55<02:38,  1.27it/s] 82%|████████▏ | 920/1120 [12:56<02:34,  1.30it/s]                                                   82%|████████▏ | 920/1120 [12:56<02:34,  1.30it/s]{'eval_loss': 0.23700974881649017, 'eval_runtime': 0.9108, 'eval_samples_per_second': 109.8, 'eval_steps_per_second': 14.274, 'epoch': 7.82}
外层迭代结束！
外层迭代结束！
{'loss': 0.0018, 'learning_rate': 6.44859813084112e-05, 'epoch': 7.91}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0189, 'learning_rate': 6.168224299065419e-05, 'epoch': 8.0}
外层迭代结束！
外层迭代结束！
{'loss': 0.0087, 'learning_rate': 5.887850467289719e-05, 'epoch': 8.09}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.004, 'learning_rate': 5.607476635514018e-05, 'epoch': 8.18}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.90it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.37it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.26it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.77it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.64it/s][A                                                  
                                               [A 82%|████████▏ | 920/1120 [12:57<02:34,  1.30it/s]
100%|██████████| 13/13 [00:00<00:00, 14.64it/s][A
                                               [A 82%|████████▏ | 921/1120 [12:58<03:48,  1.15s/it] 82%|████████▏ | 922/1120 [12:59<03:24,  1.03s/it] 82%|████████▏ | 923/1120 [13:00<03:06,  1.06it/s] 82%|████████▎ | 924/1120 [13:00<02:54,  1.13it/s] 83%|████████▎ | 925/1120 [13:01<02:56,  1.10it/s] 83%|████████▎ | 926/1120 [13:02<02:46,  1.17it/s] 83%|████████▎ | 927/1120 [13:03<02:39,  1.21it/s] 83%|████████▎ | 928/1120 [13:04<02:34,  1.24it/s] 83%|████████▎ | 929/1120 [13:05<02:42,  1.18it/s] 83%|████████▎ | 930/1120 [13:05<02:35,  1.22it/s]                                                   83%|████████▎ | 930/1120 [13:05<02:35,  1.22it/s] 83%|████████▎ | 931/1120 [13:06<02:30,  1.26it/s] 83%|████████▎ | 932/1120 [13:07<02:26,  1.28it/s] 83%|████████▎ | 933/1120 [13:08<02:35,  1.20it/s] 83%|████████▎ | 934/1120 [13:09<02:31,  1.23it/s] 83%|████████▎ | 935/1120 [13:09<02:26,  1.26it/s] 84%|████████▎ | 936/1120 [13:10<02:23,  1.29it/s] 84%|████████▎ | 937/1120 [13:11<02:32,  1.20it/s] 84%|████████▍ | 938/1120 [13:12<02:26,  1.25it/s] 84%|████████▍ | 939/1120 [13:12<02:22,  1.27it/s] 84%|████████▍ | 940/1120 [13:13<02:19,  1.29it/s]                                                   84%|████████▍ | 940/1120 [13:13<02:19,  1.29it/s] 84%|████████▍ | 941/1120 [13:14<02:28,  1.20it/s] 84%|████████▍ | 942/1120 [13:15<02:23,  1.24it/s] 84%|████████▍ | 943/1120 [13:16<02:19,  1.27it/s] 84%|████████▍ | 944/1120 [13:16<02:16,  1.29it/s] 84%|████████▍ | 945/1120 [13:17<02:25,  1.21it/s] 84%|████████▍ | 946/1120 [13:18<02:20,  1.24it/s] 85%|████████▍ | 947/1120 [13:19<02:17,  1.26it/s] 85%|████████▍ | 948/1120 [13:20<02:14,  1.28it/s] 85%|████████▍ | 949/1120 [13:21<02:23,  1.20it/s] 85%|████████▍ | 950/1120 [13:21<02:18,  1.23it/s]                                                   85%|████████▍ | 950/1120 [13:21<02:18,  1.23it/s] 85%|████████▍ | 951/1120 [13:22<02:14,  1.26it/s] 85%|████████▌ | 952/1120 [13:23<02:12,  1.27it/s] 85%|████████▌ | 953/1120 [13:24<02:20,  1.19it/s] 85%|████████▌ | 954/1120 [13:25<02:15,  1.23it/s] 85%|████████▌ | 955/1120 [13:25<02:10,  1.26it/s] 85%|████████▌ | 956/1120 [13:26<02:07,  1.29it/s] 85%|████████▌ | 957/1120 [13:27<02:17,  1.19it/s] 86%|████████▌ | 958/1120 [13:28<02:11,  1.23it/s] 86%|████████▌ | 959/1120 [13:29<02:08,  1.26it/s] 86%|████████▌ | 960/1120 [13:29<02:06,  1.27it/s]                                                   86%|████████▌ | 960/1120 [13:30<02:06,  1.27it/s]{'eval_loss': 0.24687033891677856, 'eval_runtime': 0.932, 'eval_samples_per_second': 107.301, 'eval_steps_per_second': 13.949, 'epoch': 8.18}
外层迭代结束！
外层迭代结束！
{'loss': 0.0436, 'learning_rate': 5.327102803738317e-05, 'epoch': 8.27}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0032, 'learning_rate': 5.046728971962616e-05, 'epoch': 8.36}
外层迭代结束！
外层迭代结束！
{'loss': 0.045, 'learning_rate': 4.766355140186915e-05, 'epoch': 8.44}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0062, 'learning_rate': 4.485981308411214e-05, 'epoch': 8.53}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.93it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.47it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.20it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.75it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.57it/s][A                                                  
                                               [A 86%|████████▌ | 960/1120 [13:30<02:06,  1.27it/s]
100%|██████████| 13/13 [00:00<00:00, 14.57it/s][A
                                               [A 86%|████████▌ | 961/1120 [13:31<03:06,  1.17s/it] 86%|████████▌ | 962/1120 [13:32<02:45,  1.05s/it] 86%|████████▌ | 963/1120 [13:33<02:30,  1.04it/s] 86%|████████▌ | 964/1120 [13:34<02:20,  1.11it/s] 86%|████████▌ | 965/1120 [13:35<02:22,  1.09it/s] 86%|████████▋ | 966/1120 [13:35<02:12,  1.16it/s] 86%|████████▋ | 967/1120 [13:36<02:07,  1.20it/s] 86%|████████▋ | 968/1120 [13:37<02:02,  1.25it/s] 87%|████████▋ | 969/1120 [13:38<02:08,  1.18it/s] 87%|████████▋ | 970/1120 [13:39<02:03,  1.21it/s]                                                   87%|████████▋ | 970/1120 [13:39<02:03,  1.21it/s] 87%|████████▋ | 971/1120 [13:39<01:59,  1.24it/s] 87%|████████▋ | 972/1120 [13:40<01:56,  1.27it/s] 87%|████████▋ | 973/1120 [13:41<02:03,  1.19it/s] 87%|████████▋ | 974/1120 [13:42<01:57,  1.25it/s] 87%|████████▋ | 975/1120 [13:43<01:53,  1.27it/s] 87%|████████▋ | 976/1120 [13:43<01:51,  1.29it/s] 87%|████████▋ | 977/1120 [13:44<01:57,  1.22it/s] 87%|████████▋ | 978/1120 [13:45<01:53,  1.25it/s] 87%|████████▋ | 979/1120 [13:46<01:51,  1.27it/s] 88%|████████▊ | 980/1120 [13:46<01:49,  1.28it/s]                                                   88%|████████▊ | 980/1120 [13:47<01:49,  1.28it/s] 88%|████████▊ | 981/1120 [13:47<01:55,  1.20it/s] 88%|████████▊ | 982/1120 [13:48<01:51,  1.24it/s] 88%|████████▊ | 983/1120 [13:49<01:48,  1.26it/s] 88%|████████▊ | 984/1120 [13:50<01:44,  1.30it/s] 88%|████████▊ | 985/1120 [13:51<01:51,  1.21it/s] 88%|████████▊ | 986/1120 [13:51<01:47,  1.24it/s] 88%|████████▊ | 987/1120 [13:52<01:44,  1.28it/s] 88%|████████▊ | 988/1120 [13:53<01:42,  1.29it/s] 88%|████████▊ | 989/1120 [13:54<01:48,  1.21it/s] 88%|████████▊ | 990/1120 [13:55<01:44,  1.25it/s]                                                   88%|████████▊ | 990/1120 [13:55<01:44,  1.25it/s] 88%|████████▊ | 991/1120 [13:55<01:41,  1.27it/s] 89%|████████▊ | 992/1120 [13:56<01:39,  1.29it/s] 89%|████████▊ | 993/1120 [13:57<01:45,  1.20it/s] 89%|████████▉ | 994/1120 [13:58<01:41,  1.24it/s] 89%|████████▉ | 995/1120 [13:58<01:38,  1.27it/s] 89%|████████▉ | 996/1120 [13:59<01:35,  1.29it/s] 89%|████████▉ | 997/1120 [14:00<01:41,  1.21it/s] 89%|████████▉ | 998/1120 [14:01<01:37,  1.25it/s] 89%|████████▉ | 999/1120 [14:02<01:34,  1.27it/s] 89%|████████▉ | 1000/1120 [14:02<01:33,  1.29it/s]                                                    89%|████████▉ | 1000/1120 [14:03<01:33,  1.29it/s]{'eval_loss': 0.2615872919559479, 'eval_runtime': 0.9343, 'eval_samples_per_second': 107.035, 'eval_steps_per_second': 13.915, 'epoch': 8.53}
外层迭代结束！
外层迭代结束！
{'loss': 0.0016, 'learning_rate': 4.2056074766355134e-05, 'epoch': 8.62}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0433, 'learning_rate': 3.9252336448598124e-05, 'epoch': 8.71}
外层迭代结束！
外层迭代结束！
{'loss': 0.0027, 'learning_rate': 3.6448598130841115e-05, 'epoch': 8.8}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0306, 'learning_rate': 3.3644859813084105e-05, 'epoch': 8.89}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.33it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.68it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.58it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.08it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.80it/s][A                                                   
                                               [A 89%|████████▉ | 1000/1120 [14:04<01:33,  1.29it/s]
100%|██████████| 13/13 [00:00<00:00, 14.80it/s][A
                                               [A 89%|████████▉ | 1001/1120 [14:04<02:16,  1.15s/it] 89%|████████▉ | 1002/1120 [14:05<02:00,  1.02s/it] 90%|████████▉ | 1003/1120 [14:06<01:49,  1.07it/s] 90%|████████▉ | 1004/1120 [14:07<01:41,  1.14it/s] 90%|████████▉ | 1005/1120 [14:08<01:43,  1.11it/s] 90%|████████▉ | 1006/1120 [14:08<01:37,  1.17it/s] 90%|████████▉ | 1007/1120 [14:09<01:33,  1.21it/s] 90%|█████████ | 1008/1120 [14:10<01:30,  1.24it/s] 90%|█████████ | 1009/1120 [14:11<01:34,  1.17it/s] 90%|█████████ | 1010/1120 [14:12<01:30,  1.22it/s]                                                    90%|█████████ | 1010/1120 [14:12<01:30,  1.22it/s] 90%|█████████ | 1011/1120 [14:12<01:26,  1.25it/s] 90%|█████████ | 1012/1120 [14:13<01:24,  1.28it/s] 90%|█████████ | 1013/1120 [14:14<01:28,  1.20it/s] 91%|█████████ | 1014/1120 [14:15<01:26,  1.23it/s] 91%|█████████ | 1015/1120 [14:16<01:23,  1.26it/s] 91%|█████████ | 1016/1120 [14:16<01:21,  1.28it/s] 91%|█████████ | 1017/1120 [14:17<01:26,  1.19it/s] 91%|█████████ | 1018/1120 [14:18<01:21,  1.24it/s] 91%|█████████ | 1019/1120 [14:19<01:19,  1.27it/s] 91%|█████████ | 1020/1120 [14:19<01:17,  1.29it/s]                                                    91%|█████████ | 1020/1120 [14:20<01:17,  1.29it/s] 91%|█████████ | 1021/1120 [14:20<01:22,  1.20it/s] 91%|█████████▏| 1022/1120 [14:21<01:19,  1.23it/s] 91%|█████████▏| 1023/1120 [14:22<01:16,  1.27it/s] 91%|█████████▏| 1024/1120 [14:23<01:14,  1.28it/s] 92%|█████████▏| 1025/1120 [14:24<01:19,  1.20it/s] 92%|█████████▏| 1026/1120 [14:24<01:15,  1.24it/s] 92%|█████████▏| 1027/1120 [14:25<01:13,  1.26it/s] 92%|█████████▏| 1028/1120 [14:26<01:11,  1.29it/s] 92%|█████████▏| 1029/1120 [14:27<01:15,  1.20it/s] 92%|█████████▏| 1030/1120 [14:28<01:13,  1.23it/s]                                                    92%|█████████▏| 1030/1120 [14:28<01:13,  1.23it/s] 92%|█████████▏| 1031/1120 [14:28<01:10,  1.26it/s] 92%|█████████▏| 1032/1120 [14:29<01:08,  1.28it/s] 92%|█████████▏| 1033/1120 [14:30<01:12,  1.20it/s] 92%|█████████▏| 1034/1120 [14:31<01:09,  1.24it/s] 92%|█████████▏| 1035/1120 [14:32<01:06,  1.28it/s] 92%|█████████▎| 1036/1120 [14:32<01:04,  1.31it/s] 93%|█████████▎| 1037/1120 [14:33<01:07,  1.22it/s] 93%|█████████▎| 1038/1120 [14:34<01:04,  1.27it/s] 93%|█████████▎| 1039/1120 [14:35<01:02,  1.29it/s] 93%|█████████▎| 1040/1120 [14:35<01:00,  1.32it/s]                                                    93%|█████████▎| 1040/1120 [14:36<01:00,  1.32it/s]{'eval_loss': 0.26494085788726807, 'eval_runtime': 0.9157, 'eval_samples_per_second': 109.2, 'eval_steps_per_second': 14.196, 'epoch': 8.89}
外层迭代结束！
外层迭代结束！
{'loss': 0.0048, 'learning_rate': 3.0841121495327096e-05, 'epoch': 8.98}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0045, 'learning_rate': 2.803738317757009e-05, 'epoch': 9.07}
外层迭代结束！
外层迭代结束！
{'loss': 0.0044, 'learning_rate': 2.523364485981308e-05, 'epoch': 9.16}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0095, 'learning_rate': 2.242990654205607e-05, 'epoch': 9.24}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.58it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.83it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.92it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.34it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.79it/s][A                                                   
                                               [A 93%|█████████▎| 1040/1120 [14:37<01:00,  1.32it/s]
100%|██████████| 13/13 [00:00<00:00, 14.79it/s][A
                                               [A 93%|█████████▎| 1041/1120 [14:37<01:29,  1.14s/it] 93%|█████████▎| 1042/1120 [14:38<01:19,  1.01s/it] 93%|█████████▎| 1043/1120 [14:39<01:11,  1.07it/s] 93%|█████████▎| 1044/1120 [14:40<01:06,  1.15it/s] 93%|█████████▎| 1045/1120 [14:41<01:06,  1.12it/s] 93%|█████████▎| 1046/1120 [14:41<01:02,  1.18it/s] 93%|█████████▎| 1047/1120 [14:42<00:58,  1.24it/s] 94%|█████████▎| 1048/1120 [14:43<00:56,  1.27it/s] 94%|█████████▎| 1049/1120 [14:44<00:59,  1.20it/s] 94%|█████████▍| 1050/1120 [14:44<00:55,  1.25it/s]                                                    94%|█████████▍| 1050/1120 [14:44<00:55,  1.25it/s] 94%|█████████▍| 1051/1120 [14:45<00:53,  1.29it/s] 94%|█████████▍| 1052/1120 [14:46<00:51,  1.31it/s] 94%|█████████▍| 1053/1120 [14:47<00:54,  1.22it/s] 94%|█████████▍| 1054/1120 [14:48<00:52,  1.26it/s] 94%|█████████▍| 1055/1120 [14:48<00:50,  1.29it/s] 94%|█████████▍| 1056/1120 [14:49<00:48,  1.31it/s] 94%|█████████▍| 1057/1120 [14:50<00:51,  1.22it/s] 94%|█████████▍| 1058/1120 [14:51<00:50,  1.24it/s] 95%|█████████▍| 1059/1120 [14:52<00:48,  1.26it/s] 95%|█████████▍| 1060/1120 [14:52<00:46,  1.28it/s]                                                    95%|█████████▍| 1060/1120 [14:52<00:46,  1.28it/s] 95%|█████████▍| 1061/1120 [14:53<00:49,  1.20it/s] 95%|█████████▍| 1062/1120 [14:54<00:46,  1.24it/s] 95%|█████████▍| 1063/1120 [14:55<00:44,  1.27it/s] 95%|█████████▌| 1064/1120 [14:55<00:43,  1.29it/s] 95%|█████████▌| 1065/1120 [14:56<00:45,  1.22it/s] 95%|█████████▌| 1066/1120 [14:57<00:43,  1.25it/s] 95%|█████████▌| 1067/1120 [14:58<00:41,  1.27it/s] 95%|█████████▌| 1068/1120 [14:59<00:40,  1.28it/s] 95%|█████████▌| 1069/1120 [15:00<00:42,  1.20it/s] 96%|█████████▌| 1070/1120 [15:00<00:40,  1.25it/s]                                                    96%|█████████▌| 1070/1120 [15:00<00:40,  1.25it/s] 96%|█████████▌| 1071/1120 [15:01<00:38,  1.27it/s] 96%|█████████▌| 1072/1120 [15:02<00:37,  1.28it/s] 96%|█████████▌| 1073/1120 [15:03<00:39,  1.20it/s] 96%|█████████▌| 1074/1120 [15:04<00:37,  1.23it/s] 96%|█████████▌| 1075/1120 [15:04<00:35,  1.28it/s] 96%|█████████▌| 1076/1120 [15:05<00:34,  1.29it/s] 96%|█████████▌| 1077/1120 [15:06<00:35,  1.21it/s] 96%|█████████▋| 1078/1120 [15:07<00:33,  1.24it/s] 96%|█████████▋| 1079/1120 [15:08<00:32,  1.26it/s] 96%|█████████▋| 1080/1120 [15:08<00:30,  1.30it/s]                                                    96%|█████████▋| 1080/1120 [15:08<00:30,  1.30it/s]{'eval_loss': 0.2650162875652313, 'eval_runtime': 0.9122, 'eval_samples_per_second': 109.625, 'eval_steps_per_second': 14.251, 'epoch': 9.24}
外层迭代结束！
外层迭代结束！
{'loss': 0.0177, 'learning_rate': 1.9626168224299062e-05, 'epoch': 9.33}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0089, 'learning_rate': 1.6822429906542053e-05, 'epoch': 9.42}
外层迭代结束！
外层迭代结束！
{'loss': 0.0362, 'learning_rate': 1.4018691588785045e-05, 'epoch': 9.51}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0199, 'learning_rate': 1.1214953271028036e-05, 'epoch': 9.6}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.66it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.43it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.68it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.15it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.96it/s][A                                                   
                                               [A 96%|█████████▋| 1080/1120 [15:09<00:30,  1.30it/s]
100%|██████████| 13/13 [00:00<00:00, 14.96it/s][A
                                               [A 97%|█████████▋| 1081/1120 [15:10<00:44,  1.13s/it] 97%|█████████▋| 1082/1120 [15:11<00:38,  1.02s/it] 97%|█████████▋| 1083/1120 [15:12<00:34,  1.06it/s] 97%|█████████▋| 1084/1120 [15:12<00:31,  1.14it/s] 97%|█████████▋| 1085/1120 [15:13<00:31,  1.11it/s] 97%|█████████▋| 1086/1120 [15:14<00:29,  1.17it/s] 97%|█████████▋| 1087/1120 [15:15<00:27,  1.22it/s] 97%|█████████▋| 1088/1120 [15:16<00:25,  1.26it/s] 97%|█████████▋| 1089/1120 [15:17<00:25,  1.20it/s] 97%|█████████▋| 1090/1120 [15:17<00:24,  1.24it/s]                                                    97%|█████████▋| 1090/1120 [15:17<00:24,  1.24it/s] 97%|█████████▋| 1091/1120 [15:18<00:22,  1.27it/s] 98%|█████████▊| 1092/1120 [15:19<00:21,  1.30it/s] 98%|█████████▊| 1093/1120 [15:20<00:22,  1.21it/s] 98%|█████████▊| 1094/1120 [15:20<00:20,  1.25it/s] 98%|█████████▊| 1095/1120 [15:21<00:19,  1.27it/s] 98%|█████████▊| 1096/1120 [15:22<00:18,  1.29it/s] 98%|█████████▊| 1097/1120 [15:23<00:19,  1.20it/s] 98%|█████████▊| 1098/1120 [15:24<00:17,  1.24it/s] 98%|█████████▊| 1099/1120 [15:24<00:16,  1.29it/s] 98%|█████████▊| 1100/1120 [15:25<00:15,  1.29it/s]                                                    98%|█████████▊| 1100/1120 [15:25<00:15,  1.29it/s] 98%|█████████▊| 1101/1120 [15:26<00:15,  1.21it/s] 98%|█████████▊| 1102/1120 [15:27<00:14,  1.24it/s] 98%|█████████▊| 1103/1120 [15:28<00:13,  1.27it/s] 99%|█████████▊| 1104/1120 [15:28<00:12,  1.30it/s] 99%|█████████▊| 1105/1120 [15:29<00:12,  1.22it/s] 99%|█████████▉| 1106/1120 [15:30<00:11,  1.26it/s] 99%|█████████▉| 1107/1120 [15:31<00:10,  1.29it/s] 99%|█████████▉| 1108/1120 [15:31<00:09,  1.31it/s] 99%|█████████▉| 1109/1120 [15:32<00:08,  1.23it/s] 99%|█████████▉| 1110/1120 [15:33<00:07,  1.27it/s]                                                    99%|█████████▉| 1110/1120 [15:33<00:07,  1.27it/s] 99%|█████████▉| 1111/1120 [15:34<00:06,  1.30it/s] 99%|█████████▉| 1112/1120 [15:35<00:06,  1.32it/s] 99%|█████████▉| 1113/1120 [15:36<00:05,  1.23it/s] 99%|█████████▉| 1114/1120 [15:36<00:04,  1.26it/s]100%|█████████▉| 1115/1120 [15:37<00:03,  1.29it/s]100%|█████████▉| 1116/1120 [15:38<00:03,  1.30it/s]100%|█████████▉| 1117/1120 [15:39<00:02,  1.21it/s]100%|█████████▉| 1118/1120 [15:39<00:01,  1.25it/s]100%|█████████▉| 1119/1120 [15:40<00:00,  1.28it/s]100%|██████████| 1120/1120 [15:41<00:00,  1.31it/s]                                                   100%|██████████| 1120/1120 [15:41<00:00,  1.31it/s]{'eval_loss': 0.2663497030735016, 'eval_runtime': 0.9187, 'eval_samples_per_second': 108.854, 'eval_steps_per_second': 14.151, 'epoch': 9.6}
外层迭代结束！
外层迭代结束！
{'loss': 0.0127, 'learning_rate': 8.411214953271026e-06, 'epoch': 9.69}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.016, 'learning_rate': 5.607476635514018e-06, 'epoch': 9.78}
外层迭代结束！
外层迭代结束！
{'loss': 0.0118, 'learning_rate': 2.803738317757009e-06, 'epoch': 9.87}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0114, 'learning_rate': 0.0, 'epoch': 9.96}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 21.60it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 16.85it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 15.97it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 15.45it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.18it/s][A                                                   
                                               [A100%|██████████| 1120/1120 [15:42<00:00,  1.31it/s]
100%|██████████| 13/13 [00:00<00:00, 15.18it/s][A
                                               [AThere were missing keys in the checkpoint model loaded: ['base_model.model.shared.weight', 'base_model.model.encoder.embed_tokens.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.encoder.block.0.layer.0.layer_norm.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.0.layer.1.layer_norm.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.1.layer.0.layer_norm.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.1.layer.1.layer_norm.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.2.layer.0.layer_norm.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.2.layer.1.layer_norm.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.3.layer.0.layer_norm.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.3.layer.1.layer_norm.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.4.layer.0.layer_norm.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.4.layer.1.layer_norm.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.5.layer.0.layer_norm.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.5.layer.1.layer_norm.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.6.layer.0.layer_norm.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.6.layer.1.layer_norm.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.7.layer.0.layer_norm.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.7.layer.1.layer_norm.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.8.layer.0.layer_norm.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.8.layer.1.layer_norm.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.9.layer.0.layer_norm.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.9.layer.1.layer_norm.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.10.layer.0.layer_norm.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.10.layer.1.layer_norm.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.11.layer.0.layer_norm.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.11.layer.1.layer_norm.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.12.layer.0.layer_norm.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.12.layer.1.layer_norm.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.13.layer.0.layer_norm.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.13.layer.1.layer_norm.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.14.layer.0.layer_norm.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.14.layer.1.layer_norm.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.15.layer.0.layer_norm.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.15.layer.1.layer_norm.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.16.layer.0.layer_norm.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.16.layer.1.layer_norm.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.17.layer.0.layer_norm.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.17.layer.1.layer_norm.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.18.layer.0.layer_norm.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.18.layer.1.layer_norm.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.19.layer.0.layer_norm.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.19.layer.1.layer_norm.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.20.layer.0.layer_norm.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.20.layer.1.layer_norm.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.21.layer.0.layer_norm.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.21.layer.1.layer_norm.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.22.layer.0.layer_norm.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.22.layer.1.layer_norm.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.23.layer.0.layer_norm.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.23.layer.1.layer_norm.weight', 'base_model.model.encoder.final_layer_norm.weight', 'base_model.model.decoder.embed_tokens.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.decoder.block.0.layer.0.layer_norm.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.0.layer.1.layer_norm.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.0.layer.2.layer_norm.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.1.layer.0.layer_norm.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.1.layer.1.layer_norm.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.1.layer.2.layer_norm.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.2.layer.0.layer_norm.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.2.layer.1.layer_norm.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.2.layer.2.layer_norm.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.3.layer.0.layer_norm.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.3.layer.1.layer_norm.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.3.layer.2.layer_norm.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.4.layer.0.layer_norm.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.4.layer.1.layer_norm.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.4.layer.2.layer_norm.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.5.layer.0.layer_norm.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.5.layer.1.layer_norm.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.5.layer.2.layer_norm.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.6.layer.0.layer_norm.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.6.layer.1.layer_norm.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.6.layer.2.layer_norm.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.7.layer.0.layer_norm.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.7.layer.1.layer_norm.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.7.layer.2.layer_norm.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.8.layer.0.layer_norm.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.8.layer.1.layer_norm.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.8.layer.2.layer_norm.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.9.layer.0.layer_norm.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.9.layer.1.layer_norm.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.9.layer.2.layer_norm.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.10.layer.0.layer_norm.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.10.layer.1.layer_norm.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.10.layer.2.layer_norm.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.11.layer.0.layer_norm.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.11.layer.1.layer_norm.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.11.layer.2.layer_norm.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.12.layer.0.layer_norm.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.12.layer.1.layer_norm.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.12.layer.2.layer_norm.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.13.layer.0.layer_norm.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.13.layer.1.layer_norm.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.13.layer.2.layer_norm.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.14.layer.0.layer_norm.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.14.layer.1.layer_norm.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.14.layer.2.layer_norm.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.15.layer.0.layer_norm.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.15.layer.1.layer_norm.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.15.layer.2.layer_norm.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.16.layer.0.layer_norm.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.16.layer.1.layer_norm.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.16.layer.2.layer_norm.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.17.layer.0.layer_norm.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.17.layer.1.layer_norm.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.17.layer.2.layer_norm.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.18.layer.0.layer_norm.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.18.layer.1.layer_norm.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.18.layer.2.layer_norm.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.19.layer.0.layer_norm.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.19.layer.1.layer_norm.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.19.layer.2.layer_norm.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.20.layer.0.layer_norm.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.20.layer.1.layer_norm.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.20.layer.2.layer_norm.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.21.layer.0.layer_norm.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.21.layer.1.layer_norm.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.21.layer.2.layer_norm.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.22.layer.0.layer_norm.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.22.layer.1.layer_norm.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.22.layer.2.layer_norm.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.23.layer.0.layer_norm.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.23.layer.1.layer_norm.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.23.layer.2.layer_norm.weight', 'base_model.model.decoder.final_layer_norm.weight', 'base_model.model.lm_head.weight'].
There were unexpected keys in the checkpoint model loaded: ['base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.weight'].
                                                   100%|██████████| 1120/1120 [15:42<00:00,  1.31it/s]100%|██████████| 1120/1120 [15:42<00:00,  1.19it/s]
{'eval_loss': 0.26594218611717224, 'eval_runtime': 0.8978, 'eval_samples_per_second': 111.382, 'eval_steps_per_second': 14.48, 'epoch': 9.96}
{'train_runtime': 942.7973, 'train_samples_per_second': 9.546, 'train_steps_per_second': 1.188, 'train_loss': 0.09446761230771829, 'epoch': 9.96}

 If there's a warning about missing keys above, please disregard :)
Found cached dataset json (/data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 8
micro_batch_size: 2
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: boolqa... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/5-boolqa
current data path: ./data_longsequence/train/boolqa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 782.23it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 451.97it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 775.72it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 539.18it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 879.31it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400, 选择的样本数量：8
task id: 4, history data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 463.66it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b05edc432aa3560.arrow
Loading cached split indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-63564ca35fe5a902.arrow and /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-ffa03be400b14e32.arrow
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-caeceebdafe6b209.arrow
Loading cached processed dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-8fcd88740bc9fb38.arrow
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-0b69169b53eef0ca.arrow
总样本数：1000, 选择的样本数量：20
lora_weights: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/4-qqp

pre-trained model's BOS EOS and PAD token id: None 1 0  => It should be 1,2,none
continual fine tune lora!
trainable params: 2359296 || all params: 740027392 || trainable%: 0.31881198257050464
训练数据总量：900
验证数据总量：100
Map:   0%|          | 0/100 [00:00<?, ? examples/s]/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3597: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  "`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your "
                                                   Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3e796227d5966e0a.arrow
Loading cached processed dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-fb59cb2d90fbc5e6.arrow
memory data loader 2
  0%|          | 0/1120 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/1120 [00:01<32:17,  1.73s/it]  0%|          | 2/1120 [00:02<21:42,  1.17s/it]  0%|          | 3/1120 [00:03<18:20,  1.01it/s]  0%|          | 4/1120 [00:04<16:45,  1.11it/s]  0%|          | 5/1120 [00:05<17:09,  1.08it/s]  1%|          | 6/1120 [00:05<15:57,  1.16it/s]  1%|          | 7/1120 [00:06<15:16,  1.21it/s]  1%|          | 8/1120 [00:07<14:46,  1.25it/s]  1%|          | 9/1120 [00:08<15:45,  1.18it/s]  1%|          | 10/1120 [00:09<16:30,  1.12it/s]                                                   1%|          | 10/1120 [00:09<16:30,  1.12it/s]  1%|          | 11/1120 [00:10<16:37,  1.11it/s]  1%|          | 12/1120 [00:11<16:50,  1.10it/s]  1%|          | 13/1120 [00:12<18:21,  1.00it/s]  1%|▏         | 14/1120 [00:13<17:59,  1.02it/s]  1%|▏         | 15/1120 [00:14<17:33,  1.05it/s]  1%|▏         | 16/1120 [00:14<17:11,  1.07it/s]  2%|▏         | 17/1120 [00:16<18:18,  1.00it/s]  2%|▏         | 18/1120 [00:17<18:04,  1.02it/s]  2%|▏         | 19/1120 [00:17<17:42,  1.04it/s]  2%|▏         | 20/1120 [00:18<17:19,  1.06it/s]                                                   2%|▏         | 20/1120 [00:19<17:19,  1.06it/s]  2%|▏         | 21/1120 [00:20<18:28,  1.01s/it]  2%|▏         | 22/1120 [00:20<17:50,  1.03it/s]  2%|▏         | 23/1120 [00:21<17:20,  1.05it/s]  2%|▏         | 24/1120 [00:22<17:03,  1.07it/s]  2%|▏         | 25/1120 [00:23<18:10,  1.00it/s]  2%|▏         | 26/1120 [00:24<17:40,  1.03it/s]  2%|▏         | 27/1120 [00:25<17:18,  1.05it/s]  2%|▎         | 28/1120 [00:26<17:10,  1.06it/s]  3%|▎         | 29/1120 [00:27<18:21,  1.01s/it]  3%|▎         | 30/1120 [00:28<17:44,  1.02it/s]                                                   3%|▎         | 30/1120 [00:28<17:44,  1.02it/s]  3%|▎         | 31/1120 [00:29<17:19,  1.05it/s]  3%|▎         | 32/1120 [00:30<17:01,  1.06it/s]  3%|▎         | 33/1120 [00:31<18:06,  1.00it/s]  3%|▎         | 34/1120 [00:32<17:32,  1.03it/s]  3%|▎         | 35/1120 [00:33<17:14,  1.05it/s]  3%|▎         | 36/1120 [00:34<16:55,  1.07it/s]  3%|▎         | 37/1120 [00:35<18:07,  1.00s/it]  3%|▎         | 38/1120 [00:36<17:33,  1.03it/s]  3%|▎         | 39/1120 [00:37<17:07,  1.05it/s]  4%|▎         | 40/1120 [00:38<16:51,  1.07it/s]                                                   4%|▎         | 40/1120 [00:38<16:51,  1.07it/s]外层迭代结束！
外层迭代结束！
{'loss': 0.9544, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.09}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3231, 'learning_rate': 0.00011999999999999999, 'epoch': 0.18}
外层迭代结束！
外层迭代结束！
{'loss': 0.2995, 'learning_rate': 0.00017999999999999998, 'epoch': 0.27}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.236, 'learning_rate': 0.00023999999999999998, 'epoch': 0.36}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.16it/s][A
 31%|███       | 4/13 [00:00<00:00, 11.69it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.50it/s][A
 54%|█████▍    | 7/13 [00:00<00:00,  8.76it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.06it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.34it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.41it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.13it/s][A                                                 
                                               [A  4%|▎         | 40/1120 [00:40<16:51,  1.07it/s]
100%|██████████| 13/13 [00:01<00:00,  8.13it/s][A
                                               [A  4%|▎         | 41/1120 [00:41<27:36,  1.53s/it]  4%|▍         | 42/1120 [00:42<24:12,  1.35s/it]  4%|▍         | 43/1120 [00:42<21:53,  1.22s/it]  4%|▍         | 44/1120 [00:43<20:12,  1.13s/it]  4%|▍         | 45/1120 [00:45<20:22,  1.14s/it]  4%|▍         | 46/1120 [00:45<19:02,  1.06s/it]  4%|▍         | 47/1120 [00:46<18:08,  1.01s/it]  4%|▍         | 48/1120 [00:47<17:24,  1.03it/s]  4%|▍         | 49/1120 [00:48<18:17,  1.03s/it]  4%|▍         | 50/1120 [00:49<17:36,  1.01it/s]                                                   4%|▍         | 50/1120 [00:49<17:36,  1.01it/s]  5%|▍         | 51/1120 [00:50<17:09,  1.04it/s]  5%|▍         | 52/1120 [00:51<16:49,  1.06it/s]  5%|▍         | 53/1120 [00:52<17:55,  1.01s/it]  5%|▍         | 54/1120 [00:53<17:17,  1.03it/s]  5%|▍         | 55/1120 [00:54<16:54,  1.05it/s]  5%|▌         | 56/1120 [00:55<16:38,  1.07it/s]  5%|▌         | 57/1120 [00:56<17:51,  1.01s/it]  5%|▌         | 58/1120 [00:57<17:18,  1.02it/s]  5%|▌         | 59/1120 [00:58<16:53,  1.05it/s]  5%|▌         | 60/1120 [00:59<16:34,  1.07it/s]                                                   5%|▌         | 60/1120 [00:59<16:34,  1.07it/s]  5%|▌         | 61/1120 [01:00<17:43,  1.00s/it]  6%|▌         | 62/1120 [01:01<17:07,  1.03it/s]  6%|▌         | 63/1120 [01:02<16:40,  1.06it/s]  6%|▌         | 64/1120 [01:03<16:20,  1.08it/s]  6%|▌         | 65/1120 [01:04<17:28,  1.01it/s]  6%|▌         | 66/1120 [01:05<16:52,  1.04it/s]  6%|▌         | 67/1120 [01:06<16:28,  1.07it/s]  6%|▌         | 68/1120 [01:06<16:34,  1.06it/s]  6%|▌         | 69/1120 [01:08<17:37,  1.01s/it]  6%|▋         | 70/1120 [01:09<17:04,  1.02it/s]                                                   6%|▋         | 70/1120 [01:09<17:04,  1.02it/s]  6%|▋         | 71/1120 [01:09<16:35,  1.05it/s]  6%|▋         | 72/1120 [01:10<16:22,  1.07it/s]  7%|▋         | 73/1120 [01:11<17:19,  1.01it/s]  7%|▋         | 74/1120 [01:12<16:51,  1.03it/s]  7%|▋         | 75/1120 [01:13<16:27,  1.06it/s]  7%|▋         | 76/1120 [01:14<16:13,  1.07it/s]  7%|▋         | 77/1120 [01:15<17:26,  1.00s/it]  7%|▋         | 78/1120 [01:16<16:57,  1.02it/s]  7%|▋         | 79/1120 [01:17<16:33,  1.05it/s]  7%|▋         | 80/1120 [01:18<16:15,  1.07it/s]                                                   7%|▋         | 80/1120 [01:18<16:15,  1.07it/s]{'eval_loss': 0.152785524725914, 'eval_runtime': 1.6133, 'eval_samples_per_second': 61.985, 'eval_steps_per_second': 8.058, 'epoch': 0.36}
外层迭代结束！
外层迭代结束！
{'loss': 0.1321, 'learning_rate': 0.0003, 'epoch': 0.44}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2257, 'learning_rate': 0.00029719626168224294, 'epoch': 0.53}
外层迭代结束！
外层迭代结束！
{'loss': 0.1669, 'learning_rate': 0.00029439252336448596, 'epoch': 0.62}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0955, 'learning_rate': 0.0002915887850467289, 'epoch': 0.71}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.33it/s][A
 31%|███       | 4/13 [00:00<00:00, 11.74it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.54it/s][A
 54%|█████▍    | 7/13 [00:00<00:00,  8.79it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.10it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.36it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.43it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.12it/s][A                                                 
                                               [A  7%|▋         | 80/1120 [01:20<16:15,  1.07it/s]
100%|██████████| 13/13 [00:01<00:00,  8.12it/s][A
                                               [A  7%|▋         | 81/1120 [01:21<26:25,  1.53s/it]  7%|▋         | 82/1120 [01:22<23:10,  1.34s/it]  7%|▋         | 83/1120 [01:23<20:47,  1.20s/it]  8%|▊         | 84/1120 [01:24<19:09,  1.11s/it]  8%|▊         | 85/1120 [01:25<19:22,  1.12s/it]  8%|▊         | 86/1120 [01:26<18:10,  1.05s/it]  8%|▊         | 87/1120 [01:27<17:23,  1.01s/it]  8%|▊         | 88/1120 [01:27<16:46,  1.03it/s]  8%|▊         | 89/1120 [01:29<17:37,  1.03s/it]  8%|▊         | 90/1120 [01:30<16:58,  1.01it/s]                                                   8%|▊         | 90/1120 [01:30<16:58,  1.01it/s]  8%|▊         | 91/1120 [01:30<16:32,  1.04it/s]  8%|▊         | 92/1120 [01:31<16:11,  1.06it/s]  8%|▊         | 93/1120 [01:32<17:17,  1.01s/it]  8%|▊         | 94/1120 [01:33<16:41,  1.02it/s]  8%|▊         | 95/1120 [01:34<16:19,  1.05it/s]  9%|▊         | 96/1120 [01:35<16:02,  1.06it/s]  9%|▊         | 97/1120 [01:36<17:04,  1.00s/it]  9%|▉         | 98/1120 [01:37<16:35,  1.03it/s]  9%|▉         | 99/1120 [01:38<16:09,  1.05it/s]  9%|▉         | 100/1120 [01:39<15:51,  1.07it/s]                                                    9%|▉         | 100/1120 [01:39<15:51,  1.07it/s]  9%|▉         | 101/1120 [01:40<16:59,  1.00s/it]  9%|▉         | 102/1120 [01:41<16:21,  1.04it/s]  9%|▉         | 103/1120 [01:42<16:01,  1.06it/s]  9%|▉         | 104/1120 [01:43<15:44,  1.08it/s]  9%|▉         | 105/1120 [01:44<16:48,  1.01it/s]  9%|▉         | 106/1120 [01:45<16:16,  1.04it/s] 10%|▉         | 107/1120 [01:46<15:54,  1.06it/s] 10%|▉         | 108/1120 [01:47<16:01,  1.05it/s] 10%|▉         | 109/1120 [01:48<16:58,  1.01s/it] 10%|▉         | 110/1120 [01:49<16:20,  1.03it/s]                                                   10%|▉         | 110/1120 [01:49<16:20,  1.03it/s] 10%|▉         | 111/1120 [01:50<15:58,  1.05it/s] 10%|█         | 112/1120 [01:51<15:44,  1.07it/s] 10%|█         | 113/1120 [01:52<16:45,  1.00it/s] 10%|█         | 114/1120 [01:53<16:13,  1.03it/s] 10%|█         | 115/1120 [01:54<15:49,  1.06it/s] 10%|█         | 116/1120 [01:54<15:37,  1.07it/s] 10%|█         | 117/1120 [01:56<16:37,  1.01it/s] 11%|█         | 118/1120 [01:57<16:58,  1.02s/it] 11%|█         | 119/1120 [01:58<16:19,  1.02it/s] 11%|█         | 120/1120 [01:58<15:43,  1.06it/s]                                                   11%|█         | 120/1120 [01:59<15:43,  1.06it/s]{'eval_loss': 0.13123458623886108, 'eval_runtime': 1.6056, 'eval_samples_per_second': 62.282, 'eval_steps_per_second': 8.097, 'epoch': 0.71}
外层迭代结束！
外层迭代结束！
{'loss': 0.158, 'learning_rate': 0.00028878504672897194, 'epoch': 0.8}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1461, 'learning_rate': 0.0002859813084112149, 'epoch': 0.89}
外层迭代结束！
外层迭代结束！
{'loss': 0.1681, 'learning_rate': 0.0002831775700934579, 'epoch': 0.98}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1291, 'learning_rate': 0.0002803738317757009, 'epoch': 1.07}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.28it/s][A
 31%|███       | 4/13 [00:00<00:00, 11.77it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.53it/s][A
 54%|█████▍    | 7/13 [00:00<00:00,  8.78it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.07it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.33it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.40it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.11it/s][A                                                  
                                               [A 11%|█         | 120/1120 [02:00<15:43,  1.06it/s]
100%|██████████| 13/13 [00:01<00:00,  8.11it/s][A
                                               [A 11%|█         | 121/1120 [02:01<25:26,  1.53s/it] 11%|█         | 122/1120 [02:02<22:07,  1.33s/it] 11%|█         | 123/1120 [02:03<19:41,  1.19s/it] 11%|█         | 124/1120 [02:04<18:00,  1.09s/it] 11%|█         | 125/1120 [02:05<18:01,  1.09s/it] 11%|█▏        | 126/1120 [02:06<16:51,  1.02s/it] 11%|█▏        | 127/1120 [02:07<16:04,  1.03it/s] 11%|█▏        | 128/1120 [02:08<15:33,  1.06it/s] 12%|█▏        | 129/1120 [02:09<16:25,  1.01it/s] 12%|█▏        | 130/1120 [02:09<15:42,  1.05it/s]                                                   12%|█▏        | 130/1120 [02:09<15:42,  1.05it/s] 12%|█▏        | 131/1120 [02:10<15:22,  1.07it/s] 12%|█▏        | 132/1120 [02:11<15:09,  1.09it/s] 12%|█▏        | 133/1120 [02:12<16:02,  1.02it/s] 12%|█▏        | 134/1120 [02:13<15:26,  1.06it/s] 12%|█▏        | 135/1120 [02:14<15:01,  1.09it/s] 12%|█▏        | 136/1120 [02:15<14:44,  1.11it/s] 12%|█▏        | 137/1120 [02:16<15:42,  1.04it/s] 12%|█▏        | 138/1120 [02:17<15:20,  1.07it/s] 12%|█▏        | 139/1120 [02:18<14:59,  1.09it/s] 12%|█▎        | 140/1120 [02:19<14:38,  1.12it/s]                                                   12%|█▎        | 140/1120 [02:19<14:38,  1.12it/s] 13%|█▎        | 141/1120 [02:20<15:42,  1.04it/s] 13%|█▎        | 142/1120 [02:21<15:16,  1.07it/s] 13%|█▎        | 143/1120 [02:22<14:50,  1.10it/s] 13%|█▎        | 144/1120 [02:22<14:35,  1.11it/s] 13%|█▎        | 145/1120 [02:23<15:33,  1.04it/s] 13%|█▎        | 146/1120 [02:24<15:04,  1.08it/s] 13%|█▎        | 147/1120 [02:25<14:45,  1.10it/s] 13%|█▎        | 148/1120 [02:26<14:29,  1.12it/s] 13%|█▎        | 149/1120 [02:27<15:26,  1.05it/s] 13%|█▎        | 150/1120 [02:28<15:13,  1.06it/s]                                                   13%|█▎        | 150/1120 [02:28<15:13,  1.06it/s] 13%|█▎        | 151/1120 [02:29<14:43,  1.10it/s] 14%|█▎        | 152/1120 [02:30<14:31,  1.11it/s] 14%|█▎        | 153/1120 [02:31<15:29,  1.04it/s] 14%|█▍        | 154/1120 [02:32<14:52,  1.08it/s] 14%|█▍        | 155/1120 [02:33<14:27,  1.11it/s] 14%|█▍        | 156/1120 [02:33<14:12,  1.13it/s] 14%|█▍        | 157/1120 [02:35<15:11,  1.06it/s] 14%|█▍        | 158/1120 [02:35<14:44,  1.09it/s] 14%|█▍        | 159/1120 [02:36<14:23,  1.11it/s] 14%|█▍        | 160/1120 [02:37<14:09,  1.13it/s]                                                   14%|█▍        | 160/1120 [02:37<14:09,  1.13it/s]{'eval_loss': 0.1475541889667511, 'eval_runtime': 1.6058, 'eval_samples_per_second': 62.274, 'eval_steps_per_second': 8.096, 'epoch': 1.07}
外层迭代结束！
外层迭代结束！
{'loss': 0.1589, 'learning_rate': 0.0002775700934579439, 'epoch': 1.16}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1502, 'learning_rate': 0.00027476635514018686, 'epoch': 1.24}
外层迭代结束！
外层迭代结束！
{'loss': 0.1101, 'learning_rate': 0.0002719626168224299, 'epoch': 1.33}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1537, 'learning_rate': 0.00026915887850467284, 'epoch': 1.42}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.35it/s][A
 31%|███       | 4/13 [00:00<00:00, 11.73it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.53it/s][A
 54%|█████▍    | 7/13 [00:00<00:00,  8.76it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.09it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.33it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.40it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.08it/s][A                                                  
                                               [A 14%|█▍        | 160/1120 [02:39<14:09,  1.13it/s]
100%|██████████| 13/13 [00:01<00:00,  8.08it/s][A
                                               [A 14%|█▍        | 161/1120 [02:40<23:34,  1.48s/it] 14%|█▍        | 162/1120 [02:41<20:32,  1.29s/it] 15%|█▍        | 163/1120 [02:42<18:24,  1.15s/it] 15%|█▍        | 164/1120 [02:42<16:53,  1.06s/it] 15%|█▍        | 165/1120 [02:44<17:03,  1.07s/it] 15%|█▍        | 166/1120 [02:44<16:10,  1.02s/it] 15%|█▍        | 167/1120 [02:45<15:16,  1.04it/s] 15%|█▌        | 168/1120 [02:46<14:44,  1.08it/s] 15%|█▌        | 169/1120 [02:47<15:30,  1.02it/s] 15%|█▌        | 170/1120 [02:48<14:53,  1.06it/s]                                                   15%|█▌        | 170/1120 [02:48<14:53,  1.06it/s] 15%|█▌        | 171/1120 [02:49<14:28,  1.09it/s] 15%|█▌        | 172/1120 [02:50<14:11,  1.11it/s] 15%|█▌        | 173/1120 [02:51<15:08,  1.04it/s] 16%|█▌        | 174/1120 [02:52<14:35,  1.08it/s] 16%|█▌        | 175/1120 [02:53<14:11,  1.11it/s] 16%|█▌        | 176/1120 [02:53<13:53,  1.13it/s] 16%|█▌        | 177/1120 [02:54<14:50,  1.06it/s] 16%|█▌        | 178/1120 [02:55<14:19,  1.10it/s] 16%|█▌        | 179/1120 [02:56<13:59,  1.12it/s] 16%|█▌        | 180/1120 [02:57<13:47,  1.14it/s]                                                   16%|█▌        | 180/1120 [02:57<13:47,  1.14it/s] 16%|█▌        | 181/1120 [02:58<14:45,  1.06it/s] 16%|█▋        | 182/1120 [02:59<14:17,  1.09it/s] 16%|█▋        | 183/1120 [03:00<13:59,  1.12it/s] 16%|█▋        | 184/1120 [03:01<13:45,  1.13it/s] 17%|█▋        | 185/1120 [03:02<14:37,  1.07it/s] 17%|█▋        | 186/1120 [03:03<14:11,  1.10it/s] 17%|█▋        | 187/1120 [03:03<13:52,  1.12it/s] 17%|█▋        | 188/1120 [03:04<13:38,  1.14it/s] 17%|█▋        | 189/1120 [03:05<14:39,  1.06it/s] 17%|█▋        | 190/1120 [03:06<14:09,  1.09it/s]                                                   17%|█▋        | 190/1120 [03:06<14:09,  1.09it/s] 17%|█▋        | 191/1120 [03:07<13:51,  1.12it/s] 17%|█▋        | 192/1120 [03:08<13:39,  1.13it/s] 17%|█▋        | 193/1120 [03:09<14:38,  1.05it/s] 17%|█▋        | 194/1120 [03:10<14:13,  1.09it/s] 17%|█▋        | 195/1120 [03:11<13:49,  1.12it/s] 18%|█▊        | 196/1120 [03:12<13:53,  1.11it/s] 18%|█▊        | 197/1120 [03:13<14:45,  1.04it/s] 18%|█▊        | 198/1120 [03:14<14:15,  1.08it/s] 18%|█▊        | 199/1120 [03:15<14:13,  1.08it/s] 18%|█▊        | 200/1120 [03:15<13:52,  1.11it/s]                                                   18%|█▊        | 200/1120 [03:16<13:52,  1.11it/s]{'eval_loss': 0.13484160602092743, 'eval_runtime': 1.6126, 'eval_samples_per_second': 62.011, 'eval_steps_per_second': 8.061, 'epoch': 1.42}
外层迭代结束！
外层迭代结束！
{'loss': 0.1274, 'learning_rate': 0.00026635514018691586, 'epoch': 1.51}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1361, 'learning_rate': 0.0002635514018691588, 'epoch': 1.6}
外层迭代结束！
外层迭代结束！
{'loss': 0.0904, 'learning_rate': 0.00026074766355140184, 'epoch': 1.69}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1174, 'learning_rate': 0.0002579439252336448, 'epoch': 1.78}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.28it/s][A
 31%|███       | 4/13 [00:00<00:00, 11.80it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.56it/s][A
 54%|█████▍    | 7/13 [00:00<00:00,  8.82it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.12it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.36it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.44it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.16it/s][A                                                  
                                               [A 18%|█▊        | 200/1120 [03:17<13:52,  1.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.16it/s][A
                                               [A 18%|█▊        | 201/1120 [03:18<22:48,  1.49s/it] 18%|█▊        | 202/1120 [03:19<19:48,  1.29s/it] 18%|█▊        | 203/1120 [03:20<17:45,  1.16s/it] 18%|█▊        | 204/1120 [03:21<16:14,  1.06s/it] 18%|█▊        | 205/1120 [03:22<16:23,  1.08s/it] 18%|█▊        | 206/1120 [03:23<15:18,  1.00s/it] 18%|█▊        | 207/1120 [03:24<14:32,  1.05it/s] 19%|█▊        | 208/1120 [03:24<14:01,  1.08it/s] 19%|█▊        | 209/1120 [03:25<14:43,  1.03it/s] 19%|█▉        | 210/1120 [03:26<14:07,  1.07it/s]                                                   19%|█▉        | 210/1120 [03:26<14:07,  1.07it/s] 19%|█▉        | 211/1120 [03:27<13:41,  1.11it/s] 19%|█▉        | 212/1120 [03:28<13:27,  1.12it/s] 19%|█▉        | 213/1120 [03:29<14:17,  1.06it/s] 19%|█▉        | 214/1120 [03:30<13:53,  1.09it/s] 19%|█▉        | 215/1120 [03:31<13:37,  1.11it/s] 19%|█▉        | 216/1120 [03:32<13:28,  1.12it/s] 19%|█▉        | 217/1120 [03:33<14:17,  1.05it/s] 19%|█▉        | 218/1120 [03:34<13:46,  1.09it/s] 20%|█▉        | 219/1120 [03:34<13:24,  1.12it/s] 20%|█▉        | 220/1120 [03:35<13:11,  1.14it/s]                                                   20%|█▉        | 220/1120 [03:36<13:11,  1.14it/s] 20%|█▉        | 221/1120 [03:36<14:05,  1.06it/s] 20%|█▉        | 222/1120 [03:37<13:36,  1.10it/s] 20%|█▉        | 223/1120 [03:38<13:16,  1.13it/s] 20%|██        | 224/1120 [03:39<13:03,  1.14it/s] 20%|██        | 225/1120 [03:40<13:58,  1.07it/s] 20%|██        | 226/1120 [03:41<13:34,  1.10it/s] 20%|██        | 227/1120 [03:42<13:13,  1.13it/s] 20%|██        | 228/1120 [03:42<13:02,  1.14it/s] 20%|██        | 229/1120 [03:44<13:53,  1.07it/s] 21%|██        | 230/1120 [03:44<13:26,  1.10it/s]                                                   21%|██        | 230/1120 [03:44<13:26,  1.10it/s] 21%|██        | 231/1120 [03:45<13:07,  1.13it/s] 21%|██        | 232/1120 [03:46<12:56,  1.14it/s] 21%|██        | 233/1120 [03:47<13:50,  1.07it/s] 21%|██        | 234/1120 [03:48<13:19,  1.11it/s] 21%|██        | 235/1120 [03:49<13:10,  1.12it/s] 21%|██        | 236/1120 [03:50<12:59,  1.13it/s] 21%|██        | 237/1120 [03:51<13:54,  1.06it/s] 21%|██▏       | 238/1120 [03:52<13:25,  1.09it/s] 21%|██▏       | 239/1120 [03:53<13:07,  1.12it/s] 21%|██▏       | 240/1120 [03:53<12:53,  1.14it/s]                                                   21%|██▏       | 240/1120 [03:54<12:53,  1.14it/s]{'eval_loss': 0.13869823515415192, 'eval_runtime': 1.598, 'eval_samples_per_second': 62.577, 'eval_steps_per_second': 8.135, 'epoch': 1.78}
外层迭代结束！
外层迭代结束！
{'loss': 0.1389, 'learning_rate': 0.0002551401869158878, 'epoch': 1.87}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1156, 'learning_rate': 0.0002523364485981308, 'epoch': 1.96}
外层迭代结束！
外层迭代结束！
{'loss': 0.11, 'learning_rate': 0.0002495327102803738, 'epoch': 2.04}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0826, 'learning_rate': 0.00024672897196261677, 'epoch': 2.13}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.39it/s][A
 31%|███       | 4/13 [00:00<00:00, 11.83it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.56it/s][A
 54%|█████▍    | 7/13 [00:00<00:00,  8.81it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.10it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.35it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.41it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.13it/s][A                                                  
                                               [A 21%|██▏       | 240/1120 [03:55<12:53,  1.14it/s]
100%|██████████| 13/13 [00:01<00:00,  8.13it/s][A
                                               [A 22%|██▏       | 241/1120 [03:56<21:37,  1.48s/it] 22%|██▏       | 242/1120 [03:57<18:43,  1.28s/it] 22%|██▏       | 243/1120 [03:58<16:29,  1.13s/it] 22%|██▏       | 244/1120 [03:59<14:55,  1.02s/it] 22%|██▏       | 245/1120 [04:00<14:54,  1.02s/it] 22%|██▏       | 246/1120 [04:00<13:47,  1.06it/s] 22%|██▏       | 247/1120 [04:01<12:58,  1.12it/s] 22%|██▏       | 248/1120 [04:02<12:26,  1.17it/s] 22%|██▏       | 249/1120 [04:03<13:05,  1.11it/s] 22%|██▏       | 250/1120 [04:04<13:02,  1.11it/s]                                                   22%|██▏       | 250/1120 [04:04<13:02,  1.11it/s] 22%|██▏       | 251/1120 [04:05<13:06,  1.10it/s] 22%|██▎       | 252/1120 [04:06<13:05,  1.11it/s] 23%|██▎       | 253/1120 [04:07<13:59,  1.03it/s] 23%|██▎       | 254/1120 [04:08<13:28,  1.07it/s] 23%|██▎       | 255/1120 [04:08<13:04,  1.10it/s] 23%|██▎       | 256/1120 [04:09<12:49,  1.12it/s] 23%|██▎       | 257/1120 [04:10<13:36,  1.06it/s] 23%|██▎       | 258/1120 [04:11<13:11,  1.09it/s] 23%|██▎       | 259/1120 [04:12<12:53,  1.11it/s] 23%|██▎       | 260/1120 [04:13<12:35,  1.14it/s]                                                   23%|██▎       | 260/1120 [04:13<12:35,  1.14it/s] 23%|██▎       | 261/1120 [04:14<13:25,  1.07it/s] 23%|██▎       | 262/1120 [04:15<12:59,  1.10it/s] 23%|██▎       | 263/1120 [04:16<12:40,  1.13it/s] 24%|██▎       | 264/1120 [04:17<12:29,  1.14it/s] 24%|██▎       | 265/1120 [04:18<13:16,  1.07it/s] 24%|██▍       | 266/1120 [04:18<12:52,  1.11it/s] 24%|██▍       | 267/1120 [04:19<12:34,  1.13it/s] 24%|██▍       | 268/1120 [04:20<12:20,  1.15it/s] 24%|██▍       | 269/1120 [04:21<13:22,  1.06it/s] 24%|██▍       | 270/1120 [04:22<12:54,  1.10it/s]                                                   24%|██▍       | 270/1120 [04:22<12:54,  1.10it/s] 24%|██▍       | 271/1120 [04:23<12:39,  1.12it/s] 24%|██▍       | 272/1120 [04:24<12:26,  1.14it/s] 24%|██▍       | 273/1120 [04:25<13:16,  1.06it/s] 24%|██▍       | 274/1120 [04:26<12:53,  1.09it/s] 25%|██▍       | 275/1120 [04:27<12:33,  1.12it/s] 25%|██▍       | 276/1120 [04:27<12:18,  1.14it/s] 25%|██▍       | 277/1120 [04:28<13:06,  1.07it/s] 25%|██▍       | 278/1120 [04:29<12:42,  1.10it/s] 25%|██▍       | 279/1120 [04:30<12:26,  1.13it/s] 25%|██▌       | 280/1120 [04:31<12:15,  1.14it/s]                                                   25%|██▌       | 280/1120 [04:31<12:15,  1.14it/s]{'eval_loss': 0.13943348824977875, 'eval_runtime': 1.6006, 'eval_samples_per_second': 62.478, 'eval_steps_per_second': 8.122, 'epoch': 2.13}
外层迭代结束！
外层迭代结束！
{'loss': 0.1439, 'learning_rate': 0.0002439252336448598, 'epoch': 2.22}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0937, 'learning_rate': 0.00024112149532710278, 'epoch': 2.31}
外层迭代结束！
外层迭代结束！
{'loss': 0.1677, 'learning_rate': 0.00023831775700934577, 'epoch': 2.4}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1648, 'learning_rate': 0.00023551401869158876, 'epoch': 2.49}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.82it/s][A
 31%|███       | 4/13 [00:00<00:00, 12.21it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.75it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.49it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.74it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.71it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.35it/s][A                                                  
                                               [A 25%|██▌       | 280/1120 [04:33<12:15,  1.14it/s]
100%|██████████| 13/13 [00:01<00:00,  8.35it/s][A
                                               [A 25%|██▌       | 281/1120 [04:34<20:09,  1.44s/it] 25%|██▌       | 282/1120 [04:35<18:17,  1.31s/it] 25%|██▌       | 283/1120 [04:36<16:16,  1.17s/it] 25%|██▌       | 284/1120 [04:36<14:51,  1.07s/it] 25%|██▌       | 285/1120 [04:37<14:55,  1.07s/it] 26%|██▌       | 286/1120 [04:38<13:58,  1.01s/it] 26%|██▌       | 287/1120 [04:39<13:15,  1.05it/s] 26%|██▌       | 288/1120 [04:40<12:49,  1.08it/s] 26%|██▌       | 289/1120 [04:41<13:28,  1.03it/s] 26%|██▌       | 290/1120 [04:42<12:55,  1.07it/s]                                                   26%|██▌       | 290/1120 [04:42<12:55,  1.07it/s] 26%|██▌       | 291/1120 [04:43<12:31,  1.10it/s] 26%|██▌       | 292/1120 [04:44<12:14,  1.13it/s] 26%|██▌       | 293/1120 [04:45<12:58,  1.06it/s] 26%|██▋       | 294/1120 [04:46<12:52,  1.07it/s] 26%|██▋       | 295/1120 [04:46<12:28,  1.10it/s] 26%|██▋       | 296/1120 [04:47<12:10,  1.13it/s] 27%|██▋       | 297/1120 [04:48<12:55,  1.06it/s] 27%|██▋       | 298/1120 [04:49<12:28,  1.10it/s] 27%|██▋       | 299/1120 [04:50<12:11,  1.12it/s] 27%|██▋       | 300/1120 [04:51<11:57,  1.14it/s]                                                   27%|██▋       | 300/1120 [04:51<11:57,  1.14it/s] 27%|██▋       | 301/1120 [04:52<12:43,  1.07it/s] 27%|██▋       | 302/1120 [04:53<12:19,  1.11it/s] 27%|██▋       | 303/1120 [04:54<12:01,  1.13it/s] 27%|██▋       | 304/1120 [04:54<11:48,  1.15it/s] 27%|██▋       | 305/1120 [04:56<12:38,  1.08it/s] 27%|██▋       | 306/1120 [04:56<12:16,  1.11it/s] 27%|██▋       | 307/1120 [04:57<11:59,  1.13it/s] 28%|██▊       | 308/1120 [04:58<11:47,  1.15it/s] 28%|██▊       | 309/1120 [04:59<12:36,  1.07it/s] 28%|██▊       | 310/1120 [05:00<12:14,  1.10it/s]                                                   28%|██▊       | 310/1120 [05:00<12:14,  1.10it/s] 28%|██▊       | 311/1120 [05:01<11:59,  1.12it/s] 28%|██▊       | 312/1120 [05:02<11:45,  1.15it/s] 28%|██▊       | 313/1120 [05:03<12:29,  1.08it/s] 28%|██▊       | 314/1120 [05:04<12:13,  1.10it/s] 28%|██▊       | 315/1120 [05:04<11:53,  1.13it/s] 28%|██▊       | 316/1120 [05:05<11:40,  1.15it/s] 28%|██▊       | 317/1120 [05:06<12:27,  1.07it/s] 28%|██▊       | 318/1120 [05:07<12:08,  1.10it/s] 28%|██▊       | 319/1120 [05:08<11:52,  1.12it/s] 29%|██▊       | 320/1120 [05:09<11:39,  1.14it/s]                                                   29%|██▊       | 320/1120 [05:09<11:39,  1.14it/s]{'eval_loss': 0.15082673728466034, 'eval_runtime': 1.5517, 'eval_samples_per_second': 64.447, 'eval_steps_per_second': 8.378, 'epoch': 2.49}
外层迭代结束！
外层迭代结束！
{'loss': 0.1852, 'learning_rate': 0.00023271028037383175, 'epoch': 2.58}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0858, 'learning_rate': 0.00022990654205607474, 'epoch': 2.67}
外层迭代结束！
外层迭代结束！
{'loss': 0.0706, 'learning_rate': 0.00022710280373831773, 'epoch': 2.76}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0758, 'learning_rate': 0.00022429906542056072, 'epoch': 2.84}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.73it/s][A
 31%|███       | 4/13 [00:00<00:00, 12.23it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.75it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.50it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.75it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.72it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.35it/s][A                                                  
                                               [A 29%|██▊       | 320/1120 [05:11<11:39,  1.14it/s]
100%|██████████| 13/13 [00:01<00:00,  8.35it/s][A
                                               [A 29%|██▊       | 321/1120 [05:12<19:04,  1.43s/it] 29%|██▉       | 322/1120 [05:12<16:41,  1.25s/it] 29%|██▉       | 323/1120 [05:13<15:03,  1.13s/it] 29%|██▉       | 324/1120 [05:14<13:50,  1.04s/it] 29%|██▉       | 325/1120 [05:15<13:55,  1.05s/it] 29%|██▉       | 326/1120 [05:16<13:02,  1.01it/s] 29%|██▉       | 327/1120 [05:17<12:24,  1.06it/s] 29%|██▉       | 328/1120 [05:18<12:00,  1.10it/s] 29%|██▉       | 329/1120 [05:19<12:36,  1.05it/s] 29%|██▉       | 330/1120 [05:20<12:08,  1.08it/s]                                                   29%|██▉       | 330/1120 [05:20<12:08,  1.08it/s] 30%|██▉       | 331/1120 [05:20<11:47,  1.12it/s] 30%|██▉       | 332/1120 [05:21<11:30,  1.14it/s] 30%|██▉       | 333/1120 [05:22<12:27,  1.05it/s] 30%|██▉       | 334/1120 [05:23<11:55,  1.10it/s] 30%|██▉       | 335/1120 [05:24<11:39,  1.12it/s] 30%|███       | 336/1120 [05:25<11:27,  1.14it/s] 30%|███       | 337/1120 [05:26<12:10,  1.07it/s] 30%|███       | 338/1120 [05:27<11:47,  1.11it/s] 30%|███       | 339/1120 [05:28<11:31,  1.13it/s] 30%|███       | 340/1120 [05:28<11:20,  1.15it/s]                                                   30%|███       | 340/1120 [05:29<11:20,  1.15it/s] 30%|███       | 341/1120 [05:30<12:06,  1.07it/s] 31%|███       | 342/1120 [05:30<11:45,  1.10it/s] 31%|███       | 343/1120 [05:31<11:27,  1.13it/s] 31%|███       | 344/1120 [05:32<11:16,  1.15it/s] 31%|███       | 345/1120 [05:33<11:57,  1.08it/s] 31%|███       | 346/1120 [05:34<11:38,  1.11it/s] 31%|███       | 347/1120 [05:35<11:22,  1.13it/s] 31%|███       | 348/1120 [05:36<11:10,  1.15it/s] 31%|███       | 349/1120 [05:37<11:58,  1.07it/s] 31%|███▏      | 350/1120 [05:38<11:37,  1.10it/s]                                                   31%|███▏      | 350/1120 [05:38<11:37,  1.10it/s] 31%|███▏      | 351/1120 [05:38<11:22,  1.13it/s] 31%|███▏      | 352/1120 [05:39<11:08,  1.15it/s] 32%|███▏      | 353/1120 [05:40<11:54,  1.07it/s] 32%|███▏      | 354/1120 [05:41<11:30,  1.11it/s] 32%|███▏      | 355/1120 [05:42<11:15,  1.13it/s] 32%|███▏      | 356/1120 [05:43<11:02,  1.15it/s] 32%|███▏      | 357/1120 [05:44<11:49,  1.08it/s] 32%|███▏      | 358/1120 [05:45<11:25,  1.11it/s] 32%|███▏      | 359/1120 [05:46<11:10,  1.14it/s] 32%|███▏      | 360/1120 [05:46<10:58,  1.15it/s]                                                   32%|███▏      | 360/1120 [05:47<10:58,  1.15it/s]{'eval_loss': 0.1914587765932083, 'eval_runtime': 1.5522, 'eval_samples_per_second': 64.424, 'eval_steps_per_second': 8.375, 'epoch': 2.84}
外层迭代结束！
外层迭代结束！
{'loss': 0.1319, 'learning_rate': 0.0002214953271028037, 'epoch': 2.93}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1145, 'learning_rate': 0.0002186915887850467, 'epoch': 3.02}
外层迭代结束！
外层迭代结束！
{'loss': 0.0673, 'learning_rate': 0.0002158878504672897, 'epoch': 3.11}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0604, 'learning_rate': 0.00021308411214953268, 'epoch': 3.2}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.76it/s][A
 31%|███       | 4/13 [00:00<00:00, 12.21it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.75it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.51it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.76it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.72it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.36it/s][A                                                  
                                               [A 32%|███▏      | 360/1120 [05:48<10:58,  1.15it/s]
100%|██████████| 13/13 [00:01<00:00,  8.36it/s][A
                                               [A 32%|███▏      | 361/1120 [05:49<18:07,  1.43s/it] 32%|███▏      | 362/1120 [05:50<15:51,  1.26s/it] 32%|███▏      | 363/1120 [05:51<14:16,  1.13s/it] 32%|███▎      | 364/1120 [05:52<13:10,  1.05s/it] 33%|███▎      | 365/1120 [05:53<13:28,  1.07s/it] 33%|███▎      | 366/1120 [05:54<12:32,  1.00it/s] 33%|███▎      | 367/1120 [05:55<12:24,  1.01it/s] 33%|███▎      | 368/1120 [05:55<11:50,  1.06it/s] 33%|███▎      | 369/1120 [05:57<12:14,  1.02it/s] 33%|███▎      | 370/1120 [05:57<11:40,  1.07it/s]                                                   33%|███▎      | 370/1120 [05:57<11:40,  1.07it/s] 33%|███▎      | 371/1120 [05:58<11:17,  1.11it/s] 33%|███▎      | 372/1120 [05:59<11:02,  1.13it/s] 33%|███▎      | 373/1120 [06:00<11:42,  1.06it/s] 33%|███▎      | 374/1120 [06:01<11:17,  1.10it/s] 33%|███▎      | 375/1120 [06:02<10:59,  1.13it/s] 34%|███▎      | 376/1120 [06:03<10:46,  1.15it/s] 34%|███▎      | 377/1120 [06:04<11:31,  1.08it/s] 34%|███▍      | 378/1120 [06:04<11:07,  1.11it/s] 34%|███▍      | 379/1120 [06:05<10:51,  1.14it/s] 34%|███▍      | 380/1120 [06:06<10:40,  1.16it/s]                                                   34%|███▍      | 380/1120 [06:06<10:40,  1.16it/s] 34%|███▍      | 381/1120 [06:07<11:22,  1.08it/s] 34%|███▍      | 382/1120 [06:08<11:03,  1.11it/s] 34%|███▍      | 383/1120 [06:09<10:48,  1.14it/s] 34%|███▍      | 384/1120 [06:10<10:39,  1.15it/s] 34%|███▍      | 385/1120 [06:11<11:21,  1.08it/s] 34%|███▍      | 386/1120 [06:12<11:01,  1.11it/s] 35%|███▍      | 387/1120 [06:12<10:44,  1.14it/s] 35%|███▍      | 388/1120 [06:13<10:33,  1.16it/s] 35%|███▍      | 389/1120 [06:14<11:15,  1.08it/s] 35%|███▍      | 390/1120 [06:15<10:54,  1.12it/s]                                                   35%|███▍      | 390/1120 [06:15<10:54,  1.12it/s] 35%|███▍      | 391/1120 [06:16<10:39,  1.14it/s] 35%|███▌      | 392/1120 [06:17<10:28,  1.16it/s] 35%|███▌      | 393/1120 [06:18<11:11,  1.08it/s] 35%|███▌      | 394/1120 [06:19<10:51,  1.11it/s] 35%|███▌      | 395/1120 [06:20<10:37,  1.14it/s] 35%|███▌      | 396/1120 [06:20<10:29,  1.15it/s] 35%|███▌      | 397/1120 [06:22<11:11,  1.08it/s] 36%|███▌      | 398/1120 [06:22<10:51,  1.11it/s] 36%|███▌      | 399/1120 [06:23<10:34,  1.14it/s] 36%|███▌      | 400/1120 [06:24<10:22,  1.16it/s]                                                   36%|███▌      | 400/1120 [06:24<10:22,  1.16it/s]{'eval_loss': 0.14612962305545807, 'eval_runtime': 1.5546, 'eval_samples_per_second': 64.324, 'eval_steps_per_second': 8.362, 'epoch': 3.2}
外层迭代结束！
外层迭代结束！
{'loss': 0.0567, 'learning_rate': 0.00021028037383177567, 'epoch': 3.29}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.079, 'learning_rate': 0.00020747663551401867, 'epoch': 3.38}
外层迭代结束！
外层迭代结束！
{'loss': 0.0762, 'learning_rate': 0.00020467289719626166, 'epoch': 3.47}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0714, 'learning_rate': 0.00020186915887850465, 'epoch': 3.56}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.85it/s][A
 31%|███       | 4/13 [00:00<00:00, 12.20it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.73it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.52it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.78it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.74it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.38it/s][A                                                  
                                               [A 36%|███▌      | 400/1120 [06:26<10:22,  1.16it/s]
100%|██████████| 13/13 [00:01<00:00,  8.38it/s][A
                                               [A 36%|███▌      | 401/1120 [06:27<17:10,  1.43s/it] 36%|███▌      | 402/1120 [06:28<15:01,  1.26s/it] 36%|███▌      | 403/1120 [06:28<13:31,  1.13s/it] 36%|███▌      | 404/1120 [06:29<12:26,  1.04s/it] 36%|███▌      | 405/1120 [06:30<12:36,  1.06s/it] 36%|███▋      | 406/1120 [06:31<11:55,  1.00s/it] 36%|███▋      | 407/1120 [06:32<11:35,  1.02it/s] 36%|███▋      | 408/1120 [06:33<11:05,  1.07it/s] 37%|███▋      | 409/1120 [06:34<11:32,  1.03it/s] 37%|███▋      | 410/1120 [06:35<11:01,  1.07it/s]                                                   37%|███▋      | 410/1120 [06:35<11:01,  1.07it/s] 37%|███▋      | 411/1120 [06:36<10:42,  1.10it/s] 37%|███▋      | 412/1120 [06:37<10:26,  1.13it/s] 37%|███▋      | 413/1120 [06:38<11:02,  1.07it/s] 37%|███▋      | 414/1120 [06:38<10:38,  1.11it/s] 37%|███▋      | 415/1120 [06:39<10:22,  1.13it/s] 37%|███▋      | 416/1120 [06:40<10:15,  1.14it/s] 37%|███▋      | 417/1120 [06:41<10:54,  1.07it/s] 37%|███▋      | 418/1120 [06:42<10:33,  1.11it/s] 37%|███▋      | 419/1120 [06:43<10:19,  1.13it/s] 38%|███▊      | 420/1120 [06:44<10:09,  1.15it/s]                                                   38%|███▊      | 420/1120 [06:44<10:09,  1.15it/s] 38%|███▊      | 421/1120 [06:45<10:48,  1.08it/s] 38%|███▊      | 422/1120 [06:46<10:27,  1.11it/s] 38%|███▊      | 423/1120 [06:46<10:14,  1.13it/s] 38%|███▊      | 424/1120 [06:47<10:03,  1.15it/s] 38%|███▊      | 425/1120 [06:48<10:48,  1.07it/s] 38%|███▊      | 426/1120 [06:49<10:27,  1.11it/s] 38%|███▊      | 427/1120 [06:50<10:13,  1.13it/s] 38%|███▊      | 428/1120 [06:51<10:02,  1.15it/s] 38%|███▊      | 429/1120 [06:52<10:43,  1.07it/s] 38%|███▊      | 430/1120 [06:53<10:21,  1.11it/s]                                                   38%|███▊      | 430/1120 [06:53<10:21,  1.11it/s] 38%|███▊      | 431/1120 [06:54<10:06,  1.14it/s] 39%|███▊      | 432/1120 [06:54<09:56,  1.15it/s] 39%|███▊      | 433/1120 [06:56<10:35,  1.08it/s] 39%|███▉      | 434/1120 [06:56<10:16,  1.11it/s] 39%|███▉      | 435/1120 [06:57<09:59,  1.14it/s] 39%|███▉      | 436/1120 [06:58<09:44,  1.17it/s] 39%|███▉      | 437/1120 [06:59<10:03,  1.13it/s] 39%|███▉      | 438/1120 [07:00<09:49,  1.16it/s] 39%|███▉      | 439/1120 [07:01<09:25,  1.20it/s] 39%|███▉      | 440/1120 [07:01<09:09,  1.24it/s]                                                   39%|███▉      | 440/1120 [07:01<09:09,  1.24it/s]{'eval_loss': 0.1464606076478958, 'eval_runtime': 1.547, 'eval_samples_per_second': 64.64, 'eval_steps_per_second': 8.403, 'epoch': 3.56}
外层迭代结束！
外层迭代结束！
{'loss': 0.029, 'learning_rate': 0.00019906542056074764, 'epoch': 3.64}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0584, 'learning_rate': 0.00019626168224299063, 'epoch': 3.73}
外层迭代结束！
外层迭代结束！
{'loss': 0.0856, 'learning_rate': 0.00019345794392523362, 'epoch': 3.82}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0582, 'learning_rate': 0.0001906542056074766, 'epoch': 3.91}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.85it/s][A
 31%|███       | 4/13 [00:00<00:00, 12.28it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.78it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.51it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.74it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.72it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.37it/s][A                                                  
                                               [A 39%|███▉      | 440/1120 [07:03<09:09,  1.24it/s]
100%|██████████| 13/13 [00:01<00:00,  8.37it/s][A
                                               [A 39%|███▉      | 441/1120 [07:04<15:21,  1.36s/it] 39%|███▉      | 442/1120 [07:05<13:15,  1.17s/it] 40%|███▉      | 443/1120 [07:05<11:46,  1.04s/it] 40%|███▉      | 444/1120 [07:06<10:45,  1.05it/s] 40%|███▉      | 445/1120 [07:07<10:41,  1.05it/s] 40%|███▉      | 446/1120 [07:08<09:58,  1.13it/s] 40%|███▉      | 447/1120 [07:09<09:33,  1.17it/s] 40%|████      | 448/1120 [07:09<09:13,  1.21it/s] 40%|████      | 449/1120 [07:10<09:42,  1.15it/s] 40%|████      | 450/1120 [07:11<09:18,  1.20it/s]                                                   40%|████      | 450/1120 [07:11<09:18,  1.20it/s] 40%|████      | 451/1120 [07:12<09:00,  1.24it/s] 40%|████      | 452/1120 [07:13<08:47,  1.27it/s] 40%|████      | 453/1120 [07:14<09:17,  1.20it/s] 41%|████      | 454/1120 [07:14<08:58,  1.24it/s] 41%|████      | 455/1120 [07:15<08:43,  1.27it/s] 41%|████      | 456/1120 [07:16<08:35,  1.29it/s] 41%|████      | 457/1120 [07:17<09:07,  1.21it/s] 41%|████      | 458/1120 [07:17<08:48,  1.25it/s] 41%|████      | 459/1120 [07:18<08:36,  1.28it/s] 41%|████      | 460/1120 [07:19<08:29,  1.30it/s]                                                   41%|████      | 460/1120 [07:19<08:29,  1.30it/s] 41%|████      | 461/1120 [07:20<09:03,  1.21it/s] 41%|████▏     | 462/1120 [07:21<08:45,  1.25it/s] 41%|████▏     | 463/1120 [07:21<08:36,  1.27it/s] 41%|████▏     | 464/1120 [07:22<08:25,  1.30it/s] 42%|████▏     | 465/1120 [07:23<09:12,  1.19it/s] 42%|████▏     | 466/1120 [07:24<08:51,  1.23it/s] 42%|████▏     | 467/1120 [07:25<08:34,  1.27it/s] 42%|████▏     | 468/1120 [07:25<08:23,  1.30it/s] 42%|████▏     | 469/1120 [07:26<09:10,  1.18it/s] 42%|████▏     | 470/1120 [07:27<08:49,  1.23it/s]                                                   42%|████▏     | 470/1120 [07:27<08:49,  1.23it/s] 42%|████▏     | 471/1120 [07:28<08:35,  1.26it/s] 42%|████▏     | 472/1120 [07:29<08:20,  1.30it/s] 42%|████▏     | 473/1120 [07:30<08:58,  1.20it/s] 42%|████▏     | 474/1120 [07:30<08:39,  1.24it/s] 42%|████▏     | 475/1120 [07:31<08:27,  1.27it/s] 42%|████▎     | 476/1120 [07:32<08:16,  1.30it/s] 43%|████▎     | 477/1120 [07:33<08:51,  1.21it/s] 43%|████▎     | 478/1120 [07:33<08:35,  1.24it/s] 43%|████▎     | 479/1120 [07:34<08:24,  1.27it/s] 43%|████▎     | 480/1120 [07:35<08:14,  1.30it/s]                                                   43%|████▎     | 480/1120 [07:35<08:14,  1.30it/s]{'eval_loss': 0.15730561316013336, 'eval_runtime': 1.548, 'eval_samples_per_second': 64.599, 'eval_steps_per_second': 8.398, 'epoch': 3.91}
外层迭代结束！
外层迭代结束！
{'loss': 0.1875, 'learning_rate': 0.0001878504672897196, 'epoch': 4.0}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0375, 'learning_rate': 0.0001850467289719626, 'epoch': 4.09}
外层迭代结束！
外层迭代结束！
{'loss': 0.0578, 'learning_rate': 0.00018224299065420558, 'epoch': 4.18}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0501, 'learning_rate': 0.00017943925233644857, 'epoch': 4.27}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.78it/s][A
 31%|███       | 4/13 [00:00<00:00, 12.24it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.76it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.50it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.75it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.72it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.37it/s][A                                                  
                                               [A 43%|████▎     | 480/1120 [07:37<08:14,  1.30it/s]
100%|██████████| 13/13 [00:01<00:00,  8.37it/s][A
                                               [A 43%|████▎     | 481/1120 [07:38<14:10,  1.33s/it] 43%|████▎     | 482/1120 [07:38<12:16,  1.15s/it] 43%|████▎     | 483/1120 [07:39<10:54,  1.03s/it] 43%|████▎     | 484/1120 [07:40<10:02,  1.05it/s] 43%|████▎     | 485/1120 [07:41<10:00,  1.06it/s] 43%|████▎     | 486/1120 [07:41<09:20,  1.13it/s] 43%|████▎     | 487/1120 [07:42<08:52,  1.19it/s] 44%|████▎     | 488/1120 [07:43<08:31,  1.24it/s] 44%|████▎     | 489/1120 [07:44<09:00,  1.17it/s] 44%|████▍     | 490/1120 [07:45<08:38,  1.22it/s]                                                   44%|████▍     | 490/1120 [07:45<08:38,  1.22it/s] 44%|████▍     | 491/1120 [07:45<08:21,  1.25it/s] 44%|████▍     | 492/1120 [07:46<08:08,  1.28it/s] 44%|████▍     | 493/1120 [07:47<08:42,  1.20it/s] 44%|████▍     | 494/1120 [07:48<08:26,  1.24it/s] 44%|████▍     | 495/1120 [07:49<08:11,  1.27it/s] 44%|████▍     | 496/1120 [07:49<08:03,  1.29it/s] 44%|████▍     | 497/1120 [07:50<08:33,  1.21it/s] 44%|████▍     | 498/1120 [07:51<08:21,  1.24it/s] 45%|████▍     | 499/1120 [07:52<08:09,  1.27it/s] 45%|████▍     | 500/1120 [07:53<08:00,  1.29it/s]                                                   45%|████▍     | 500/1120 [07:53<08:00,  1.29it/s] 45%|████▍     | 501/1120 [07:53<08:30,  1.21it/s] 45%|████▍     | 502/1120 [07:54<08:12,  1.25it/s] 45%|████▍     | 503/1120 [07:55<08:02,  1.28it/s] 45%|████▌     | 504/1120 [07:56<07:58,  1.29it/s] 45%|████▌     | 505/1120 [07:57<08:28,  1.21it/s] 45%|████▌     | 506/1120 [07:57<08:12,  1.25it/s] 45%|████▌     | 507/1120 [07:58<08:00,  1.28it/s] 45%|████▌     | 508/1120 [07:59<07:50,  1.30it/s] 45%|████▌     | 509/1120 [08:00<08:18,  1.23it/s] 46%|████▌     | 510/1120 [08:01<08:05,  1.26it/s]                                                   46%|████▌     | 510/1120 [08:01<08:05,  1.26it/s] 46%|████▌     | 511/1120 [08:01<07:56,  1.28it/s] 46%|████▌     | 512/1120 [08:02<07:45,  1.30it/s] 46%|████▌     | 513/1120 [08:03<08:17,  1.22it/s] 46%|████▌     | 514/1120 [08:04<08:01,  1.26it/s] 46%|████▌     | 515/1120 [08:05<08:04,  1.25it/s] 46%|████▌     | 516/1120 [08:05<07:56,  1.27it/s] 46%|████▌     | 517/1120 [08:06<08:26,  1.19it/s] 46%|████▋     | 518/1120 [08:07<08:06,  1.24it/s] 46%|████▋     | 519/1120 [08:08<07:55,  1.26it/s] 46%|████▋     | 520/1120 [08:08<07:46,  1.29it/s]                                                   46%|████▋     | 520/1120 [08:09<07:46,  1.29it/s]{'eval_loss': 0.14034047722816467, 'eval_runtime': 1.55, 'eval_samples_per_second': 64.518, 'eval_steps_per_second': 8.387, 'epoch': 4.27}
外层迭代结束！
外层迭代结束！
{'loss': 0.0556, 'learning_rate': 0.00017663551401869156, 'epoch': 4.36}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0373, 'learning_rate': 0.00017383177570093455, 'epoch': 4.44}
外层迭代结束！
外层迭代结束！
{'loss': 0.0366, 'learning_rate': 0.00017102803738317754, 'epoch': 4.53}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0411, 'learning_rate': 0.00016822429906542053, 'epoch': 4.62}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.82it/s][A
 31%|███       | 4/13 [00:00<00:00, 12.18it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.72it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.45it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.77it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.74it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.36it/s][A                                                  
                                               [A 46%|████▋     | 520/1120 [08:10<07:46,  1.29it/s]
100%|██████████| 13/13 [00:01<00:00,  8.36it/s][A
                                               [A 47%|████▋     | 521/1120 [08:11<13:19,  1.34s/it] 47%|████▋     | 522/1120 [08:12<11:31,  1.16s/it] 47%|████▋     | 523/1120 [08:13<10:15,  1.03s/it] 47%|████▋     | 524/1120 [08:13<09:21,  1.06it/s] 47%|████▋     | 525/1120 [08:14<09:20,  1.06it/s] 47%|████▋     | 526/1120 [08:15<08:43,  1.13it/s] 47%|████▋     | 527/1120 [08:16<08:17,  1.19it/s] 47%|████▋     | 528/1120 [08:16<07:58,  1.24it/s] 47%|████▋     | 529/1120 [08:17<08:23,  1.17it/s] 47%|████▋     | 530/1120 [08:18<08:06,  1.21it/s]                                                   47%|████▋     | 530/1120 [08:18<08:06,  1.21it/s] 47%|████▋     | 531/1120 [08:19<07:50,  1.25it/s] 48%|████▊     | 532/1120 [08:20<07:39,  1.28it/s] 48%|████▊     | 533/1120 [08:21<08:06,  1.21it/s] 48%|████▊     | 534/1120 [08:21<07:48,  1.25it/s] 48%|████▊     | 535/1120 [08:22<07:36,  1.28it/s] 48%|████▊     | 536/1120 [08:23<07:29,  1.30it/s] 48%|████▊     | 537/1120 [08:24<07:58,  1.22it/s] 48%|████▊     | 538/1120 [08:25<07:43,  1.25it/s] 48%|████▊     | 539/1120 [08:25<07:34,  1.28it/s] 48%|████▊     | 540/1120 [08:26<07:25,  1.30it/s]                                                   48%|████▊     | 540/1120 [08:26<07:25,  1.30it/s] 48%|████▊     | 541/1120 [08:27<07:55,  1.22it/s] 48%|████▊     | 542/1120 [08:28<07:40,  1.25it/s] 48%|████▊     | 543/1120 [08:28<07:31,  1.28it/s] 49%|████▊     | 544/1120 [08:29<07:22,  1.30it/s] 49%|████▊     | 545/1120 [08:30<07:53,  1.21it/s] 49%|████▉     | 546/1120 [08:31<07:38,  1.25it/s] 49%|████▉     | 547/1120 [08:32<07:25,  1.29it/s] 49%|████▉     | 548/1120 [08:32<07:17,  1.31it/s] 49%|████▉     | 549/1120 [08:33<07:46,  1.22it/s] 49%|████▉     | 550/1120 [08:34<07:32,  1.26it/s]                                                   49%|████▉     | 550/1120 [08:34<07:32,  1.26it/s] 49%|████▉     | 551/1120 [08:35<07:22,  1.29it/s] 49%|████▉     | 552/1120 [08:35<07:15,  1.30it/s] 49%|████▉     | 553/1120 [08:36<07:45,  1.22it/s] 49%|████▉     | 554/1120 [08:37<07:58,  1.18it/s] 50%|████▉     | 555/1120 [08:38<07:38,  1.23it/s] 50%|████▉     | 556/1120 [08:39<07:24,  1.27it/s] 50%|████▉     | 557/1120 [08:40<07:51,  1.19it/s] 50%|████▉     | 558/1120 [08:40<07:33,  1.24it/s] 50%|████▉     | 559/1120 [08:41<07:22,  1.27it/s] 50%|█████     | 560/1120 [08:42<07:12,  1.30it/s]                                                   50%|█████     | 560/1120 [08:42<07:12,  1.30it/s]{'eval_loss': 0.15664374828338623, 'eval_runtime': 1.5509, 'eval_samples_per_second': 64.477, 'eval_steps_per_second': 8.382, 'epoch': 4.62}
外层迭代结束！
外层迭代结束！
{'loss': 0.0639, 'learning_rate': 0.00016542056074766352, 'epoch': 4.71}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.077, 'learning_rate': 0.00016261682242990652, 'epoch': 4.8}
外层迭代结束！
外层迭代结束！
{'loss': 0.0069, 'learning_rate': 0.0001598130841121495, 'epoch': 4.89}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0841, 'learning_rate': 0.0001570093457943925, 'epoch': 4.98}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.93it/s][A
 31%|███       | 4/13 [00:00<00:00, 12.25it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.76it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.48it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.73it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.71it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.36it/s][A                                                  
                                               [A 50%|█████     | 560/1120 [08:44<07:12,  1.30it/s]
100%|██████████| 13/13 [00:01<00:00,  8.36it/s][A
                                               [A 50%|█████     | 561/1120 [08:45<12:19,  1.32s/it] 50%|█████     | 562/1120 [08:45<10:40,  1.15s/it] 50%|█████     | 563/1120 [08:46<09:32,  1.03s/it] 50%|█████     | 564/1120 [08:47<08:44,  1.06it/s] 50%|█████     | 565/1120 [08:48<08:41,  1.06it/s] 51%|█████     | 566/1120 [08:48<08:07,  1.14it/s] 51%|█████     | 567/1120 [08:49<07:44,  1.19it/s] 51%|█████     | 568/1120 [08:50<07:27,  1.23it/s] 51%|█████     | 569/1120 [08:51<07:47,  1.18it/s] 51%|█████     | 570/1120 [08:52<07:30,  1.22it/s]                                                   51%|█████     | 570/1120 [08:52<07:30,  1.22it/s] 51%|█████     | 571/1120 [08:52<07:17,  1.26it/s] 51%|█████     | 572/1120 [08:53<07:10,  1.27it/s] 51%|█████     | 573/1120 [08:54<07:34,  1.20it/s] 51%|█████▏    | 574/1120 [08:55<07:17,  1.25it/s] 51%|█████▏    | 575/1120 [08:56<07:07,  1.28it/s] 51%|█████▏    | 576/1120 [08:56<06:59,  1.30it/s] 52%|█████▏    | 577/1120 [08:57<07:26,  1.22it/s] 52%|█████▏    | 578/1120 [08:58<07:11,  1.26it/s] 52%|█████▏    | 579/1120 [08:59<07:00,  1.29it/s] 52%|█████▏    | 580/1120 [08:59<06:53,  1.31it/s]                                                   52%|█████▏    | 580/1120 [09:00<06:53,  1.31it/s] 52%|█████▏    | 581/1120 [09:00<07:21,  1.22it/s] 52%|█████▏    | 582/1120 [09:01<07:21,  1.22it/s] 52%|█████▏    | 583/1120 [09:02<07:06,  1.26it/s] 52%|█████▏    | 584/1120 [09:03<06:54,  1.29it/s] 52%|█████▏    | 585/1120 [09:04<07:20,  1.22it/s] 52%|█████▏    | 586/1120 [09:04<07:06,  1.25it/s] 52%|█████▏    | 587/1120 [09:05<06:56,  1.28it/s] 52%|█████▎    | 588/1120 [09:06<06:48,  1.30it/s] 53%|█████▎    | 589/1120 [09:07<07:14,  1.22it/s] 53%|█████▎    | 590/1120 [09:08<07:13,  1.22it/s]                                                   53%|█████▎    | 590/1120 [09:08<07:13,  1.22it/s] 53%|█████▎    | 591/1120 [09:08<07:00,  1.26it/s] 53%|█████▎    | 592/1120 [09:09<06:51,  1.28it/s] 53%|█████▎    | 593/1120 [09:10<07:18,  1.20it/s] 53%|█████▎    | 594/1120 [09:11<07:03,  1.24it/s] 53%|█████▎    | 595/1120 [09:12<06:52,  1.27it/s] 53%|█████▎    | 596/1120 [09:12<06:43,  1.30it/s] 53%|█████▎    | 597/1120 [09:13<07:10,  1.21it/s] 53%|█████▎    | 598/1120 [09:14<06:56,  1.25it/s] 53%|█████▎    | 599/1120 [09:15<06:46,  1.28it/s] 54%|█████▎    | 600/1120 [09:15<06:41,  1.29it/s]                                                   54%|█████▎    | 600/1120 [09:16<06:41,  1.29it/s]{'eval_loss': 0.16974231600761414, 'eval_runtime': 1.5508, 'eval_samples_per_second': 64.484, 'eval_steps_per_second': 8.383, 'epoch': 4.98}
外层迭代结束！
外层迭代结束！
{'loss': 0.0503, 'learning_rate': 0.0001542056074766355, 'epoch': 5.07}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0565, 'learning_rate': 0.00015140186915887848, 'epoch': 5.16}
外层迭代结束！
外层迭代结束！
{'loss': 0.0438, 'learning_rate': 0.00014859813084112147, 'epoch': 5.24}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0157, 'learning_rate': 0.00014579439252336446, 'epoch': 5.33}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.84it/s][A
 31%|███       | 4/13 [00:00<00:00, 12.26it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.76it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.49it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.73it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.71it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.36it/s][A                                                  
                                               [A 54%|█████▎    | 600/1120 [09:17<06:41,  1.29it/s]
100%|██████████| 13/13 [00:01<00:00,  8.36it/s][A
                                               [A 54%|█████▎    | 601/1120 [09:18<11:27,  1.32s/it] 54%|█████▍    | 602/1120 [09:19<09:55,  1.15s/it] 54%|█████▍    | 603/1120 [09:20<08:50,  1.03s/it] 54%|█████▍    | 604/1120 [09:20<08:05,  1.06it/s] 54%|█████▍    | 605/1120 [09:21<08:05,  1.06it/s] 54%|█████▍    | 606/1120 [09:22<07:32,  1.14it/s] 54%|█████▍    | 607/1120 [09:23<07:08,  1.20it/s] 54%|█████▍    | 608/1120 [09:23<06:53,  1.24it/s] 54%|█████▍    | 609/1120 [09:24<07:14,  1.18it/s] 54%|█████▍    | 610/1120 [09:25<06:57,  1.22it/s]                                                   54%|█████▍    | 610/1120 [09:25<06:57,  1.22it/s] 55%|█████▍    | 611/1120 [09:26<06:44,  1.26it/s] 55%|█████▍    | 612/1120 [09:27<06:33,  1.29it/s] 55%|█████▍    | 613/1120 [09:28<06:59,  1.21it/s] 55%|█████▍    | 614/1120 [09:28<06:46,  1.24it/s] 55%|█████▍    | 615/1120 [09:29<06:36,  1.27it/s] 55%|█████▌    | 616/1120 [09:30<06:31,  1.29it/s] 55%|█████▌    | 617/1120 [09:31<06:56,  1.21it/s] 55%|█████▌    | 618/1120 [09:31<06:41,  1.25it/s] 55%|█████▌    | 619/1120 [09:32<06:31,  1.28it/s] 55%|█████▌    | 620/1120 [09:33<06:23,  1.30it/s]                                                   55%|█████▌    | 620/1120 [09:33<06:23,  1.30it/s] 55%|█████▌    | 621/1120 [09:34<06:49,  1.22it/s] 56%|█████▌    | 622/1120 [09:35<06:33,  1.27it/s] 56%|█████▌    | 623/1120 [09:35<06:28,  1.28it/s] 56%|█████▌    | 624/1120 [09:36<06:44,  1.22it/s] 56%|█████▌    | 625/1120 [09:37<07:32,  1.09it/s] 56%|█████▌    | 626/1120 [09:38<07:14,  1.14it/s] 56%|█████▌    | 627/1120 [09:39<07:01,  1.17it/s] 56%|█████▌    | 628/1120 [09:40<06:51,  1.20it/s] 56%|█████▌    | 629/1120 [09:41<07:17,  1.12it/s] 56%|█████▋    | 630/1120 [09:42<07:03,  1.16it/s]                                                   56%|█████▋    | 630/1120 [09:42<07:03,  1.16it/s] 56%|█████▋    | 631/1120 [09:42<07:00,  1.16it/s] 56%|█████▋    | 632/1120 [09:43<07:03,  1.15it/s] 57%|█████▋    | 633/1120 [09:44<07:41,  1.06it/s] 57%|█████▋    | 634/1120 [09:45<07:30,  1.08it/s] 57%|█████▋    | 635/1120 [09:46<07:23,  1.09it/s] 57%|█████▋    | 636/1120 [09:47<07:20,  1.10it/s] 57%|█████▋    | 637/1120 [09:48<07:53,  1.02it/s] 57%|█████▋    | 638/1120 [09:49<07:37,  1.05it/s] 57%|█████▋    | 639/1120 [09:50<07:23,  1.08it/s] 57%|█████▋    | 640/1120 [09:51<07:12,  1.11it/s]                                                   57%|█████▋    | 640/1120 [09:51<07:12,  1.11it/s]{'eval_loss': 0.19805915653705597, 'eval_runtime': 1.5513, 'eval_samples_per_second': 64.462, 'eval_steps_per_second': 8.38, 'epoch': 5.33}
外层迭代结束！
外层迭代结束！
{'loss': 0.043, 'learning_rate': 0.00014299065420560745, 'epoch': 5.42}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0392, 'learning_rate': 0.00014018691588785044, 'epoch': 5.51}
外层迭代结束！
外层迭代结束！
{'loss': 0.0413, 'learning_rate': 0.00013738317757009343, 'epoch': 5.6}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0407, 'learning_rate': 0.00013457943925233642, 'epoch': 5.69}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.25it/s][A
 31%|███       | 4/13 [00:00<00:00, 11.71it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.51it/s][A
 54%|█████▍    | 7/13 [00:00<00:00,  8.76it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.08it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.34it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.40it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.05it/s][A                                                  
                                               [A 57%|█████▋    | 640/1120 [09:53<07:12,  1.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.05it/s][A
                                               [A 57%|█████▋    | 641/1120 [09:54<11:37,  1.46s/it] 57%|█████▋    | 642/1120 [09:54<09:58,  1.25s/it] 57%|█████▋    | 643/1120 [09:55<08:45,  1.10s/it] 57%|█████▊    | 644/1120 [09:56<08:17,  1.05s/it] 58%|█████▊    | 645/1120 [09:57<08:01,  1.01s/it] 58%|█████▊    | 646/1120 [09:58<07:24,  1.07it/s] 58%|█████▊    | 647/1120 [09:59<06:57,  1.13it/s] 58%|█████▊    | 648/1120 [09:59<06:36,  1.19it/s] 58%|█████▊    | 649/1120 [10:00<06:52,  1.14it/s] 58%|█████▊    | 650/1120 [10:01<06:34,  1.19it/s]                                                   58%|█████▊    | 650/1120 [10:01<06:34,  1.19it/s] 58%|█████▊    | 651/1120 [10:02<06:20,  1.23it/s] 58%|█████▊    | 652/1120 [10:02<06:11,  1.26it/s] 58%|█████▊    | 653/1120 [10:03<06:34,  1.18it/s] 58%|█████▊    | 654/1120 [10:04<06:20,  1.22it/s] 58%|█████▊    | 655/1120 [10:05<06:08,  1.26it/s] 59%|█████▊    | 656/1120 [10:06<06:00,  1.29it/s] 59%|█████▊    | 657/1120 [10:07<06:21,  1.21it/s] 59%|█████▉    | 658/1120 [10:07<06:08,  1.25it/s] 59%|█████▉    | 659/1120 [10:08<06:00,  1.28it/s] 59%|█████▉    | 660/1120 [10:09<05:53,  1.30it/s]                                                   59%|█████▉    | 660/1120 [10:09<05:53,  1.30it/s] 59%|█████▉    | 661/1120 [10:10<06:29,  1.18it/s] 59%|█████▉    | 662/1120 [10:11<06:14,  1.22it/s] 59%|█████▉    | 663/1120 [10:11<06:03,  1.26it/s] 59%|█████▉    | 664/1120 [10:12<05:55,  1.28it/s] 59%|█████▉    | 665/1120 [10:13<06:16,  1.21it/s] 59%|█████▉    | 666/1120 [10:14<06:03,  1.25it/s] 60%|█████▉    | 667/1120 [10:14<05:53,  1.28it/s] 60%|█████▉    | 668/1120 [10:15<05:47,  1.30it/s] 60%|█████▉    | 669/1120 [10:16<06:10,  1.22it/s] 60%|█████▉    | 670/1120 [10:17<05:58,  1.26it/s]                                                   60%|█████▉    | 670/1120 [10:17<05:58,  1.26it/s] 60%|█████▉    | 671/1120 [10:18<05:49,  1.28it/s] 60%|██████    | 672/1120 [10:18<05:43,  1.31it/s] 60%|██████    | 673/1120 [10:19<06:06,  1.22it/s] 60%|██████    | 674/1120 [10:20<05:55,  1.25it/s] 60%|██████    | 675/1120 [10:21<05:47,  1.28it/s] 60%|██████    | 676/1120 [10:22<05:40,  1.30it/s] 60%|██████    | 677/1120 [10:23<06:04,  1.22it/s] 61%|██████    | 678/1120 [10:23<05:52,  1.26it/s] 61%|██████    | 679/1120 [10:24<05:42,  1.29it/s] 61%|██████    | 680/1120 [10:25<05:38,  1.30it/s]                                                   61%|██████    | 680/1120 [10:25<05:38,  1.30it/s]{'eval_loss': 0.20361670851707458, 'eval_runtime': 1.6134, 'eval_samples_per_second': 61.982, 'eval_steps_per_second': 8.058, 'epoch': 5.69}
外层迭代结束！
外层迭代结束！
{'loss': 0.0408, 'learning_rate': 0.0001317757009345794, 'epoch': 5.78}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0617, 'learning_rate': 0.0001289719626168224, 'epoch': 5.87}
外层迭代结束！
外层迭代结束！
{'loss': 0.0802, 'learning_rate': 0.0001261682242990654, 'epoch': 5.96}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0313, 'learning_rate': 0.00012336448598130838, 'epoch': 6.04}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.87it/s][A
 31%|███       | 4/13 [00:00<00:00, 12.18it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.73it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.49it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.76it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.72it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.37it/s][A                                                  
                                               [A 61%|██████    | 680/1120 [10:26<05:38,  1.30it/s]
100%|██████████| 13/13 [00:01<00:00,  8.37it/s][A
                                               [A 61%|██████    | 681/1120 [10:27<09:40,  1.32s/it] 61%|██████    | 682/1120 [10:28<08:22,  1.15s/it] 61%|██████    | 683/1120 [10:29<07:28,  1.03s/it] 61%|██████    | 684/1120 [10:30<06:50,  1.06it/s] 61%|██████    | 685/1120 [10:31<06:49,  1.06it/s] 61%|██████▏   | 686/1120 [10:31<06:22,  1.13it/s] 61%|██████▏   | 687/1120 [10:32<06:03,  1.19it/s] 61%|██████▏   | 688/1120 [10:33<05:49,  1.23it/s] 62%|██████▏   | 689/1120 [10:34<06:06,  1.18it/s] 62%|██████▏   | 690/1120 [10:34<05:50,  1.23it/s]                                                   62%|██████▏   | 690/1120 [10:34<05:50,  1.23it/s] 62%|██████▏   | 691/1120 [10:35<05:40,  1.26it/s] 62%|██████▏   | 692/1120 [10:36<05:32,  1.29it/s] 62%|██████▏   | 693/1120 [10:37<05:52,  1.21it/s] 62%|██████▏   | 694/1120 [10:38<05:40,  1.25it/s] 62%|██████▏   | 695/1120 [10:38<05:32,  1.28it/s] 62%|██████▏   | 696/1120 [10:39<05:27,  1.29it/s] 62%|██████▏   | 697/1120 [10:40<05:50,  1.21it/s] 62%|██████▏   | 698/1120 [10:41<05:40,  1.24it/s] 62%|██████▏   | 699/1120 [10:42<05:31,  1.27it/s] 62%|██████▎   | 700/1120 [10:42<05:25,  1.29it/s]                                                   62%|██████▎   | 700/1120 [10:42<05:25,  1.29it/s] 63%|██████▎   | 701/1120 [10:43<05:45,  1.21it/s] 63%|██████▎   | 702/1120 [10:44<05:34,  1.25it/s] 63%|██████▎   | 703/1120 [10:45<05:26,  1.28it/s] 63%|██████▎   | 704/1120 [10:46<05:30,  1.26it/s] 63%|██████▎   | 705/1120 [10:46<05:47,  1.19it/s] 63%|██████▎   | 706/1120 [10:47<05:34,  1.24it/s] 63%|██████▎   | 707/1120 [10:48<05:27,  1.26it/s] 63%|██████▎   | 708/1120 [10:49<05:21,  1.28it/s] 63%|██████▎   | 709/1120 [10:50<05:41,  1.20it/s] 63%|██████▎   | 710/1120 [10:50<05:30,  1.24it/s]                                                   63%|██████▎   | 710/1120 [10:50<05:30,  1.24it/s] 63%|██████▎   | 711/1120 [10:51<05:21,  1.27it/s] 64%|██████▎   | 712/1120 [10:52<05:17,  1.29it/s] 64%|██████▎   | 713/1120 [10:53<05:36,  1.21it/s] 64%|██████▍   | 714/1120 [10:54<05:25,  1.25it/s] 64%|██████▍   | 715/1120 [10:54<05:18,  1.27it/s] 64%|██████▍   | 716/1120 [10:55<05:12,  1.29it/s] 64%|██████▍   | 717/1120 [10:56<05:33,  1.21it/s] 64%|██████▍   | 718/1120 [10:57<05:22,  1.25it/s] 64%|██████▍   | 719/1120 [10:58<05:14,  1.28it/s] 64%|██████▍   | 720/1120 [10:58<05:07,  1.30it/s]                                                   64%|██████▍   | 720/1120 [10:58<05:07,  1.30it/s]{'eval_loss': 0.19802922010421753, 'eval_runtime': 1.5501, 'eval_samples_per_second': 64.511, 'eval_steps_per_second': 8.386, 'epoch': 6.04}
外层迭代结束！
外层迭代结束！
{'loss': 0.0218, 'learning_rate': 0.00012056074766355139, 'epoch': 6.13}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.038, 'learning_rate': 0.00011775700934579438, 'epoch': 6.22}
外层迭代结束！
外层迭代结束！
{'loss': 0.0231, 'learning_rate': 0.00011495327102803737, 'epoch': 6.31}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0448, 'learning_rate': 0.00011214953271028036, 'epoch': 6.4}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.85it/s][A
 31%|███       | 4/13 [00:00<00:00, 12.20it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.73it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.50it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.77it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.72it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.36it/s][A                                                  
                                               [A 64%|██████▍   | 720/1120 [11:00<05:07,  1.30it/s]
100%|██████████| 13/13 [00:01<00:00,  8.36it/s][A
                                               [A 64%|██████▍   | 721/1120 [11:01<08:51,  1.33s/it] 64%|██████▍   | 722/1120 [11:02<07:40,  1.16s/it] 65%|██████▍   | 723/1120 [11:02<06:48,  1.03s/it] 65%|██████▍   | 724/1120 [11:03<06:13,  1.06it/s] 65%|██████▍   | 725/1120 [11:04<06:14,  1.05it/s] 65%|██████▍   | 726/1120 [11:05<05:49,  1.13it/s] 65%|██████▍   | 727/1120 [11:06<05:31,  1.19it/s] 65%|██████▌   | 728/1120 [11:06<05:17,  1.23it/s] 65%|██████▌   | 729/1120 [11:07<05:33,  1.17it/s] 65%|██████▌   | 730/1120 [11:08<05:18,  1.22it/s]                                                   65%|██████▌   | 730/1120 [11:08<05:18,  1.22it/s] 65%|██████▌   | 731/1120 [11:09<05:10,  1.25it/s] 65%|██████▌   | 732/1120 [11:09<05:03,  1.28it/s] 65%|██████▌   | 733/1120 [11:10<05:24,  1.19it/s] 66%|██████▌   | 734/1120 [11:11<05:12,  1.24it/s] 66%|██████▌   | 735/1120 [11:12<05:02,  1.27it/s] 66%|██████▌   | 736/1120 [11:13<04:57,  1.29it/s] 66%|██████▌   | 737/1120 [11:14<05:15,  1.22it/s] 66%|██████▌   | 738/1120 [11:14<05:04,  1.26it/s] 66%|██████▌   | 739/1120 [11:15<04:56,  1.28it/s] 66%|██████▌   | 740/1120 [11:16<04:54,  1.29it/s]                                                   66%|██████▌   | 740/1120 [11:16<04:54,  1.29it/s] 66%|██████▌   | 741/1120 [11:17<05:17,  1.19it/s] 66%|██████▋   | 742/1120 [11:18<05:09,  1.22it/s] 66%|██████▋   | 743/1120 [11:18<04:59,  1.26it/s] 66%|██████▋   | 744/1120 [11:19<04:51,  1.29it/s] 67%|██████▋   | 745/1120 [11:20<05:12,  1.20it/s] 67%|██████▋   | 746/1120 [11:21<05:01,  1.24it/s] 67%|██████▋   | 747/1120 [11:22<04:53,  1.27it/s] 67%|██████▋   | 748/1120 [11:22<04:46,  1.30it/s] 67%|██████▋   | 749/1120 [11:23<05:08,  1.20it/s] 67%|██████▋   | 750/1120 [11:24<04:56,  1.25it/s]                                                   67%|██████▋   | 750/1120 [11:24<04:56,  1.25it/s] 67%|██████▋   | 751/1120 [11:25<04:48,  1.28it/s] 67%|██████▋   | 752/1120 [11:25<04:42,  1.30it/s] 67%|██████▋   | 753/1120 [11:26<05:02,  1.21it/s] 67%|██████▋   | 754/1120 [11:27<04:51,  1.25it/s] 67%|██████▋   | 755/1120 [11:28<04:46,  1.28it/s] 68%|██████▊   | 756/1120 [11:29<04:41,  1.29it/s] 68%|██████▊   | 757/1120 [11:30<04:59,  1.21it/s] 68%|██████▊   | 758/1120 [11:30<04:51,  1.24it/s] 68%|██████▊   | 759/1120 [11:31<04:44,  1.27it/s] 68%|██████▊   | 760/1120 [11:32<04:38,  1.29it/s]                                                   68%|██████▊   | 760/1120 [11:32<04:38,  1.29it/s]{'eval_loss': 0.20263099670410156, 'eval_runtime': 1.5505, 'eval_samples_per_second': 64.497, 'eval_steps_per_second': 8.385, 'epoch': 6.4}
外层迭代结束！
外层迭代结束！
{'loss': 0.0245, 'learning_rate': 0.00010934579439252335, 'epoch': 6.49}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0577, 'learning_rate': 0.00010654205607476634, 'epoch': 6.58}
外层迭代结束！
外层迭代结束！
{'loss': 0.0813, 'learning_rate': 0.00010373831775700933, 'epoch': 6.67}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0349, 'learning_rate': 0.00010093457943925232, 'epoch': 6.76}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.85it/s][A
 31%|███       | 4/13 [00:00<00:00, 12.18it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.71it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.49it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.78it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.74it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.36it/s][A                                                  
                                               [A 68%|██████▊   | 760/1120 [11:34<04:38,  1.29it/s]
100%|██████████| 13/13 [00:01<00:00,  8.36it/s][A
                                               [A 68%|██████▊   | 761/1120 [11:35<08:25,  1.41s/it] 68%|██████▊   | 762/1120 [11:36<07:31,  1.26s/it] 68%|██████▊   | 763/1120 [11:36<06:45,  1.14s/it] 68%|██████▊   | 764/1120 [11:37<06:12,  1.05s/it] 68%|██████▊   | 765/1120 [11:38<06:16,  1.06s/it] 68%|██████▊   | 766/1120 [11:39<05:51,  1.01it/s] 68%|██████▊   | 767/1120 [11:40<05:52,  1.00it/s] 69%|██████▊   | 768/1120 [11:41<05:34,  1.05it/s] 69%|██████▊   | 769/1120 [11:42<05:45,  1.02it/s] 69%|██████▉   | 770/1120 [11:43<05:28,  1.06it/s]                                                   69%|██████▉   | 770/1120 [11:43<05:28,  1.06it/s] 69%|██████▉   | 771/1120 [11:44<05:20,  1.09it/s] 69%|██████▉   | 772/1120 [11:45<05:10,  1.12it/s] 69%|██████▉   | 773/1120 [11:46<05:28,  1.06it/s] 69%|██████▉   | 774/1120 [11:47<05:17,  1.09it/s] 69%|██████▉   | 775/1120 [11:47<05:07,  1.12it/s] 69%|██████▉   | 776/1120 [11:48<05:02,  1.14it/s] 69%|██████▉   | 777/1120 [11:49<05:21,  1.07it/s] 69%|██████▉   | 778/1120 [11:50<05:10,  1.10it/s] 70%|██████▉   | 779/1120 [11:51<05:10,  1.10it/s] 70%|██████▉   | 780/1120 [11:52<05:02,  1.12it/s]                                                   70%|██████▉   | 780/1120 [11:52<05:02,  1.12it/s] 70%|██████▉   | 781/1120 [11:53<05:21,  1.06it/s] 70%|██████▉   | 782/1120 [11:54<05:09,  1.09it/s] 70%|██████▉   | 783/1120 [11:55<05:00,  1.12it/s] 70%|███████   | 784/1120 [11:56<04:54,  1.14it/s] 70%|███████   | 785/1120 [11:57<05:13,  1.07it/s] 70%|███████   | 786/1120 [11:57<05:02,  1.10it/s] 70%|███████   | 787/1120 [11:58<04:55,  1.13it/s] 70%|███████   | 788/1120 [11:59<04:50,  1.14it/s] 70%|███████   | 789/1120 [12:00<05:11,  1.06it/s] 71%|███████   | 790/1120 [12:01<05:01,  1.10it/s]                                                   71%|███████   | 790/1120 [12:01<05:01,  1.10it/s] 71%|███████   | 791/1120 [12:02<04:54,  1.12it/s] 71%|███████   | 792/1120 [12:03<04:48,  1.14it/s] 71%|███████   | 793/1120 [12:04<05:14,  1.04it/s] 71%|███████   | 794/1120 [12:05<05:02,  1.08it/s] 71%|███████   | 795/1120 [12:06<04:52,  1.11it/s] 71%|███████   | 796/1120 [12:06<04:46,  1.13it/s] 71%|███████   | 797/1120 [12:08<05:04,  1.06it/s] 71%|███████▏  | 798/1120 [12:08<04:53,  1.10it/s] 71%|███████▏  | 799/1120 [12:09<04:45,  1.12it/s] 71%|███████▏  | 800/1120 [12:10<04:42,  1.13it/s]                                                   71%|███████▏  | 800/1120 [12:10<04:42,  1.13it/s]{'eval_loss': 0.2142665684223175, 'eval_runtime': 1.5502, 'eval_samples_per_second': 64.508, 'eval_steps_per_second': 8.386, 'epoch': 6.76}
外层迭代结束！
外层迭代结束！
{'loss': 0.0522, 'learning_rate': 9.813084112149531e-05, 'epoch': 6.84}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0555, 'learning_rate': 9.53271028037383e-05, 'epoch': 6.93}
外层迭代结束！
外层迭代结束！
{'loss': 0.0158, 'learning_rate': 9.25233644859813e-05, 'epoch': 7.02}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0222, 'learning_rate': 8.971962616822429e-05, 'epoch': 7.11}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.39it/s][A
 31%|███       | 4/13 [00:00<00:00, 11.84it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.57it/s][A
 54%|█████▍    | 7/13 [00:00<00:00,  8.79it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.11it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.35it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.42it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.14it/s][A                                                  
                                               [A 71%|███████▏  | 800/1120 [12:12<04:42,  1.13it/s]
100%|██████████| 13/13 [00:01<00:00,  8.14it/s][A
                                               [A 72%|███████▏  | 801/1120 [12:13<07:48,  1.47s/it] 72%|███████▏  | 802/1120 [12:14<06:49,  1.29s/it] 72%|███████▏  | 803/1120 [12:15<06:05,  1.15s/it] 72%|███████▏  | 804/1120 [12:15<05:35,  1.06s/it] 72%|███████▏  | 805/1120 [12:17<05:37,  1.07s/it] 72%|███████▏  | 806/1120 [12:17<05:14,  1.00s/it] 72%|███████▏  | 807/1120 [12:18<04:59,  1.05it/s] 72%|███████▏  | 808/1120 [12:19<04:47,  1.09it/s] 72%|███████▏  | 809/1120 [12:20<05:01,  1.03it/s] 72%|███████▏  | 810/1120 [12:21<04:49,  1.07it/s]                                                   72%|███████▏  | 810/1120 [12:21<04:49,  1.07it/s] 72%|███████▏  | 811/1120 [12:22<04:54,  1.05it/s] 72%|███████▎  | 812/1120 [12:23<04:43,  1.09it/s] 73%|███████▎  | 813/1120 [12:24<05:00,  1.02it/s] 73%|███████▎  | 814/1120 [12:25<04:46,  1.07it/s] 73%|███████▎  | 815/1120 [12:26<04:37,  1.10it/s] 73%|███████▎  | 816/1120 [12:27<04:34,  1.11it/s] 73%|███████▎  | 817/1120 [12:28<04:51,  1.04it/s] 73%|███████▎  | 818/1120 [12:29<04:43,  1.07it/s] 73%|███████▎  | 819/1120 [12:29<04:35,  1.09it/s] 73%|███████▎  | 820/1120 [12:30<04:31,  1.10it/s]                                                   73%|███████▎  | 820/1120 [12:31<04:31,  1.10it/s] 73%|███████▎  | 821/1120 [12:31<04:48,  1.04it/s] 73%|███████▎  | 822/1120 [12:32<04:37,  1.07it/s] 73%|███████▎  | 823/1120 [12:33<04:29,  1.10it/s] 74%|███████▎  | 824/1120 [12:34<04:24,  1.12it/s] 74%|███████▎  | 825/1120 [12:35<04:41,  1.05it/s] 74%|███████▍  | 826/1120 [12:36<04:33,  1.07it/s] 74%|███████▍  | 827/1120 [12:37<04:25,  1.11it/s] 74%|███████▍  | 828/1120 [12:38<04:19,  1.13it/s] 74%|███████▍  | 829/1120 [12:39<04:35,  1.05it/s] 74%|███████▍  | 830/1120 [12:40<04:25,  1.09it/s]                                                   74%|███████▍  | 830/1120 [12:40<04:25,  1.09it/s] 74%|███████▍  | 831/1120 [12:40<04:18,  1.12it/s] 74%|███████▍  | 832/1120 [12:41<04:14,  1.13it/s] 74%|███████▍  | 833/1120 [12:42<04:30,  1.06it/s] 74%|███████▍  | 834/1120 [12:43<04:22,  1.09it/s] 75%|███████▍  | 835/1120 [12:44<04:09,  1.14it/s] 75%|███████▍  | 836/1120 [12:45<03:57,  1.20it/s] 75%|███████▍  | 837/1120 [12:46<04:05,  1.15it/s] 75%|███████▍  | 838/1120 [12:46<03:54,  1.20it/s] 75%|███████▍  | 839/1120 [12:47<03:46,  1.24it/s] 75%|███████▌  | 840/1120 [12:48<03:40,  1.27it/s]                                                   75%|███████▌  | 840/1120 [12:48<03:40,  1.27it/s]{'eval_loss': 0.21596328914165497, 'eval_runtime': 1.6046, 'eval_samples_per_second': 62.322, 'eval_steps_per_second': 8.102, 'epoch': 7.11}
外层迭代结束！
外层迭代结束！
{'loss': 0.0405, 'learning_rate': 8.691588785046728e-05, 'epoch': 7.2}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0291, 'learning_rate': 8.411214953271027e-05, 'epoch': 7.29}
外层迭代结束！
外层迭代结束！
{'loss': 0.0152, 'learning_rate': 8.130841121495326e-05, 'epoch': 7.38}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0218, 'learning_rate': 7.850467289719625e-05, 'epoch': 7.47}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.85it/s][A
 31%|███       | 4/13 [00:00<00:00, 12.21it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.73it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.51it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.77it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.74it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.38it/s][A                                                  
                                               [A 75%|███████▌  | 840/1120 [12:50<03:40,  1.27it/s]
100%|██████████| 13/13 [00:01<00:00,  8.38it/s][A
                                               [A 75%|███████▌  | 841/1120 [12:51<06:16,  1.35s/it] 75%|███████▌  | 842/1120 [12:51<05:24,  1.17s/it] 75%|███████▌  | 843/1120 [12:52<04:48,  1.04s/it] 75%|███████▌  | 844/1120 [12:53<04:22,  1.05it/s] 75%|███████▌  | 845/1120 [12:54<04:21,  1.05it/s] 76%|███████▌  | 846/1120 [12:54<04:03,  1.13it/s] 76%|███████▌  | 847/1120 [12:55<03:51,  1.18it/s] 76%|███████▌  | 848/1120 [12:56<03:40,  1.23it/s] 76%|███████▌  | 849/1120 [12:57<03:51,  1.17it/s] 76%|███████▌  | 850/1120 [12:58<03:41,  1.22it/s]                                                   76%|███████▌  | 850/1120 [12:58<03:41,  1.22it/s] 76%|███████▌  | 851/1120 [12:58<03:34,  1.25it/s] 76%|███████▌  | 852/1120 [12:59<03:28,  1.28it/s] 76%|███████▌  | 853/1120 [13:00<03:42,  1.20it/s] 76%|███████▋  | 854/1120 [13:01<03:34,  1.24it/s] 76%|███████▋  | 855/1120 [13:02<03:28,  1.27it/s] 76%|███████▋  | 856/1120 [13:02<03:24,  1.29it/s] 77%|███████▋  | 857/1120 [13:03<03:37,  1.21it/s] 77%|███████▋  | 858/1120 [13:04<03:30,  1.25it/s] 77%|███████▋  | 859/1120 [13:05<03:24,  1.27it/s] 77%|███████▋  | 860/1120 [13:06<03:21,  1.29it/s]                                                   77%|███████▋  | 860/1120 [13:06<03:21,  1.29it/s] 77%|███████▋  | 861/1120 [13:06<03:33,  1.21it/s] 77%|███████▋  | 862/1120 [13:07<03:27,  1.24it/s] 77%|███████▋  | 863/1120 [13:08<03:21,  1.27it/s] 77%|███████▋  | 864/1120 [13:09<03:18,  1.29it/s] 77%|███████▋  | 865/1120 [13:10<03:30,  1.21it/s] 77%|███████▋  | 866/1120 [13:10<03:24,  1.24it/s] 77%|███████▋  | 867/1120 [13:11<03:18,  1.27it/s] 78%|███████▊  | 868/1120 [13:12<03:14,  1.30it/s] 78%|███████▊  | 869/1120 [13:13<03:27,  1.21it/s] 78%|███████▊  | 870/1120 [13:14<03:25,  1.22it/s]                                                   78%|███████▊  | 870/1120 [13:14<03:25,  1.22it/s] 78%|███████▊  | 871/1120 [13:14<03:18,  1.25it/s] 78%|███████▊  | 872/1120 [13:15<03:13,  1.28it/s] 78%|███████▊  | 873/1120 [13:16<03:25,  1.20it/s] 78%|███████▊  | 874/1120 [13:17<03:18,  1.24it/s] 78%|███████▊  | 875/1120 [13:18<03:13,  1.27it/s] 78%|███████▊  | 876/1120 [13:18<03:08,  1.30it/s] 78%|███████▊  | 877/1120 [13:19<03:20,  1.21it/s] 78%|███████▊  | 878/1120 [13:20<03:16,  1.23it/s] 78%|███████▊  | 879/1120 [13:21<03:10,  1.26it/s] 79%|███████▊  | 880/1120 [13:22<03:08,  1.27it/s]                                                   79%|███████▊  | 880/1120 [13:22<03:08,  1.27it/s]{'eval_loss': 0.24742448329925537, 'eval_runtime': 1.55, 'eval_samples_per_second': 64.516, 'eval_steps_per_second': 8.387, 'epoch': 7.47}
外层迭代结束！
外层迭代结束！
{'loss': 0.0739, 'learning_rate': 7.570093457943924e-05, 'epoch': 7.56}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0637, 'learning_rate': 7.289719626168223e-05, 'epoch': 7.64}
外层迭代结束！
外层迭代结束！
{'loss': 0.0224, 'learning_rate': 7.009345794392522e-05, 'epoch': 7.73}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0421, 'learning_rate': 6.728971962616821e-05, 'epoch': 7.82}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.83it/s][A
 31%|███       | 4/13 [00:00<00:00, 12.17it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.71it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.49it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.77it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.75it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.36it/s][A                                                  
                                               [A 79%|███████▊  | 880/1120 [13:23<03:08,  1.27it/s]
100%|██████████| 13/13 [00:01<00:00,  8.36it/s][A
                                               [A 79%|███████▊  | 881/1120 [13:24<05:20,  1.34s/it] 79%|███████▉  | 882/1120 [13:25<04:36,  1.16s/it] 79%|███████▉  | 883/1120 [13:26<04:05,  1.04s/it] 79%|███████▉  | 884/1120 [13:26<03:44,  1.05it/s] 79%|███████▉  | 885/1120 [13:27<03:42,  1.06it/s] 79%|███████▉  | 886/1120 [13:28<03:27,  1.13it/s] 79%|███████▉  | 887/1120 [13:29<03:22,  1.15it/s] 79%|███████▉  | 888/1120 [13:30<03:13,  1.20it/s] 79%|███████▉  | 889/1120 [13:31<03:22,  1.14it/s] 79%|███████▉  | 890/1120 [13:31<03:13,  1.19it/s]                                                   79%|███████▉  | 890/1120 [13:31<03:13,  1.19it/s] 80%|███████▉  | 891/1120 [13:32<03:05,  1.24it/s] 80%|███████▉  | 892/1120 [13:33<02:59,  1.27it/s] 80%|███████▉  | 893/1120 [13:34<03:09,  1.20it/s] 80%|███████▉  | 894/1120 [13:35<03:02,  1.24it/s] 80%|███████▉  | 895/1120 [13:35<02:57,  1.26it/s] 80%|████████  | 896/1120 [13:36<02:54,  1.29it/s] 80%|████████  | 897/1120 [13:37<03:04,  1.21it/s] 80%|████████  | 898/1120 [13:38<02:57,  1.25it/s] 80%|████████  | 899/1120 [13:39<02:53,  1.27it/s] 80%|████████  | 900/1120 [13:39<02:49,  1.30it/s]                                                   80%|████████  | 900/1120 [13:39<02:49,  1.30it/s] 80%|████████  | 901/1120 [13:40<03:00,  1.21it/s] 81%|████████  | 902/1120 [13:41<02:54,  1.25it/s] 81%|████████  | 903/1120 [13:42<02:49,  1.28it/s] 81%|████████  | 904/1120 [13:42<02:46,  1.30it/s] 81%|████████  | 905/1120 [13:43<02:56,  1.22it/s] 81%|████████  | 906/1120 [13:44<02:50,  1.25it/s] 81%|████████  | 907/1120 [13:45<02:46,  1.28it/s] 81%|████████  | 908/1120 [13:46<02:42,  1.31it/s] 81%|████████  | 909/1120 [13:47<02:52,  1.22it/s] 81%|████████▏ | 910/1120 [13:47<02:47,  1.25it/s]                                                   81%|████████▏ | 910/1120 [13:47<02:47,  1.25it/s] 81%|████████▏ | 911/1120 [13:48<02:42,  1.28it/s] 81%|████████▏ | 912/1120 [13:49<02:40,  1.30it/s] 82%|████████▏ | 913/1120 [13:50<02:50,  1.22it/s] 82%|████████▏ | 914/1120 [13:50<02:44,  1.25it/s] 82%|████████▏ | 915/1120 [13:51<02:40,  1.28it/s] 82%|████████▏ | 916/1120 [13:52<02:36,  1.30it/s] 82%|████████▏ | 917/1120 [13:53<02:47,  1.21it/s] 82%|████████▏ | 918/1120 [13:54<02:42,  1.25it/s] 82%|████████▏ | 919/1120 [13:54<02:37,  1.28it/s] 82%|████████▏ | 920/1120 [13:55<02:34,  1.30it/s]                                                   82%|████████▏ | 920/1120 [13:55<02:34,  1.30it/s]{'eval_loss': 0.23201730847358704, 'eval_runtime': 1.5513, 'eval_samples_per_second': 64.463, 'eval_steps_per_second': 8.38, 'epoch': 7.82}
外层迭代结束！
外层迭代结束！
{'loss': 0.0051, 'learning_rate': 6.44859813084112e-05, 'epoch': 7.91}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.025, 'learning_rate': 6.168224299065419e-05, 'epoch': 8.0}
外层迭代结束！
外层迭代结束！
{'loss': 0.0385, 'learning_rate': 5.887850467289719e-05, 'epoch': 8.09}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0129, 'learning_rate': 5.607476635514018e-05, 'epoch': 8.18}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.88it/s][A
 31%|███       | 4/13 [00:00<00:00, 12.26it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.77it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.49it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.74it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.72it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.36it/s][A                                                  
                                               [A 82%|████████▏ | 920/1120 [13:57<02:34,  1.30it/s]
100%|██████████| 13/13 [00:01<00:00,  8.36it/s][A
                                               [A 82%|████████▏ | 921/1120 [13:58<04:25,  1.34s/it] 82%|████████▏ | 922/1120 [13:59<03:49,  1.16s/it] 82%|████████▏ | 923/1120 [13:59<03:23,  1.03s/it] 82%|████████▎ | 924/1120 [14:00<03:06,  1.05it/s] 83%|████████▎ | 925/1120 [14:01<03:04,  1.06it/s] 83%|████████▎ | 926/1120 [14:02<02:52,  1.12it/s] 83%|████████▎ | 927/1120 [14:02<02:43,  1.18it/s] 83%|████████▎ | 928/1120 [14:03<02:37,  1.22it/s] 83%|████████▎ | 929/1120 [14:04<02:44,  1.16it/s] 83%|████████▎ | 930/1120 [14:05<02:45,  1.15it/s]                                                   83%|████████▎ | 930/1120 [14:05<02:45,  1.15it/s] 83%|████████▎ | 931/1120 [14:06<02:47,  1.13it/s] 83%|████████▎ | 932/1120 [14:07<02:46,  1.13it/s] 83%|████████▎ | 933/1120 [14:08<02:53,  1.08it/s] 83%|████████▎ | 934/1120 [14:09<02:44,  1.13it/s] 83%|████████▎ | 935/1120 [14:09<02:38,  1.16it/s] 84%|████████▎ | 936/1120 [14:10<02:35,  1.18it/s] 84%|████████▎ | 937/1120 [14:11<02:47,  1.09it/s] 84%|████████▍ | 938/1120 [14:12<02:41,  1.13it/s] 84%|████████▍ | 939/1120 [14:13<02:35,  1.17it/s] 84%|████████▍ | 940/1120 [14:14<02:30,  1.20it/s]                                                   84%|████████▍ | 940/1120 [14:14<02:30,  1.20it/s] 84%|████████▍ | 941/1120 [14:15<02:40,  1.12it/s] 84%|████████▍ | 942/1120 [14:16<02:36,  1.14it/s] 84%|████████▍ | 943/1120 [14:17<02:34,  1.15it/s] 84%|████████▍ | 944/1120 [14:17<02:31,  1.16it/s] 84%|████████▍ | 945/1120 [14:18<02:43,  1.07it/s] 84%|████████▍ | 946/1120 [14:19<02:40,  1.09it/s] 85%|████████▍ | 947/1120 [14:20<02:37,  1.10it/s] 85%|████████▍ | 948/1120 [14:21<02:34,  1.11it/s] 85%|████████▍ | 949/1120 [14:22<02:47,  1.02it/s] 85%|████████▍ | 950/1120 [14:23<02:43,  1.04it/s]                                                   85%|████████▍ | 950/1120 [14:23<02:43,  1.04it/s] 85%|████████▍ | 951/1120 [14:24<02:38,  1.06it/s] 85%|████████▌ | 952/1120 [14:25<02:32,  1.10it/s] 85%|████████▌ | 953/1120 [14:26<02:40,  1.04it/s] 85%|████████▌ | 954/1120 [14:27<02:34,  1.08it/s] 85%|████████▌ | 955/1120 [14:28<02:28,  1.11it/s] 85%|████████▌ | 956/1120 [14:29<02:25,  1.13it/s] 85%|████████▌ | 957/1120 [14:30<02:33,  1.06it/s] 86%|████████▌ | 958/1120 [14:30<02:28,  1.09it/s] 86%|████████▌ | 959/1120 [14:31<02:24,  1.12it/s] 86%|████████▌ | 960/1120 [14:32<02:21,  1.13it/s]                                                   86%|████████▌ | 960/1120 [14:32<02:21,  1.13it/s]{'eval_loss': 0.23224453628063202, 'eval_runtime': 1.5492, 'eval_samples_per_second': 64.551, 'eval_steps_per_second': 8.392, 'epoch': 8.18}
外层迭代结束！
外层迭代结束！
{'loss': 0.0589, 'learning_rate': 5.327102803738317e-05, 'epoch': 8.27}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0363, 'learning_rate': 5.046728971962616e-05, 'epoch': 8.36}
外层迭代结束！
外层迭代结束！
{'loss': 0.0275, 'learning_rate': 4.766355140186915e-05, 'epoch': 8.44}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0477, 'learning_rate': 4.485981308411214e-05, 'epoch': 8.53}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.38it/s][A
 31%|███       | 4/13 [00:00<00:00, 11.81it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.56it/s][A
 54%|█████▍    | 7/13 [00:00<00:00,  8.81it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.11it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.36it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.43it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.13it/s][A                                                  
                                               [A 86%|████████▌ | 960/1120 [14:34<02:21,  1.13it/s]
100%|██████████| 13/13 [00:01<00:00,  8.13it/s][A
                                               [A 86%|████████▌ | 961/1120 [14:35<03:52,  1.46s/it] 86%|████████▌ | 962/1120 [14:36<03:22,  1.28s/it] 86%|████████▌ | 963/1120 [14:37<03:00,  1.15s/it] 86%|████████▌ | 964/1120 [14:38<02:44,  1.05s/it] 86%|████████▌ | 965/1120 [14:39<02:44,  1.06s/it] 86%|████████▋ | 966/1120 [14:39<02:33,  1.00it/s] 86%|████████▋ | 967/1120 [14:40<02:25,  1.05it/s] 86%|████████▋ | 968/1120 [14:41<02:27,  1.03it/s] 87%|████████▋ | 969/1120 [14:42<02:31,  1.00s/it] 87%|████████▋ | 970/1120 [14:43<02:22,  1.05it/s]                                                   87%|████████▋ | 970/1120 [14:43<02:22,  1.05it/s] 87%|████████▋ | 971/1120 [14:44<02:16,  1.09it/s] 87%|████████▋ | 972/1120 [14:45<02:12,  1.12it/s] 87%|████████▋ | 973/1120 [14:46<02:23,  1.02it/s] 87%|████████▋ | 974/1120 [14:47<02:16,  1.07it/s] 87%|████████▋ | 975/1120 [14:48<02:11,  1.10it/s] 87%|████████▋ | 976/1120 [14:49<02:07,  1.13it/s] 87%|████████▋ | 977/1120 [14:50<02:15,  1.05it/s] 87%|████████▋ | 978/1120 [14:51<02:10,  1.09it/s] 87%|████████▋ | 979/1120 [14:51<02:06,  1.12it/s] 88%|████████▊ | 980/1120 [14:52<02:06,  1.11it/s]                                                   88%|████████▊ | 980/1120 [14:53<02:06,  1.11it/s] 88%|████████▊ | 981/1120 [14:53<02:12,  1.05it/s] 88%|████████▊ | 982/1120 [14:54<02:07,  1.08it/s] 88%|████████▊ | 983/1120 [14:55<02:02,  1.12it/s] 88%|████████▊ | 984/1120 [14:56<01:59,  1.13it/s] 88%|████████▊ | 985/1120 [14:57<02:06,  1.06it/s] 88%|████████▊ | 986/1120 [14:58<02:01,  1.10it/s] 88%|████████▊ | 987/1120 [14:59<01:58,  1.12it/s] 88%|████████▊ | 988/1120 [14:59<01:55,  1.14it/s] 88%|████████▊ | 989/1120 [15:01<02:02,  1.07it/s] 88%|████████▊ | 990/1120 [15:01<01:57,  1.10it/s]                                                   88%|████████▊ | 990/1120 [15:01<01:57,  1.10it/s] 88%|████████▊ | 991/1120 [15:02<01:55,  1.12it/s] 89%|████████▊ | 992/1120 [15:03<01:52,  1.14it/s] 89%|████████▊ | 993/1120 [15:04<01:59,  1.07it/s] 89%|████████▉ | 994/1120 [15:05<01:54,  1.10it/s] 89%|████████▉ | 995/1120 [15:06<01:51,  1.12it/s] 89%|████████▉ | 996/1120 [15:07<01:48,  1.14it/s] 89%|████████▉ | 997/1120 [15:08<01:55,  1.06it/s] 89%|████████▉ | 998/1120 [15:09<01:51,  1.10it/s] 89%|████████▉ | 999/1120 [15:09<01:47,  1.12it/s] 89%|████████▉ | 1000/1120 [15:10<01:45,  1.14it/s]                                                    89%|████████▉ | 1000/1120 [15:11<01:45,  1.14it/s]{'eval_loss': 0.22834885120391846, 'eval_runtime': 1.5995, 'eval_samples_per_second': 62.52, 'eval_steps_per_second': 8.128, 'epoch': 8.53}
外层迭代结束！
外层迭代结束！
{'loss': 0.0379, 'learning_rate': 4.2056074766355134e-05, 'epoch': 8.62}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0236, 'learning_rate': 3.9252336448598124e-05, 'epoch': 8.71}
外层迭代结束！
外层迭代结束！
{'loss': 0.0179, 'learning_rate': 3.6448598130841115e-05, 'epoch': 8.8}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0106, 'learning_rate': 3.3644859813084105e-05, 'epoch': 8.89}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.35it/s][A
 31%|███       | 4/13 [00:00<00:00, 11.81it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.56it/s][A
 54%|█████▍    | 7/13 [00:00<00:00,  8.81it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.12it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.36it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.43it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.14it/s][A                                                   
                                               [A 89%|████████▉ | 1000/1120 [15:12<01:45,  1.14it/s]
100%|██████████| 13/13 [00:01<00:00,  8.14it/s][A
                                               [A 89%|████████▉ | 1001/1120 [15:13<02:53,  1.46s/it] 89%|████████▉ | 1002/1120 [15:14<02:30,  1.27s/it] 90%|████████▉ | 1003/1120 [15:15<02:13,  1.15s/it] 90%|████████▉ | 1004/1120 [15:16<02:02,  1.06s/it] 90%|████████▉ | 1005/1120 [15:17<02:02,  1.07s/it] 90%|████████▉ | 1006/1120 [15:18<01:53,  1.00it/s] 90%|████████▉ | 1007/1120 [15:18<01:47,  1.05it/s] 90%|█████████ | 1008/1120 [15:19<01:42,  1.09it/s] 90%|█████████ | 1009/1120 [15:20<01:47,  1.03it/s] 90%|█████████ | 1010/1120 [15:21<01:42,  1.08it/s]                                                    90%|█████████ | 1010/1120 [15:21<01:42,  1.08it/s] 90%|█████████ | 1011/1120 [15:22<01:38,  1.11it/s] 90%|█████████ | 1012/1120 [15:23<01:37,  1.10it/s] 90%|█████████ | 1013/1120 [15:24<01:42,  1.04it/s] 91%|█████████ | 1014/1120 [15:25<01:38,  1.08it/s] 91%|█████████ | 1015/1120 [15:26<01:34,  1.11it/s] 91%|█████████ | 1016/1120 [15:27<01:31,  1.14it/s] 91%|█████████ | 1017/1120 [15:28<01:36,  1.06it/s] 91%|█████████ | 1018/1120 [15:28<01:32,  1.10it/s] 91%|█████████ | 1019/1120 [15:29<01:29,  1.13it/s] 91%|█████████ | 1020/1120 [15:30<01:27,  1.14it/s]                                                    91%|█████████ | 1020/1120 [15:30<01:27,  1.14it/s] 91%|█████████ | 1021/1120 [15:31<01:33,  1.06it/s] 91%|█████████▏| 1022/1120 [15:32<01:29,  1.10it/s] 91%|█████████▏| 1023/1120 [15:33<01:25,  1.13it/s] 91%|█████████▏| 1024/1120 [15:34<01:24,  1.14it/s] 92%|█████████▏| 1025/1120 [15:35<01:29,  1.06it/s] 92%|█████████▏| 1026/1120 [15:36<01:25,  1.10it/s] 92%|█████████▏| 1027/1120 [15:37<01:22,  1.12it/s] 92%|█████████▏| 1028/1120 [15:37<01:20,  1.14it/s] 92%|█████████▏| 1029/1120 [15:39<01:27,  1.04it/s] 92%|█████████▏| 1030/1120 [15:39<01:23,  1.08it/s]                                                    92%|█████████▏| 1030/1120 [15:39<01:23,  1.08it/s] 92%|█████████▏| 1031/1120 [15:40<01:20,  1.11it/s] 92%|█████████▏| 1032/1120 [15:41<01:17,  1.13it/s] 92%|█████████▏| 1033/1120 [15:42<01:21,  1.06it/s] 92%|█████████▏| 1034/1120 [15:43<01:18,  1.10it/s] 92%|█████████▏| 1035/1120 [15:44<01:16,  1.12it/s] 92%|█████████▎| 1036/1120 [15:45<01:13,  1.14it/s] 93%|█████████▎| 1037/1120 [15:46<01:18,  1.06it/s] 93%|█████████▎| 1038/1120 [15:47<01:15,  1.09it/s] 93%|█████████▎| 1039/1120 [15:48<01:12,  1.11it/s] 93%|█████████▎| 1040/1120 [15:48<01:10,  1.14it/s]                                                    93%|█████████▎| 1040/1120 [15:49<01:10,  1.14it/s]{'eval_loss': 0.2262316197156906, 'eval_runtime': 1.5978, 'eval_samples_per_second': 62.586, 'eval_steps_per_second': 8.136, 'epoch': 8.89}
外层迭代结束！
外层迭代结束！
{'loss': 0.0228, 'learning_rate': 3.0841121495327096e-05, 'epoch': 8.98}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0574, 'learning_rate': 2.803738317757009e-05, 'epoch': 9.07}
外层迭代结束！
外层迭代结束！
{'loss': 0.0364, 'learning_rate': 2.523364485981308e-05, 'epoch': 9.16}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0102, 'learning_rate': 2.242990654205607e-05, 'epoch': 9.24}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.41it/s][A
 31%|███       | 4/13 [00:00<00:00, 11.83it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.56it/s][A
 54%|█████▍    | 7/13 [00:00<00:00,  8.81it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.12it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.36it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.43it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.14it/s][A                                                   
                                               [A 93%|█████████▎| 1040/1120 [15:50<01:10,  1.14it/s]
100%|██████████| 13/13 [00:01<00:00,  8.14it/s][A
                                               [A 93%|█████████▎| 1041/1120 [15:51<01:54,  1.45s/it] 93%|█████████▎| 1042/1120 [15:52<01:36,  1.24s/it] 93%|█████████▎| 1043/1120 [15:53<01:24,  1.09s/it] 93%|█████████▎| 1044/1120 [15:53<01:15,  1.01it/s] 93%|█████████▎| 1045/1120 [15:54<01:13,  1.02it/s] 93%|█████████▎| 1046/1120 [15:55<01:07,  1.10it/s] 93%|█████████▎| 1047/1120 [15:56<01:02,  1.16it/s] 94%|█████████▎| 1048/1120 [15:57<00:59,  1.20it/s] 94%|█████████▎| 1049/1120 [15:58<01:01,  1.15it/s] 94%|█████████▍| 1050/1120 [15:58<00:58,  1.20it/s]                                                    94%|█████████▍| 1050/1120 [15:58<00:58,  1.20it/s] 94%|█████████▍| 1051/1120 [15:59<00:55,  1.24it/s] 94%|█████████▍| 1052/1120 [16:00<00:53,  1.27it/s] 94%|█████████▍| 1053/1120 [16:01<00:55,  1.20it/s] 94%|█████████▍| 1054/1120 [16:01<00:53,  1.24it/s] 94%|█████████▍| 1055/1120 [16:02<00:51,  1.26it/s] 94%|█████████▍| 1056/1120 [16:03<00:49,  1.29it/s] 94%|█████████▍| 1057/1120 [16:04<00:52,  1.20it/s] 94%|█████████▍| 1058/1120 [16:05<00:53,  1.17it/s] 95%|█████████▍| 1059/1120 [16:06<00:50,  1.21it/s] 95%|█████████▍| 1060/1120 [16:06<00:48,  1.25it/s]                                                    95%|█████████▍| 1060/1120 [16:07<00:48,  1.25it/s] 95%|█████████▍| 1061/1120 [16:07<00:49,  1.19it/s] 95%|█████████▍| 1062/1120 [16:08<00:47,  1.23it/s] 95%|█████████▍| 1063/1120 [16:09<00:45,  1.26it/s] 95%|█████████▌| 1064/1120 [16:10<00:43,  1.29it/s] 95%|█████████▌| 1065/1120 [16:10<00:45,  1.21it/s] 95%|█████████▌| 1066/1120 [16:11<00:43,  1.24it/s] 95%|█████████▌| 1067/1120 [16:12<00:41,  1.27it/s] 95%|█████████▌| 1068/1120 [16:13<00:40,  1.29it/s] 95%|█████████▌| 1069/1120 [16:14<00:42,  1.21it/s] 96%|█████████▌| 1070/1120 [16:14<00:39,  1.25it/s]                                                    96%|█████████▌| 1070/1120 [16:14<00:39,  1.25it/s] 96%|█████████▌| 1071/1120 [16:15<00:38,  1.28it/s] 96%|█████████▌| 1072/1120 [16:16<00:36,  1.30it/s] 96%|█████████▌| 1073/1120 [16:17<00:38,  1.22it/s] 96%|█████████▌| 1074/1120 [16:18<00:36,  1.26it/s] 96%|█████████▌| 1075/1120 [16:18<00:35,  1.28it/s] 96%|█████████▌| 1076/1120 [16:19<00:33,  1.30it/s] 96%|█████████▌| 1077/1120 [16:20<00:35,  1.22it/s] 96%|█████████▋| 1078/1120 [16:21<00:33,  1.25it/s] 96%|█████████▋| 1079/1120 [16:21<00:31,  1.28it/s] 96%|█████████▋| 1080/1120 [16:22<00:30,  1.30it/s]                                                    96%|█████████▋| 1080/1120 [16:22<00:30,  1.30it/s]{'eval_loss': 0.22806987166404724, 'eval_runtime': 1.5983, 'eval_samples_per_second': 62.568, 'eval_steps_per_second': 8.134, 'epoch': 9.24}
外层迭代结束！
外层迭代结束！
{'loss': 0.0198, 'learning_rate': 1.9626168224299062e-05, 'epoch': 9.33}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0412, 'learning_rate': 1.6822429906542053e-05, 'epoch': 9.42}
外层迭代结束！
外层迭代结束！
{'loss': 0.0058, 'learning_rate': 1.4018691588785045e-05, 'epoch': 9.51}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.021, 'learning_rate': 1.1214953271028036e-05, 'epoch': 9.6}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.89it/s][A
 31%|███       | 4/13 [00:00<00:00, 12.26it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.77it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.50it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.75it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.72it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.37it/s][A                                                   
                                               [A 96%|█████████▋| 1080/1120 [16:24<00:30,  1.30it/s]
100%|██████████| 13/13 [00:01<00:00,  8.37it/s][A
                                               [A 97%|█████████▋| 1081/1120 [16:25<00:51,  1.32s/it] 97%|█████████▋| 1082/1120 [16:26<00:43,  1.15s/it] 97%|█████████▋| 1083/1120 [16:26<00:38,  1.03s/it] 97%|█████████▋| 1084/1120 [16:27<00:34,  1.06it/s] 97%|█████████▋| 1085/1120 [16:28<00:33,  1.05it/s] 97%|█████████▋| 1086/1120 [16:29<00:30,  1.13it/s] 97%|█████████▋| 1087/1120 [16:30<00:27,  1.18it/s] 97%|█████████▋| 1088/1120 [16:30<00:26,  1.22it/s] 97%|█████████▋| 1089/1120 [16:31<00:26,  1.17it/s] 97%|█████████▋| 1090/1120 [16:32<00:24,  1.21it/s]                                                    97%|█████████▋| 1090/1120 [16:32<00:24,  1.21it/s] 97%|█████████▋| 1091/1120 [16:33<00:23,  1.25it/s] 98%|█████████▊| 1092/1120 [16:33<00:21,  1.28it/s] 98%|█████████▊| 1093/1120 [16:34<00:22,  1.20it/s] 98%|█████████▊| 1094/1120 [16:35<00:21,  1.23it/s] 98%|█████████▊| 1095/1120 [16:36<00:19,  1.26it/s] 98%|█████████▊| 1096/1120 [16:37<00:18,  1.29it/s] 98%|█████████▊| 1097/1120 [16:38<00:19,  1.20it/s] 98%|█████████▊| 1098/1120 [16:38<00:17,  1.24it/s] 98%|█████████▊| 1099/1120 [16:39<00:16,  1.26it/s] 98%|█████████▊| 1100/1120 [16:40<00:15,  1.28it/s]                                                    98%|█████████▊| 1100/1120 [16:40<00:15,  1.28it/s] 98%|█████████▊| 1101/1120 [16:41<00:15,  1.21it/s] 98%|█████████▊| 1102/1120 [16:42<00:14,  1.25it/s] 98%|█████████▊| 1103/1120 [16:42<00:13,  1.27it/s] 99%|█████████▊| 1104/1120 [16:43<00:12,  1.29it/s] 99%|█████████▊| 1105/1120 [16:44<00:12,  1.21it/s] 99%|█████████▉| 1106/1120 [16:45<00:11,  1.25it/s] 99%|█████████▉| 1107/1120 [16:45<00:10,  1.28it/s] 99%|█████████▉| 1108/1120 [16:46<00:09,  1.30it/s] 99%|█████████▉| 1109/1120 [16:47<00:09,  1.22it/s] 99%|█████████▉| 1110/1120 [16:48<00:08,  1.21it/s]                                                    99%|█████████▉| 1110/1120 [16:48<00:08,  1.21it/s] 99%|█████████▉| 1111/1120 [16:49<00:07,  1.25it/s] 99%|█████████▉| 1112/1120 [16:49<00:06,  1.28it/s] 99%|█████████▉| 1113/1120 [16:50<00:05,  1.19it/s] 99%|█████████▉| 1114/1120 [16:51<00:04,  1.24it/s]100%|█████████▉| 1115/1120 [16:52<00:03,  1.27it/s]100%|█████████▉| 1116/1120 [16:53<00:03,  1.29it/s]100%|█████████▉| 1117/1120 [16:54<00:02,  1.21it/s]100%|█████████▉| 1118/1120 [16:54<00:01,  1.25it/s]100%|█████████▉| 1119/1120 [16:55<00:00,  1.28it/s]100%|██████████| 1120/1120 [16:56<00:00,  1.29it/s]                                                   100%|██████████| 1120/1120 [16:56<00:00,  1.29it/s]{'eval_loss': 0.2295091450214386, 'eval_runtime': 1.5491, 'eval_samples_per_second': 64.555, 'eval_steps_per_second': 8.392, 'epoch': 9.6}
外层迭代结束！
外层迭代结束！
{'loss': 0.0218, 'learning_rate': 8.411214953271026e-06, 'epoch': 9.69}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0548, 'learning_rate': 5.607476635514018e-06, 'epoch': 9.78}
外层迭代结束！
外层迭代结束！
{'loss': 0.004, 'learning_rate': 2.803738317757009e-06, 'epoch': 9.87}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0172, 'learning_rate': 0.0, 'epoch': 9.96}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 14.81it/s][A
 31%|███       | 4/13 [00:00<00:00, 12.18it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  8.72it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.49it/s][A
 69%|██████▉   | 9/13 [00:01<00:00,  7.77it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  7.73it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.36it/s][A                                                   
                                               [A100%|██████████| 1120/1120 [16:58<00:00,  1.29it/s]
100%|██████████| 13/13 [00:01<00:00,  8.36it/s][A
                                               [AThere were missing keys in the checkpoint model loaded: ['base_model.model.shared.weight', 'base_model.model.encoder.embed_tokens.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.encoder.block.0.layer.0.layer_norm.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.0.layer.1.layer_norm.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.1.layer.0.layer_norm.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.1.layer.1.layer_norm.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.2.layer.0.layer_norm.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.2.layer.1.layer_norm.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.3.layer.0.layer_norm.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.3.layer.1.layer_norm.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.4.layer.0.layer_norm.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.4.layer.1.layer_norm.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.5.layer.0.layer_norm.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.5.layer.1.layer_norm.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.6.layer.0.layer_norm.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.6.layer.1.layer_norm.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.7.layer.0.layer_norm.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.7.layer.1.layer_norm.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.8.layer.0.layer_norm.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.8.layer.1.layer_norm.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.9.layer.0.layer_norm.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.9.layer.1.layer_norm.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.10.layer.0.layer_norm.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.10.layer.1.layer_norm.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.11.layer.0.layer_norm.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.11.layer.1.layer_norm.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.12.layer.0.layer_norm.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.12.layer.1.layer_norm.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.13.layer.0.layer_norm.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.13.layer.1.layer_norm.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.14.layer.0.layer_norm.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.14.layer.1.layer_norm.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.15.layer.0.layer_norm.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.15.layer.1.layer_norm.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.16.layer.0.layer_norm.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.16.layer.1.layer_norm.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.17.layer.0.layer_norm.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.17.layer.1.layer_norm.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.18.layer.0.layer_norm.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.18.layer.1.layer_norm.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.19.layer.0.layer_norm.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.19.layer.1.layer_norm.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.20.layer.0.layer_norm.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.20.layer.1.layer_norm.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.21.layer.0.layer_norm.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.21.layer.1.layer_norm.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.22.layer.0.layer_norm.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.22.layer.1.layer_norm.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.23.layer.0.layer_norm.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.23.layer.1.layer_norm.weight', 'base_model.model.encoder.final_layer_norm.weight', 'base_model.model.decoder.embed_tokens.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.decoder.block.0.layer.0.layer_norm.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.0.layer.1.layer_norm.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.0.layer.2.layer_norm.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.1.layer.0.layer_norm.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.1.layer.1.layer_norm.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.1.layer.2.layer_norm.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.2.layer.0.layer_norm.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.2.layer.1.layer_norm.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.2.layer.2.layer_norm.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.3.layer.0.layer_norm.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.3.layer.1.layer_norm.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.3.layer.2.layer_norm.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.4.layer.0.layer_norm.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.4.layer.1.layer_norm.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.4.layer.2.layer_norm.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.5.layer.0.layer_norm.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.5.layer.1.layer_norm.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.5.layer.2.layer_norm.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.6.layer.0.layer_norm.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.6.layer.1.layer_norm.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.6.layer.2.layer_norm.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.7.layer.0.layer_norm.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.7.layer.1.layer_norm.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.7.layer.2.layer_norm.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.8.layer.0.layer_norm.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.8.layer.1.layer_norm.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.8.layer.2.layer_norm.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.9.layer.0.layer_norm.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.9.layer.1.layer_norm.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.9.layer.2.layer_norm.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.10.layer.0.layer_norm.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.10.layer.1.layer_norm.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.10.layer.2.layer_norm.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.11.layer.0.layer_norm.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.11.layer.1.layer_norm.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.11.layer.2.layer_norm.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.12.layer.0.layer_norm.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.12.layer.1.layer_norm.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.12.layer.2.layer_norm.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.13.layer.0.layer_norm.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.13.layer.1.layer_norm.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.13.layer.2.layer_norm.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.14.layer.0.layer_norm.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.14.layer.1.layer_norm.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.14.layer.2.layer_norm.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.15.layer.0.layer_norm.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.15.layer.1.layer_norm.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.15.layer.2.layer_norm.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.16.layer.0.layer_norm.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.16.layer.1.layer_norm.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.16.layer.2.layer_norm.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.17.layer.0.layer_norm.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.17.layer.1.layer_norm.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.17.layer.2.layer_norm.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.18.layer.0.layer_norm.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.18.layer.1.layer_norm.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.18.layer.2.layer_norm.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.19.layer.0.layer_norm.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.19.layer.1.layer_norm.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.19.layer.2.layer_norm.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.20.layer.0.layer_norm.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.20.layer.1.layer_norm.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.20.layer.2.layer_norm.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.21.layer.0.layer_norm.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.21.layer.1.layer_norm.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.21.layer.2.layer_norm.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.22.layer.0.layer_norm.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.22.layer.1.layer_norm.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.22.layer.2.layer_norm.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.23.layer.0.layer_norm.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.23.layer.1.layer_norm.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.23.layer.2.layer_norm.weight', 'base_model.model.decoder.final_layer_norm.weight', 'base_model.model.lm_head.weight'].
There were unexpected keys in the checkpoint model loaded: ['base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.weight'].
                                                   100%|██████████| 1120/1120 [16:58<00:00,  1.29it/s]100%|██████████| 1120/1120 [16:58<00:00,  1.10it/s]
{'eval_loss': 0.230378195643425, 'eval_runtime': 1.5518, 'eval_samples_per_second': 64.443, 'eval_steps_per_second': 8.378, 'epoch': 9.96}
{'train_runtime': 1018.3557, 'train_samples_per_second': 8.838, 'train_steps_per_second': 1.1, 'train_loss': 0.08140073564967938, 'epoch': 9.96}

 If there's a warning about missing keys above, please disregard :)
Found cached dataset json (/data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 8
micro_batch_size: 2
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: rte... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/6-rte
current data path: ./data_longsequence/train/rte_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 796.64it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 635.40it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 857.56it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 962.22it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 458.49it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400, 选择的样本数量：8
task id: 4, history data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 469.79it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b05edc432aa3560.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 5, history data path: ./data_longsequence/train/boolqa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 858.61it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-856891a4945fd30a.arrow
总样本数：1000, 选择的样本数量：20
lora_weights: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/5-boolqa

pre-trained model's BOS EOS and PAD token id: None 1 0  => It should be 1,2,none
continual fine tune lora!
trainable params: 2359296 || all params: 740027392 || trainable%: 0.31881198257050464
训练数据总量：900
验证数据总量：100
Map:   0%|          | 0/900 [00:00<?, ? examples/s]/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3597: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  "`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your "
Map: 100%|██████████| 900/900 [00:00<00:00, 6837.89 examples/s]                                                               Map:   0%|          | 0/100 [00:00<?, ? examples/s]                                                   Map:   0%|          | 0/93 [00:00<?, ? examples/s]                                                  memory data loader 2
  0%|          | 0/1120 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/1120 [00:01<26:22,  1.41s/it]  0%|          | 2/1120 [00:02<19:07,  1.03s/it]  0%|          | 3/1120 [00:02<16:41,  1.11it/s]  0%|          | 4/1120 [00:03<15:30,  1.20it/s]  0%|          | 5/1120 [00:04<17:01,  1.09it/s]  1%|          | 6/1120 [00:05<15:56,  1.16it/s]  1%|          | 7/1120 [00:06<15:11,  1.22it/s]  1%|          | 8/1120 [00:06<14:38,  1.27it/s]  1%|          | 9/1120 [00:07<15:34,  1.19it/s]  1%|          | 10/1120 [00:08<15:00,  1.23it/s]                                                   1%|          | 10/1120 [00:08<15:00,  1.23it/s]  1%|          | 11/1120 [00:09<14:38,  1.26it/s]  1%|          | 12/1120 [00:10<14:18,  1.29it/s]  1%|          | 13/1120 [00:11<15:34,  1.19it/s]  1%|▏         | 14/1120 [00:11<15:02,  1.23it/s]  1%|▏         | 15/1120 [00:12<14:37,  1.26it/s]  1%|▏         | 16/1120 [00:13<14:19,  1.28it/s]  2%|▏         | 17/1120 [00:14<15:19,  1.20it/s]  2%|▏         | 18/1120 [00:15<14:55,  1.23it/s]  2%|▏         | 19/1120 [00:15<14:33,  1.26it/s]  2%|▏         | 20/1120 [00:16<14:17,  1.28it/s]                                                   2%|▏         | 20/1120 [00:16<14:17,  1.28it/s]  2%|▏         | 21/1120 [00:17<15:05,  1.21it/s]  2%|▏         | 22/1120 [00:18<14:41,  1.25it/s]  2%|▏         | 23/1120 [00:18<14:20,  1.28it/s]  2%|▏         | 24/1120 [00:19<14:07,  1.29it/s]  2%|▏         | 25/1120 [00:20<16:10,  1.13it/s]  2%|▏         | 26/1120 [00:21<15:23,  1.18it/s]  2%|▏         | 27/1120 [00:22<14:52,  1.22it/s]  2%|▎         | 28/1120 [00:23<14:27,  1.26it/s]  3%|▎         | 29/1120 [00:24<16:20,  1.11it/s]  3%|▎         | 30/1120 [00:25<15:29,  1.17it/s]                                                   3%|▎         | 30/1120 [00:25<15:29,  1.17it/s]  3%|▎         | 31/1120 [00:25<14:53,  1.22it/s]  3%|▎         | 32/1120 [00:26<14:27,  1.25it/s]  3%|▎         | 33/1120 [00:27<15:17,  1.18it/s]  3%|▎         | 34/1120 [00:28<14:46,  1.23it/s]  3%|▎         | 35/1120 [00:28<14:22,  1.26it/s]  3%|▎         | 36/1120 [00:29<14:05,  1.28it/s]  3%|▎         | 37/1120 [00:30<15:19,  1.18it/s]  3%|▎         | 38/1120 [00:31<14:48,  1.22it/s]  3%|▎         | 39/1120 [00:32<14:22,  1.25it/s]  4%|▎         | 40/1120 [00:32<14:02,  1.28it/s]                                                   4%|▎         | 40/1120 [00:33<14:02,  1.28it/s]外层迭代结束！
外层迭代结束！
{'loss': 2.9889, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.09}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 2.4011, 'learning_rate': 0.00011999999999999999, 'epoch': 0.18}
外层迭代结束！
外层迭代结束！
{'loss': 0.6139, 'learning_rate': 0.00017999999999999998, 'epoch': 0.27}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.3788, 'learning_rate': 0.00023999999999999998, 'epoch': 0.36}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.84it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 15.96it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 14.74it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 13.81it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 13.87it/s][A
100%|██████████| 13/13 [00:00<00:00, 13.98it/s][A                                                 
                                               [A  4%|▎         | 40/1120 [00:34<14:02,  1.28it/s]
100%|██████████| 13/13 [00:00<00:00, 13.98it/s][A
                                               [A  4%|▎         | 41/1120 [00:35<21:03,  1.17s/it]  4%|▍         | 42/1120 [00:35<18:44,  1.04s/it]  4%|▍         | 43/1120 [00:36<17:09,  1.05it/s]  4%|▍         | 44/1120 [00:37<15:58,  1.12it/s]  4%|▍         | 45/1120 [00:38<16:31,  1.08it/s]  4%|▍         | 46/1120 [00:39<15:35,  1.15it/s]  4%|▍         | 47/1120 [00:39<14:53,  1.20it/s]  4%|▍         | 48/1120 [00:40<14:23,  1.24it/s]  4%|▍         | 49/1120 [00:41<15:10,  1.18it/s]  4%|▍         | 50/1120 [00:42<14:35,  1.22it/s]                                                   4%|▍         | 50/1120 [00:42<14:35,  1.22it/s]  5%|▍         | 51/1120 [00:42<14:11,  1.26it/s]  5%|▍         | 52/1120 [00:43<13:53,  1.28it/s]  5%|▍         | 53/1120 [00:44<15:02,  1.18it/s]  5%|▍         | 54/1120 [00:45<14:26,  1.23it/s]  5%|▍         | 55/1120 [00:46<14:03,  1.26it/s]  5%|▌         | 56/1120 [00:46<13:45,  1.29it/s]  5%|▌         | 57/1120 [00:47<14:43,  1.20it/s]  5%|▌         | 58/1120 [00:48<14:15,  1.24it/s]  5%|▌         | 59/1120 [00:49<13:55,  1.27it/s]  5%|▌         | 60/1120 [00:50<13:40,  1.29it/s]                                                   5%|▌         | 60/1120 [00:50<13:40,  1.29it/s]  5%|▌         | 61/1120 [00:51<14:32,  1.21it/s]  6%|▌         | 62/1120 [00:51<14:07,  1.25it/s]  6%|▌         | 63/1120 [00:52<13:58,  1.26it/s]  6%|▌         | 64/1120 [00:53<13:42,  1.28it/s]  6%|▌         | 65/1120 [00:54<14:51,  1.18it/s]  6%|▌         | 66/1120 [00:55<14:19,  1.23it/s]  6%|▌         | 67/1120 [00:55<14:01,  1.25it/s]  6%|▌         | 68/1120 [00:56<13:46,  1.27it/s]  6%|▌         | 69/1120 [00:57<14:39,  1.20it/s]  6%|▋         | 70/1120 [00:58<14:08,  1.24it/s]                                                   6%|▋         | 70/1120 [00:58<14:08,  1.24it/s]  6%|▋         | 71/1120 [00:59<13:47,  1.27it/s]  6%|▋         | 72/1120 [00:59<13:34,  1.29it/s]  7%|▋         | 73/1120 [01:00<14:42,  1.19it/s]  7%|▋         | 74/1120 [01:01<14:09,  1.23it/s]  7%|▋         | 75/1120 [01:02<13:47,  1.26it/s]  7%|▋         | 76/1120 [01:02<13:32,  1.29it/s]  7%|▋         | 77/1120 [01:03<14:33,  1.19it/s]  7%|▋         | 78/1120 [01:04<14:03,  1.23it/s]  7%|▋         | 79/1120 [01:05<13:43,  1.26it/s]  7%|▋         | 80/1120 [01:06<13:29,  1.29it/s]                                                   7%|▋         | 80/1120 [01:06<13:29,  1.29it/s]{'eval_loss': 0.1787821650505066, 'eval_runtime': 0.9825, 'eval_samples_per_second': 101.78, 'eval_steps_per_second': 13.231, 'epoch': 0.36}
外层迭代结束！
外层迭代结束！
{'loss': 0.1837, 'learning_rate': 0.0003, 'epoch': 0.44}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2261, 'learning_rate': 0.00029719626168224294, 'epoch': 0.53}
外层迭代结束！
外层迭代结束！
{'loss': 0.1916, 'learning_rate': 0.00029439252336448596, 'epoch': 0.62}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2368, 'learning_rate': 0.0002915887850467289, 'epoch': 0.71}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.82it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 15.95it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 14.72it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 13.76it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 13.74it/s][A
100%|██████████| 13/13 [00:00<00:00, 13.89it/s][A                                                 
                                               [A  7%|▋         | 80/1120 [01:07<13:29,  1.29it/s]
100%|██████████| 13/13 [00:00<00:00, 13.89it/s][A
                                               [A  7%|▋         | 81/1120 [01:08<20:27,  1.18s/it]  7%|▋         | 82/1120 [01:09<18:10,  1.05s/it]  7%|▋         | 83/1120 [01:09<16:34,  1.04it/s]  8%|▊         | 84/1120 [01:10<15:26,  1.12it/s]  8%|▊         | 85/1120 [01:11<15:58,  1.08it/s]  8%|▊         | 86/1120 [01:12<15:00,  1.15it/s]  8%|▊         | 87/1120 [01:13<14:20,  1.20it/s]  8%|▊         | 88/1120 [01:13<13:55,  1.24it/s]  8%|▊         | 89/1120 [01:14<14:45,  1.16it/s]  8%|▊         | 90/1120 [01:15<14:08,  1.21it/s]                                                   8%|▊         | 90/1120 [01:15<14:08,  1.21it/s]  8%|▊         | 91/1120 [01:16<13:46,  1.24it/s]  8%|▊         | 92/1120 [01:17<13:29,  1.27it/s]  8%|▊         | 93/1120 [01:17<14:17,  1.20it/s]  8%|▊         | 94/1120 [01:18<13:56,  1.23it/s]  8%|▊         | 95/1120 [01:19<13:34,  1.26it/s]  9%|▊         | 96/1120 [01:20<13:18,  1.28it/s]  9%|▊         | 97/1120 [01:21<14:26,  1.18it/s]  9%|▉         | 98/1120 [01:21<13:57,  1.22it/s]  9%|▉         | 99/1120 [01:22<13:35,  1.25it/s]  9%|▉         | 100/1120 [01:23<13:18,  1.28it/s]                                                    9%|▉         | 100/1120 [01:23<13:18,  1.28it/s]  9%|▉         | 101/1120 [01:24<14:11,  1.20it/s]  9%|▉         | 102/1120 [01:25<13:45,  1.23it/s]  9%|▉         | 103/1120 [01:25<13:24,  1.26it/s]  9%|▉         | 104/1120 [01:26<13:09,  1.29it/s]  9%|▉         | 105/1120 [01:27<14:01,  1.21it/s]  9%|▉         | 106/1120 [01:28<13:37,  1.24it/s] 10%|▉         | 107/1120 [01:29<13:17,  1.27it/s] 10%|▉         | 108/1120 [01:29<13:07,  1.28it/s] 10%|▉         | 109/1120 [01:30<13:59,  1.20it/s] 10%|▉         | 110/1120 [01:31<13:35,  1.24it/s]                                                   10%|▉         | 110/1120 [01:31<13:35,  1.24it/s] 10%|▉         | 111/1120 [01:32<13:15,  1.27it/s] 10%|█         | 112/1120 [01:33<13:00,  1.29it/s] 10%|█         | 113/1120 [01:34<14:03,  1.19it/s] 10%|█         | 114/1120 [01:34<13:37,  1.23it/s] 10%|█         | 115/1120 [01:35<13:16,  1.26it/s] 10%|█         | 116/1120 [01:36<13:02,  1.28it/s] 10%|█         | 117/1120 [01:37<14:07,  1.18it/s] 11%|█         | 118/1120 [01:38<13:36,  1.23it/s] 11%|█         | 119/1120 [01:38<13:13,  1.26it/s] 11%|█         | 120/1120 [01:39<12:59,  1.28it/s]                                                   11%|█         | 120/1120 [01:39<12:59,  1.28it/s]{'eval_loss': 0.0986703559756279, 'eval_runtime': 0.9866, 'eval_samples_per_second': 101.356, 'eval_steps_per_second': 13.176, 'epoch': 0.71}
外层迭代结束！
外层迭代结束！
{'loss': 0.1508, 'learning_rate': 0.00028878504672897194, 'epoch': 0.8}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1925, 'learning_rate': 0.0002859813084112149, 'epoch': 0.89}
外层迭代结束！
外层迭代结束！
{'loss': 0.1813, 'learning_rate': 0.0002831775700934579, 'epoch': 0.98}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1099, 'learning_rate': 0.0002803738317757009, 'epoch': 1.07}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.94it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 16.00it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 14.69it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 13.77it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 13.83it/s][A
100%|██████████| 13/13 [00:00<00:00, 13.95it/s][A                                                  
                                               [A 11%|█         | 120/1120 [01:40<12:59,  1.28it/s]
100%|██████████| 13/13 [00:00<00:00, 13.95it/s][A
                                               [A 11%|█         | 121/1120 [01:41<19:40,  1.18s/it] 11%|█         | 122/1120 [01:42<17:27,  1.05s/it] 11%|█         | 123/1120 [01:43<15:53,  1.05it/s] 11%|█         | 124/1120 [01:43<14:47,  1.12it/s] 11%|█         | 125/1120 [01:44<15:08,  1.10it/s] 11%|█▏        | 126/1120 [01:45<14:17,  1.16it/s] 11%|█▏        | 127/1120 [01:46<13:40,  1.21it/s] 11%|█▏        | 128/1120 [01:47<13:14,  1.25it/s] 12%|█▏        | 129/1120 [01:48<14:52,  1.11it/s] 12%|█▏        | 130/1120 [01:48<14:04,  1.17it/s]                                                   12%|█▏        | 130/1120 [01:48<14:04,  1.17it/s] 12%|█▏        | 131/1120 [01:49<13:31,  1.22it/s] 12%|█▏        | 132/1120 [01:50<13:07,  1.25it/s] 12%|█▏        | 133/1120 [01:51<13:55,  1.18it/s] 12%|█▏        | 134/1120 [01:52<13:24,  1.23it/s] 12%|█▏        | 135/1120 [01:52<13:02,  1.26it/s] 12%|█▏        | 136/1120 [01:53<12:46,  1.28it/s] 12%|█▏        | 137/1120 [01:54<13:54,  1.18it/s] 12%|█▏        | 138/1120 [01:55<13:23,  1.22it/s] 12%|█▏        | 139/1120 [01:56<13:02,  1.25it/s] 12%|█▎        | 140/1120 [01:56<12:45,  1.28it/s]                                                   12%|█▎        | 140/1120 [01:57<12:45,  1.28it/s] 13%|█▎        | 141/1120 [01:57<13:35,  1.20it/s] 13%|█▎        | 142/1120 [01:58<13:09,  1.24it/s] 13%|█▎        | 143/1120 [01:59<12:50,  1.27it/s] 13%|█▎        | 144/1120 [02:00<12:36,  1.29it/s] 13%|█▎        | 145/1120 [02:01<13:38,  1.19it/s] 13%|█▎        | 146/1120 [02:01<13:09,  1.23it/s] 13%|█▎        | 147/1120 [02:02<12:48,  1.27it/s] 13%|█▎        | 148/1120 [02:03<12:35,  1.29it/s] 13%|█▎        | 149/1120 [02:04<13:40,  1.18it/s] 13%|█▎        | 150/1120 [02:05<13:09,  1.23it/s]                                                   13%|█▎        | 150/1120 [02:05<13:09,  1.23it/s] 13%|█▎        | 151/1120 [02:05<12:48,  1.26it/s] 14%|█▎        | 152/1120 [02:06<12:34,  1.28it/s] 14%|█▎        | 153/1120 [02:07<13:23,  1.20it/s] 14%|█▍        | 154/1120 [02:08<13:01,  1.24it/s] 14%|█▍        | 155/1120 [02:09<12:44,  1.26it/s] 14%|█▍        | 156/1120 [02:09<12:28,  1.29it/s] 14%|█▍        | 157/1120 [02:10<13:16,  1.21it/s] 14%|█▍        | 158/1120 [02:11<12:51,  1.25it/s] 14%|█▍        | 159/1120 [02:12<12:33,  1.28it/s] 14%|█▍        | 160/1120 [02:12<12:22,  1.29it/s]                                                   14%|█▍        | 160/1120 [02:13<12:22,  1.29it/s]{'eval_loss': 0.08900248259305954, 'eval_runtime': 0.9833, 'eval_samples_per_second': 101.701, 'eval_steps_per_second': 13.221, 'epoch': 1.07}
外层迭代结束！
外层迭代结束！
{'loss': 0.1268, 'learning_rate': 0.0002775700934579439, 'epoch': 1.16}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1077, 'learning_rate': 0.00027476635514018686, 'epoch': 1.24}
外层迭代结束！
外层迭代结束！
{'loss': 0.13, 'learning_rate': 0.0002719626168224299, 'epoch': 1.33}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0767, 'learning_rate': 0.00026915887850467284, 'epoch': 1.42}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.99it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 16.00it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 14.77it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 13.85it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 13.91it/s][A
100%|██████████| 13/13 [00:00<00:00, 14.01it/s][A                                                  
                                               [A 14%|█▍        | 160/1120 [02:14<12:22,  1.29it/s]
100%|██████████| 13/13 [00:00<00:00, 14.01it/s][A
                                               [A 14%|█▍        | 161/1120 [02:14<18:32,  1.16s/it] 14%|█▍        | 162/1120 [02:15<16:36,  1.04s/it] 15%|█▍        | 163/1120 [02:16<15:11,  1.05it/s] 15%|█▍        | 164/1120 [02:17<14:11,  1.12it/s] 15%|█▍        | 165/1120 [02:18<14:38,  1.09it/s] 15%|█▍        | 166/1120 [02:18<13:45,  1.16it/s] 15%|█▍        | 167/1120 [02:19<13:08,  1.21it/s] 15%|█▌        | 168/1120 [02:20<12:42,  1.25it/s] 15%|█▌        | 169/1120 [02:21<13:23,  1.18it/s] 15%|█▌        | 170/1120 [02:22<12:54,  1.23it/s]                                                   15%|█▌        | 170/1120 [02:22<12:54,  1.23it/s] 15%|█▌        | 171/1120 [02:22<12:34,  1.26it/s] 15%|█▌        | 172/1120 [02:23<12:19,  1.28it/s] 15%|█▌        | 173/1120 [02:24<13:08,  1.20it/s] 16%|█▌        | 174/1120 [02:25<12:44,  1.24it/s] 16%|█▌        | 175/1120 [02:26<12:26,  1.27it/s] 16%|█▌        | 176/1120 [02:26<12:18,  1.28it/s] 16%|█▌        | 177/1120 [02:27<13:08,  1.20it/s] 16%|█▌        | 178/1120 [02:28<12:42,  1.24it/s] 16%|█▌        | 179/1120 [02:29<12:23,  1.27it/s] 16%|█▌        | 180/1120 [02:30<12:08,  1.29it/s]                                                   16%|█▌        | 180/1120 [02:30<12:08,  1.29it/s] 16%|█▌        | 181/1120 [02:31<13:05,  1.19it/s] 16%|█▋        | 182/1120 [02:31<12:39,  1.23it/s] 16%|█▋        | 183/1120 [02:32<12:23,  1.26it/s] 16%|█▋        | 184/1120 [02:33<12:08,  1.28it/s] 17%|█▋        | 185/1120 [02:34<12:59,  1.20it/s] 17%|█▋        | 186/1120 [02:34<12:33,  1.24it/s] 17%|█▋        | 187/1120 [02:35<12:16,  1.27it/s] 17%|█▋        | 188/1120 [02:36<12:03,  1.29it/s] 17%|█▋        | 189/1120 [02:37<12:58,  1.20it/s] 17%|█▋        | 190/1120 [02:38<12:32,  1.24it/s]                                                   17%|█▋        | 190/1120 [02:38<12:32,  1.24it/s] 17%|█▋        | 191/1120 [02:38<12:13,  1.27it/s] 17%|█▋        | 192/1120 [02:39<11:59,  1.29it/s] 17%|█▋        | 193/1120 [02:40<12:59,  1.19it/s] 17%|█▋        | 194/1120 [02:41<12:31,  1.23it/s] 17%|█▋        | 195/1120 [02:42<12:11,  1.26it/s] 18%|█▊        | 196/1120 [02:42<11:58,  1.29it/s] 18%|█▊        | 197/1120 [02:44<13:39,  1.13it/s] 18%|█▊        | 198/1120 [02:44<13:00,  1.18it/s] 18%|█▊        | 199/1120 [02:45<12:32,  1.22it/s] 18%|█▊        | 200/1120 [02:46<12:15,  1.25it/s]                                                   18%|█▊        | 200/1120 [02:46<12:15,  1.25it/s]{'eval_loss': 0.06673522293567657, 'eval_runtime': 0.9792, 'eval_samples_per_second': 102.119, 'eval_steps_per_second': 13.275, 'epoch': 1.42}
外层迭代结束！
外层迭代结束！
{'loss': 0.1081, 'learning_rate': 0.00026635514018691586, 'epoch': 1.51}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0811, 'learning_rate': 0.0002635514018691588, 'epoch': 1.6}
外层迭代结束！
外层迭代结束！
{'loss': 0.1754, 'learning_rate': 0.00026074766355140184, 'epoch': 1.69}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0861, 'learning_rate': 0.0002579439252336448, 'epoch': 1.78}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.86it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 16.02it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 14.78it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 13.86it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 13.82it/s][A
100%|██████████| 13/13 [00:00<00:00, 13.93it/s][A                                                  
                                               [A 18%|█▊        | 200/1120 [02:47<12:15,  1.25it/s]
100%|██████████| 13/13 [00:00<00:00, 13.93it/s][A
                                               [A 18%|█▊        | 201/1120 [02:48<18:02,  1.18s/it] 18%|█▊        | 202/1120 [02:49<16:02,  1.05s/it] 18%|█▊        | 203/1120 [02:49<14:34,  1.05it/s] 18%|█▊        | 204/1120 [02:50<13:35,  1.12it/s] 18%|█▊        | 205/1120 [02:51<14:42,  1.04it/s] 18%|█▊        | 206/1120 [02:52<13:42,  1.11it/s] 18%|█▊        | 207/1120 [02:53<12:59,  1.17it/s] 19%|█▊        | 208/1120 [02:53<12:28,  1.22it/s] 19%|█▊        | 209/1120 [02:54<13:24,  1.13it/s] 19%|█▉        | 210/1120 [02:55<12:45,  1.19it/s]                                                   19%|█▉        | 210/1120 [02:55<12:45,  1.19it/s] 19%|█▉        | 211/1120 [02:56<12:22,  1.22it/s] 19%|█▉        | 212/1120 [02:57<12:02,  1.26it/s] 19%|█▉        | 213/1120 [02:58<13:03,  1.16it/s] 19%|█▉        | 214/1120 [02:59<12:31,  1.21it/s] 19%|█▉        | 215/1120 [02:59<12:11,  1.24it/s] 19%|█▉        | 216/1120 [03:00<11:55,  1.26it/s] 19%|█▉        | 217/1120 [03:01<12:49,  1.17it/s] 19%|█▉        | 218/1120 [03:02<12:18,  1.22it/s] 20%|█▉        | 219/1120 [03:03<11:58,  1.25it/s] 20%|█▉        | 220/1120 [03:03<11:42,  1.28it/s]                                                   20%|█▉        | 220/1120 [03:03<11:42,  1.28it/s] 20%|█▉        | 221/1120 [03:04<12:30,  1.20it/s] 20%|█▉        | 222/1120 [03:05<12:06,  1.24it/s] 20%|█▉        | 223/1120 [03:06<11:51,  1.26it/s] 20%|██        | 224/1120 [03:06<11:39,  1.28it/s] 20%|██        | 225/1120 [03:07<12:36,  1.18it/s] 20%|██        | 226/1120 [03:08<12:15,  1.22it/s] 20%|██        | 227/1120 [03:09<11:56,  1.25it/s] 20%|██        | 228/1120 [03:10<11:39,  1.28it/s] 20%|██        | 229/1120 [03:11<12:35,  1.18it/s] 21%|██        | 230/1120 [03:11<12:08,  1.22it/s]                                                   21%|██        | 230/1120 [03:11<12:08,  1.22it/s] 21%|██        | 231/1120 [03:12<11:50,  1.25it/s] 21%|██        | 232/1120 [03:13<11:34,  1.28it/s] 21%|██        | 233/1120 [03:14<12:21,  1.20it/s] 21%|██        | 234/1120 [03:15<11:59,  1.23it/s] 21%|██        | 235/1120 [03:15<11:44,  1.26it/s] 21%|██        | 236/1120 [03:16<11:33,  1.28it/s] 21%|██        | 237/1120 [03:17<12:15,  1.20it/s] 21%|██▏       | 238/1120 [03:18<11:49,  1.24it/s] 21%|██▏       | 239/1120 [03:19<11:31,  1.27it/s] 21%|██▏       | 240/1120 [03:19<11:19,  1.30it/s]                                                   21%|██▏       | 240/1120 [03:20<11:19,  1.30it/s]{'eval_loss': 0.07059337198734283, 'eval_runtime': 0.983, 'eval_samples_per_second': 101.727, 'eval_steps_per_second': 13.224, 'epoch': 1.78}
外层迭代结束！
外层迭代结束！
{'loss': 0.1333, 'learning_rate': 0.0002551401869158878, 'epoch': 1.87}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1131, 'learning_rate': 0.0002523364485981308, 'epoch': 1.96}
外层迭代结束！
外层迭代结束！
{'loss': 0.0874, 'learning_rate': 0.0002495327102803738, 'epoch': 2.04}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0468, 'learning_rate': 0.00024672897196261677, 'epoch': 2.13}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.04it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.33it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 14.61it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.07it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.10it/s][A                                                  
                                               [A 21%|██▏       | 240/1120 [03:21<11:19,  1.30it/s]
100%|██████████| 13/13 [00:00<00:00, 14.10it/s][A
                                               [A 22%|██▏       | 241/1120 [03:22<17:44,  1.21s/it] 22%|██▏       | 242/1120 [03:22<15:41,  1.07s/it] 22%|██▏       | 243/1120 [03:23<14:14,  1.03it/s] 22%|██▏       | 244/1120 [03:24<13:15,  1.10it/s] 22%|██▏       | 245/1120 [03:25<13:25,  1.09it/s] 22%|██▏       | 246/1120 [03:26<12:39,  1.15it/s] 22%|██▏       | 247/1120 [03:26<12:09,  1.20it/s] 22%|██▏       | 248/1120 [03:27<11:43,  1.24it/s] 22%|██▏       | 249/1120 [03:28<12:23,  1.17it/s] 22%|██▏       | 250/1120 [03:29<11:56,  1.21it/s]                                                   22%|██▏       | 250/1120 [03:29<11:56,  1.21it/s] 22%|██▏       | 251/1120 [03:30<11:34,  1.25it/s] 22%|██▎       | 252/1120 [03:30<11:22,  1.27it/s] 23%|██▎       | 253/1120 [03:31<12:16,  1.18it/s] 23%|██▎       | 254/1120 [03:32<11:48,  1.22it/s] 23%|██▎       | 255/1120 [03:33<11:29,  1.25it/s] 23%|██▎       | 256/1120 [03:34<11:16,  1.28it/s] 23%|██▎       | 257/1120 [03:34<12:02,  1.19it/s] 23%|██▎       | 258/1120 [03:35<11:36,  1.24it/s] 23%|██▎       | 259/1120 [03:36<11:19,  1.27it/s] 23%|██▎       | 260/1120 [03:37<11:08,  1.29it/s]                                                   23%|██▎       | 260/1120 [03:37<11:08,  1.29it/s] 23%|██▎       | 261/1120 [03:38<12:05,  1.18it/s] 23%|██▎       | 262/1120 [03:38<11:39,  1.23it/s] 23%|██▎       | 263/1120 [03:39<11:21,  1.26it/s] 24%|██▎       | 264/1120 [03:40<11:06,  1.28it/s] 24%|██▎       | 265/1120 [03:41<11:52,  1.20it/s] 24%|██▍       | 266/1120 [03:42<11:32,  1.23it/s] 24%|██▍       | 267/1120 [03:42<11:13,  1.27it/s] 24%|██▍       | 268/1120 [03:43<11:00,  1.29it/s] 24%|██▍       | 269/1120 [03:44<11:54,  1.19it/s] 24%|██▍       | 270/1120 [03:45<11:29,  1.23it/s]                                                   24%|██▍       | 270/1120 [03:45<11:29,  1.23it/s] 24%|██▍       | 271/1120 [03:46<11:11,  1.27it/s] 24%|██▍       | 272/1120 [03:46<10:57,  1.29it/s] 24%|██▍       | 273/1120 [03:47<11:41,  1.21it/s] 24%|██▍       | 274/1120 [03:48<11:22,  1.24it/s] 25%|██▍       | 275/1120 [03:49<11:05,  1.27it/s] 25%|██▍       | 276/1120 [03:50<10:53,  1.29it/s] 25%|██▍       | 277/1120 [03:51<11:40,  1.20it/s] 25%|██▍       | 278/1120 [03:51<11:15,  1.25it/s] 25%|██▍       | 279/1120 [03:52<11:02,  1.27it/s] 25%|██▌       | 280/1120 [03:53<10:50,  1.29it/s]                                                   25%|██▌       | 280/1120 [03:53<10:50,  1.29it/s]{'eval_loss': 0.05847404524683952, 'eval_runtime': 0.9759, 'eval_samples_per_second': 102.466, 'eval_steps_per_second': 13.321, 'epoch': 2.13}
外层迭代结束！
外层迭代结束！
{'loss': 0.0835, 'learning_rate': 0.0002439252336448598, 'epoch': 2.22}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0534, 'learning_rate': 0.00024112149532710278, 'epoch': 2.31}
外层迭代结束！
外层迭代结束！
{'loss': 0.0295, 'learning_rate': 0.00023831775700934577, 'epoch': 2.4}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1116, 'learning_rate': 0.00023551401869158876, 'epoch': 2.49}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.93it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 16.03it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 14.64it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 13.70it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 13.53it/s][A
100%|██████████| 13/13 [00:00<00:00, 13.67it/s][A                                                  
                                               [A 25%|██▌       | 280/1120 [03:54<10:50,  1.29it/s]
100%|██████████| 13/13 [00:00<00:00, 13.67it/s][A
                                               [A 25%|██▌       | 281/1120 [03:55<16:33,  1.18s/it] 25%|██▌       | 282/1120 [03:56<14:42,  1.05s/it] 25%|██▌       | 283/1120 [03:56<13:28,  1.04it/s] 25%|██▌       | 284/1120 [03:57<12:32,  1.11it/s] 25%|██▌       | 285/1120 [03:58<12:48,  1.09it/s] 26%|██▌       | 286/1120 [03:59<12:03,  1.15it/s] 26%|██▌       | 287/1120 [04:00<11:33,  1.20it/s] 26%|██▌       | 288/1120 [04:00<11:12,  1.24it/s] 26%|██▌       | 289/1120 [04:01<11:54,  1.16it/s] 26%|██▌       | 290/1120 [04:02<11:30,  1.20it/s]                                                   26%|██▌       | 290/1120 [04:02<11:30,  1.20it/s] 26%|██▌       | 291/1120 [04:03<11:15,  1.23it/s] 26%|██▌       | 292/1120 [04:04<11:03,  1.25it/s] 26%|██▌       | 293/1120 [04:05<11:54,  1.16it/s] 26%|██▋       | 294/1120 [04:05<11:25,  1.20it/s] 26%|██▋       | 295/1120 [04:06<11:06,  1.24it/s] 26%|██▋       | 296/1120 [04:07<10:49,  1.27it/s] 27%|██▋       | 297/1120 [04:08<11:30,  1.19it/s] 27%|██▋       | 298/1120 [04:09<11:08,  1.23it/s] 27%|██▋       | 299/1120 [04:09<10:50,  1.26it/s] 27%|██▋       | 300/1120 [04:10<10:39,  1.28it/s]                                                   27%|██▋       | 300/1120 [04:10<10:39,  1.28it/s] 27%|██▋       | 301/1120 [04:11<11:30,  1.19it/s] 27%|██▋       | 302/1120 [04:12<11:04,  1.23it/s] 27%|██▋       | 303/1120 [04:13<10:47,  1.26it/s] 27%|██▋       | 304/1120 [04:13<10:34,  1.29it/s] 27%|██▋       | 305/1120 [04:14<11:32,  1.18it/s] 27%|██▋       | 306/1120 [04:15<11:06,  1.22it/s] 27%|██▋       | 307/1120 [04:16<10:49,  1.25it/s] 28%|██▊       | 308/1120 [04:17<10:46,  1.26it/s] 28%|██▊       | 309/1120 [04:18<11:46,  1.15it/s] 28%|██▊       | 310/1120 [04:18<11:14,  1.20it/s]                                                   28%|██▊       | 310/1120 [04:18<11:14,  1.20it/s] 28%|██▊       | 311/1120 [04:19<10:51,  1.24it/s] 28%|██▊       | 312/1120 [04:20<10:36,  1.27it/s] 28%|██▊       | 313/1120 [04:21<11:16,  1.19it/s] 28%|██▊       | 314/1120 [04:22<10:50,  1.24it/s] 28%|██▊       | 315/1120 [04:22<10:29,  1.28it/s] 28%|██▊       | 316/1120 [04:23<10:20,  1.30it/s] 28%|██▊       | 317/1120 [04:24<11:12,  1.19it/s] 28%|██▊       | 318/1120 [04:25<10:48,  1.24it/s] 28%|██▊       | 319/1120 [04:26<10:32,  1.27it/s] 29%|██▊       | 320/1120 [04:26<10:19,  1.29it/s]                                                   29%|██▊       | 320/1120 [04:27<10:19,  1.29it/s]{'eval_loss': 0.07529108971357346, 'eval_runtime': 0.9956, 'eval_samples_per_second': 100.446, 'eval_steps_per_second': 13.058, 'epoch': 2.49}
外层迭代结束！
外层迭代结束！
{'loss': 0.0861, 'learning_rate': 0.00023271028037383175, 'epoch': 2.58}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0772, 'learning_rate': 0.00022990654205607474, 'epoch': 2.67}
外层迭代结束！
外层迭代结束！
{'loss': 0.0434, 'learning_rate': 0.00022710280373831773, 'epoch': 2.76}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0512, 'learning_rate': 0.00022429906542056072, 'epoch': 2.84}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.96it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 16.03it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 14.76it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 13.83it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 13.87it/s][A
100%|██████████| 13/13 [00:00<00:00, 13.99it/s][A                                                  
                                               [A 29%|██▊       | 320/1120 [04:27<10:19,  1.29it/s]
100%|██████████| 13/13 [00:00<00:00, 13.99it/s][A
                                               [A 29%|██▊       | 321/1120 [04:28<15:28,  1.16s/it] 29%|██▉       | 322/1120 [04:29<13:46,  1.04s/it] 29%|██▉       | 323/1120 [04:30<12:36,  1.05it/s] 29%|██▉       | 324/1120 [04:31<11:49,  1.12it/s] 29%|██▉       | 325/1120 [04:32<12:15,  1.08it/s] 29%|██▉       | 326/1120 [04:32<11:32,  1.15it/s] 29%|██▉       | 327/1120 [04:33<11:00,  1.20it/s] 29%|██▉       | 328/1120 [04:34<10:39,  1.24it/s] 29%|██▉       | 329/1120 [04:35<11:13,  1.17it/s] 29%|██▉       | 330/1120 [04:36<10:46,  1.22it/s]                                                   29%|██▉       | 330/1120 [04:36<10:46,  1.22it/s] 30%|██▉       | 331/1120 [04:36<10:29,  1.25it/s] 30%|██▉       | 332/1120 [04:37<10:15,  1.28it/s] 30%|██▉       | 333/1120 [04:38<11:39,  1.12it/s] 30%|██▉       | 334/1120 [04:39<11:05,  1.18it/s] 30%|██▉       | 335/1120 [04:40<10:40,  1.23it/s] 30%|███       | 336/1120 [04:40<10:24,  1.26it/s] 30%|███       | 337/1120 [04:41<11:02,  1.18it/s] 30%|███       | 338/1120 [04:42<10:38,  1.22it/s] 30%|███       | 339/1120 [04:43<10:21,  1.26it/s] 30%|███       | 340/1120 [04:44<10:07,  1.28it/s]                                                   30%|███       | 340/1120 [04:44<10:07,  1.28it/s] 30%|███       | 341/1120 [04:45<10:47,  1.20it/s] 31%|███       | 342/1120 [04:45<10:25,  1.24it/s] 31%|███       | 343/1120 [04:46<10:11,  1.27it/s] 31%|███       | 344/1120 [04:47<10:01,  1.29it/s] 31%|███       | 345/1120 [04:48<11:30,  1.12it/s] 31%|███       | 346/1120 [04:49<10:54,  1.18it/s] 31%|███       | 347/1120 [04:49<10:29,  1.23it/s] 31%|███       | 348/1120 [04:50<10:10,  1.26it/s] 31%|███       | 349/1120 [04:51<10:46,  1.19it/s] 31%|███▏      | 350/1120 [04:52<10:24,  1.23it/s]                                                   31%|███▏      | 350/1120 [04:52<10:24,  1.23it/s] 31%|███▏      | 351/1120 [04:53<10:08,  1.26it/s] 31%|███▏      | 352/1120 [04:53<09:54,  1.29it/s] 32%|███▏      | 353/1120 [04:54<10:38,  1.20it/s] 32%|███▏      | 354/1120 [04:55<10:17,  1.24it/s] 32%|███▏      | 355/1120 [04:56<10:03,  1.27it/s] 32%|███▏      | 356/1120 [04:57<09:55,  1.28it/s] 32%|███▏      | 357/1120 [04:58<10:33,  1.20it/s] 32%|███▏      | 358/1120 [04:58<10:13,  1.24it/s] 32%|███▏      | 359/1120 [04:59<09:59,  1.27it/s] 32%|███▏      | 360/1120 [05:00<09:47,  1.29it/s]                                                   32%|███▏      | 360/1120 [05:00<09:47,  1.29it/s]{'eval_loss': 0.09702932089567184, 'eval_runtime': 0.9805, 'eval_samples_per_second': 101.987, 'eval_steps_per_second': 13.258, 'epoch': 2.84}
外层迭代结束！
外层迭代结束！
{'loss': 0.1246, 'learning_rate': 0.0002214953271028037, 'epoch': 2.93}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1052, 'learning_rate': 0.0002186915887850467, 'epoch': 3.02}
外层迭代结束！
外层迭代结束！
{'loss': 0.0874, 'learning_rate': 0.0002158878504672897, 'epoch': 3.11}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0543, 'learning_rate': 0.00021308411214953268, 'epoch': 3.2}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.93it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 16.03it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 14.77it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 13.85it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 13.91it/s][A
100%|██████████| 13/13 [00:00<00:00, 14.00it/s][A                                                  
                                               [A 32%|███▏      | 360/1120 [05:01<09:47,  1.29it/s]
100%|██████████| 13/13 [00:00<00:00, 14.00it/s][A
                                               [A 32%|███▏      | 361/1120 [05:02<14:39,  1.16s/it] 32%|███▏      | 362/1120 [05:03<13:03,  1.03s/it] 32%|███▏      | 363/1120 [05:03<11:56,  1.06it/s] 32%|███▎      | 364/1120 [05:04<11:10,  1.13it/s] 33%|███▎      | 365/1120 [05:05<11:30,  1.09it/s] 33%|███▎      | 366/1120 [05:06<10:50,  1.16it/s] 33%|███▎      | 367/1120 [05:07<10:22,  1.21it/s] 33%|███▎      | 368/1120 [05:07<10:02,  1.25it/s] 33%|███▎      | 369/1120 [05:08<10:38,  1.18it/s] 33%|███▎      | 370/1120 [05:09<10:16,  1.22it/s]                                                   33%|███▎      | 370/1120 [05:09<10:16,  1.22it/s] 33%|███▎      | 371/1120 [05:10<09:57,  1.25it/s] 33%|███▎      | 372/1120 [05:10<09:46,  1.28it/s] 33%|███▎      | 373/1120 [05:11<10:34,  1.18it/s] 33%|███▎      | 374/1120 [05:12<10:09,  1.22it/s] 33%|███▎      | 375/1120 [05:13<09:51,  1.26it/s] 34%|███▎      | 376/1120 [05:14<09:40,  1.28it/s] 34%|███▎      | 377/1120 [05:15<10:23,  1.19it/s] 34%|███▍      | 378/1120 [05:15<10:01,  1.23it/s] 34%|███▍      | 379/1120 [05:16<09:47,  1.26it/s] 34%|███▍      | 380/1120 [05:17<09:34,  1.29it/s]                                                   34%|███▍      | 380/1120 [05:17<09:34,  1.29it/s] 34%|███▍      | 381/1120 [05:18<10:21,  1.19it/s] 34%|███▍      | 382/1120 [05:19<09:58,  1.23it/s] 34%|███▍      | 383/1120 [05:19<09:42,  1.26it/s] 34%|███▍      | 384/1120 [05:20<09:36,  1.28it/s] 34%|███▍      | 385/1120 [05:21<10:13,  1.20it/s] 34%|███▍      | 386/1120 [05:22<09:52,  1.24it/s] 35%|███▍      | 387/1120 [05:23<09:37,  1.27it/s] 35%|███▍      | 388/1120 [05:23<09:26,  1.29it/s] 35%|███▍      | 389/1120 [05:24<10:12,  1.19it/s] 35%|███▍      | 390/1120 [05:25<09:51,  1.23it/s]                                                   35%|███▍      | 390/1120 [05:25<09:51,  1.23it/s] 35%|███▍      | 391/1120 [05:26<09:36,  1.26it/s] 35%|███▌      | 392/1120 [05:27<09:26,  1.28it/s] 35%|███▌      | 393/1120 [05:28<10:12,  1.19it/s] 35%|███▌      | 394/1120 [05:28<09:50,  1.23it/s] 35%|███▌      | 395/1120 [05:29<09:35,  1.26it/s] 35%|███▌      | 396/1120 [05:30<09:24,  1.28it/s] 35%|███▌      | 397/1120 [05:31<10:00,  1.20it/s] 36%|███▌      | 398/1120 [05:31<09:39,  1.24it/s] 36%|███▌      | 399/1120 [05:32<09:26,  1.27it/s] 36%|███▌      | 400/1120 [05:33<09:16,  1.29it/s]                                                   36%|███▌      | 400/1120 [05:33<09:16,  1.29it/s]{'eval_loss': 0.06694658100605011, 'eval_runtime': 0.9794, 'eval_samples_per_second': 102.108, 'eval_steps_per_second': 13.274, 'epoch': 3.2}
外层迭代结束！
外层迭代结束！
{'loss': 0.0684, 'learning_rate': 0.00021028037383177567, 'epoch': 3.29}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0427, 'learning_rate': 0.00020747663551401867, 'epoch': 3.38}
外层迭代结束！
外层迭代结束！
{'loss': 0.0333, 'learning_rate': 0.00020467289719626166, 'epoch': 3.47}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0561, 'learning_rate': 0.00020186915887850465, 'epoch': 3.56}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.91it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 16.03it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 14.75it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 13.83it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 13.86it/s][A
100%|██████████| 13/13 [00:00<00:00, 13.96it/s][A                                                  
                                               [A 36%|███▌      | 400/1120 [05:34<09:16,  1.29it/s]
100%|██████████| 13/13 [00:00<00:00, 13.96it/s][A
                                               [A 36%|███▌      | 401/1120 [05:35<14:03,  1.17s/it] 36%|███▌      | 402/1120 [05:36<12:30,  1.05s/it] 36%|███▌      | 403/1120 [05:37<11:25,  1.05it/s] 36%|███▌      | 404/1120 [05:37<10:38,  1.12it/s] 36%|███▌      | 405/1120 [05:38<10:51,  1.10it/s] 36%|███▋      | 406/1120 [05:39<10:14,  1.16it/s] 36%|███▋      | 407/1120 [05:40<09:48,  1.21it/s] 36%|███▋      | 408/1120 [05:40<09:29,  1.25it/s] 37%|███▋      | 409/1120 [05:41<10:02,  1.18it/s] 37%|███▋      | 410/1120 [05:42<09:39,  1.22it/s]                                                   37%|███▋      | 410/1120 [05:42<09:39,  1.22it/s] 37%|███▋      | 411/1120 [05:43<09:22,  1.26it/s] 37%|███▋      | 412/1120 [05:44<09:10,  1.29it/s] 37%|███▋      | 413/1120 [05:45<09:52,  1.19it/s] 37%|███▋      | 414/1120 [05:45<09:30,  1.24it/s] 37%|███▋      | 415/1120 [05:46<09:16,  1.27it/s] 37%|███▋      | 416/1120 [05:47<09:05,  1.29it/s] 37%|███▋      | 417/1120 [05:48<09:40,  1.21it/s] 37%|███▋      | 418/1120 [05:49<09:22,  1.25it/s] 37%|███▋      | 419/1120 [05:49<09:08,  1.28it/s] 38%|███▊      | 420/1120 [05:50<08:59,  1.30it/s]                                                   38%|███▊      | 420/1120 [05:50<08:59,  1.30it/s] 38%|███▊      | 421/1120 [05:51<09:44,  1.20it/s] 38%|███▊      | 422/1120 [05:52<09:22,  1.24it/s] 38%|███▊      | 423/1120 [05:53<09:06,  1.27it/s] 38%|███▊      | 424/1120 [05:53<08:56,  1.30it/s] 38%|███▊      | 425/1120 [05:54<09:35,  1.21it/s] 38%|███▊      | 426/1120 [05:55<09:17,  1.24it/s] 38%|███▊      | 427/1120 [05:56<09:06,  1.27it/s] 38%|███▊      | 428/1120 [05:56<08:57,  1.29it/s] 38%|███▊      | 429/1120 [05:57<09:33,  1.20it/s] 38%|███▊      | 430/1120 [05:58<09:16,  1.24it/s]                                                   38%|███▊      | 430/1120 [05:58<09:16,  1.24it/s] 38%|███▊      | 431/1120 [05:59<09:02,  1.27it/s] 39%|███▊      | 432/1120 [06:00<08:52,  1.29it/s] 39%|███▊      | 433/1120 [06:01<09:39,  1.19it/s] 39%|███▉      | 434/1120 [06:01<09:18,  1.23it/s] 39%|███▉      | 435/1120 [06:02<09:03,  1.26it/s] 39%|███▉      | 436/1120 [06:03<08:52,  1.29it/s] 39%|███▉      | 437/1120 [06:04<10:05,  1.13it/s] 39%|███▉      | 438/1120 [06:05<09:34,  1.19it/s] 39%|███▉      | 439/1120 [06:06<09:12,  1.23it/s] 39%|███▉      | 440/1120 [06:06<08:58,  1.26it/s]                                                   39%|███▉      | 440/1120 [06:06<08:58,  1.26it/s]{'eval_loss': 0.07087436318397522, 'eval_runtime': 0.9819, 'eval_samples_per_second': 101.839, 'eval_steps_per_second': 13.239, 'epoch': 3.56}
外层迭代结束！
外层迭代结束！
{'loss': 0.0306, 'learning_rate': 0.00019906542056074764, 'epoch': 3.64}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0481, 'learning_rate': 0.00019626168224299063, 'epoch': 3.73}
外层迭代结束！
外层迭代结束！
{'loss': 0.0197, 'learning_rate': 0.00019345794392523362, 'epoch': 3.82}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0638, 'learning_rate': 0.0001906542056074766, 'epoch': 3.91}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.86it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 16.01it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 14.75it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 13.80it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 13.77it/s][A
100%|██████████| 13/13 [00:00<00:00, 13.91it/s][A                                                  
                                               [A 39%|███▉      | 440/1120 [06:07<08:58,  1.26it/s]
100%|██████████| 13/13 [00:00<00:00, 13.91it/s][A
                                               [A 39%|███▉      | 441/1120 [06:08<13:14,  1.17s/it] 39%|███▉      | 442/1120 [06:09<11:48,  1.04s/it] 40%|███▉      | 443/1120 [06:10<10:47,  1.05it/s] 40%|███▉      | 444/1120 [06:11<10:05,  1.12it/s] 40%|███▉      | 445/1120 [06:12<10:15,  1.10it/s] 40%|███▉      | 446/1120 [06:12<09:40,  1.16it/s] 40%|███▉      | 447/1120 [06:13<09:16,  1.21it/s] 40%|████      | 448/1120 [06:14<09:00,  1.24it/s] 40%|████      | 449/1120 [06:15<09:33,  1.17it/s] 40%|████      | 450/1120 [06:15<09:12,  1.21it/s]                                                   40%|████      | 450/1120 [06:15<09:12,  1.21it/s] 40%|████      | 451/1120 [06:16<08:56,  1.25it/s] 40%|████      | 452/1120 [06:17<08:47,  1.27it/s] 40%|████      | 453/1120 [06:18<09:30,  1.17it/s] 41%|████      | 454/1120 [06:19<09:08,  1.21it/s] 41%|████      | 455/1120 [06:20<08:53,  1.25it/s] 41%|████      | 456/1120 [06:20<08:42,  1.27it/s] 41%|████      | 457/1120 [06:21<09:26,  1.17it/s] 41%|████      | 458/1120 [06:22<09:05,  1.21it/s] 41%|████      | 459/1120 [06:23<08:49,  1.25it/s] 41%|████      | 460/1120 [06:24<08:39,  1.27it/s]                                                   41%|████      | 460/1120 [06:24<08:39,  1.27it/s] 41%|████      | 461/1120 [06:24<09:14,  1.19it/s] 41%|████▏     | 462/1120 [06:25<08:56,  1.23it/s] 41%|████▏     | 463/1120 [06:26<08:42,  1.26it/s] 41%|████▏     | 464/1120 [06:27<08:33,  1.28it/s] 42%|████▏     | 465/1120 [06:28<09:15,  1.18it/s] 42%|████▏     | 466/1120 [06:29<08:57,  1.22it/s] 42%|████▏     | 467/1120 [06:29<08:42,  1.25it/s] 42%|████▏     | 468/1120 [06:30<08:33,  1.27it/s] 42%|████▏     | 469/1120 [06:31<09:07,  1.19it/s] 42%|████▏     | 470/1120 [06:32<08:46,  1.23it/s]                                                   42%|████▏     | 470/1120 [06:32<08:46,  1.23it/s] 42%|████▏     | 471/1120 [06:32<08:35,  1.26it/s] 42%|████▏     | 472/1120 [06:33<08:26,  1.28it/s] 42%|████▏     | 473/1120 [06:34<09:04,  1.19it/s] 42%|████▏     | 474/1120 [06:35<08:46,  1.23it/s] 42%|████▏     | 475/1120 [06:36<08:32,  1.26it/s] 42%|████▎     | 476/1120 [06:36<08:23,  1.28it/s] 43%|████▎     | 477/1120 [06:37<09:04,  1.18it/s] 43%|████▎     | 478/1120 [06:38<08:44,  1.22it/s] 43%|████▎     | 479/1120 [06:39<08:30,  1.26it/s] 43%|████▎     | 480/1120 [06:40<08:19,  1.28it/s]                                                   43%|████▎     | 480/1120 [06:40<08:19,  1.28it/s]{'eval_loss': 0.09258821606636047, 'eval_runtime': 0.9845, 'eval_samples_per_second': 101.571, 'eval_steps_per_second': 13.204, 'epoch': 3.91}
外层迭代结束！
外层迭代结束！
{'loss': 0.0485, 'learning_rate': 0.0001878504672897196, 'epoch': 4.0}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0198, 'learning_rate': 0.0001850467289719626, 'epoch': 4.09}
外层迭代结束！
外层迭代结束！
{'loss': 0.0357, 'learning_rate': 0.00018224299065420558, 'epoch': 4.18}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0143, 'learning_rate': 0.00017943925233644857, 'epoch': 4.27}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.68it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 15.89it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 14.68it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 13.79it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 13.82it/s][A
100%|██████████| 13/13 [00:00<00:00, 13.93it/s][A                                                  
                                               [A 43%|████▎     | 480/1120 [06:41<08:19,  1.28it/s]
100%|██████████| 13/13 [00:00<00:00, 13.93it/s][A
                                               [A 43%|████▎     | 481/1120 [06:42<12:32,  1.18s/it] 43%|████▎     | 482/1120 [06:43<11:10,  1.05s/it] 43%|████▎     | 483/1120 [06:43<10:12,  1.04it/s] 43%|████▎     | 484/1120 [06:44<09:33,  1.11it/s] 43%|████▎     | 485/1120 [06:45<09:47,  1.08it/s] 43%|████▎     | 486/1120 [06:46<09:13,  1.15it/s] 43%|████▎     | 487/1120 [06:47<08:51,  1.19it/s] 44%|████▎     | 488/1120 [06:47<08:35,  1.23it/s] 44%|████▎     | 489/1120 [06:48<09:03,  1.16it/s] 44%|████▍     | 490/1120 [06:49<08:43,  1.20it/s]                                                   44%|████▍     | 490/1120 [06:49<08:43,  1.20it/s] 44%|████▍     | 491/1120 [06:50<08:26,  1.24it/s] 44%|████▍     | 492/1120 [06:51<08:15,  1.27it/s] 44%|████▍     | 493/1120 [06:52<08:55,  1.17it/s] 44%|████▍     | 494/1120 [06:52<08:35,  1.21it/s] 44%|████▍     | 495/1120 [06:53<08:20,  1.25it/s] 44%|████▍     | 496/1120 [06:54<08:10,  1.27it/s] 44%|████▍     | 497/1120 [06:55<08:51,  1.17it/s] 44%|████▍     | 498/1120 [06:56<08:35,  1.21it/s] 45%|████▍     | 499/1120 [06:56<08:19,  1.24it/s] 45%|████▍     | 500/1120 [06:57<08:11,  1.26it/s]                                                   45%|████▍     | 500/1120 [06:57<08:11,  1.26it/s] 45%|████▍     | 501/1120 [06:58<08:50,  1.17it/s] 45%|████▍     | 502/1120 [06:59<08:31,  1.21it/s] 45%|████▍     | 503/1120 [07:00<08:20,  1.23it/s] 45%|████▌     | 504/1120 [07:00<08:11,  1.25it/s] 45%|████▌     | 505/1120 [07:01<08:44,  1.17it/s] 45%|████▌     | 506/1120 [07:02<08:26,  1.21it/s] 45%|████▌     | 507/1120 [07:03<08:15,  1.24it/s] 45%|████▌     | 508/1120 [07:04<08:07,  1.26it/s] 45%|████▌     | 509/1120 [07:05<08:48,  1.16it/s] 46%|████▌     | 510/1120 [07:05<08:30,  1.19it/s]                                                   46%|████▌     | 510/1120 [07:05<08:30,  1.19it/s] 46%|████▌     | 511/1120 [07:06<08:15,  1.23it/s] 46%|████▌     | 512/1120 [07:07<08:07,  1.25it/s] 46%|████▌     | 513/1120 [07:08<08:38,  1.17it/s] 46%|████▌     | 514/1120 [07:09<08:23,  1.20it/s] 46%|████▌     | 515/1120 [07:10<08:12,  1.23it/s] 46%|████▌     | 516/1120 [07:10<08:02,  1.25it/s] 46%|████▌     | 517/1120 [07:11<08:42,  1.15it/s] 46%|████▋     | 518/1120 [07:12<08:22,  1.20it/s] 46%|████▋     | 519/1120 [07:13<08:10,  1.22it/s] 46%|████▋     | 520/1120 [07:14<08:00,  1.25it/s]                                                   46%|████▋     | 520/1120 [07:14<08:00,  1.25it/s]{'eval_loss': 0.08340428024530411, 'eval_runtime': 0.9856, 'eval_samples_per_second': 101.461, 'eval_steps_per_second': 13.19, 'epoch': 4.27}
外层迭代结束！
外层迭代结束！
{'loss': 0.0461, 'learning_rate': 0.00017663551401869156, 'epoch': 4.36}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0488, 'learning_rate': 0.00017383177570093455, 'epoch': 4.44}
外层迭代结束！
外层迭代结束！
{'loss': 0.0337, 'learning_rate': 0.00017102803738317754, 'epoch': 4.53}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0469, 'learning_rate': 0.00016822429906542053, 'epoch': 4.62}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.77it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 15.78it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 14.20it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 13.47it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 13.56it/s][A
100%|██████████| 13/13 [00:00<00:00, 13.69it/s][A                                                  
                                               [A 46%|████▋     | 520/1120 [07:15<08:00,  1.25it/s]
100%|██████████| 13/13 [00:00<00:00, 13.69it/s][A
                                               [A 47%|████▋     | 521/1120 [07:16<12:02,  1.21s/it] 47%|████▋     | 522/1120 [07:17<10:40,  1.07s/it] 47%|████▋     | 523/1120 [07:17<09:43,  1.02it/s] 47%|████▋     | 524/1120 [07:18<09:03,  1.10it/s] 47%|████▋     | 525/1120 [07:19<09:14,  1.07it/s] 47%|████▋     | 526/1120 [07:20<08:41,  1.14it/s] 47%|████▋     | 527/1120 [07:21<08:17,  1.19it/s] 47%|████▋     | 528/1120 [07:21<08:01,  1.23it/s] 47%|████▋     | 529/1120 [07:22<08:34,  1.15it/s] 47%|████▋     | 530/1120 [07:23<08:13,  1.20it/s]                                                   47%|████▋     | 530/1120 [07:23<08:13,  1.20it/s] 47%|████▋     | 531/1120 [07:24<07:57,  1.23it/s] 48%|████▊     | 532/1120 [07:25<07:45,  1.26it/s] 48%|████▊     | 533/1120 [07:25<08:13,  1.19it/s] 48%|████▊     | 534/1120 [07:26<07:56,  1.23it/s] 48%|████▊     | 535/1120 [07:27<07:42,  1.26it/s] 48%|████▊     | 536/1120 [07:28<07:36,  1.28it/s] 48%|████▊     | 537/1120 [07:29<08:07,  1.20it/s] 48%|████▊     | 538/1120 [07:29<07:51,  1.23it/s] 48%|████▊     | 539/1120 [07:30<07:41,  1.26it/s] 48%|████▊     | 540/1120 [07:31<07:31,  1.28it/s]                                                   48%|████▊     | 540/1120 [07:31<07:31,  1.28it/s] 48%|████▊     | 541/1120 [07:32<08:10,  1.18it/s] 48%|████▊     | 542/1120 [07:33<07:52,  1.22it/s] 48%|████▊     | 543/1120 [07:33<07:40,  1.25it/s] 49%|████▊     | 544/1120 [07:34<07:33,  1.27it/s] 49%|████▊     | 545/1120 [07:35<08:07,  1.18it/s] 49%|████▉     | 546/1120 [07:36<07:50,  1.22it/s] 49%|████▉     | 547/1120 [07:37<07:38,  1.25it/s] 49%|████▉     | 548/1120 [07:37<07:29,  1.27it/s] 49%|████▉     | 549/1120 [07:38<08:05,  1.18it/s] 49%|████▉     | 550/1120 [07:39<07:48,  1.22it/s]                                                   49%|████▉     | 550/1120 [07:39<07:48,  1.22it/s] 49%|████▉     | 551/1120 [07:40<07:36,  1.25it/s] 49%|████▉     | 552/1120 [07:41<07:27,  1.27it/s] 49%|████▉     | 553/1120 [07:42<07:55,  1.19it/s] 49%|████▉     | 554/1120 [07:42<07:40,  1.23it/s] 50%|████▉     | 555/1120 [07:43<07:32,  1.25it/s] 50%|████▉     | 556/1120 [07:44<07:22,  1.27it/s] 50%|████▉     | 557/1120 [07:45<07:50,  1.20it/s] 50%|████▉     | 558/1120 [07:46<07:34,  1.24it/s] 50%|████▉     | 559/1120 [07:46<07:23,  1.26it/s] 50%|█████     | 560/1120 [07:47<07:14,  1.29it/s]                                                   50%|█████     | 560/1120 [07:47<07:14,  1.29it/s]{'eval_loss': 0.0768827274441719, 'eval_runtime': 1.0019, 'eval_samples_per_second': 99.808, 'eval_steps_per_second': 12.975, 'epoch': 4.62}
外层迭代结束！
外层迭代结束！
{'loss': 0.0634, 'learning_rate': 0.00016542056074766352, 'epoch': 4.71}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0554, 'learning_rate': 0.00016261682242990652, 'epoch': 4.8}
外层迭代结束！
外层迭代结束！
{'loss': 0.0114, 'learning_rate': 0.0001598130841121495, 'epoch': 4.89}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0742, 'learning_rate': 0.0001570093457943925, 'epoch': 4.98}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.81it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 15.92it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 14.68it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 13.76it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 13.79it/s][A
100%|██████████| 13/13 [00:00<00:00, 13.89it/s][A                                                  
                                               [A 50%|█████     | 560/1120 [07:48<07:14,  1.29it/s]
100%|██████████| 13/13 [00:00<00:00, 13.89it/s][A
                                               [A 50%|█████     | 561/1120 [07:49<11:01,  1.18s/it] 50%|█████     | 562/1120 [07:50<09:46,  1.05s/it] 50%|█████     | 563/1120 [07:51<08:53,  1.04it/s] 50%|█████     | 564/1120 [07:52<08:17,  1.12it/s] 50%|█████     | 565/1120 [07:53<08:58,  1.03it/s] 51%|█████     | 566/1120 [07:53<08:21,  1.11it/s] 51%|█████     | 567/1120 [07:54<07:56,  1.16it/s] 51%|█████     | 568/1120 [07:55<07:37,  1.21it/s] 51%|█████     | 569/1120 [07:56<08:00,  1.15it/s] 51%|█████     | 570/1120 [07:57<07:39,  1.20it/s]                                                   51%|█████     | 570/1120 [07:57<07:39,  1.20it/s] 51%|█████     | 571/1120 [07:57<07:24,  1.24it/s] 51%|█████     | 572/1120 [07:58<07:13,  1.26it/s] 51%|█████     | 573/1120 [07:59<07:39,  1.19it/s] 51%|█████▏    | 574/1120 [08:00<07:23,  1.23it/s] 51%|█████▏    | 575/1120 [08:01<07:11,  1.26it/s] 51%|█████▏    | 576/1120 [08:01<07:03,  1.28it/s] 52%|█████▏    | 577/1120 [08:02<07:36,  1.19it/s] 52%|█████▏    | 578/1120 [08:03<07:21,  1.23it/s] 52%|█████▏    | 579/1120 [08:04<07:11,  1.25it/s] 52%|█████▏    | 580/1120 [08:05<07:01,  1.28it/s]                                                   52%|█████▏    | 580/1120 [08:05<07:01,  1.28it/s] 52%|█████▏    | 581/1120 [08:06<07:27,  1.20it/s] 52%|█████▏    | 582/1120 [08:06<07:14,  1.24it/s] 52%|█████▏    | 583/1120 [08:07<07:02,  1.27it/s] 52%|█████▏    | 584/1120 [08:08<06:56,  1.29it/s] 52%|█████▏    | 585/1120 [08:09<07:24,  1.20it/s] 52%|█████▏    | 586/1120 [08:09<07:10,  1.24it/s] 52%|█████▏    | 587/1120 [08:10<07:00,  1.27it/s] 52%|█████▎    | 588/1120 [08:11<06:55,  1.28it/s] 53%|█████▎    | 589/1120 [08:12<07:22,  1.20it/s] 53%|█████▎    | 590/1120 [08:13<07:09,  1.23it/s]                                                   53%|█████▎    | 590/1120 [08:13<07:09,  1.23it/s] 53%|█████▎    | 591/1120 [08:13<07:01,  1.26it/s] 53%|█████▎    | 592/1120 [08:14<06:57,  1.27it/s] 53%|█████▎    | 593/1120 [08:15<07:32,  1.16it/s] 53%|█████▎    | 594/1120 [08:16<07:16,  1.20it/s] 53%|█████▎    | 595/1120 [08:17<07:04,  1.24it/s] 53%|█████▎    | 596/1120 [08:18<06:55,  1.26it/s] 53%|█████▎    | 597/1120 [08:19<07:23,  1.18it/s] 53%|█████▎    | 598/1120 [08:19<07:07,  1.22it/s] 53%|█████▎    | 599/1120 [08:20<06:56,  1.25it/s] 54%|█████▎    | 600/1120 [08:21<07:01,  1.23it/s]                                                   54%|█████▎    | 600/1120 [08:21<07:01,  1.23it/s]{'eval_loss': 0.07353218644857407, 'eval_runtime': 0.9867, 'eval_samples_per_second': 101.352, 'eval_steps_per_second': 13.176, 'epoch': 4.98}
外层迭代结束！
外层迭代结束！
{'loss': 0.0291, 'learning_rate': 0.0001542056074766355, 'epoch': 5.07}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0172, 'learning_rate': 0.00015140186915887848, 'epoch': 5.16}
外层迭代结束！
外层迭代结束！
{'loss': 0.0221, 'learning_rate': 0.00014859813084112147, 'epoch': 5.24}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0284, 'learning_rate': 0.00014579439252336446, 'epoch': 5.33}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 15.29it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 14.14it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 13.66it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 13.19it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 13.33it/s][A
100%|██████████| 13/13 [00:00<00:00, 13.54it/s][A                                                  
                                               [A 54%|█████▎    | 600/1120 [08:22<07:01,  1.23it/s]
100%|██████████| 13/13 [00:00<00:00, 13.54it/s][A
                                               [A 54%|█████▎    | 601/1120 [08:23<10:22,  1.20s/it] 54%|█████▍    | 602/1120 [08:24<09:05,  1.05s/it] 54%|█████▍    | 603/1120 [08:24<08:25,  1.02it/s] 54%|█████▍    | 604/1120 [08:25<07:41,  1.12it/s] 54%|█████▍    | 605/1120 [08:26<07:40,  1.12it/s] 54%|█████▍    | 606/1120 [08:27<07:09,  1.20it/s] 54%|█████▍    | 607/1120 [08:27<06:49,  1.25it/s] 54%|█████▍    | 608/1120 [08:28<06:33,  1.30it/s] 54%|█████▍    | 609/1120 [08:29<06:52,  1.24it/s] 54%|█████▍    | 610/1120 [08:30<06:36,  1.29it/s]                                                   54%|█████▍    | 610/1120 [08:30<06:36,  1.29it/s] 55%|█████▍    | 611/1120 [08:30<06:23,  1.33it/s] 55%|█████▍    | 612/1120 [08:31<06:16,  1.35it/s] 55%|█████▍    | 613/1120 [08:32<06:39,  1.27it/s] 55%|█████▍    | 614/1120 [08:33<06:24,  1.32it/s] 55%|█████▍    | 615/1120 [08:33<06:13,  1.35it/s] 55%|█████▌    | 616/1120 [08:34<06:07,  1.37it/s] 55%|█████▌    | 617/1120 [08:35<06:35,  1.27it/s] 55%|█████▌    | 618/1120 [08:36<06:22,  1.31it/s] 55%|█████▌    | 619/1120 [08:37<06:11,  1.35it/s] 55%|█████▌    | 620/1120 [08:37<06:03,  1.38it/s]                                                   55%|█████▌    | 620/1120 [08:37<06:03,  1.38it/s] 55%|█████▌    | 621/1120 [08:38<06:29,  1.28it/s] 56%|█████▌    | 622/1120 [08:39<06:14,  1.33it/s] 56%|█████▌    | 623/1120 [08:40<06:11,  1.34it/s] 56%|█████▌    | 624/1120 [08:40<06:10,  1.34it/s] 56%|█████▌    | 625/1120 [08:41<06:33,  1.26it/s] 56%|█████▌    | 626/1120 [08:42<06:18,  1.31it/s] 56%|█████▌    | 627/1120 [08:43<06:05,  1.35it/s] 56%|█████▌    | 628/1120 [08:43<05:57,  1.38it/s] 56%|█████▌    | 629/1120 [08:44<06:21,  1.29it/s] 56%|█████▋    | 630/1120 [08:45<06:07,  1.33it/s]                                                   56%|█████▋    | 630/1120 [08:45<06:07,  1.33it/s] 56%|█████▋    | 631/1120 [08:46<05:58,  1.36it/s] 56%|█████▋    | 632/1120 [08:46<05:51,  1.39it/s] 57%|█████▋    | 633/1120 [08:47<06:15,  1.30it/s] 57%|█████▋    | 634/1120 [08:48<06:05,  1.33it/s] 57%|█████▋    | 635/1120 [08:49<05:56,  1.36it/s] 57%|█████▋    | 636/1120 [08:49<05:49,  1.39it/s] 57%|█████▋    | 637/1120 [08:50<06:12,  1.30it/s] 57%|█████▋    | 638/1120 [08:51<05:59,  1.34it/s] 57%|█████▋    | 639/1120 [08:51<05:52,  1.37it/s] 57%|█████▋    | 640/1120 [08:52<05:48,  1.38it/s]                                                   57%|█████▋    | 640/1120 [08:52<05:48,  1.38it/s]{'eval_loss': 0.0797237753868103, 'eval_runtime': 1.0403, 'eval_samples_per_second': 96.124, 'eval_steps_per_second': 12.496, 'epoch': 5.33}
外层迭代结束！
外层迭代结束！
{'loss': 0.0133, 'learning_rate': 0.00014299065420560745, 'epoch': 5.42}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0502, 'learning_rate': 0.00014018691588785044, 'epoch': 5.51}
外层迭代结束！
外层迭代结束！
{'loss': 0.029, 'learning_rate': 0.00013738317757009343, 'epoch': 5.6}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0329, 'learning_rate': 0.00013457943925233642, 'epoch': 5.69}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.67it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.70it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 14.94it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.36it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.45it/s][A                                                  
                                               [A 57%|█████▋    | 640/1120 [08:53<05:48,  1.38it/s]
100%|██████████| 13/13 [00:00<00:00, 14.45it/s][A
                                               [A 57%|█████▋    | 641/1120 [08:54<08:52,  1.11s/it] 57%|█████▋    | 642/1120 [08:55<07:51,  1.01it/s] 57%|█████▋    | 643/1120 [08:56<07:07,  1.11it/s] 57%|█████▊    | 644/1120 [08:56<06:40,  1.19it/s] 58%|█████▊    | 645/1120 [08:57<06:51,  1.15it/s] 58%|█████▊    | 646/1120 [08:58<06:26,  1.23it/s] 58%|█████▊    | 647/1120 [08:59<06:07,  1.29it/s] 58%|█████▊    | 648/1120 [08:59<05:56,  1.32it/s] 58%|█████▊    | 649/1120 [09:00<06:13,  1.26it/s] 58%|█████▊    | 650/1120 [09:01<05:58,  1.31it/s]                                                   58%|█████▊    | 650/1120 [09:01<05:58,  1.31it/s] 58%|█████▊    | 651/1120 [09:02<05:48,  1.34it/s] 58%|█████▊    | 652/1120 [09:02<05:42,  1.37it/s] 58%|█████▊    | 653/1120 [09:03<06:04,  1.28it/s] 58%|█████▊    | 654/1120 [09:04<05:51,  1.32it/s] 58%|█████▊    | 655/1120 [09:05<05:43,  1.36it/s] 59%|█████▊    | 656/1120 [09:05<05:35,  1.38it/s] 59%|█████▊    | 657/1120 [09:06<06:04,  1.27it/s] 59%|█████▉    | 658/1120 [09:07<05:50,  1.32it/s] 59%|█████▉    | 659/1120 [09:08<05:40,  1.35it/s] 59%|█████▉    | 660/1120 [09:08<05:34,  1.38it/s]                                                   59%|█████▉    | 660/1120 [09:08<05:34,  1.38it/s] 59%|█████▉    | 661/1120 [09:09<05:57,  1.29it/s] 59%|█████▉    | 662/1120 [09:10<05:44,  1.33it/s] 59%|█████▉    | 663/1120 [09:11<05:35,  1.36it/s] 59%|█████▉    | 664/1120 [09:11<05:29,  1.38it/s] 59%|█████▉    | 665/1120 [09:12<05:50,  1.30it/s] 59%|█████▉    | 666/1120 [09:13<05:43,  1.32it/s] 60%|█████▉    | 667/1120 [09:14<05:34,  1.36it/s] 60%|█████▉    | 668/1120 [09:14<05:28,  1.38it/s] 60%|█████▉    | 669/1120 [09:15<05:53,  1.28it/s] 60%|█████▉    | 670/1120 [09:16<05:42,  1.32it/s]                                                   60%|█████▉    | 670/1120 [09:16<05:42,  1.32it/s] 60%|█████▉    | 671/1120 [09:17<05:31,  1.35it/s] 60%|██████    | 672/1120 [09:17<05:24,  1.38it/s] 60%|██████    | 673/1120 [09:18<05:48,  1.28it/s] 60%|██████    | 674/1120 [09:19<05:36,  1.33it/s] 60%|██████    | 675/1120 [09:20<05:27,  1.36it/s] 60%|██████    | 676/1120 [09:20<05:20,  1.38it/s] 60%|██████    | 677/1120 [09:21<05:42,  1.29it/s] 61%|██████    | 678/1120 [09:22<05:32,  1.33it/s] 61%|██████    | 679/1120 [09:23<05:23,  1.36it/s] 61%|██████    | 680/1120 [09:23<05:18,  1.38it/s]                                                   61%|██████    | 680/1120 [09:23<05:18,  1.38it/s]{'eval_loss': 0.07404603809118271, 'eval_runtime': 0.9496, 'eval_samples_per_second': 105.305, 'eval_steps_per_second': 13.69, 'epoch': 5.69}
外层迭代结束！
外层迭代结束！
{'loss': 0.0428, 'learning_rate': 0.0001317757009345794, 'epoch': 5.78}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.04, 'learning_rate': 0.0001289719626168224, 'epoch': 5.87}
外层迭代结束！
外层迭代结束！
{'loss': 0.0147, 'learning_rate': 0.0001261682242990654, 'epoch': 5.96}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0206, 'learning_rate': 0.00012336448598130838, 'epoch': 6.04}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.56it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.67it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 14.93it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.38it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.45it/s][A                                                  
                                               [A 61%|██████    | 680/1120 [09:24<05:18,  1.38it/s]
100%|██████████| 13/13 [00:00<00:00, 14.45it/s][A
                                               [A 61%|██████    | 681/1120 [09:25<08:03,  1.10s/it] 61%|██████    | 682/1120 [09:26<07:08,  1.02it/s] 61%|██████    | 683/1120 [09:27<06:29,  1.12it/s] 61%|██████    | 684/1120 [09:27<06:02,  1.20it/s] 61%|██████    | 685/1120 [09:28<06:15,  1.16it/s] 61%|██████▏   | 686/1120 [09:29<05:52,  1.23it/s] 61%|██████▏   | 687/1120 [09:30<05:36,  1.29it/s] 61%|██████▏   | 688/1120 [09:30<05:25,  1.33it/s] 62%|██████▏   | 689/1120 [09:31<05:48,  1.24it/s] 62%|██████▏   | 690/1120 [09:32<05:33,  1.29it/s]                                                   62%|██████▏   | 690/1120 [09:32<05:33,  1.29it/s] 62%|██████▏   | 691/1120 [09:33<05:21,  1.33it/s] 62%|██████▏   | 692/1120 [09:33<05:13,  1.37it/s] 62%|██████▏   | 693/1120 [09:34<05:33,  1.28it/s] 62%|██████▏   | 694/1120 [09:35<05:24,  1.31it/s] 62%|██████▏   | 695/1120 [09:36<05:17,  1.34it/s] 62%|██████▏   | 696/1120 [09:36<05:09,  1.37it/s] 62%|██████▏   | 697/1120 [09:37<05:38,  1.25it/s] 62%|██████▏   | 698/1120 [09:38<05:25,  1.30it/s] 62%|██████▏   | 699/1120 [09:39<05:18,  1.32it/s] 62%|██████▎   | 700/1120 [09:39<05:12,  1.34it/s]                                                   62%|██████▎   | 700/1120 [09:40<05:12,  1.34it/s] 63%|██████▎   | 701/1120 [09:40<05:30,  1.27it/s] 63%|██████▎   | 702/1120 [09:41<05:21,  1.30it/s] 63%|██████▎   | 703/1120 [09:42<05:13,  1.33it/s] 63%|██████▎   | 704/1120 [09:42<05:06,  1.36it/s] 63%|██████▎   | 705/1120 [09:43<05:33,  1.24it/s] 63%|██████▎   | 706/1120 [09:44<05:20,  1.29it/s] 63%|██████▎   | 707/1120 [09:45<05:14,  1.31it/s] 63%|██████▎   | 708/1120 [09:46<05:08,  1.34it/s] 63%|██████▎   | 709/1120 [09:47<05:50,  1.17it/s] 63%|██████▎   | 710/1120 [09:47<05:33,  1.23it/s]                                                   63%|██████▎   | 710/1120 [09:47<05:33,  1.23it/s] 63%|██████▎   | 711/1120 [09:48<05:21,  1.27it/s] 64%|██████▎   | 712/1120 [09:49<05:14,  1.30it/s] 64%|██████▎   | 713/1120 [09:50<05:32,  1.22it/s] 64%|██████▍   | 714/1120 [09:51<05:18,  1.27it/s] 64%|██████▍   | 715/1120 [09:51<05:08,  1.31it/s] 64%|██████▍   | 716/1120 [09:52<05:02,  1.33it/s] 64%|██████▍   | 717/1120 [09:53<05:26,  1.23it/s] 64%|██████▍   | 718/1120 [09:54<05:15,  1.27it/s] 64%|██████▍   | 719/1120 [09:54<05:07,  1.31it/s] 64%|██████▍   | 720/1120 [09:55<05:01,  1.33it/s]                                                   64%|██████▍   | 720/1120 [09:55<05:01,  1.33it/s]{'eval_loss': 0.08108244836330414, 'eval_runtime': 0.9501, 'eval_samples_per_second': 105.25, 'eval_steps_per_second': 13.683, 'epoch': 6.04}
外层迭代结束！
外层迭代结束！
{'loss': 0.0031, 'learning_rate': 0.00012056074766355139, 'epoch': 6.13}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.02, 'learning_rate': 0.00011775700934579438, 'epoch': 6.22}
外层迭代结束！
外层迭代结束！
{'loss': 0.0013, 'learning_rate': 0.00011495327102803737, 'epoch': 6.31}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0089, 'learning_rate': 0.00011214953271028036, 'epoch': 6.4}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.02it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.52it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 14.84it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.33it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.44it/s][A                                                  
                                               [A 64%|██████▍   | 720/1120 [09:56<05:01,  1.33it/s]
100%|██████████| 13/13 [00:00<00:00, 14.44it/s][A
                                               [A 64%|██████▍   | 721/1120 [09:57<07:33,  1.14s/it] 64%|██████▍   | 722/1120 [09:58<06:44,  1.02s/it] 65%|██████▍   | 723/1120 [09:59<06:06,  1.08it/s] 65%|██████▍   | 724/1120 [09:59<05:40,  1.16it/s] 65%|██████▍   | 725/1120 [10:00<05:43,  1.15it/s] 65%|██████▍   | 726/1120 [10:01<05:23,  1.22it/s] 65%|██████▍   | 727/1120 [10:02<05:09,  1.27it/s] 65%|██████▌   | 728/1120 [10:02<04:58,  1.31it/s] 65%|██████▌   | 729/1120 [10:03<05:14,  1.24it/s] 65%|██████▌   | 730/1120 [10:04<05:04,  1.28it/s]                                                   65%|██████▌   | 730/1120 [10:04<05:04,  1.28it/s] 65%|██████▌   | 731/1120 [10:05<04:55,  1.32it/s] 65%|██████▌   | 732/1120 [10:05<04:49,  1.34it/s] 65%|██████▌   | 733/1120 [10:06<05:12,  1.24it/s] 66%|██████▌   | 734/1120 [10:07<04:59,  1.29it/s] 66%|██████▌   | 735/1120 [10:08<04:49,  1.33it/s] 66%|██████▌   | 736/1120 [10:08<04:42,  1.36it/s] 66%|██████▌   | 737/1120 [10:09<05:00,  1.27it/s] 66%|██████▌   | 738/1120 [10:10<04:49,  1.32it/s] 66%|██████▌   | 739/1120 [10:11<04:42,  1.35it/s] 66%|██████▌   | 740/1120 [10:11<04:36,  1.37it/s]                                                   66%|██████▌   | 740/1120 [10:12<04:36,  1.37it/s] 66%|██████▌   | 741/1120 [10:12<04:56,  1.28it/s] 66%|██████▋   | 742/1120 [10:13<04:48,  1.31it/s] 66%|██████▋   | 743/1120 [10:14<04:42,  1.33it/s] 66%|██████▋   | 744/1120 [10:14<04:37,  1.35it/s] 67%|██████▋   | 745/1120 [10:15<05:01,  1.24it/s] 67%|██████▋   | 746/1120 [10:16<04:50,  1.29it/s] 67%|██████▋   | 747/1120 [10:17<04:39,  1.33it/s] 67%|██████▋   | 748/1120 [10:17<04:32,  1.36it/s] 67%|██████▋   | 749/1120 [10:18<04:50,  1.28it/s] 67%|██████▋   | 750/1120 [10:19<04:39,  1.33it/s]                                                   67%|██████▋   | 750/1120 [10:19<04:39,  1.33it/s] 67%|██████▋   | 751/1120 [10:20<04:31,  1.36it/s] 67%|██████▋   | 752/1120 [10:20<04:26,  1.38it/s] 67%|██████▋   | 753/1120 [10:21<04:46,  1.28it/s] 67%|██████▋   | 754/1120 [10:22<04:35,  1.33it/s] 67%|██████▋   | 755/1120 [10:23<04:27,  1.36it/s] 68%|██████▊   | 756/1120 [10:23<04:22,  1.39it/s] 68%|██████▊   | 757/1120 [10:24<04:45,  1.27it/s] 68%|██████▊   | 758/1120 [10:25<04:34,  1.32it/s] 68%|██████▊   | 759/1120 [10:26<04:27,  1.35it/s] 68%|██████▊   | 760/1120 [10:26<04:21,  1.38it/s]                                                   68%|██████▊   | 760/1120 [10:27<04:21,  1.38it/s]{'eval_loss': 0.08753755688667297, 'eval_runtime': 0.9552, 'eval_samples_per_second': 104.685, 'eval_steps_per_second': 13.609, 'epoch': 6.4}
外层迭代结束！
外层迭代结束！
{'loss': 0.0025, 'learning_rate': 0.00010934579439252335, 'epoch': 6.49}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.008, 'learning_rate': 0.00010654205607476634, 'epoch': 6.58}
外层迭代结束！
外层迭代结束！
{'loss': 0.0046, 'learning_rate': 0.00010373831775700933, 'epoch': 6.67}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0261, 'learning_rate': 0.00010093457943925232, 'epoch': 6.76}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.59it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.68it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 14.92it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.33it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.43it/s][A                                                  
                                               [A 68%|██████▊   | 760/1120 [10:28<04:21,  1.38it/s]
100%|██████████| 13/13 [00:00<00:00, 14.43it/s][A
                                               [A 68%|██████▊   | 761/1120 [10:28<06:39,  1.11s/it] 68%|██████▊   | 762/1120 [10:29<05:53,  1.01it/s] 68%|██████▊   | 763/1120 [10:30<05:22,  1.11it/s] 68%|██████▊   | 764/1120 [10:31<04:58,  1.19it/s] 68%|██████▊   | 765/1120 [10:31<05:05,  1.16it/s] 68%|██████▊   | 766/1120 [10:32<04:47,  1.23it/s] 68%|██████▊   | 767/1120 [10:33<04:34,  1.28it/s] 69%|██████▊   | 768/1120 [10:34<04:26,  1.32it/s] 69%|██████▊   | 769/1120 [10:35<04:59,  1.17it/s] 69%|██████▉   | 770/1120 [10:35<04:41,  1.24it/s]                                                   69%|██████▉   | 770/1120 [10:35<04:41,  1.24it/s] 69%|██████▉   | 771/1120 [10:36<04:30,  1.29it/s] 69%|██████▉   | 772/1120 [10:37<04:21,  1.33it/s] 69%|██████▉   | 773/1120 [10:38<04:43,  1.22it/s] 69%|██████▉   | 774/1120 [10:38<04:29,  1.28it/s] 69%|██████▉   | 775/1120 [10:39<04:20,  1.33it/s] 69%|██████▉   | 776/1120 [10:40<04:12,  1.36it/s] 69%|██████▉   | 777/1120 [10:41<04:32,  1.26it/s] 69%|██████▉   | 778/1120 [10:41<04:21,  1.31it/s] 70%|██████▉   | 779/1120 [10:42<04:15,  1.34it/s] 70%|██████▉   | 780/1120 [10:43<04:09,  1.36it/s]                                                   70%|██████▉   | 780/1120 [10:43<04:09,  1.36it/s] 70%|██████▉   | 781/1120 [10:44<04:26,  1.27it/s] 70%|██████▉   | 782/1120 [10:44<04:17,  1.31it/s] 70%|██████▉   | 783/1120 [10:45<04:10,  1.35it/s] 70%|███████   | 784/1120 [10:46<04:05,  1.37it/s] 70%|███████   | 785/1120 [10:47<04:40,  1.20it/s] 70%|███████   | 786/1120 [10:48<04:24,  1.26it/s] 70%|███████   | 787/1120 [10:48<04:14,  1.31it/s] 70%|███████   | 788/1120 [10:49<04:06,  1.35it/s] 70%|███████   | 789/1120 [10:50<04:24,  1.25it/s] 71%|███████   | 790/1120 [10:51<04:14,  1.30it/s]                                                   71%|███████   | 790/1120 [10:51<04:14,  1.30it/s] 71%|███████   | 791/1120 [10:51<04:05,  1.34it/s] 71%|███████   | 792/1120 [10:52<04:03,  1.35it/s] 71%|███████   | 793/1120 [10:53<04:21,  1.25it/s] 71%|███████   | 794/1120 [10:54<04:15,  1.28it/s] 71%|███████   | 795/1120 [10:54<04:11,  1.29it/s] 71%|███████   | 796/1120 [10:55<04:06,  1.31it/s] 71%|███████   | 797/1120 [10:56<04:23,  1.23it/s] 71%|███████▏  | 798/1120 [10:57<04:14,  1.27it/s] 71%|███████▏  | 799/1120 [10:58<04:08,  1.29it/s] 71%|███████▏  | 800/1120 [10:58<04:04,  1.31it/s]                                                   71%|███████▏  | 800/1120 [10:59<04:04,  1.31it/s]{'eval_loss': 0.09374084323644638, 'eval_runtime': 0.9511, 'eval_samples_per_second': 105.144, 'eval_steps_per_second': 13.669, 'epoch': 6.76}
外层迭代结束！
外层迭代结束！
{'loss': 0.0029, 'learning_rate': 9.813084112149531e-05, 'epoch': 6.84}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0229, 'learning_rate': 9.53271028037383e-05, 'epoch': 6.93}
外层迭代结束！
外层迭代结束！
{'loss': 0.0029, 'learning_rate': 9.25233644859813e-05, 'epoch': 7.02}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0063, 'learning_rate': 8.971962616822429e-05, 'epoch': 7.11}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.46it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.65it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 14.80it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.23it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.34it/s][A                                                  
                                               [A 71%|███████▏  | 800/1120 [11:00<04:04,  1.31it/s]
100%|██████████| 13/13 [00:00<00:00, 14.34it/s][A
                                               [A 72%|███████▏  | 801/1120 [11:00<06:10,  1.16s/it] 72%|███████▏  | 802/1120 [11:01<05:29,  1.03s/it] 72%|███████▏  | 803/1120 [11:02<05:00,  1.05it/s] 72%|███████▏  | 804/1120 [11:03<04:41,  1.12it/s] 72%|███████▏  | 805/1120 [11:04<04:47,  1.10it/s] 72%|███████▏  | 806/1120 [11:04<04:29,  1.16it/s] 72%|███████▏  | 807/1120 [11:05<04:17,  1.22it/s] 72%|███████▏  | 808/1120 [11:06<04:07,  1.26it/s] 72%|███████▏  | 809/1120 [11:07<04:24,  1.18it/s] 72%|███████▏  | 810/1120 [11:08<04:12,  1.23it/s]                                                   72%|███████▏  | 810/1120 [11:08<04:12,  1.23it/s] 72%|███████▏  | 811/1120 [11:08<04:03,  1.27it/s] 72%|███████▎  | 812/1120 [11:09<03:56,  1.30it/s] 73%|███████▎  | 813/1120 [11:10<04:12,  1.21it/s] 73%|███████▎  | 814/1120 [11:11<04:00,  1.27it/s] 73%|███████▎  | 815/1120 [11:11<03:52,  1.31it/s] 73%|███████▎  | 816/1120 [11:12<03:45,  1.35it/s] 73%|███████▎  | 817/1120 [11:13<03:59,  1.27it/s] 73%|███████▎  | 818/1120 [11:14<03:50,  1.31it/s] 73%|███████▎  | 819/1120 [11:14<03:44,  1.34it/s] 73%|███████▎  | 820/1120 [11:15<03:42,  1.35it/s]                                                   73%|███████▎  | 820/1120 [11:15<03:42,  1.35it/s] 73%|███████▎  | 821/1120 [11:16<04:01,  1.24it/s] 73%|███████▎  | 822/1120 [11:17<03:50,  1.30it/s] 73%|███████▎  | 823/1120 [11:17<03:42,  1.33it/s] 74%|███████▎  | 824/1120 [11:18<03:38,  1.35it/s] 74%|███████▎  | 825/1120 [11:19<03:52,  1.27it/s] 74%|███████▍  | 826/1120 [11:20<03:44,  1.31it/s] 74%|███████▍  | 827/1120 [11:21<03:39,  1.33it/s] 74%|███████▍  | 828/1120 [11:21<03:36,  1.35it/s] 74%|███████▍  | 829/1120 [11:22<03:49,  1.27it/s] 74%|███████▍  | 830/1120 [11:23<03:41,  1.31it/s]                                                   74%|███████▍  | 830/1120 [11:23<03:41,  1.31it/s] 74%|███████▍  | 831/1120 [11:24<03:36,  1.34it/s] 74%|███████▍  | 832/1120 [11:24<03:32,  1.36it/s] 74%|███████▍  | 833/1120 [11:25<03:47,  1.26it/s] 74%|███████▍  | 834/1120 [11:26<03:38,  1.31it/s] 75%|███████▍  | 835/1120 [11:27<03:32,  1.34it/s] 75%|███████▍  | 836/1120 [11:27<03:27,  1.37it/s] 75%|███████▍  | 837/1120 [11:28<03:45,  1.25it/s] 75%|███████▍  | 838/1120 [11:29<03:36,  1.30it/s] 75%|███████▍  | 839/1120 [11:30<03:30,  1.33it/s] 75%|███████▌  | 840/1120 [11:30<03:26,  1.35it/s]                                                   75%|███████▌  | 840/1120 [11:31<03:26,  1.35it/s]{'eval_loss': 0.08971317112445831, 'eval_runtime': 0.9559, 'eval_samples_per_second': 104.612, 'eval_steps_per_second': 13.6, 'epoch': 7.11}
外层迭代结束！
外层迭代结束！
{'loss': 0.0111, 'learning_rate': 8.691588785046728e-05, 'epoch': 7.2}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0633, 'learning_rate': 8.411214953271027e-05, 'epoch': 7.29}
外层迭代结束！
外层迭代结束！
{'loss': 0.015, 'learning_rate': 8.130841121495326e-05, 'epoch': 7.38}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0062, 'learning_rate': 7.850467289719625e-05, 'epoch': 7.47}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.56it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.57it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 14.85it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.28it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.25it/s][A                                                  
                                               [A 75%|███████▌  | 840/1120 [11:32<03:26,  1.35it/s]
100%|██████████| 13/13 [00:00<00:00, 14.25it/s][A
                                               [A 75%|███████▌  | 841/1120 [11:32<05:16,  1.13s/it] 75%|███████▌  | 842/1120 [11:33<04:39,  1.01s/it] 75%|███████▌  | 843/1120 [11:34<04:15,  1.08it/s] 75%|███████▌  | 844/1120 [11:35<03:56,  1.17it/s] 75%|███████▌  | 845/1120 [11:36<04:03,  1.13it/s] 76%|███████▌  | 846/1120 [11:36<03:47,  1.20it/s] 76%|███████▌  | 847/1120 [11:37<03:36,  1.26it/s] 76%|███████▌  | 848/1120 [11:38<03:28,  1.31it/s] 76%|███████▌  | 849/1120 [11:39<03:41,  1.22it/s] 76%|███████▌  | 850/1120 [11:39<03:31,  1.28it/s]                                                   76%|███████▌  | 850/1120 [11:39<03:31,  1.28it/s] 76%|███████▌  | 851/1120 [11:40<03:24,  1.32it/s] 76%|███████▌  | 852/1120 [11:41<03:17,  1.35it/s] 76%|███████▌  | 853/1120 [11:42<03:33,  1.25it/s] 76%|███████▋  | 854/1120 [11:42<03:24,  1.30it/s] 76%|███████▋  | 855/1120 [11:43<03:17,  1.34it/s] 76%|███████▋  | 856/1120 [11:44<03:12,  1.37it/s] 77%|███████▋  | 857/1120 [11:45<03:26,  1.28it/s] 77%|███████▋  | 858/1120 [11:45<03:17,  1.32it/s] 77%|███████▋  | 859/1120 [11:46<03:12,  1.35it/s] 77%|███████▋  | 860/1120 [11:47<03:08,  1.38it/s]                                                   77%|███████▋  | 860/1120 [11:47<03:08,  1.38it/s] 77%|███████▋  | 861/1120 [11:48<03:24,  1.27it/s] 77%|███████▋  | 862/1120 [11:48<03:16,  1.32it/s] 77%|███████▋  | 863/1120 [11:49<03:10,  1.35it/s] 77%|███████▋  | 864/1120 [11:50<03:06,  1.38it/s] 77%|███████▋  | 865/1120 [11:51<03:21,  1.27it/s] 77%|███████▋  | 866/1120 [11:51<03:12,  1.32it/s] 77%|███████▋  | 867/1120 [11:52<03:08,  1.35it/s] 78%|███████▊  | 868/1120 [11:53<03:03,  1.37it/s] 78%|███████▊  | 869/1120 [11:54<03:14,  1.29it/s] 78%|███████▊  | 870/1120 [11:54<03:10,  1.32it/s]                                                   78%|███████▊  | 870/1120 [11:54<03:10,  1.32it/s] 78%|███████▊  | 871/1120 [11:55<03:04,  1.35it/s] 78%|███████▊  | 872/1120 [11:56<03:00,  1.38it/s] 78%|███████▊  | 873/1120 [11:57<03:13,  1.28it/s] 78%|███████▊  | 874/1120 [11:57<03:06,  1.32it/s] 78%|███████▊  | 875/1120 [11:58<03:02,  1.35it/s] 78%|███████▊  | 876/1120 [11:59<02:58,  1.37it/s] 78%|███████▊  | 877/1120 [12:00<03:09,  1.29it/s] 78%|███████▊  | 878/1120 [12:00<03:02,  1.33it/s] 78%|███████▊  | 879/1120 [12:01<02:57,  1.36it/s] 79%|███████▊  | 880/1120 [12:02<02:53,  1.39it/s]                                                   79%|███████▊  | 880/1120 [12:02<02:53,  1.39it/s]{'eval_loss': 0.08700259029865265, 'eval_runtime': 0.9592, 'eval_samples_per_second': 104.259, 'eval_steps_per_second': 13.554, 'epoch': 7.47}
外层迭代结束！
外层迭代结束！
{'loss': 0.0128, 'learning_rate': 7.570093457943924e-05, 'epoch': 7.56}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0057, 'learning_rate': 7.289719626168223e-05, 'epoch': 7.64}
外层迭代结束！
外层迭代结束！
{'loss': 0.0076, 'learning_rate': 7.009345794392522e-05, 'epoch': 7.73}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0444, 'learning_rate': 6.728971962616821e-05, 'epoch': 7.82}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.50it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.67it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 14.92it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.40it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.50it/s][A                                                  
                                               [A 79%|███████▊  | 880/1120 [12:03<02:53,  1.39it/s]
100%|██████████| 13/13 [00:00<00:00, 14.50it/s][A
                                               [A 79%|███████▊  | 881/1120 [12:04<04:24,  1.11s/it] 79%|███████▉  | 882/1120 [12:04<03:54,  1.01it/s] 79%|███████▉  | 883/1120 [12:05<03:32,  1.12it/s] 79%|███████▉  | 884/1120 [12:06<03:18,  1.19it/s] 79%|███████▉  | 885/1120 [12:07<03:21,  1.17it/s] 79%|███████▉  | 886/1120 [12:07<03:08,  1.24it/s] 79%|███████▉  | 887/1120 [12:08<03:00,  1.29it/s] 79%|███████▉  | 888/1120 [12:09<02:54,  1.33it/s] 79%|███████▉  | 889/1120 [12:10<03:06,  1.24it/s] 79%|███████▉  | 890/1120 [12:10<02:58,  1.29it/s]                                                   79%|███████▉  | 890/1120 [12:10<02:58,  1.29it/s] 80%|███████▉  | 891/1120 [12:11<02:52,  1.33it/s] 80%|███████▉  | 892/1120 [12:12<02:49,  1.35it/s] 80%|███████▉  | 893/1120 [12:13<02:59,  1.26it/s] 80%|███████▉  | 894/1120 [12:13<02:53,  1.30it/s] 80%|███████▉  | 895/1120 [12:14<02:51,  1.31it/s] 80%|████████  | 896/1120 [12:15<02:47,  1.34it/s] 80%|████████  | 897/1120 [12:16<02:59,  1.24it/s] 80%|████████  | 898/1120 [12:17<02:52,  1.29it/s] 80%|████████  | 899/1120 [12:17<02:46,  1.33it/s] 80%|████████  | 900/1120 [12:18<02:44,  1.34it/s]                                                   80%|████████  | 900/1120 [12:18<02:44,  1.34it/s] 80%|████████  | 901/1120 [12:19<02:54,  1.25it/s] 81%|████████  | 902/1120 [12:20<02:48,  1.30it/s] 81%|████████  | 903/1120 [12:20<02:44,  1.32it/s] 81%|████████  | 904/1120 [12:21<02:40,  1.35it/s] 81%|████████  | 905/1120 [12:22<03:02,  1.17it/s] 81%|████████  | 906/1120 [12:23<02:53,  1.24it/s] 81%|████████  | 907/1120 [12:24<02:45,  1.28it/s] 81%|████████  | 908/1120 [12:24<02:41,  1.31it/s] 81%|████████  | 909/1120 [12:25<03:02,  1.16it/s] 81%|████████▏ | 910/1120 [12:26<02:52,  1.22it/s]                                                   81%|████████▏ | 910/1120 [12:26<02:52,  1.22it/s] 81%|████████▏ | 911/1120 [12:27<02:45,  1.27it/s] 81%|████████▏ | 912/1120 [12:28<02:39,  1.30it/s] 82%|████████▏ | 913/1120 [12:29<02:49,  1.22it/s] 82%|████████▏ | 914/1120 [12:29<02:40,  1.28it/s] 82%|████████▏ | 915/1120 [12:30<02:37,  1.30it/s] 82%|████████▏ | 916/1120 [12:31<02:33,  1.33it/s] 82%|████████▏ | 917/1120 [12:32<02:57,  1.15it/s] 82%|████████▏ | 918/1120 [12:33<02:46,  1.21it/s] 82%|████████▏ | 919/1120 [12:33<02:37,  1.27it/s] 82%|████████▏ | 920/1120 [12:34<02:34,  1.30it/s]                                                   82%|████████▏ | 920/1120 [12:34<02:34,  1.30it/s]{'eval_loss': 0.1136048212647438, 'eval_runtime': 0.9474, 'eval_samples_per_second': 105.547, 'eval_steps_per_second': 13.721, 'epoch': 7.82}
外层迭代结束！
外层迭代结束！
{'loss': 0.0171, 'learning_rate': 6.44859813084112e-05, 'epoch': 7.91}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0014, 'learning_rate': 6.168224299065419e-05, 'epoch': 8.0}
外层迭代结束！
外层迭代结束！
{'loss': 0.0189, 'learning_rate': 5.887850467289719e-05, 'epoch': 8.09}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0062, 'learning_rate': 5.607476635514018e-05, 'epoch': 8.18}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.74it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 16.10it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 14.99it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 14.04it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 14.20it/s][A
100%|██████████| 13/13 [00:00<00:00, 14.50it/s][A                                                  
                                               [A 82%|████████▏ | 920/1120 [12:35<02:34,  1.30it/s]
100%|██████████| 13/13 [00:00<00:00, 14.50it/s][A
                                               [A 82%|████████▏ | 921/1120 [12:36<03:48,  1.15s/it] 82%|████████▏ | 922/1120 [12:37<03:22,  1.02s/it] 82%|████████▏ | 923/1120 [12:37<03:03,  1.07it/s] 82%|████████▎ | 924/1120 [12:38<02:50,  1.15it/s] 83%|████████▎ | 925/1120 [12:39<02:51,  1.14it/s] 83%|████████▎ | 926/1120 [12:40<02:42,  1.20it/s] 83%|████████▎ | 927/1120 [12:41<02:35,  1.24it/s] 83%|████████▎ | 928/1120 [12:41<02:28,  1.29it/s] 83%|████████▎ | 929/1120 [12:42<02:39,  1.20it/s] 83%|████████▎ | 930/1120 [12:43<02:32,  1.25it/s]                                                   83%|████████▎ | 930/1120 [12:43<02:32,  1.25it/s] 83%|████████▎ | 931/1120 [12:44<02:26,  1.29it/s] 83%|████████▎ | 932/1120 [12:44<02:23,  1.31it/s] 83%|████████▎ | 933/1120 [12:45<02:31,  1.24it/s] 83%|████████▎ | 934/1120 [12:46<02:27,  1.26it/s] 83%|████████▎ | 935/1120 [12:47<02:22,  1.30it/s] 84%|████████▎ | 936/1120 [12:47<02:17,  1.33it/s] 84%|████████▎ | 937/1120 [12:48<02:27,  1.24it/s] 84%|████████▍ | 938/1120 [12:49<02:21,  1.28it/s] 84%|████████▍ | 939/1120 [12:50<02:18,  1.31it/s] 84%|████████▍ | 940/1120 [12:51<02:15,  1.33it/s]                                                   84%|████████▍ | 940/1120 [12:51<02:15,  1.33it/s] 84%|████████▍ | 941/1120 [12:51<02:22,  1.26it/s] 84%|████████▍ | 942/1120 [12:52<02:18,  1.29it/s] 84%|████████▍ | 943/1120 [12:53<02:14,  1.32it/s] 84%|████████▍ | 944/1120 [12:54<02:11,  1.34it/s] 84%|████████▍ | 945/1120 [12:55<02:22,  1.23it/s] 84%|████████▍ | 946/1120 [12:55<02:16,  1.27it/s] 85%|████████▍ | 947/1120 [12:56<02:12,  1.31it/s] 85%|████████▍ | 948/1120 [12:57<02:09,  1.33it/s] 85%|████████▍ | 949/1120 [12:58<02:19,  1.23it/s] 85%|████████▍ | 950/1120 [12:58<02:13,  1.27it/s]                                                   85%|████████▍ | 950/1120 [12:58<02:13,  1.27it/s] 85%|████████▍ | 951/1120 [12:59<02:08,  1.31it/s] 85%|████████▌ | 952/1120 [13:00<02:05,  1.34it/s] 85%|████████▌ | 953/1120 [13:01<02:16,  1.23it/s] 85%|████████▌ | 954/1120 [13:02<02:09,  1.28it/s] 85%|████████▌ | 955/1120 [13:02<02:06,  1.31it/s] 85%|████████▌ | 956/1120 [13:03<02:02,  1.34it/s] 85%|████████▌ | 957/1120 [13:04<02:10,  1.25it/s] 86%|████████▌ | 958/1120 [13:05<02:05,  1.30it/s] 86%|████████▌ | 959/1120 [13:05<02:01,  1.32it/s] 86%|████████▌ | 960/1120 [13:06<01:59,  1.34it/s]                                                   86%|████████▌ | 960/1120 [13:06<01:59,  1.34it/s]{'eval_loss': 0.10097969323396683, 'eval_runtime': 0.9584, 'eval_samples_per_second': 104.34, 'eval_steps_per_second': 13.564, 'epoch': 8.18}
外层迭代结束！
外层迭代结束！
{'loss': 0.0177, 'learning_rate': 5.327102803738317e-05, 'epoch': 8.27}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0175, 'learning_rate': 5.046728971962616e-05, 'epoch': 8.36}
外层迭代结束！
外层迭代结束！
{'loss': 0.0036, 'learning_rate': 4.766355140186915e-05, 'epoch': 8.44}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0046, 'learning_rate': 4.485981308411214e-05, 'epoch': 8.53}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.50it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.42it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 14.74it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.27it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.36it/s][A                                                  
                                               [A 86%|████████▌ | 960/1120 [13:07<01:59,  1.34it/s]
100%|██████████| 13/13 [00:00<00:00, 14.36it/s][A
                                               [A 86%|████████▌ | 961/1120 [13:08<02:58,  1.12s/it] 86%|████████▌ | 962/1120 [13:09<02:38,  1.00s/it] 86%|████████▌ | 963/1120 [13:09<02:23,  1.10it/s] 86%|████████▌ | 964/1120 [13:10<02:13,  1.17it/s] 86%|████████▌ | 965/1120 [13:11<02:24,  1.08it/s] 86%|████████▋ | 966/1120 [13:12<02:13,  1.16it/s] 86%|████████▋ | 967/1120 [13:13<02:05,  1.22it/s] 86%|████████▋ | 968/1120 [13:13<01:59,  1.27it/s] 87%|████████▋ | 969/1120 [13:14<02:07,  1.19it/s] 87%|████████▋ | 970/1120 [13:15<02:01,  1.24it/s]                                                   87%|████████▋ | 970/1120 [13:15<02:01,  1.24it/s] 87%|████████▋ | 971/1120 [13:16<01:56,  1.27it/s] 87%|████████▋ | 972/1120 [13:17<01:52,  1.31it/s] 87%|████████▋ | 973/1120 [13:18<01:59,  1.23it/s] 87%|████████▋ | 974/1120 [13:18<01:55,  1.27it/s] 87%|████████▋ | 975/1120 [13:19<01:51,  1.30it/s] 87%|████████▋ | 976/1120 [13:20<01:47,  1.34it/s] 87%|████████▋ | 977/1120 [13:21<01:55,  1.23it/s] 87%|████████▋ | 978/1120 [13:21<01:50,  1.29it/s] 87%|████████▋ | 979/1120 [13:22<01:46,  1.32it/s] 88%|████████▊ | 980/1120 [13:23<01:44,  1.33it/s]                                                   88%|████████▊ | 980/1120 [13:23<01:44,  1.33it/s] 88%|████████▊ | 981/1120 [13:24<01:52,  1.23it/s] 88%|████████▊ | 982/1120 [13:24<01:48,  1.28it/s] 88%|████████▊ | 983/1120 [13:25<01:44,  1.31it/s] 88%|████████▊ | 984/1120 [13:26<01:41,  1.34it/s] 88%|████████▊ | 985/1120 [13:27<01:47,  1.25it/s] 88%|████████▊ | 986/1120 [13:27<01:43,  1.30it/s] 88%|████████▊ | 987/1120 [13:28<01:40,  1.32it/s] 88%|████████▊ | 988/1120 [13:29<01:38,  1.34it/s] 88%|████████▊ | 989/1120 [13:30<01:44,  1.26it/s] 88%|████████▊ | 990/1120 [13:31<01:41,  1.28it/s]                                                   88%|████████▊ | 990/1120 [13:31<01:41,  1.28it/s] 88%|████████▊ | 991/1120 [13:31<01:38,  1.31it/s] 89%|████████▊ | 992/1120 [13:32<01:36,  1.33it/s] 89%|████████▊ | 993/1120 [13:33<01:44,  1.22it/s] 89%|████████▉ | 994/1120 [13:34<01:38,  1.28it/s] 89%|████████▉ | 995/1120 [13:34<01:36,  1.29it/s] 89%|████████▉ | 996/1120 [13:35<01:34,  1.32it/s] 89%|████████▉ | 997/1120 [13:36<01:41,  1.21it/s] 89%|████████▉ | 998/1120 [13:37<01:37,  1.25it/s] 89%|████████▉ | 999/1120 [13:38<01:33,  1.30it/s] 89%|████████▉ | 1000/1120 [13:38<01:30,  1.32it/s]                                                    89%|████████▉ | 1000/1120 [13:39<01:30,  1.32it/s]{'eval_loss': 0.08412308990955353, 'eval_runtime': 0.9571, 'eval_samples_per_second': 104.482, 'eval_steps_per_second': 13.583, 'epoch': 8.53}
外层迭代结束！
外层迭代结束！
{'loss': 0.016, 'learning_rate': 4.2056074766355134e-05, 'epoch': 8.62}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0055, 'learning_rate': 3.9252336448598124e-05, 'epoch': 8.71}
外层迭代结束！
外层迭代结束！
{'loss': 0.009, 'learning_rate': 3.6448598130841115e-05, 'epoch': 8.8}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0027, 'learning_rate': 3.3644859813084105e-05, 'epoch': 8.89}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.48it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.25it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 14.68it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.21it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.32it/s][A                                                   
                                               [A 89%|████████▉ | 1000/1120 [13:39<01:30,  1.32it/s]
100%|██████████| 13/13 [00:00<00:00, 14.32it/s][A
                                               [A 89%|████████▉ | 1001/1120 [13:40<02:15,  1.14s/it] 89%|████████▉ | 1002/1120 [13:41<02:00,  1.02s/it] 90%|████████▉ | 1003/1120 [13:42<01:48,  1.08it/s] 90%|████████▉ | 1004/1120 [13:43<01:40,  1.15it/s] 90%|████████▉ | 1005/1120 [13:44<01:43,  1.12it/s] 90%|████████▉ | 1006/1120 [13:44<01:36,  1.18it/s] 90%|████████▉ | 1007/1120 [13:45<01:31,  1.23it/s] 90%|█████████ | 1008/1120 [13:46<01:27,  1.29it/s] 90%|█████████ | 1009/1120 [13:47<01:33,  1.19it/s] 90%|█████████ | 1010/1120 [13:47<01:28,  1.24it/s]                                                    90%|█████████ | 1010/1120 [13:47<01:28,  1.24it/s] 90%|█████████ | 1011/1120 [13:48<01:24,  1.29it/s] 90%|█████████ | 1012/1120 [13:49<01:22,  1.32it/s] 90%|█████████ | 1013/1120 [13:50<01:25,  1.25it/s] 91%|█████████ | 1014/1120 [13:50<01:22,  1.28it/s] 91%|█████████ | 1015/1120 [13:51<01:20,  1.30it/s] 91%|█████████ | 1016/1120 [13:52<01:17,  1.34it/s] 91%|█████████ | 1017/1120 [13:53<01:24,  1.22it/s] 91%|█████████ | 1018/1120 [13:54<01:20,  1.27it/s] 91%|█████████ | 1019/1120 [13:54<01:18,  1.29it/s] 91%|█████████ | 1020/1120 [13:55<01:15,  1.32it/s]                                                    91%|█████████ | 1020/1120 [13:55<01:15,  1.32it/s] 91%|█████████ | 1021/1120 [13:56<01:19,  1.25it/s] 91%|█████████▏| 1022/1120 [13:57<01:16,  1.28it/s] 91%|█████████▏| 1023/1120 [13:57<01:13,  1.31it/s] 91%|█████████▏| 1024/1120 [13:58<01:11,  1.34it/s] 92%|█████████▏| 1025/1120 [13:59<01:15,  1.26it/s] 92%|█████████▏| 1026/1120 [14:00<01:12,  1.30it/s] 92%|█████████▏| 1027/1120 [14:00<01:10,  1.33it/s] 92%|█████████▏| 1028/1120 [14:01<01:08,  1.35it/s] 92%|█████████▏| 1029/1120 [14:02<01:13,  1.24it/s] 92%|█████████▏| 1030/1120 [14:03<01:11,  1.26it/s]                                                    92%|█████████▏| 1030/1120 [14:03<01:11,  1.26it/s] 92%|█████████▏| 1031/1120 [14:04<01:09,  1.28it/s] 92%|█████████▏| 1032/1120 [14:04<01:07,  1.31it/s] 92%|█████████▏| 1033/1120 [14:05<01:11,  1.22it/s] 92%|█████████▏| 1034/1120 [14:06<01:07,  1.27it/s] 92%|█████████▏| 1035/1120 [14:07<01:05,  1.30it/s] 92%|█████████▎| 1036/1120 [14:07<01:03,  1.33it/s] 93%|█████████▎| 1037/1120 [14:08<01:07,  1.23it/s] 93%|█████████▎| 1038/1120 [14:09<01:04,  1.28it/s] 93%|█████████▎| 1039/1120 [14:10<01:01,  1.32it/s] 93%|█████████▎| 1040/1120 [14:11<00:59,  1.34it/s]                                                    93%|█████████▎| 1040/1120 [14:11<00:59,  1.34it/s]{'eval_loss': 0.10326313972473145, 'eval_runtime': 0.9607, 'eval_samples_per_second': 104.095, 'eval_steps_per_second': 13.532, 'epoch': 8.89}
外层迭代结束！
外层迭代结束！
{'loss': 0.0276, 'learning_rate': 3.0841121495327096e-05, 'epoch': 8.98}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0043, 'learning_rate': 2.803738317757009e-05, 'epoch': 9.07}
外层迭代结束！
外层迭代结束！
{'loss': 0.0038, 'learning_rate': 2.523364485981308e-05, 'epoch': 9.16}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0034, 'learning_rate': 2.242990654205607e-05, 'epoch': 9.24}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.22it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.38it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 14.75it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.27it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.42it/s][A                                                   
                                               [A 93%|█████████▎| 1040/1120 [14:12<00:59,  1.34it/s]
100%|██████████| 13/13 [00:00<00:00, 14.42it/s][A
                                               [A 93%|█████████▎| 1041/1120 [14:13<01:29,  1.14s/it] 93%|█████████▎| 1042/1120 [14:13<01:18,  1.01s/it] 93%|█████████▎| 1043/1120 [14:14<01:10,  1.09it/s] 93%|█████████▎| 1044/1120 [14:15<01:05,  1.16it/s] 93%|█████████▎| 1045/1120 [14:16<01:05,  1.14it/s] 93%|█████████▎| 1046/1120 [14:16<01:01,  1.19it/s] 93%|█████████▎| 1047/1120 [14:17<00:58,  1.24it/s] 94%|█████████▎| 1048/1120 [14:18<00:55,  1.29it/s] 94%|█████████▎| 1049/1120 [14:19<00:59,  1.20it/s] 94%|█████████▍| 1050/1120 [14:20<00:56,  1.25it/s]                                                    94%|█████████▍| 1050/1120 [14:20<00:56,  1.25it/s] 94%|█████████▍| 1051/1120 [14:20<00:53,  1.30it/s] 94%|█████████▍| 1052/1120 [14:21<00:51,  1.33it/s] 94%|█████████▍| 1053/1120 [14:22<00:53,  1.25it/s] 94%|█████████▍| 1054/1120 [14:23<00:51,  1.29it/s] 94%|█████████▍| 1055/1120 [14:23<00:49,  1.32it/s] 94%|█████████▍| 1056/1120 [14:24<00:47,  1.35it/s] 94%|█████████▍| 1057/1120 [14:25<00:50,  1.26it/s] 94%|█████████▍| 1058/1120 [14:26<00:47,  1.31it/s] 95%|█████████▍| 1059/1120 [14:26<00:45,  1.35it/s] 95%|█████████▍| 1060/1120 [14:27<00:43,  1.38it/s]                                                    95%|█████████▍| 1060/1120 [14:27<00:43,  1.38it/s] 95%|█████████▍| 1061/1120 [14:28<00:46,  1.26it/s] 95%|█████████▍| 1062/1120 [14:29<00:44,  1.31it/s] 95%|█████████▍| 1063/1120 [14:29<00:42,  1.36it/s] 95%|█████████▌| 1064/1120 [14:30<00:40,  1.39it/s] 95%|█████████▌| 1065/1120 [14:31<00:42,  1.30it/s] 95%|█████████▌| 1066/1120 [14:32<00:40,  1.34it/s] 95%|█████████▌| 1067/1120 [14:32<00:38,  1.37it/s] 95%|█████████▌| 1068/1120 [14:33<00:37,  1.40it/s] 95%|█████████▌| 1069/1120 [14:34<00:39,  1.29it/s] 96%|█████████▌| 1070/1120 [14:34<00:37,  1.34it/s]                                                    96%|█████████▌| 1070/1120 [14:34<00:37,  1.34it/s] 96%|█████████▌| 1071/1120 [14:35<00:35,  1.36it/s] 96%|█████████▌| 1072/1120 [14:36<00:34,  1.38it/s] 96%|█████████▌| 1073/1120 [14:37<00:36,  1.27it/s] 96%|█████████▌| 1074/1120 [14:38<00:34,  1.32it/s] 96%|█████████▌| 1075/1120 [14:38<00:33,  1.35it/s] 96%|█████████▌| 1076/1120 [14:39<00:32,  1.37it/s] 96%|█████████▌| 1077/1120 [14:40<00:33,  1.28it/s] 96%|█████████▋| 1078/1120 [14:41<00:31,  1.31it/s] 96%|█████████▋| 1079/1120 [14:41<00:30,  1.34it/s] 96%|█████████▋| 1080/1120 [14:42<00:29,  1.37it/s]                                                    96%|█████████▋| 1080/1120 [14:42<00:29,  1.37it/s]{'eval_loss': 0.08405634760856628, 'eval_runtime': 0.9561, 'eval_samples_per_second': 104.589, 'eval_steps_per_second': 13.597, 'epoch': 9.24}
外层迭代结束！
外层迭代结束！
{'loss': 0.0052, 'learning_rate': 1.9626168224299062e-05, 'epoch': 9.33}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0161, 'learning_rate': 1.6822429906542053e-05, 'epoch': 9.42}
外层迭代结束！
外层迭代结束！
{'loss': 0.0065, 'learning_rate': 1.4018691588785045e-05, 'epoch': 9.51}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0055, 'learning_rate': 1.1214953271028036e-05, 'epoch': 9.6}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 20.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 15.59it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 14.83it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 14.17it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 14.20it/s][A                                                   
                                               [A 96%|█████████▋| 1080/1120 [14:43<00:29,  1.37it/s]
100%|██████████| 13/13 [00:00<00:00, 14.20it/s][A
                                               [A 97%|█████████▋| 1081/1120 [14:44<00:45,  1.17s/it] 97%|█████████▋| 1082/1120 [14:45<00:39,  1.04s/it] 97%|█████████▋| 1083/1120 [14:46<00:34,  1.06it/s] 97%|█████████▋| 1084/1120 [14:46<00:31,  1.14it/s] 97%|█████████▋| 1085/1120 [14:47<00:31,  1.11it/s] 97%|█████████▋| 1086/1120 [14:48<00:28,  1.18it/s] 97%|█████████▋| 1087/1120 [14:49<00:26,  1.24it/s] 97%|█████████▋| 1088/1120 [14:49<00:24,  1.28it/s] 97%|█████████▋| 1089/1120 [14:50<00:25,  1.21it/s] 97%|█████████▋| 1090/1120 [14:51<00:23,  1.26it/s]                                                    97%|█████████▋| 1090/1120 [14:51<00:23,  1.26it/s] 97%|█████████▋| 1091/1120 [14:52<00:22,  1.29it/s] 98%|█████████▊| 1092/1120 [14:53<00:21,  1.32it/s] 98%|█████████▊| 1093/1120 [14:53<00:22,  1.22it/s] 98%|█████████▊| 1094/1120 [14:54<00:20,  1.26it/s] 98%|█████████▊| 1095/1120 [14:55<00:19,  1.30it/s] 98%|█████████▊| 1096/1120 [14:56<00:18,  1.33it/s] 98%|█████████▊| 1097/1120 [14:57<00:18,  1.25it/s] 98%|█████████▊| 1098/1120 [14:57<00:17,  1.29it/s] 98%|█████████▊| 1099/1120 [14:58<00:15,  1.33it/s] 98%|█████████▊| 1100/1120 [14:59<00:14,  1.35it/s]                                                    98%|█████████▊| 1100/1120 [14:59<00:14,  1.35it/s] 98%|█████████▊| 1101/1120 [15:00<00:15,  1.26it/s] 98%|█████████▊| 1102/1120 [15:00<00:13,  1.31it/s] 98%|█████████▊| 1103/1120 [15:01<00:12,  1.33it/s] 99%|█████████▊| 1104/1120 [15:02<00:11,  1.35it/s] 99%|█████████▊| 1105/1120 [15:03<00:11,  1.26it/s] 99%|█████████▉| 1106/1120 [15:03<00:10,  1.30it/s] 99%|█████████▉| 1107/1120 [15:04<00:09,  1.33it/s] 99%|█████████▉| 1108/1120 [15:05<00:08,  1.34it/s] 99%|█████████▉| 1109/1120 [15:06<00:08,  1.26it/s] 99%|█████████▉| 1110/1120 [15:06<00:07,  1.31it/s]                                                    99%|█████████▉| 1110/1120 [15:06<00:07,  1.31it/s] 99%|█████████▉| 1111/1120 [15:07<00:06,  1.33it/s] 99%|█████████▉| 1112/1120 [15:08<00:05,  1.35it/s] 99%|█████████▉| 1113/1120 [15:09<00:05,  1.23it/s] 99%|█████████▉| 1114/1120 [15:10<00:04,  1.27it/s]100%|█████████▉| 1115/1120 [15:10<00:03,  1.32it/s]100%|█████████▉| 1116/1120 [15:11<00:02,  1.34it/s]100%|█████████▉| 1117/1120 [15:12<00:02,  1.23it/s]100%|█████████▉| 1118/1120 [15:13<00:01,  1.28it/s]100%|█████████▉| 1119/1120 [15:13<00:00,  1.31it/s]100%|██████████| 1120/1120 [15:14<00:00,  1.34it/s]                                                   100%|██████████| 1120/1120 [15:14<00:00,  1.34it/s]{'eval_loss': 0.08696474879980087, 'eval_runtime': 0.9618, 'eval_samples_per_second': 103.968, 'eval_steps_per_second': 13.516, 'epoch': 9.6}
外层迭代结束！
外层迭代结束！
{'loss': 0.0228, 'learning_rate': 8.411214953271026e-06, 'epoch': 9.69}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0236, 'learning_rate': 5.607476635514018e-06, 'epoch': 9.78}
外层迭代结束！
外层迭代结束！
{'loss': 0.004, 'learning_rate': 2.803738317757009e-06, 'epoch': 9.87}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0035, 'learning_rate': 0.0, 'epoch': 9.96}

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 19.62it/s][A
 38%|███▊      | 5/13 [00:00<00:00, 15.93it/s][A
 54%|█████▍    | 7/13 [00:00<00:00, 14.54it/s][A
 69%|██████▉   | 9/13 [00:00<00:00, 13.71it/s][A
 85%|████████▍ | 11/13 [00:00<00:00, 13.87it/s][A
100%|██████████| 13/13 [00:00<00:00, 14.17it/s][A                                                   
                                               [A100%|██████████| 1120/1120 [15:15<00:00,  1.34it/s]
100%|██████████| 13/13 [00:00<00:00, 14.17it/s][A
                                               [AThere were missing keys in the checkpoint model loaded: ['base_model.model.shared.weight', 'base_model.model.encoder.embed_tokens.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.encoder.block.0.layer.0.layer_norm.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.0.layer.1.layer_norm.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.1.layer.0.layer_norm.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.1.layer.1.layer_norm.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.2.layer.0.layer_norm.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.2.layer.1.layer_norm.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.3.layer.0.layer_norm.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.3.layer.1.layer_norm.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.4.layer.0.layer_norm.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.4.layer.1.layer_norm.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.5.layer.0.layer_norm.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.5.layer.1.layer_norm.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.6.layer.0.layer_norm.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.6.layer.1.layer_norm.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.7.layer.0.layer_norm.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.7.layer.1.layer_norm.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.8.layer.0.layer_norm.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.8.layer.1.layer_norm.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.9.layer.0.layer_norm.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.9.layer.1.layer_norm.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.10.layer.0.layer_norm.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.10.layer.1.layer_norm.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.11.layer.0.layer_norm.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.11.layer.1.layer_norm.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.12.layer.0.layer_norm.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.12.layer.1.layer_norm.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.13.layer.0.layer_norm.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.13.layer.1.layer_norm.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.14.layer.0.layer_norm.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.14.layer.1.layer_norm.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.15.layer.0.layer_norm.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.15.layer.1.layer_norm.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.16.layer.0.layer_norm.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.16.layer.1.layer_norm.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.17.layer.0.layer_norm.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.17.layer.1.layer_norm.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.18.layer.0.layer_norm.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.18.layer.1.layer_norm.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.19.layer.0.layer_norm.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.19.layer.1.layer_norm.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.20.layer.0.layer_norm.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.20.layer.1.layer_norm.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.21.layer.0.layer_norm.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.21.layer.1.layer_norm.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.22.layer.0.layer_norm.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.22.layer.1.layer_norm.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.23.layer.0.layer_norm.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.23.layer.1.layer_norm.weight', 'base_model.model.encoder.final_layer_norm.weight', 'base_model.model.decoder.embed_tokens.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.decoder.block.0.layer.0.layer_norm.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.0.layer.1.layer_norm.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.0.layer.2.layer_norm.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.1.layer.0.layer_norm.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.1.layer.1.layer_norm.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.1.layer.2.layer_norm.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.2.layer.0.layer_norm.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.2.layer.1.layer_norm.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.2.layer.2.layer_norm.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.3.layer.0.layer_norm.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.3.layer.1.layer_norm.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.3.layer.2.layer_norm.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.4.layer.0.layer_norm.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.4.layer.1.layer_norm.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.4.layer.2.layer_norm.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.5.layer.0.layer_norm.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.5.layer.1.layer_norm.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.5.layer.2.layer_norm.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.6.layer.0.layer_norm.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.6.layer.1.layer_norm.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.6.layer.2.layer_norm.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.7.layer.0.layer_norm.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.7.layer.1.layer_norm.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.7.layer.2.layer_norm.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.8.layer.0.layer_norm.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.8.layer.1.layer_norm.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.8.layer.2.layer_norm.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.9.layer.0.layer_norm.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.9.layer.1.layer_norm.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.9.layer.2.layer_norm.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.10.layer.0.layer_norm.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.10.layer.1.layer_norm.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.10.layer.2.layer_norm.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.11.layer.0.layer_norm.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.11.layer.1.layer_norm.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.11.layer.2.layer_norm.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.12.layer.0.layer_norm.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.12.layer.1.layer_norm.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.12.layer.2.layer_norm.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.13.layer.0.layer_norm.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.13.layer.1.layer_norm.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.13.layer.2.layer_norm.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.14.layer.0.layer_norm.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.14.layer.1.layer_norm.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.14.layer.2.layer_norm.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.15.layer.0.layer_norm.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.15.layer.1.layer_norm.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.15.layer.2.layer_norm.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.16.layer.0.layer_norm.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.16.layer.1.layer_norm.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.16.layer.2.layer_norm.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.17.layer.0.layer_norm.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.17.layer.1.layer_norm.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.17.layer.2.layer_norm.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.18.layer.0.layer_norm.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.18.layer.1.layer_norm.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.18.layer.2.layer_norm.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.19.layer.0.layer_norm.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.19.layer.1.layer_norm.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.19.layer.2.layer_norm.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.20.layer.0.layer_norm.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.20.layer.1.layer_norm.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.20.layer.2.layer_norm.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.21.layer.0.layer_norm.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.21.layer.1.layer_norm.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.21.layer.2.layer_norm.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.22.layer.0.layer_norm.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.22.layer.1.layer_norm.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.22.layer.2.layer_norm.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.23.layer.0.layer_norm.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.23.layer.1.layer_norm.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.23.layer.2.layer_norm.weight', 'base_model.model.decoder.final_layer_norm.weight', 'base_model.model.lm_head.weight'].
There were unexpected keys in the checkpoint model loaded: ['base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.weight'].
                                                   100%|██████████| 1120/1120 [15:16<00:00,  1.34it/s]100%|██████████| 1120/1120 [15:16<00:00,  1.22it/s]
{'eval_loss': 0.0923762321472168, 'eval_runtime': 0.9778, 'eval_samples_per_second': 102.266, 'eval_steps_per_second': 13.295, 'epoch': 9.96}
{'train_runtime': 916.0607, 'train_samples_per_second': 9.825, 'train_steps_per_second': 1.223, 'train_loss': 0.104988675804842, 'epoch': 9.96}

 If there's a warning about missing keys above, please disregard :)
Found cached dataset json (/data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 8
micro_batch_size: 2
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: imdb... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/7-imdb
current data path: ./data_longsequence/train/imdb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 797.85it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 1026.25it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 470.11it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 275.45it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 983.42it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400, 选择的样本数量：8
task id: 4, history data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 482.33it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b05edc432aa3560.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 5, history data path: ./data_longsequence/train/boolqa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 584.00it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-856891a4945fd30a.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 6, history data path: ./data_longsequence/train/rte_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 507.23it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-239b26a3aab39f27.arrow
总样本数：1000, 选择的样本数量：20
lora_weights: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/6-rte

pre-trained model's BOS EOS and PAD token id: None 1 0  => It should be 1,2,none
continual fine tune lora!
trainable params: 2359296 || all params: 740027392 || trainable%: 0.31881198257050464
训练数据总量：900
验证数据总量：100
Map:   0%|          | 0/900 [00:00<?, ? examples/s]/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3597: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  "`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your "
Map: 100%|██████████| 900/900 [00:00<00:00, 3293.11 examples/s]                                                               Map:   0%|          | 0/100 [00:00<?, ? examples/s]                                                   Map:   0%|          | 0/113 [00:00<?, ? examples/s]                                                   memory data loader 2
  0%|          | 0/1120 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/1120 [00:01<28:00,  1.50s/it]  0%|          | 2/1120 [00:02<21:50,  1.17s/it]  0%|          | 3/1120 [00:03<20:45,  1.11s/it]  0%|          | 4/1120 [00:04<18:42,  1.01s/it]  0%|          | 5/1120 [00:05<18:24,  1.01it/s]  1%|          | 6/1120 [00:06<17:10,  1.08it/s]  1%|          | 7/1120 [00:06<16:52,  1.10it/s]  1%|          | 8/1120 [00:07<16:40,  1.11it/s]  1%|          | 9/1120 [00:08<17:06,  1.08it/s]  1%|          | 10/1120 [00:09<17:37,  1.05it/s]                                                   1%|          | 10/1120 [00:09<17:37,  1.05it/s]  1%|          | 11/1120 [00:10<16:24,  1.13it/s]  1%|          | 12/1120 [00:11<16:31,  1.12it/s]  1%|          | 13/1120 [00:12<18:11,  1.01it/s]  1%|▏         | 14/1120 [00:13<18:02,  1.02it/s]  1%|▏         | 15/1120 [00:14<16:46,  1.10it/s]  1%|▏         | 16/1120 [00:15<16:06,  1.14it/s]  2%|▏         | 17/1120 [00:16<17:17,  1.06it/s]  2%|▏         | 18/1120 [00:17<16:56,  1.08it/s]  2%|▏         | 19/1120 [00:18<16:51,  1.09it/s]  2%|▏         | 20/1120 [00:18<16:41,  1.10it/s]                                                   2%|▏         | 20/1120 [00:19<16:41,  1.10it/s]  2%|▏         | 21/1120 [00:20<17:24,  1.05it/s]  2%|▏         | 22/1120 [00:21<18:05,  1.01it/s]  2%|▏         | 23/1120 [00:21<17:02,  1.07it/s]  2%|▏         | 24/1120 [00:22<16:29,  1.11it/s]  2%|▏         | 25/1120 [00:23<18:04,  1.01it/s]  2%|▏         | 26/1120 [00:24<17:52,  1.02it/s]  2%|▏         | 27/1120 [00:25<18:17,  1.00s/it]  2%|▎         | 28/1120 [00:26<16:47,  1.08it/s]  3%|▎         | 29/1120 [00:27<18:44,  1.03s/it]  3%|▎         | 30/1120 [00:28<17:59,  1.01it/s]                                                   3%|▎         | 30/1120 [00:28<17:59,  1.01it/s]  3%|▎         | 31/1120 [00:29<18:02,  1.01it/s]  3%|▎         | 32/1120 [00:30<17:25,  1.04it/s]  3%|▎         | 33/1120 [00:31<17:20,  1.04it/s]  3%|▎         | 34/1120 [00:32<16:13,  1.12it/s]  3%|▎         | 35/1120 [00:33<16:06,  1.12it/s]  3%|▎         | 36/1120 [00:34<16:08,  1.12it/s]  3%|▎         | 37/1120 [00:35<17:25,  1.04it/s]  3%|▎         | 38/1120 [00:36<17:35,  1.03it/s]  3%|▎         | 39/1120 [00:37<16:45,  1.08it/s]  4%|▎         | 40/1120 [00:38<16:34,  1.09it/s]                                                   4%|▎         | 40/1120 [00:38<16:34,  1.09it/s]外层迭代结束！
外层迭代结束！
{'loss': 3.8864, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.09}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 2.3306, 'learning_rate': 0.00011999999999999999, 'epoch': 0.18}
外层迭代结束！
外层迭代结束！
{'loss': 0.8293, 'learning_rate': 0.00017999999999999998, 'epoch': 0.27}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.256, 'learning_rate': 0.00023999999999999998, 'epoch': 0.36}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.01it/s][A
 23%|██▎       | 3/13 [00:01<00:04,  2.10it/s][A
 31%|███       | 4/13 [00:01<00:04,  2.22it/s][A
 38%|███▊      | 5/13 [00:02<00:03,  2.18it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.44it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.53it/s][A
 62%|██████▏   | 8/13 [00:03<00:01,  2.91it/s][A
 69%|██████▉   | 9/13 [00:03<00:01,  3.32it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.68it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.36it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.92it/s][A                                                 
                                               [A  4%|▎         | 40/1120 [00:42<16:34,  1.09it/s]
100%|██████████| 13/13 [00:04<00:00,  3.92it/s][A
                                               [A  4%|▎         | 41/1120 [00:43<40:23,  2.25s/it]  4%|▍         | 42/1120 [00:44<33:00,  1.84s/it]  4%|▍         | 43/1120 [00:45<27:42,  1.54s/it]  4%|▍         | 44/1120 [00:46<24:53,  1.39s/it]  4%|▍         | 45/1120 [00:47<24:07,  1.35s/it]  4%|▍         | 46/1120 [00:48<20:52,  1.17s/it]  4%|▍         | 47/1120 [00:48<18:59,  1.06s/it]  4%|▍         | 48/1120 [00:49<17:21,  1.03it/s]  4%|▍         | 49/1120 [00:50<17:36,  1.01it/s]  4%|▍         | 50/1120 [00:51<17:03,  1.05it/s]                                                   4%|▍         | 50/1120 [00:51<17:03,  1.05it/s]  5%|▍         | 51/1120 [00:52<16:50,  1.06it/s]  5%|▍         | 52/1120 [00:53<15:34,  1.14it/s]  5%|▍         | 53/1120 [00:54<15:47,  1.13it/s]  5%|▍         | 54/1120 [00:55<16:12,  1.10it/s]  5%|▍         | 55/1120 [00:55<15:33,  1.14it/s]  5%|▌         | 56/1120 [00:56<15:51,  1.12it/s]  5%|▌         | 57/1120 [00:57<16:37,  1.07it/s]  5%|▌         | 58/1120 [00:58<15:32,  1.14it/s]  5%|▌         | 59/1120 [00:59<15:14,  1.16it/s]  5%|▌         | 60/1120 [01:00<15:35,  1.13it/s]                                                   5%|▌         | 60/1120 [01:00<15:35,  1.13it/s]  5%|▌         | 61/1120 [01:01<16:39,  1.06it/s]  6%|▌         | 62/1120 [01:02<16:23,  1.08it/s]  6%|▌         | 63/1120 [01:03<15:19,  1.15it/s]  6%|▌         | 64/1120 [01:03<15:09,  1.16it/s]  6%|▌         | 65/1120 [01:05<16:37,  1.06it/s]  6%|▌         | 66/1120 [01:05<15:31,  1.13it/s]  6%|▌         | 67/1120 [01:06<14:51,  1.18it/s]  6%|▌         | 68/1120 [01:07<14:36,  1.20it/s]  6%|▌         | 69/1120 [01:08<16:34,  1.06it/s]  6%|▋         | 70/1120 [01:09<16:17,  1.07it/s]                                                   6%|▋         | 70/1120 [01:09<16:17,  1.07it/s]  6%|▋         | 71/1120 [01:10<15:28,  1.13it/s]  6%|▋         | 72/1120 [01:11<15:35,  1.12it/s]  7%|▋         | 73/1120 [01:12<17:35,  1.01s/it]  7%|▋         | 74/1120 [01:13<16:53,  1.03it/s]  7%|▋         | 75/1120 [01:14<17:13,  1.01it/s]  7%|▋         | 76/1120 [01:15<17:12,  1.01it/s]  7%|▋         | 77/1120 [01:16<17:31,  1.01s/it]  7%|▋         | 78/1120 [01:17<16:13,  1.07it/s]  7%|▋         | 79/1120 [01:18<15:39,  1.11it/s]  7%|▋         | 80/1120 [01:18<15:36,  1.11it/s]                                                   7%|▋         | 80/1120 [01:19<15:36,  1.11it/s]{'eval_loss': 0.08881152421236038, 'eval_runtime': 4.2479, 'eval_samples_per_second': 23.541, 'eval_steps_per_second': 3.06, 'epoch': 0.36}
外层迭代结束！
外层迭代结束！
{'loss': 0.1207, 'learning_rate': 0.0003, 'epoch': 0.44}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.184, 'learning_rate': 0.00029719626168224294, 'epoch': 0.53}
外层迭代结束！
外层迭代结束！
{'loss': 0.0883, 'learning_rate': 0.00029439252336448596, 'epoch': 0.62}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.2112, 'learning_rate': 0.0002915887850467289, 'epoch': 0.71}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  4.99it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.99it/s][A                                                 
                                               [A  7%|▋         | 80/1120 [01:23<15:36,  1.11it/s]
100%|██████████| 13/13 [00:03<00:00,  3.99it/s][A
                                               [A  7%|▋         | 81/1120 [01:24<37:18,  2.15s/it]  7%|▋         | 82/1120 [01:24<31:07,  1.80s/it]  7%|▋         | 83/1120 [01:25<25:51,  1.50s/it]  8%|▊         | 84/1120 [01:26<23:13,  1.35s/it]  8%|▊         | 85/1120 [01:27<22:04,  1.28s/it]  8%|▊         | 86/1120 [01:28<20:21,  1.18s/it]  8%|▊         | 87/1120 [01:29<18:02,  1.05s/it]  8%|▊         | 88/1120 [01:30<17:34,  1.02s/it]  8%|▊         | 89/1120 [01:31<17:18,  1.01s/it]  8%|▊         | 90/1120 [01:32<15:54,  1.08it/s]                                                   8%|▊         | 90/1120 [01:32<15:54,  1.08it/s]  8%|▊         | 91/1120 [01:33<16:29,  1.04it/s]  8%|▊         | 92/1120 [01:34<15:52,  1.08it/s]  8%|▊         | 93/1120 [01:35<16:52,  1.01it/s]  8%|▊         | 94/1120 [01:36<16:11,  1.06it/s]  8%|▊         | 95/1120 [01:37<16:23,  1.04it/s]  9%|▊         | 96/1120 [01:38<16:02,  1.06it/s]  9%|▊         | 97/1120 [01:39<18:01,  1.06s/it]  9%|▉         | 98/1120 [01:40<17:10,  1.01s/it]  9%|▉         | 99/1120 [01:41<17:02,  1.00s/it]  9%|▉         | 100/1120 [01:42<16:16,  1.04it/s]                                                    9%|▉         | 100/1120 [01:42<16:16,  1.04it/s]  9%|▉         | 101/1120 [01:43<17:49,  1.05s/it]  9%|▉         | 102/1120 [01:44<16:08,  1.05it/s]  9%|▉         | 103/1120 [01:44<15:23,  1.10it/s]  9%|▉         | 104/1120 [01:45<16:10,  1.05it/s]  9%|▉         | 105/1120 [01:47<17:34,  1.04s/it]  9%|▉         | 106/1120 [01:48<16:49,  1.00it/s] 10%|▉         | 107/1120 [01:48<15:41,  1.08it/s] 10%|▉         | 108/1120 [01:49<15:33,  1.08it/s] 10%|▉         | 109/1120 [01:50<15:50,  1.06it/s] 10%|▉         | 110/1120 [01:51<15:02,  1.12it/s]                                                   10%|▉         | 110/1120 [01:51<15:02,  1.12it/s] 10%|▉         | 111/1120 [01:52<15:04,  1.12it/s] 10%|█         | 112/1120 [01:53<14:57,  1.12it/s] 10%|█         | 113/1120 [01:54<15:59,  1.05it/s] 10%|█         | 114/1120 [01:55<16:02,  1.05it/s] 10%|█         | 115/1120 [01:56<15:03,  1.11it/s] 10%|█         | 116/1120 [01:56<14:54,  1.12it/s] 10%|█         | 117/1120 [01:57<15:01,  1.11it/s] 11%|█         | 118/1120 [01:58<14:55,  1.12it/s] 11%|█         | 119/1120 [01:59<14:46,  1.13it/s] 11%|█         | 120/1120 [02:00<16:02,  1.04it/s]                                                   11%|█         | 120/1120 [02:01<16:02,  1.04it/s]{'eval_loss': 0.08669179677963257, 'eval_runtime': 3.8639, 'eval_samples_per_second': 25.88, 'eval_steps_per_second': 3.364, 'epoch': 0.71}
外层迭代结束！
外层迭代结束！
{'loss': 0.2461, 'learning_rate': 0.00028878504672897194, 'epoch': 0.8}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.203, 'learning_rate': 0.0002859813084112149, 'epoch': 0.89}
外层迭代结束！
外层迭代结束！
{'loss': 0.0666, 'learning_rate': 0.0002831775700934579, 'epoch': 0.98}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0792, 'learning_rate': 0.0002803738317757009, 'epoch': 1.07}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  4.99it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.72it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.98it/s][A                                                  
                                               [A 11%|█         | 120/1120 [02:04<16:02,  1.04it/s]
100%|██████████| 13/13 [00:03<00:00,  3.98it/s][A
                                               [A 11%|█         | 121/1120 [02:05<37:05,  2.23s/it] 11%|█         | 122/1120 [02:07<31:45,  1.91s/it] 11%|█         | 123/1120 [02:07<25:59,  1.56s/it] 11%|█         | 124/1120 [02:08<23:01,  1.39s/it] 11%|█         | 125/1120 [02:09<20:52,  1.26s/it] 11%|█▏        | 126/1120 [02:10<19:59,  1.21s/it] 11%|█▏        | 127/1120 [02:11<18:16,  1.10s/it] 11%|█▏        | 128/1120 [02:12<17:11,  1.04s/it] 12%|█▏        | 129/1120 [02:13<17:16,  1.05s/it] 12%|█▏        | 130/1120 [02:14<16:45,  1.02s/it]                                                   12%|█▏        | 130/1120 [02:14<16:45,  1.02s/it] 12%|█▏        | 131/1120 [02:15<15:57,  1.03it/s] 12%|█▏        | 132/1120 [02:16<16:00,  1.03it/s] 12%|█▏        | 133/1120 [02:17<15:58,  1.03it/s] 12%|█▏        | 134/1120 [02:18<15:55,  1.03it/s] 12%|█▏        | 135/1120 [02:19<14:50,  1.11it/s] 12%|█▏        | 136/1120 [02:20<14:21,  1.14it/s] 12%|█▏        | 137/1120 [02:21<16:40,  1.02s/it] 12%|█▏        | 138/1120 [02:22<15:25,  1.06it/s] 12%|█▏        | 139/1120 [02:23<15:15,  1.07it/s] 12%|█▎        | 140/1120 [02:23<14:38,  1.12it/s]                                                   12%|█▎        | 140/1120 [02:24<14:38,  1.12it/s] 13%|█▎        | 141/1120 [02:24<14:59,  1.09it/s] 13%|█▎        | 142/1120 [02:25<14:06,  1.16it/s] 13%|█▎        | 143/1120 [02:26<13:41,  1.19it/s] 13%|█▎        | 144/1120 [02:27<13:31,  1.20it/s] 13%|█▎        | 145/1120 [02:28<14:52,  1.09it/s] 13%|█▎        | 146/1120 [02:28<13:50,  1.17it/s] 13%|█▎        | 147/1120 [02:29<13:46,  1.18it/s] 13%|█▎        | 148/1120 [02:30<13:30,  1.20it/s] 13%|█▎        | 149/1120 [02:31<15:19,  1.06it/s] 13%|█▎        | 150/1120 [02:32<14:42,  1.10it/s]                                                   13%|█▎        | 150/1120 [02:32<14:42,  1.10it/s] 13%|█▎        | 151/1120 [02:33<14:31,  1.11it/s] 14%|█▎        | 152/1120 [02:34<14:44,  1.09it/s] 14%|█▎        | 153/1120 [02:35<16:03,  1.00it/s] 14%|█▍        | 154/1120 [02:36<15:04,  1.07it/s] 14%|█▍        | 155/1120 [02:37<15:10,  1.06it/s] 14%|█▍        | 156/1120 [02:38<15:35,  1.03it/s] 14%|█▍        | 157/1120 [02:39<15:39,  1.03it/s] 14%|█▍        | 158/1120 [02:40<15:01,  1.07it/s] 14%|█▍        | 159/1120 [02:40<13:51,  1.16it/s] 14%|█▍        | 160/1120 [02:41<14:06,  1.13it/s]                                                   14%|█▍        | 160/1120 [02:42<14:06,  1.13it/s]{'eval_loss': 0.07776523381471634, 'eval_runtime': 3.8669, 'eval_samples_per_second': 25.86, 'eval_steps_per_second': 3.362, 'epoch': 1.07}
外层迭代结束！
外层迭代结束！
{'loss': 0.0659, 'learning_rate': 0.0002775700934579439, 'epoch': 1.16}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1301, 'learning_rate': 0.00027476635514018686, 'epoch': 1.24}
外层迭代结束！
外层迭代结束！
{'loss': 0.0924, 'learning_rate': 0.0002719626168224299, 'epoch': 1.33}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0508, 'learning_rate': 0.00026915887850467284, 'epoch': 1.42}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  4.99it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.18it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.10it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.42it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.98it/s][A                                                  
                                               [A 14%|█▍        | 160/1120 [02:45<14:06,  1.13it/s]
100%|██████████| 13/13 [00:03<00:00,  3.98it/s][A
                                               [A 14%|█▍        | 161/1120 [02:47<34:33,  2.16s/it] 14%|█▍        | 162/1120 [02:48<28:53,  1.81s/it] 15%|█▍        | 163/1120 [02:48<24:41,  1.55s/it] 15%|█▍        | 164/1120 [02:49<21:24,  1.34s/it] 15%|█▍        | 165/1120 [02:50<20:22,  1.28s/it] 15%|█▍        | 166/1120 [02:51<18:15,  1.15s/it] 15%|█▍        | 167/1120 [02:52<17:08,  1.08s/it] 15%|█▌        | 168/1120 [02:53<16:06,  1.02s/it] 15%|█▌        | 169/1120 [02:54<16:50,  1.06s/it] 15%|█▌        | 170/1120 [02:55<15:30,  1.02it/s]                                                   15%|█▌        | 170/1120 [02:55<15:30,  1.02it/s] 15%|█▌        | 171/1120 [02:56<14:40,  1.08it/s] 15%|█▌        | 172/1120 [02:57<14:29,  1.09it/s] 15%|█▌        | 173/1120 [02:58<14:41,  1.07it/s] 16%|█▌        | 174/1120 [02:59<14:50,  1.06it/s] 16%|█▌        | 175/1120 [03:00<15:05,  1.04it/s] 16%|█▌        | 176/1120 [03:00<14:06,  1.11it/s] 16%|█▌        | 177/1120 [03:01<14:18,  1.10it/s] 16%|█▌        | 178/1120 [03:02<13:50,  1.13it/s] 16%|█▌        | 179/1120 [03:03<15:13,  1.03it/s] 16%|█▌        | 180/1120 [03:04<14:41,  1.07it/s]                                                   16%|█▌        | 180/1120 [03:04<14:41,  1.07it/s] 16%|█▌        | 181/1120 [03:06<16:18,  1.04s/it] 16%|█▋        | 182/1120 [03:06<14:47,  1.06it/s] 16%|█▋        | 183/1120 [03:07<14:36,  1.07it/s] 16%|█▋        | 184/1120 [03:08<13:44,  1.14it/s] 17%|█▋        | 185/1120 [03:09<15:24,  1.01it/s] 17%|█▋        | 186/1120 [03:10<15:31,  1.00it/s] 17%|█▋        | 187/1120 [03:11<15:22,  1.01it/s] 17%|█▋        | 188/1120 [03:12<14:44,  1.05it/s] 17%|█▋        | 189/1120 [03:13<15:37,  1.01s/it] 17%|█▋        | 190/1120 [03:14<14:23,  1.08it/s]                                                   17%|█▋        | 190/1120 [03:14<14:23,  1.08it/s] 17%|█▋        | 191/1120 [03:15<14:20,  1.08it/s] 17%|█▋        | 192/1120 [03:16<13:59,  1.11it/s] 17%|█▋        | 193/1120 [03:17<15:41,  1.02s/it] 17%|█▋        | 194/1120 [03:18<15:52,  1.03s/it] 17%|█▋        | 195/1120 [03:19<15:01,  1.03it/s] 18%|█▊        | 196/1120 [03:20<15:14,  1.01it/s] 18%|█▊        | 197/1120 [03:21<17:39,  1.15s/it] 18%|█▊        | 198/1120 [03:22<16:08,  1.05s/it] 18%|█▊        | 199/1120 [03:23<15:22,  1.00s/it] 18%|█▊        | 200/1120 [03:24<14:05,  1.09it/s]                                                   18%|█▊        | 200/1120 [03:24<14:05,  1.09it/s]{'eval_loss': 0.10633355379104614, 'eval_runtime': 3.8663, 'eval_samples_per_second': 25.865, 'eval_steps_per_second': 3.362, 'epoch': 1.42}
外层迭代结束！
外层迭代结束！
{'loss': 0.129, 'learning_rate': 0.00026635514018691586, 'epoch': 1.51}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0387, 'learning_rate': 0.0002635514018691588, 'epoch': 1.6}
外层迭代结束！
外层迭代结束！
{'loss': 0.1877, 'learning_rate': 0.00026074766355140184, 'epoch': 1.69}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1776, 'learning_rate': 0.0002579439252336448, 'epoch': 1.78}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.01it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.98it/s][A                                                  
                                               [A 18%|█▊        | 200/1120 [03:28<14:05,  1.09it/s]
100%|██████████| 13/13 [00:03<00:00,  3.98it/s][A
                                               [A 18%|█▊        | 201/1120 [03:29<34:35,  2.26s/it] 18%|█▊        | 202/1120 [03:30<27:43,  1.81s/it] 18%|█▊        | 203/1120 [03:31<22:52,  1.50s/it] 18%|█▊        | 204/1120 [03:32<20:07,  1.32s/it] 18%|█▊        | 205/1120 [03:33<18:46,  1.23s/it] 18%|█▊        | 206/1120 [03:33<16:18,  1.07s/it] 18%|█▊        | 207/1120 [03:34<15:02,  1.01it/s] 19%|█▊        | 208/1120 [03:35<14:00,  1.09it/s] 19%|█▊        | 209/1120 [03:36<15:59,  1.05s/it] 19%|█▉        | 210/1120 [03:37<15:20,  1.01s/it]                                                   19%|█▉        | 210/1120 [03:37<15:20,  1.01s/it] 19%|█▉        | 211/1120 [03:38<14:07,  1.07it/s] 19%|█▉        | 212/1120 [03:39<13:29,  1.12it/s] 19%|█▉        | 213/1120 [03:40<14:05,  1.07it/s] 19%|█▉        | 214/1120 [03:41<14:36,  1.03it/s] 19%|█▉        | 215/1120 [03:42<14:38,  1.03it/s] 19%|█▉        | 216/1120 [03:43<14:36,  1.03it/s] 19%|█▉        | 217/1120 [03:44<15:11,  1.01s/it] 19%|█▉        | 218/1120 [03:45<14:38,  1.03it/s] 20%|█▉        | 219/1120 [03:46<14:10,  1.06it/s] 20%|█▉        | 220/1120 [03:46<13:14,  1.13it/s]                                                   20%|█▉        | 220/1120 [03:47<13:14,  1.13it/s] 20%|█▉        | 221/1120 [03:48<15:22,  1.03s/it] 20%|█▉        | 222/1120 [03:49<14:16,  1.05it/s] 20%|█▉        | 223/1120 [03:49<13:26,  1.11it/s] 20%|██        | 224/1120 [03:50<13:02,  1.14it/s] 20%|██        | 225/1120 [03:51<13:59,  1.07it/s] 20%|██        | 226/1120 [03:52<13:10,  1.13it/s] 20%|██        | 227/1120 [03:53<13:17,  1.12it/s] 20%|██        | 228/1120 [03:54<13:27,  1.11it/s] 20%|██        | 229/1120 [03:55<14:07,  1.05it/s] 21%|██        | 230/1120 [03:56<13:10,  1.13it/s]                                                   21%|██        | 230/1120 [03:56<13:10,  1.13it/s] 21%|██        | 231/1120 [03:57<13:24,  1.11it/s] 21%|██        | 232/1120 [03:57<12:50,  1.15it/s] 21%|██        | 233/1120 [03:59<14:17,  1.03it/s] 21%|██        | 234/1120 [03:59<13:58,  1.06it/s] 21%|██        | 235/1120 [04:00<13:20,  1.11it/s] 21%|██        | 236/1120 [04:01<13:21,  1.10it/s] 21%|██        | 237/1120 [04:03<15:53,  1.08s/it] 21%|██▏       | 238/1120 [04:04<15:30,  1.06s/it] 21%|██▏       | 239/1120 [04:05<15:51,  1.08s/it] 21%|██▏       | 240/1120 [04:06<15:03,  1.03s/it]                                                   21%|██▏       | 240/1120 [04:06<15:03,  1.03s/it]{'eval_loss': 0.08022172003984451, 'eval_runtime': 3.8678, 'eval_samples_per_second': 25.855, 'eval_steps_per_second': 3.361, 'epoch': 1.78}
外层迭代结束！
外层迭代结束！
{'loss': 0.0993, 'learning_rate': 0.0002551401869158878, 'epoch': 1.87}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0594, 'learning_rate': 0.0002523364485981308, 'epoch': 1.96}
外层迭代结束！
外层迭代结束！
{'loss': 0.0507, 'learning_rate': 0.0002495327102803738, 'epoch': 2.04}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0515, 'learning_rate': 0.00024672897196261677, 'epoch': 2.13}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.02it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.10it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.79it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.99it/s][A                                                  
                                               [A 21%|██▏       | 240/1120 [04:10<15:03,  1.03s/it]
100%|██████████| 13/13 [00:03<00:00,  3.99it/s][A
                                               [A 22%|██▏       | 241/1120 [04:11<33:19,  2.28s/it] 22%|██▏       | 242/1120 [04:12<27:11,  1.86s/it] 22%|██▏       | 243/1120 [04:13<22:58,  1.57s/it] 22%|██▏       | 244/1120 [04:14<20:08,  1.38s/it] 22%|██▏       | 245/1120 [04:15<18:14,  1.25s/it] 22%|██▏       | 246/1120 [04:15<16:48,  1.15s/it] 22%|██▏       | 247/1120 [04:16<15:25,  1.06s/it] 22%|██▏       | 248/1120 [04:17<13:57,  1.04it/s] 22%|██▏       | 249/1120 [04:18<14:08,  1.03it/s] 22%|██▏       | 250/1120 [04:19<13:42,  1.06it/s]                                                   22%|██▏       | 250/1120 [04:19<13:42,  1.06it/s] 22%|██▏       | 251/1120 [04:20<14:58,  1.03s/it] 22%|██▎       | 252/1120 [04:21<13:45,  1.05it/s] 23%|██▎       | 253/1120 [04:22<14:08,  1.02it/s] 23%|██▎       | 254/1120 [04:23<14:28,  1.00s/it] 23%|██▎       | 255/1120 [04:24<13:21,  1.08it/s] 23%|██▎       | 256/1120 [04:25<13:19,  1.08it/s] 23%|██▎       | 257/1120 [04:26<13:54,  1.03it/s] 23%|██▎       | 258/1120 [04:27<13:49,  1.04it/s] 23%|██▎       | 259/1120 [04:28<14:11,  1.01it/s] 23%|██▎       | 260/1120 [04:29<13:22,  1.07it/s]                                                   23%|██▎       | 260/1120 [04:29<13:22,  1.07it/s] 23%|██▎       | 261/1120 [04:30<14:17,  1.00it/s] 23%|██▎       | 262/1120 [04:31<13:35,  1.05it/s] 23%|██▎       | 263/1120 [04:31<12:40,  1.13it/s] 24%|██▎       | 264/1120 [04:32<12:15,  1.16it/s] 24%|██▎       | 265/1120 [04:33<13:27,  1.06it/s] 24%|██▍       | 266/1120 [04:34<13:24,  1.06it/s] 24%|██▍       | 267/1120 [04:35<13:17,  1.07it/s] 24%|██▍       | 268/1120 [04:36<12:49,  1.11it/s] 24%|██▍       | 269/1120 [04:37<13:30,  1.05it/s] 24%|██▍       | 270/1120 [04:38<12:48,  1.11it/s]                                                   24%|██▍       | 270/1120 [04:38<12:48,  1.11it/s] 24%|██▍       | 271/1120 [04:39<12:49,  1.10it/s] 24%|██▍       | 272/1120 [04:40<12:58,  1.09it/s] 24%|██▍       | 273/1120 [04:41<14:18,  1.01s/it] 24%|██▍       | 274/1120 [04:42<13:26,  1.05it/s] 25%|██▍       | 275/1120 [04:42<12:22,  1.14it/s] 25%|██▍       | 276/1120 [04:43<11:48,  1.19it/s] 25%|██▍       | 277/1120 [04:44<12:15,  1.15it/s] 25%|██▍       | 278/1120 [04:45<11:39,  1.20it/s] 25%|██▍       | 279/1120 [04:46<11:54,  1.18it/s] 25%|██▌       | 280/1120 [04:47<12:00,  1.17it/s]                                                   25%|██▌       | 280/1120 [04:47<12:00,  1.17it/s]{'eval_loss': 0.09382521361112595, 'eval_runtime': 3.8673, 'eval_samples_per_second': 25.858, 'eval_steps_per_second': 3.361, 'epoch': 2.13}
外层迭代结束！
外层迭代结束！
{'loss': 0.1456, 'learning_rate': 0.0002439252336448598, 'epoch': 2.22}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.041, 'learning_rate': 0.00024112149532710278, 'epoch': 2.31}
外层迭代结束！
外层迭代结束！
{'loss': 0.0546, 'learning_rate': 0.00023831775700934577, 'epoch': 2.4}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1082, 'learning_rate': 0.00023551401869158876, 'epoch': 2.49}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  4.99it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.18it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.10it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.42it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.98it/s][A                                                  
                                               [A 25%|██▌       | 280/1120 [04:51<12:00,  1.17it/s]
100%|██████████| 13/13 [00:03<00:00,  3.98it/s][A
                                               [A 25%|██▌       | 281/1120 [04:52<30:41,  2.20s/it] 25%|██▌       | 282/1120 [04:53<25:28,  1.82s/it] 25%|██▌       | 283/1120 [04:54<22:01,  1.58s/it] 25%|██▌       | 284/1120 [04:55<19:34,  1.40s/it] 25%|██▌       | 285/1120 [04:56<18:30,  1.33s/it] 26%|██▌       | 286/1120 [04:57<15:59,  1.15s/it] 26%|██▌       | 287/1120 [04:58<15:04,  1.09s/it] 26%|██▌       | 288/1120 [04:59<14:23,  1.04s/it] 26%|██▌       | 289/1120 [05:00<14:33,  1.05s/it] 26%|██▌       | 290/1120 [05:00<13:03,  1.06it/s]                                                   26%|██▌       | 290/1120 [05:00<13:03,  1.06it/s] 26%|██▌       | 291/1120 [05:01<12:11,  1.13it/s] 26%|██▌       | 292/1120 [05:02<11:30,  1.20it/s] 26%|██▌       | 293/1120 [05:03<13:06,  1.05it/s] 26%|██▋       | 294/1120 [05:04<12:44,  1.08it/s] 26%|██▋       | 295/1120 [05:05<12:02,  1.14it/s] 26%|██▋       | 296/1120 [05:06<12:24,  1.11it/s] 27%|██▋       | 297/1120 [05:07<12:47,  1.07it/s] 27%|██▋       | 298/1120 [05:08<12:37,  1.08it/s] 27%|██▋       | 299/1120 [05:08<12:11,  1.12it/s] 27%|██▋       | 300/1120 [05:09<12:08,  1.13it/s]                                                   27%|██▋       | 300/1120 [05:09<12:08,  1.13it/s] 27%|██▋       | 301/1120 [05:10<12:49,  1.06it/s] 27%|██▋       | 302/1120 [05:11<12:11,  1.12it/s] 27%|██▋       | 303/1120 [05:12<12:00,  1.13it/s] 27%|██▋       | 304/1120 [05:13<11:15,  1.21it/s] 27%|██▋       | 305/1120 [05:14<12:41,  1.07it/s] 27%|██▋       | 306/1120 [05:15<13:00,  1.04it/s] 27%|██▋       | 307/1120 [05:16<12:52,  1.05it/s] 28%|██▊       | 308/1120 [05:17<11:56,  1.13it/s] 28%|██▊       | 309/1120 [05:18<13:42,  1.01s/it] 28%|██▊       | 310/1120 [05:19<14:29,  1.07s/it]                                                   28%|██▊       | 310/1120 [05:19<14:29,  1.07s/it] 28%|██▊       | 311/1120 [05:20<13:57,  1.04s/it] 28%|██▊       | 312/1120 [05:21<13:00,  1.03it/s] 28%|██▊       | 313/1120 [05:22<12:50,  1.05it/s] 28%|██▊       | 314/1120 [05:23<12:21,  1.09it/s] 28%|██▊       | 315/1120 [05:24<12:39,  1.06it/s] 28%|██▊       | 316/1120 [05:25<13:23,  1.00it/s] 28%|██▊       | 317/1120 [05:26<14:54,  1.11s/it] 28%|██▊       | 318/1120 [05:27<13:43,  1.03s/it] 28%|██▊       | 319/1120 [05:28<13:35,  1.02s/it] 29%|██▊       | 320/1120 [05:29<12:54,  1.03it/s]                                                   29%|██▊       | 320/1120 [05:29<12:54,  1.03it/s]{'eval_loss': 0.10798494517803192, 'eval_runtime': 3.8674, 'eval_samples_per_second': 25.857, 'eval_steps_per_second': 3.361, 'epoch': 2.49}
外层迭代结束！
外层迭代结束！
{'loss': 0.0811, 'learning_rate': 0.00023271028037383175, 'epoch': 2.58}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0559, 'learning_rate': 0.00022990654205607474, 'epoch': 2.67}
外层迭代结束！
外层迭代结束！
{'loss': 0.1123, 'learning_rate': 0.00022710280373831773, 'epoch': 2.76}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0775, 'learning_rate': 0.00022429906542056072, 'epoch': 2.84}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.02it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.18it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.99it/s][A                                                  
                                               [A 29%|██▊       | 320/1120 [05:33<12:54,  1.03it/s]
100%|██████████| 13/13 [00:03<00:00,  3.99it/s][A
                                               [A 29%|██▊       | 321/1120 [05:34<29:03,  2.18s/it] 29%|██▉       | 322/1120 [05:35<24:29,  1.84s/it] 29%|██▉       | 323/1120 [05:36<21:04,  1.59s/it] 29%|██▉       | 324/1120 [05:37<19:10,  1.45s/it] 29%|██▉       | 325/1120 [05:38<18:24,  1.39s/it] 29%|██▉       | 326/1120 [05:39<16:44,  1.26s/it] 29%|██▉       | 327/1120 [05:40<15:44,  1.19s/it] 29%|██▉       | 328/1120 [05:41<14:08,  1.07s/it] 29%|██▉       | 329/1120 [05:42<13:45,  1.04s/it] 29%|██▉       | 330/1120 [05:43<12:36,  1.04it/s]                                                   29%|██▉       | 330/1120 [05:43<12:36,  1.04it/s] 30%|██▉       | 331/1120 [05:44<12:14,  1.07it/s] 30%|██▉       | 332/1120 [05:44<11:38,  1.13it/s] 30%|██▉       | 333/1120 [05:46<13:20,  1.02s/it] 30%|██▉       | 334/1120 [05:46<12:24,  1.06it/s] 30%|██▉       | 335/1120 [05:47<11:38,  1.12it/s] 30%|███       | 336/1120 [05:48<11:05,  1.18it/s] 30%|███       | 337/1120 [05:49<12:08,  1.07it/s] 30%|███       | 338/1120 [05:50<11:46,  1.11it/s] 30%|███       | 339/1120 [05:51<11:14,  1.16it/s] 30%|███       | 340/1120 [05:52<11:24,  1.14it/s]                                                   30%|███       | 340/1120 [05:52<11:24,  1.14it/s] 30%|███       | 341/1120 [05:53<12:39,  1.03it/s] 31%|███       | 342/1120 [05:54<12:19,  1.05it/s] 31%|███       | 343/1120 [05:55<12:03,  1.07it/s] 31%|███       | 344/1120 [05:55<11:54,  1.09it/s] 31%|███       | 345/1120 [05:56<12:14,  1.05it/s] 31%|███       | 346/1120 [05:57<11:55,  1.08it/s] 31%|███       | 347/1120 [05:58<11:12,  1.15it/s] 31%|███       | 348/1120 [05:59<11:03,  1.16it/s] 31%|███       | 349/1120 [06:00<12:46,  1.01it/s] 31%|███▏      | 350/1120 [06:01<11:47,  1.09it/s]                                                   31%|███▏      | 350/1120 [06:01<11:47,  1.09it/s] 31%|███▏      | 351/1120 [06:02<11:20,  1.13it/s] 31%|███▏      | 352/1120 [06:03<10:48,  1.18it/s] 32%|███▏      | 353/1120 [06:04<11:22,  1.12it/s] 32%|███▏      | 354/1120 [06:04<11:04,  1.15it/s] 32%|███▏      | 355/1120 [06:05<11:34,  1.10it/s] 32%|███▏      | 356/1120 [06:06<11:45,  1.08it/s] 32%|███▏      | 357/1120 [06:07<12:16,  1.04it/s] 32%|███▏      | 358/1120 [06:08<12:23,  1.03it/s] 32%|███▏      | 359/1120 [06:09<11:56,  1.06it/s] 32%|███▏      | 360/1120 [06:10<11:45,  1.08it/s]                                                   32%|███▏      | 360/1120 [06:10<11:45,  1.08it/s]{'eval_loss': 0.08871769905090332, 'eval_runtime': 3.868, 'eval_samples_per_second': 25.853, 'eval_steps_per_second': 3.361, 'epoch': 2.84}
外层迭代结束！
外层迭代结束！
{'loss': 0.0429, 'learning_rate': 0.0002214953271028037, 'epoch': 2.93}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.1432, 'learning_rate': 0.0002186915887850467, 'epoch': 3.02}
外层迭代结束！
外层迭代结束！
{'loss': 0.0913, 'learning_rate': 0.0002158878504672897, 'epoch': 3.11}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0629, 'learning_rate': 0.00021308411214953268, 'epoch': 3.2}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.00it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.10it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.47it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.42it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.98it/s][A                                                  
                                               [A 32%|███▏      | 360/1120 [06:14<11:45,  1.08it/s]
100%|██████████| 13/13 [00:03<00:00,  3.98it/s][A
                                               [A 32%|███▏      | 361/1120 [06:15<27:38,  2.19s/it] 32%|███▏      | 362/1120 [06:16<22:42,  1.80s/it] 32%|███▏      | 363/1120 [06:17<19:47,  1.57s/it] 32%|███▎      | 364/1120 [06:18<16:39,  1.32s/it] 33%|███▎      | 365/1120 [06:19<15:26,  1.23s/it] 33%|███▎      | 366/1120 [06:20<13:51,  1.10s/it] 33%|███▎      | 367/1120 [06:21<12:37,  1.01s/it] 33%|███▎      | 368/1120 [06:22<12:55,  1.03s/it] 33%|███▎      | 369/1120 [06:23<12:44,  1.02s/it] 33%|███▎      | 370/1120 [06:24<13:06,  1.05s/it]                                                   33%|███▎      | 370/1120 [06:24<13:06,  1.05s/it] 33%|███▎      | 371/1120 [06:25<12:37,  1.01s/it] 33%|███▎      | 372/1120 [06:25<11:28,  1.09it/s] 33%|███▎      | 373/1120 [06:27<12:36,  1.01s/it] 33%|███▎      | 374/1120 [06:28<12:16,  1.01it/s] 33%|███▎      | 375/1120 [06:28<12:03,  1.03it/s] 34%|███▎      | 376/1120 [06:29<11:21,  1.09it/s] 34%|███▎      | 377/1120 [06:30<11:28,  1.08it/s] 34%|███▍      | 378/1120 [06:31<11:54,  1.04it/s] 34%|███▍      | 379/1120 [06:32<12:48,  1.04s/it] 34%|███▍      | 380/1120 [06:33<12:04,  1.02it/s]                                                   34%|███▍      | 380/1120 [06:33<12:04,  1.02it/s] 34%|███▍      | 381/1120 [06:34<12:36,  1.02s/it] 34%|███▍      | 382/1120 [06:35<12:13,  1.01it/s] 34%|███▍      | 383/1120 [06:36<11:51,  1.04it/s] 34%|███▍      | 384/1120 [06:37<10:59,  1.12it/s] 34%|███▍      | 385/1120 [06:38<12:15,  1.00s/it] 34%|███▍      | 386/1120 [06:39<11:20,  1.08it/s] 35%|███▍      | 387/1120 [06:40<11:46,  1.04it/s] 35%|███▍      | 388/1120 [06:41<11:03,  1.10it/s] 35%|███▍      | 389/1120 [06:42<11:22,  1.07it/s] 35%|███▍      | 390/1120 [06:43<11:20,  1.07it/s]                                                   35%|███▍      | 390/1120 [06:43<11:20,  1.07it/s] 35%|███▍      | 391/1120 [06:44<11:36,  1.05it/s] 35%|███▌      | 392/1120 [06:45<11:02,  1.10it/s] 35%|███▌      | 393/1120 [06:45<11:13,  1.08it/s] 35%|███▌      | 394/1120 [06:46<11:22,  1.06it/s] 35%|███▌      | 395/1120 [06:47<10:44,  1.13it/s] 35%|███▌      | 396/1120 [06:48<10:50,  1.11it/s] 35%|███▌      | 397/1120 [06:49<10:59,  1.10it/s] 36%|███▌      | 398/1120 [06:50<11:10,  1.08it/s] 36%|███▌      | 399/1120 [06:51<11:15,  1.07it/s] 36%|███▌      | 400/1120 [06:52<10:46,  1.11it/s]                                                   36%|███▌      | 400/1120 [06:52<10:46,  1.11it/s]{'eval_loss': 0.10033725947141647, 'eval_runtime': 3.8665, 'eval_samples_per_second': 25.863, 'eval_steps_per_second': 3.362, 'epoch': 3.2}
外层迭代结束！
外层迭代结束！
{'loss': 0.0657, 'learning_rate': 0.00021028037383177567, 'epoch': 3.29}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0838, 'learning_rate': 0.00020747663551401867, 'epoch': 3.38}
外层迭代结束！
外层迭代结束！
{'loss': 0.0231, 'learning_rate': 0.00020467289719626166, 'epoch': 3.47}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0619, 'learning_rate': 0.00020186915887850465, 'epoch': 3.56}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  4.99it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.18it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.74it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.98it/s][A                                                  
                                               [A 36%|███▌      | 400/1120 [06:56<10:46,  1.11it/s]
100%|██████████| 13/13 [00:03<00:00,  3.98it/s][A
                                               [A 36%|███▌      | 401/1120 [06:57<25:27,  2.12s/it] 36%|███▌      | 402/1120 [06:58<21:41,  1.81s/it] 36%|███▌      | 403/1120 [06:59<18:56,  1.58s/it] 36%|███▌      | 404/1120 [07:00<16:01,  1.34s/it] 36%|███▌      | 405/1120 [07:01<14:34,  1.22s/it] 36%|███▋      | 406/1120 [07:02<13:12,  1.11s/it] 36%|███▋      | 407/1120 [07:02<11:57,  1.01s/it] 36%|███▋      | 408/1120 [07:03<11:30,  1.03it/s] 37%|███▋      | 409/1120 [07:04<12:00,  1.01s/it] 37%|███▋      | 410/1120 [07:05<11:29,  1.03it/s]                                                   37%|███▋      | 410/1120 [07:05<11:29,  1.03it/s] 37%|███▋      | 411/1120 [07:06<11:17,  1.05it/s] 37%|███▋      | 412/1120 [07:07<10:55,  1.08it/s] 37%|███▋      | 413/1120 [07:08<11:13,  1.05it/s] 37%|███▋      | 414/1120 [07:09<10:51,  1.08it/s] 37%|███▋      | 415/1120 [07:10<11:00,  1.07it/s] 37%|███▋      | 416/1120 [07:11<10:15,  1.14it/s] 37%|███▋      | 417/1120 [07:12<11:41,  1.00it/s] 37%|███▋      | 418/1120 [07:13<10:44,  1.09it/s] 37%|███▋      | 419/1120 [07:13<10:48,  1.08it/s] 38%|███▊      | 420/1120 [07:14<10:26,  1.12it/s]                                                   38%|███▊      | 420/1120 [07:14<10:26,  1.12it/s] 38%|███▊      | 421/1120 [07:15<11:27,  1.02it/s] 38%|███▊      | 422/1120 [07:16<11:28,  1.01it/s] 38%|███▊      | 423/1120 [07:18<11:43,  1.01s/it] 38%|███▊      | 424/1120 [07:18<10:54,  1.06it/s] 38%|███▊      | 425/1120 [07:19<11:10,  1.04it/s] 38%|███▊      | 426/1120 [07:20<11:16,  1.03it/s] 38%|███▊      | 427/1120 [07:21<10:44,  1.07it/s] 38%|███▊      | 428/1120 [07:22<11:09,  1.03it/s] 38%|███▊      | 429/1120 [07:23<11:34,  1.01s/it] 38%|███▊      | 430/1120 [07:24<11:23,  1.01it/s]                                                   38%|███▊      | 430/1120 [07:24<11:23,  1.01it/s] 38%|███▊      | 431/1120 [07:25<11:32,  1.00s/it] 39%|███▊      | 432/1120 [07:26<10:50,  1.06it/s] 39%|███▊      | 433/1120 [07:27<11:48,  1.03s/it] 39%|███▉      | 434/1120 [07:28<11:19,  1.01it/s] 39%|███▉      | 435/1120 [07:29<10:48,  1.06it/s] 39%|███▉      | 436/1120 [07:30<10:43,  1.06it/s] 39%|███▉      | 437/1120 [07:31<11:08,  1.02it/s] 39%|███▉      | 438/1120 [07:32<10:57,  1.04it/s] 39%|███▉      | 439/1120 [07:33<10:57,  1.04it/s] 39%|███▉      | 440/1120 [07:34<10:36,  1.07it/s]                                                   39%|███▉      | 440/1120 [07:34<10:36,  1.07it/s]{'eval_loss': 0.16021797060966492, 'eval_runtime': 3.8684, 'eval_samples_per_second': 25.851, 'eval_steps_per_second': 3.361, 'epoch': 3.56}
外层迭代结束！
外层迭代结束！
{'loss': 0.0839, 'learning_rate': 0.00019906542056074764, 'epoch': 3.64}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0786, 'learning_rate': 0.00019626168224299063, 'epoch': 3.73}
外层迭代结束！
外层迭代结束！
{'loss': 0.0775, 'learning_rate': 0.00019345794392523362, 'epoch': 3.82}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0133, 'learning_rate': 0.0001906542056074766, 'epoch': 3.91}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.01it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.10it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.99it/s][A                                                  
                                               [A 39%|███▉      | 440/1120 [07:38<10:36,  1.07it/s]
100%|██████████| 13/13 [00:03<00:00,  3.99it/s][A
                                               [A 39%|███▉      | 441/1120 [07:39<24:53,  2.20s/it] 39%|███▉      | 442/1120 [07:40<20:26,  1.81s/it] 40%|███▉      | 443/1120 [07:41<18:34,  1.65s/it] 40%|███▉      | 444/1120 [07:42<16:00,  1.42s/it] 40%|███▉      | 445/1120 [07:43<14:29,  1.29s/it] 40%|███▉      | 446/1120 [07:44<12:32,  1.12s/it] 40%|███▉      | 447/1120 [07:45<12:03,  1.07s/it] 40%|████      | 448/1120 [07:46<11:24,  1.02s/it] 40%|████      | 449/1120 [07:47<11:03,  1.01it/s] 40%|████      | 450/1120 [07:47<10:06,  1.10it/s]                                                   40%|████      | 450/1120 [07:47<10:06,  1.10it/s] 40%|████      | 451/1120 [07:48<10:11,  1.09it/s] 40%|████      | 452/1120 [07:49<10:03,  1.11it/s] 40%|████      | 453/1120 [07:50<11:11,  1.01s/it] 41%|████      | 454/1120 [07:51<10:46,  1.03it/s] 41%|████      | 455/1120 [07:52<10:00,  1.11it/s] 41%|████      | 456/1120 [07:53<09:41,  1.14it/s] 41%|████      | 457/1120 [07:54<10:38,  1.04it/s] 41%|████      | 458/1120 [07:55<10:08,  1.09it/s] 41%|████      | 459/1120 [07:55<09:26,  1.17it/s] 41%|████      | 460/1120 [07:56<09:33,  1.15it/s]                                                   41%|████      | 460/1120 [07:57<09:33,  1.15it/s] 41%|████      | 461/1120 [07:57<10:16,  1.07it/s] 41%|████▏     | 462/1120 [07:58<09:44,  1.13it/s] 41%|████▏     | 463/1120 [07:59<09:52,  1.11it/s] 41%|████▏     | 464/1120 [08:00<09:26,  1.16it/s] 42%|████▏     | 465/1120 [08:01<10:38,  1.03it/s] 42%|████▏     | 466/1120 [08:02<10:15,  1.06it/s] 42%|████▏     | 467/1120 [08:03<10:15,  1.06it/s] 42%|████▏     | 468/1120 [08:04<10:56,  1.01s/it] 42%|████▏     | 469/1120 [08:05<11:46,  1.09s/it] 42%|████▏     | 470/1120 [08:06<11:20,  1.05s/it]                                                   42%|████▏     | 470/1120 [08:06<11:20,  1.05s/it] 42%|████▏     | 471/1120 [08:07<10:23,  1.04it/s] 42%|████▏     | 472/1120 [08:08<09:45,  1.11it/s] 42%|████▏     | 473/1120 [08:09<10:35,  1.02it/s] 42%|████▏     | 474/1120 [08:10<10:18,  1.05it/s] 42%|████▏     | 475/1120 [08:11<09:54,  1.08it/s] 42%|████▎     | 476/1120 [08:12<09:43,  1.10it/s] 43%|████▎     | 477/1120 [08:13<10:54,  1.02s/it] 43%|████▎     | 478/1120 [08:14<10:01,  1.07it/s] 43%|████▎     | 479/1120 [08:15<10:24,  1.03it/s] 43%|████▎     | 480/1120 [08:15<09:36,  1.11it/s]                                                   43%|████▎     | 480/1120 [08:16<09:36,  1.11it/s]{'eval_loss': 0.09509440511465073, 'eval_runtime': 3.8662, 'eval_samples_per_second': 25.865, 'eval_steps_per_second': 3.362, 'epoch': 3.91}
外层迭代结束！
外层迭代结束！
{'loss': 0.0869, 'learning_rate': 0.0001878504672897196, 'epoch': 4.0}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0197, 'learning_rate': 0.0001850467289719626, 'epoch': 4.09}
外层迭代结束！
外层迭代结束！
{'loss': 0.0559, 'learning_rate': 0.00018224299065420558, 'epoch': 4.18}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0586, 'learning_rate': 0.00017943925233644857, 'epoch': 4.27}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.00it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.18it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.46it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.98it/s][A                                                  
                                               [A 43%|████▎     | 480/1120 [08:20<09:36,  1.11it/s]
100%|██████████| 13/13 [00:03<00:00,  3.98it/s][A
                                               [A 43%|████▎     | 481/1120 [08:21<23:02,  2.16s/it] 43%|████▎     | 482/1120 [08:22<19:13,  1.81s/it] 43%|████▎     | 483/1120 [08:22<16:18,  1.54s/it] 43%|████▎     | 484/1120 [08:23<13:48,  1.30s/it] 43%|████▎     | 485/1120 [08:24<13:27,  1.27s/it] 43%|████▎     | 486/1120 [08:25<11:48,  1.12s/it] 43%|████▎     | 487/1120 [08:26<11:07,  1.06s/it] 44%|████▎     | 488/1120 [08:27<10:49,  1.03s/it] 44%|████▎     | 489/1120 [08:28<10:51,  1.03s/it] 44%|████▍     | 490/1120 [08:29<10:53,  1.04s/it]                                                   44%|████▍     | 490/1120 [08:29<10:53,  1.04s/it] 44%|████▍     | 491/1120 [08:30<10:37,  1.01s/it] 44%|████▍     | 492/1120 [08:31<10:30,  1.00s/it] 44%|████▍     | 493/1120 [08:32<10:38,  1.02s/it] 44%|████▍     | 494/1120 [08:33<10:01,  1.04it/s] 44%|████▍     | 495/1120 [08:34<10:28,  1.01s/it] 44%|████▍     | 496/1120 [08:35<09:29,  1.10it/s] 44%|████▍     | 497/1120 [08:36<09:29,  1.09it/s] 44%|████▍     | 498/1120 [08:36<08:52,  1.17it/s] 45%|████▍     | 499/1120 [08:37<08:46,  1.18it/s] 45%|████▍     | 500/1120 [08:38<09:20,  1.11it/s]                                                   45%|████▍     | 500/1120 [08:39<09:20,  1.11it/s] 45%|████▍     | 501/1120 [08:40<10:35,  1.03s/it] 45%|████▍     | 502/1120 [08:40<09:31,  1.08it/s] 45%|████▍     | 503/1120 [08:41<09:44,  1.06it/s] 45%|████▌     | 504/1120 [08:42<09:20,  1.10it/s] 45%|████▌     | 505/1120 [08:43<10:32,  1.03s/it] 45%|████▌     | 506/1120 [08:44<09:36,  1.07it/s] 45%|████▌     | 507/1120 [08:45<09:50,  1.04it/s] 45%|████▌     | 508/1120 [08:46<09:39,  1.06it/s] 45%|████▌     | 509/1120 [08:47<10:15,  1.01s/it] 46%|████▌     | 510/1120 [08:48<10:30,  1.03s/it]                                                   46%|████▌     | 510/1120 [08:48<10:30,  1.03s/it] 46%|████▌     | 511/1120 [08:49<09:39,  1.05it/s] 46%|████▌     | 512/1120 [08:50<09:11,  1.10it/s] 46%|████▌     | 513/1120 [08:51<09:46,  1.03it/s] 46%|████▌     | 514/1120 [08:52<09:41,  1.04it/s] 46%|████▌     | 515/1120 [08:53<09:14,  1.09it/s] 46%|████▌     | 516/1120 [08:54<08:49,  1.14it/s] 46%|████▌     | 517/1120 [08:55<09:24,  1.07it/s] 46%|████▋     | 518/1120 [08:55<09:02,  1.11it/s] 46%|████▋     | 519/1120 [08:56<09:19,  1.07it/s] 46%|████▋     | 520/1120 [08:57<08:44,  1.14it/s]                                                   46%|████▋     | 520/1120 [08:57<08:44,  1.14it/s]{'eval_loss': 0.10246836394071579, 'eval_runtime': 3.8676, 'eval_samples_per_second': 25.856, 'eval_steps_per_second': 3.361, 'epoch': 4.27}
外层迭代结束！
外层迭代结束！
{'loss': 0.0281, 'learning_rate': 0.00017663551401869156, 'epoch': 4.36}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0714, 'learning_rate': 0.00017383177570093455, 'epoch': 4.44}
外层迭代结束！
外层迭代结束！
{'loss': 0.0242, 'learning_rate': 0.00017102803738317754, 'epoch': 4.53}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0211, 'learning_rate': 0.00016822429906542053, 'epoch': 4.62}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.01it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.98it/s][A                                                  
                                               [A 46%|████▋     | 520/1120 [09:01<08:44,  1.14it/s]
100%|██████████| 13/13 [00:03<00:00,  3.98it/s][A
                                               [A 47%|████▋     | 521/1120 [09:02<21:17,  2.13s/it] 47%|████▋     | 522/1120 [09:03<17:12,  1.73s/it] 47%|████▋     | 523/1120 [09:04<14:33,  1.46s/it] 47%|████▋     | 524/1120 [09:05<12:55,  1.30s/it] 47%|████▋     | 525/1120 [09:06<12:23,  1.25s/it] 47%|████▋     | 526/1120 [09:07<11:24,  1.15s/it] 47%|████▋     | 527/1120 [09:08<11:32,  1.17s/it] 47%|████▋     | 528/1120 [09:09<10:14,  1.04s/it] 47%|████▋     | 529/1120 [09:10<09:57,  1.01s/it] 47%|████▋     | 530/1120 [09:11<09:47,  1.00it/s]                                                   47%|████▋     | 530/1120 [09:11<09:47,  1.00it/s] 47%|████▋     | 531/1120 [09:12<09:44,  1.01it/s] 48%|████▊     | 532/1120 [09:13<09:20,  1.05it/s] 48%|████▊     | 533/1120 [09:14<10:14,  1.05s/it] 48%|████▊     | 534/1120 [09:15<09:31,  1.03it/s] 48%|████▊     | 535/1120 [09:15<09:03,  1.08it/s] 48%|████▊     | 536/1120 [09:16<08:44,  1.11it/s] 48%|████▊     | 537/1120 [09:17<08:49,  1.10it/s] 48%|████▊     | 538/1120 [09:18<08:22,  1.16it/s] 48%|████▊     | 539/1120 [09:19<08:33,  1.13it/s] 48%|████▊     | 540/1120 [09:20<09:08,  1.06it/s]                                                   48%|████▊     | 540/1120 [09:20<09:08,  1.06it/s] 48%|████▊     | 541/1120 [09:21<09:13,  1.05it/s] 48%|████▊     | 542/1120 [09:22<08:39,  1.11it/s] 48%|████▊     | 543/1120 [09:23<08:48,  1.09it/s] 49%|████▊     | 544/1120 [09:24<08:55,  1.08it/s] 49%|████▊     | 545/1120 [09:25<09:03,  1.06it/s] 49%|████▉     | 546/1120 [09:25<08:29,  1.13it/s] 49%|████▉     | 547/1120 [09:26<08:18,  1.15it/s] 49%|████▉     | 548/1120 [09:27<08:21,  1.14it/s] 49%|████▉     | 549/1120 [09:28<09:37,  1.01s/it] 49%|████▉     | 550/1120 [09:29<08:45,  1.08it/s]                                                   49%|████▉     | 550/1120 [09:29<08:45,  1.08it/s] 49%|████▉     | 551/1120 [09:30<08:31,  1.11it/s] 49%|████▉     | 552/1120 [09:31<08:21,  1.13it/s] 49%|████▉     | 553/1120 [09:32<08:41,  1.09it/s] 49%|████▉     | 554/1120 [09:33<08:10,  1.15it/s] 50%|████▉     | 555/1120 [09:33<08:18,  1.13it/s] 50%|████▉     | 556/1120 [09:34<08:30,  1.10it/s] 50%|████▉     | 557/1120 [09:35<08:58,  1.05it/s] 50%|████▉     | 558/1120 [09:36<08:53,  1.05it/s] 50%|████▉     | 559/1120 [09:37<08:39,  1.08it/s] 50%|█████     | 560/1120 [09:38<08:35,  1.09it/s]                                                   50%|█████     | 560/1120 [09:38<08:35,  1.09it/s]{'eval_loss': 0.11102917045354843, 'eval_runtime': 3.8679, 'eval_samples_per_second': 25.854, 'eval_steps_per_second': 3.361, 'epoch': 4.62}
外层迭代结束！
外层迭代结束！
{'loss': 0.0229, 'learning_rate': 0.00016542056074766352, 'epoch': 4.71}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0318, 'learning_rate': 0.00016261682242990652, 'epoch': 4.8}
外层迭代结束！
外层迭代结束！
{'loss': 0.0629, 'learning_rate': 0.0001598130841121495, 'epoch': 4.89}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0078, 'learning_rate': 0.0001570093457943925, 'epoch': 4.98}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.00it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.47it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.42it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.98it/s][A                                                  
                                               [A 50%|█████     | 560/1120 [09:42<08:35,  1.09it/s]
100%|██████████| 13/13 [00:03<00:00,  3.98it/s][A
                                               [A 50%|█████     | 561/1120 [09:44<20:56,  2.25s/it] 50%|█████     | 562/1120 [09:44<17:07,  1.84s/it] 50%|█████     | 563/1120 [09:45<14:12,  1.53s/it] 50%|█████     | 564/1120 [09:46<12:27,  1.34s/it] 50%|█████     | 565/1120 [09:47<11:38,  1.26s/it] 51%|█████     | 566/1120 [09:48<10:54,  1.18s/it] 51%|█████     | 567/1120 [09:49<09:42,  1.05s/it] 51%|█████     | 568/1120 [09:50<09:26,  1.03s/it] 51%|█████     | 569/1120 [09:51<09:19,  1.01s/it] 51%|█████     | 570/1120 [09:52<09:36,  1.05s/it]                                                   51%|█████     | 570/1120 [09:52<09:36,  1.05s/it] 51%|█████     | 571/1120 [09:53<08:59,  1.02it/s] 51%|█████     | 572/1120 [09:54<08:51,  1.03it/s] 51%|█████     | 573/1120 [09:55<09:06,  1.00it/s] 51%|█████▏    | 574/1120 [09:56<08:43,  1.04it/s] 51%|█████▏    | 575/1120 [09:56<08:07,  1.12it/s] 51%|█████▏    | 576/1120 [09:57<07:58,  1.14it/s] 52%|█████▏    | 577/1120 [09:58<08:15,  1.10it/s] 52%|█████▏    | 578/1120 [09:59<07:44,  1.17it/s] 52%|█████▏    | 579/1120 [10:00<08:01,  1.12it/s] 52%|█████▏    | 580/1120 [10:01<08:09,  1.10it/s]                                                   52%|█████▏    | 580/1120 [10:01<08:09,  1.10it/s] 52%|█████▏    | 581/1120 [10:02<08:22,  1.07it/s] 52%|█████▏    | 582/1120 [10:03<08:10,  1.10it/s] 52%|█████▏    | 583/1120 [10:04<07:38,  1.17it/s] 52%|█████▏    | 584/1120 [10:04<07:39,  1.17it/s] 52%|█████▏    | 585/1120 [10:05<08:13,  1.08it/s] 52%|█████▏    | 586/1120 [10:06<08:15,  1.08it/s] 52%|█████▏    | 587/1120 [10:07<07:51,  1.13it/s] 52%|█████▎    | 588/1120 [10:08<07:37,  1.16it/s] 53%|█████▎    | 589/1120 [10:09<08:43,  1.01it/s] 53%|█████▎    | 590/1120 [10:10<08:53,  1.01s/it]                                                   53%|█████▎    | 590/1120 [10:10<08:53,  1.01s/it] 53%|█████▎    | 591/1120 [10:11<08:15,  1.07it/s] 53%|█████▎    | 592/1120 [10:12<08:10,  1.08it/s] 53%|█████▎    | 593/1120 [10:13<08:38,  1.02it/s] 53%|█████▎    | 594/1120 [10:14<08:19,  1.05it/s] 53%|█████▎    | 595/1120 [10:15<08:36,  1.02it/s] 53%|█████▎    | 596/1120 [10:16<09:14,  1.06s/it] 53%|█████▎    | 597/1120 [10:17<09:08,  1.05s/it] 53%|█████▎    | 598/1120 [10:18<09:12,  1.06s/it] 53%|█████▎    | 599/1120 [10:19<09:10,  1.06s/it] 54%|█████▎    | 600/1120 [10:20<08:27,  1.02it/s]                                                   54%|█████▎    | 600/1120 [10:20<08:27,  1.02it/s]{'eval_loss': 0.13587169349193573, 'eval_runtime': 3.8684, 'eval_samples_per_second': 25.85, 'eval_steps_per_second': 3.361, 'epoch': 4.98}
外层迭代结束！
外层迭代结束！
{'loss': 0.0392, 'learning_rate': 0.0001542056074766355, 'epoch': 5.07}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0257, 'learning_rate': 0.00015140186915887848, 'epoch': 5.16}
外层迭代结束！
外层迭代结束！
{'loss': 0.0203, 'learning_rate': 0.00014859813084112147, 'epoch': 5.24}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0291, 'learning_rate': 0.00014579439252336446, 'epoch': 5.33}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.00it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.74it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.99it/s][A                                                  
                                               [A 54%|█████▎    | 600/1120 [10:24<08:27,  1.02it/s]
100%|██████████| 13/13 [00:03<00:00,  3.99it/s][A
                                               [A 54%|█████▎    | 601/1120 [10:25<18:57,  2.19s/it] 54%|█████▍    | 602/1120 [10:26<15:06,  1.75s/it] 54%|█████▍    | 603/1120 [10:27<12:58,  1.51s/it] 54%|█████▍    | 604/1120 [10:28<10:52,  1.26s/it] 54%|█████▍    | 605/1120 [10:29<10:25,  1.22s/it] 54%|█████▍    | 606/1120 [10:30<09:26,  1.10s/it] 54%|█████▍    | 607/1120 [10:30<08:46,  1.03s/it] 54%|█████▍    | 608/1120 [10:31<08:47,  1.03s/it] 54%|█████▍    | 609/1120 [10:33<09:20,  1.10s/it] 54%|█████▍    | 610/1120 [10:33<08:24,  1.01it/s]                                                   54%|█████▍    | 610/1120 [10:33<08:24,  1.01it/s] 55%|█████▍    | 611/1120 [10:34<07:49,  1.08it/s] 55%|█████▍    | 612/1120 [10:35<07:43,  1.10it/s] 55%|█████▍    | 613/1120 [10:36<08:03,  1.05it/s] 55%|█████▍    | 614/1120 [10:37<07:50,  1.08it/s] 55%|█████▍    | 615/1120 [10:38<07:30,  1.12it/s] 55%|█████▌    | 616/1120 [10:39<07:52,  1.07it/s] 55%|█████▌    | 617/1120 [10:40<07:55,  1.06it/s] 55%|█████▌    | 618/1120 [10:41<08:08,  1.03it/s] 55%|█████▌    | 619/1120 [10:42<08:21,  1.00s/it] 55%|█████▌    | 620/1120 [10:43<07:55,  1.05it/s]                                                   55%|█████▌    | 620/1120 [10:43<07:55,  1.05it/s] 55%|█████▌    | 621/1120 [10:44<07:51,  1.06it/s] 56%|█████▌    | 622/1120 [10:45<07:29,  1.11it/s] 56%|█████▌    | 623/1120 [10:45<07:22,  1.12it/s] 56%|█████▌    | 624/1120 [10:46<07:40,  1.08it/s] 56%|█████▌    | 625/1120 [10:47<07:52,  1.05it/s] 56%|█████▌    | 626/1120 [10:48<07:39,  1.08it/s] 56%|█████▌    | 627/1120 [10:49<07:58,  1.03it/s] 56%|█████▌    | 628/1120 [10:50<07:27,  1.10it/s] 56%|█████▌    | 629/1120 [10:51<08:03,  1.02it/s] 56%|█████▋    | 630/1120 [10:52<07:38,  1.07it/s]                                                   56%|█████▋    | 630/1120 [10:52<07:38,  1.07it/s] 56%|█████▋    | 631/1120 [10:53<07:03,  1.15it/s] 56%|█████▋    | 632/1120 [10:54<07:27,  1.09it/s] 57%|█████▋    | 633/1120 [10:55<07:39,  1.06it/s] 57%|█████▋    | 634/1120 [10:56<07:28,  1.08it/s] 57%|█████▋    | 635/1120 [10:56<06:57,  1.16it/s] 57%|█████▋    | 636/1120 [10:57<07:14,  1.11it/s] 57%|█████▋    | 637/1120 [10:59<07:55,  1.02it/s] 57%|█████▋    | 638/1120 [11:00<07:43,  1.04it/s] 57%|█████▋    | 639/1120 [11:00<07:17,  1.10it/s] 57%|█████▋    | 640/1120 [11:01<07:40,  1.04it/s]                                                   57%|█████▋    | 640/1120 [11:02<07:40,  1.04it/s]{'eval_loss': 0.14206834137439728, 'eval_runtime': 3.8668, 'eval_samples_per_second': 25.861, 'eval_steps_per_second': 3.362, 'epoch': 5.33}
外层迭代结束！
外层迭代结束！
{'loss': 0.0877, 'learning_rate': 0.00014299065420560745, 'epoch': 5.42}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0058, 'learning_rate': 0.00014018691588785044, 'epoch': 5.51}
外层迭代结束！
外层迭代结束！
{'loss': 0.0496, 'learning_rate': 0.00013738317757009343, 'epoch': 5.6}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.008, 'learning_rate': 0.00013457943925233642, 'epoch': 5.69}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.00it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.74it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.99it/s][A                                                  
                                               [A 57%|█████▋    | 640/1120 [11:05<07:40,  1.04it/s]
100%|██████████| 13/13 [00:03<00:00,  3.99it/s][A
                                               [A 57%|█████▋    | 641/1120 [11:07<17:50,  2.24s/it] 57%|█████▋    | 642/1120 [11:07<14:32,  1.82s/it] 57%|█████▋    | 643/1120 [11:08<12:08,  1.53s/it] 57%|█████▊    | 644/1120 [11:09<10:33,  1.33s/it] 58%|█████▊    | 645/1120 [11:10<10:05,  1.27s/it] 58%|█████▊    | 646/1120 [11:11<08:46,  1.11s/it] 58%|█████▊    | 647/1120 [11:12<08:07,  1.03s/it] 58%|█████▊    | 648/1120 [11:13<07:57,  1.01s/it] 58%|█████▊    | 649/1120 [11:14<07:45,  1.01it/s] 58%|█████▊    | 650/1120 [11:15<07:42,  1.02it/s]                                                   58%|█████▊    | 650/1120 [11:15<07:42,  1.02it/s] 58%|█████▊    | 651/1120 [11:15<07:05,  1.10it/s] 58%|█████▊    | 652/1120 [11:16<07:03,  1.11it/s] 58%|█████▊    | 653/1120 [11:17<07:20,  1.06it/s] 58%|█████▊    | 654/1120 [11:18<06:50,  1.14it/s] 58%|█████▊    | 655/1120 [11:19<07:09,  1.08it/s] 59%|█████▊    | 656/1120 [11:20<06:46,  1.14it/s] 59%|█████▊    | 657/1120 [11:21<07:19,  1.05it/s] 59%|█████▉    | 658/1120 [11:22<07:20,  1.05it/s] 59%|█████▉    | 659/1120 [11:23<07:16,  1.06it/s] 59%|█████▉    | 660/1120 [11:24<06:48,  1.13it/s]                                                   59%|█████▉    | 660/1120 [11:24<06:48,  1.13it/s] 59%|█████▉    | 661/1120 [11:25<07:16,  1.05it/s] 59%|█████▉    | 662/1120 [11:26<07:03,  1.08it/s] 59%|█████▉    | 663/1120 [11:27<06:57,  1.09it/s] 59%|█████▉    | 664/1120 [11:27<06:38,  1.14it/s] 59%|█████▉    | 665/1120 [11:28<06:58,  1.09it/s] 59%|█████▉    | 666/1120 [11:29<06:59,  1.08it/s] 60%|█████▉    | 667/1120 [11:30<06:59,  1.08it/s] 60%|█████▉    | 668/1120 [11:31<07:10,  1.05it/s] 60%|█████▉    | 669/1120 [11:32<07:10,  1.05it/s] 60%|█████▉    | 670/1120 [11:33<07:35,  1.01s/it]                                                   60%|█████▉    | 670/1120 [11:33<07:35,  1.01s/it] 60%|█████▉    | 671/1120 [11:34<07:11,  1.04it/s] 60%|██████    | 672/1120 [11:35<07:03,  1.06it/s] 60%|██████    | 673/1120 [11:36<07:24,  1.01it/s] 60%|██████    | 674/1120 [11:37<07:13,  1.03it/s] 60%|██████    | 675/1120 [11:38<06:46,  1.10it/s] 60%|██████    | 676/1120 [11:39<06:24,  1.16it/s] 60%|██████    | 677/1120 [11:40<07:03,  1.05it/s] 61%|██████    | 678/1120 [11:41<06:34,  1.12it/s] 61%|██████    | 679/1120 [11:42<06:38,  1.11it/s] 61%|██████    | 680/1120 [11:43<06:54,  1.06it/s]                                                   61%|██████    | 680/1120 [11:43<06:54,  1.06it/s]{'eval_loss': 0.14375001192092896, 'eval_runtime': 3.8654, 'eval_samples_per_second': 25.87, 'eval_steps_per_second': 3.363, 'epoch': 5.69}
外层迭代结束！
外层迭代结束！
{'loss': 0.0371, 'learning_rate': 0.0001317757009345794, 'epoch': 5.78}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0442, 'learning_rate': 0.0001289719626168224, 'epoch': 5.87}
外层迭代结束！
外层迭代结束！
{'loss': 0.081, 'learning_rate': 0.0001261682242990654, 'epoch': 5.96}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0384, 'learning_rate': 0.00012336448598130838, 'epoch': 6.04}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.00it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.98it/s][A                                                  
                                               [A 61%|██████    | 680/1120 [11:47<06:54,  1.06it/s]
100%|██████████| 13/13 [00:03<00:00,  3.98it/s][A
                                               [A 61%|██████    | 681/1120 [11:48<15:55,  2.18s/it] 61%|██████    | 682/1120 [11:49<13:22,  1.83s/it] 61%|██████    | 683/1120 [11:50<11:34,  1.59s/it] 61%|██████    | 684/1120 [11:51<10:09,  1.40s/it] 61%|██████    | 685/1120 [11:52<09:34,  1.32s/it] 61%|██████▏   | 686/1120 [11:53<08:25,  1.16s/it] 61%|██████▏   | 687/1120 [11:53<07:55,  1.10s/it] 61%|██████▏   | 688/1120 [11:54<07:35,  1.05s/it] 62%|██████▏   | 689/1120 [11:55<07:31,  1.05s/it] 62%|██████▏   | 690/1120 [11:57<07:31,  1.05s/it]                                                   62%|██████▏   | 690/1120 [11:57<07:31,  1.05s/it] 62%|██████▏   | 691/1120 [11:57<06:52,  1.04it/s] 62%|██████▏   | 692/1120 [11:58<06:39,  1.07it/s] 62%|██████▏   | 693/1120 [11:59<07:22,  1.04s/it] 62%|██████▏   | 694/1120 [12:00<07:24,  1.04s/it] 62%|██████▏   | 695/1120 [12:01<07:00,  1.01it/s] 62%|██████▏   | 696/1120 [12:02<07:15,  1.03s/it] 62%|██████▏   | 697/1120 [12:04<08:01,  1.14s/it] 62%|██████▏   | 698/1120 [12:05<07:39,  1.09s/it] 62%|██████▏   | 699/1120 [12:06<07:20,  1.05s/it] 62%|██████▎   | 700/1120 [12:07<07:01,  1.00s/it]                                                   62%|██████▎   | 700/1120 [12:07<07:01,  1.00s/it] 63%|██████▎   | 701/1120 [12:08<07:27,  1.07s/it] 63%|██████▎   | 702/1120 [12:09<07:00,  1.01s/it] 63%|██████▎   | 703/1120 [12:10<06:28,  1.07it/s] 63%|██████▎   | 704/1120 [12:10<06:04,  1.14it/s] 63%|██████▎   | 705/1120 [12:11<06:42,  1.03it/s] 63%|██████▎   | 706/1120 [12:12<06:39,  1.04it/s] 63%|██████▎   | 707/1120 [12:13<06:34,  1.05it/s] 63%|██████▎   | 708/1120 [12:14<06:22,  1.08it/s] 63%|██████▎   | 709/1120 [12:15<06:42,  1.02it/s] 63%|██████▎   | 710/1120 [12:16<06:26,  1.06it/s]                                                   63%|██████▎   | 710/1120 [12:16<06:26,  1.06it/s] 63%|██████▎   | 711/1120 [12:17<06:16,  1.09it/s] 64%|██████▎   | 712/1120 [12:18<06:16,  1.08it/s] 64%|██████▎   | 713/1120 [12:19<06:35,  1.03it/s] 64%|██████▍   | 714/1120 [12:20<06:18,  1.07it/s] 64%|██████▍   | 715/1120 [12:21<05:49,  1.16it/s] 64%|██████▍   | 716/1120 [12:22<05:57,  1.13it/s] 64%|██████▍   | 717/1120 [12:23<06:58,  1.04s/it] 64%|██████▍   | 718/1120 [12:24<06:48,  1.02s/it] 64%|██████▍   | 719/1120 [12:25<06:18,  1.06it/s] 64%|██████▍   | 720/1120 [12:26<06:14,  1.07it/s]                                                   64%|██████▍   | 720/1120 [12:26<06:14,  1.07it/s]{'eval_loss': 0.14292040467262268, 'eval_runtime': 3.8685, 'eval_samples_per_second': 25.85, 'eval_steps_per_second': 3.36, 'epoch': 6.04}
外层迭代结束！
外层迭代结束！
{'loss': 0.0051, 'learning_rate': 0.00012056074766355139, 'epoch': 6.13}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0046, 'learning_rate': 0.00011775700934579438, 'epoch': 6.22}
外层迭代结束！
外层迭代结束！
{'loss': 0.0146, 'learning_rate': 0.00011495327102803737, 'epoch': 6.31}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0131, 'learning_rate': 0.00011214953271028036, 'epoch': 6.4}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.00it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.47it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.98it/s][A                                                  
                                               [A 64%|██████▍   | 720/1120 [12:30<06:14,  1.07it/s]
100%|██████████| 13/13 [00:03<00:00,  3.98it/s][A
                                               [A 64%|██████▍   | 721/1120 [12:31<14:24,  2.17s/it] 64%|██████▍   | 722/1120 [12:32<12:14,  1.85s/it] 65%|██████▍   | 723/1120 [12:33<10:17,  1.56s/it] 65%|██████▍   | 724/1120 [12:33<08:43,  1.32s/it] 65%|██████▍   | 725/1120 [12:34<07:57,  1.21s/it] 65%|██████▍   | 726/1120 [12:35<07:04,  1.08s/it] 65%|██████▍   | 727/1120 [12:36<07:07,  1.09s/it] 65%|██████▌   | 728/1120 [12:37<06:34,  1.01s/it] 65%|██████▌   | 729/1120 [12:38<06:43,  1.03s/it] 65%|██████▌   | 730/1120 [12:39<06:04,  1.07it/s]                                                   65%|██████▌   | 730/1120 [12:39<06:04,  1.07it/s] 65%|██████▌   | 731/1120 [12:40<05:52,  1.10it/s] 65%|██████▌   | 732/1120 [12:41<05:55,  1.09it/s] 65%|██████▌   | 733/1120 [12:42<06:26,  1.00it/s] 66%|██████▌   | 734/1120 [12:43<06:05,  1.06it/s] 66%|██████▌   | 735/1120 [12:44<06:01,  1.06it/s] 66%|██████▌   | 736/1120 [12:44<05:48,  1.10it/s] 66%|██████▌   | 737/1120 [12:45<06:05,  1.05it/s] 66%|██████▌   | 738/1120 [12:46<06:05,  1.05it/s] 66%|██████▌   | 739/1120 [12:47<05:56,  1.07it/s] 66%|██████▌   | 740/1120 [12:48<05:47,  1.09it/s]                                                   66%|██████▌   | 740/1120 [12:48<05:47,  1.09it/s] 66%|██████▌   | 741/1120 [12:49<05:51,  1.08it/s] 66%|██████▋   | 742/1120 [12:50<05:34,  1.13it/s] 66%|██████▋   | 743/1120 [12:51<05:51,  1.07it/s] 66%|██████▋   | 744/1120 [12:52<05:43,  1.09it/s] 67%|██████▋   | 745/1120 [12:53<06:11,  1.01it/s] 67%|██████▋   | 746/1120 [12:54<05:43,  1.09it/s] 67%|██████▋   | 747/1120 [12:55<05:47,  1.07it/s] 67%|██████▋   | 748/1120 [12:55<05:27,  1.14it/s] 67%|██████▋   | 749/1120 [12:56<05:42,  1.08it/s] 67%|██████▋   | 750/1120 [12:57<05:41,  1.08it/s]                                                   67%|██████▋   | 750/1120 [12:57<05:41,  1.08it/s] 67%|██████▋   | 751/1120 [12:58<05:22,  1.14it/s] 67%|██████▋   | 752/1120 [12:59<05:20,  1.15it/s] 67%|██████▋   | 753/1120 [13:00<05:34,  1.10it/s] 67%|██████▋   | 754/1120 [13:01<05:19,  1.15it/s] 67%|██████▋   | 755/1120 [13:02<05:18,  1.14it/s] 68%|██████▊   | 756/1120 [13:02<05:14,  1.16it/s] 68%|██████▊   | 757/1120 [13:04<06:16,  1.04s/it] 68%|██████▊   | 758/1120 [13:05<05:59,  1.01it/s] 68%|██████▊   | 759/1120 [13:06<05:55,  1.02it/s] 68%|██████▊   | 760/1120 [13:07<05:47,  1.04it/s]                                                   68%|██████▊   | 760/1120 [13:07<05:47,  1.04it/s]{'eval_loss': 0.1439341902732849, 'eval_runtime': 3.8683, 'eval_samples_per_second': 25.851, 'eval_steps_per_second': 3.361, 'epoch': 6.4}
外层迭代结束！
外层迭代结束！
{'loss': 0.0239, 'learning_rate': 0.00010934579439252335, 'epoch': 6.49}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.005, 'learning_rate': 0.00010654205607476634, 'epoch': 6.58}
外层迭代结束！
外层迭代结束！
{'loss': 0.1251, 'learning_rate': 0.00010373831775700933, 'epoch': 6.67}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0737, 'learning_rate': 0.00010093457943925232, 'epoch': 6.76}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.00it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.99it/s][A                                                  
                                               [A 68%|██████▊   | 760/1120 [13:11<05:47,  1.04it/s]
100%|██████████| 13/13 [00:03<00:00,  3.99it/s][A
                                               [A 68%|██████▊   | 761/1120 [13:12<13:30,  2.26s/it] 68%|██████▊   | 762/1120 [13:13<10:49,  1.81s/it] 68%|██████▊   | 763/1120 [13:14<09:02,  1.52s/it] 68%|██████▊   | 764/1120 [13:14<07:37,  1.28s/it] 68%|██████▊   | 765/1120 [13:15<07:11,  1.21s/it] 68%|██████▊   | 766/1120 [13:16<06:41,  1.13s/it] 68%|██████▊   | 767/1120 [13:17<06:11,  1.05s/it] 69%|██████▊   | 768/1120 [13:18<05:51,  1.00it/s] 69%|██████▊   | 769/1120 [13:19<06:10,  1.05s/it] 69%|██████▉   | 770/1120 [13:20<05:52,  1.01s/it]                                                   69%|██████▉   | 770/1120 [13:20<05:52,  1.01s/it] 69%|██████▉   | 771/1120 [13:21<05:35,  1.04it/s] 69%|██████▉   | 772/1120 [13:22<05:36,  1.03it/s] 69%|██████▉   | 773/1120 [13:23<05:55,  1.02s/it] 69%|██████▉   | 774/1120 [13:24<05:32,  1.04it/s] 69%|██████▉   | 775/1120 [13:25<05:27,  1.05it/s] 69%|██████▉   | 776/1120 [13:26<05:45,  1.01s/it] 69%|██████▉   | 777/1120 [13:27<05:58,  1.05s/it] 69%|██████▉   | 778/1120 [13:28<05:28,  1.04it/s] 70%|██████▉   | 779/1120 [13:29<05:12,  1.09it/s] 70%|██████▉   | 780/1120 [13:30<05:19,  1.07it/s]                                                   70%|██████▉   | 780/1120 [13:30<05:19,  1.07it/s] 70%|██████▉   | 781/1120 [13:31<05:35,  1.01it/s] 70%|██████▉   | 782/1120 [13:32<05:22,  1.05it/s] 70%|██████▉   | 783/1120 [13:33<05:13,  1.07it/s] 70%|███████   | 784/1120 [13:34<05:25,  1.03it/s] 70%|███████   | 785/1120 [13:35<05:47,  1.04s/it] 70%|███████   | 786/1120 [13:36<05:32,  1.00it/s] 70%|███████   | 787/1120 [13:37<05:27,  1.02it/s] 70%|███████   | 788/1120 [13:38<05:09,  1.07it/s] 70%|███████   | 789/1120 [13:39<05:50,  1.06s/it] 71%|███████   | 790/1120 [13:40<05:19,  1.03it/s]                                                   71%|███████   | 790/1120 [13:40<05:19,  1.03it/s] 71%|███████   | 791/1120 [13:41<05:29,  1.00s/it] 71%|███████   | 792/1120 [13:41<05:07,  1.07it/s] 71%|███████   | 793/1120 [13:43<05:16,  1.03it/s] 71%|███████   | 794/1120 [13:43<05:05,  1.07it/s] 71%|███████   | 795/1120 [13:44<04:48,  1.13it/s] 71%|███████   | 796/1120 [13:45<04:35,  1.18it/s] 71%|███████   | 797/1120 [13:46<04:52,  1.10it/s] 71%|███████▏  | 798/1120 [13:47<04:33,  1.18it/s] 71%|███████▏  | 799/1120 [13:48<04:32,  1.18it/s] 71%|███████▏  | 800/1120 [13:48<04:25,  1.20it/s]                                                   71%|███████▏  | 800/1120 [13:49<04:25,  1.20it/s]{'eval_loss': 0.14443743228912354, 'eval_runtime': 3.8659, 'eval_samples_per_second': 25.867, 'eval_steps_per_second': 3.363, 'epoch': 6.76}
外层迭代结束！
外层迭代结束！
{'loss': 0.0118, 'learning_rate': 9.813084112149531e-05, 'epoch': 6.84}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0083, 'learning_rate': 9.53271028037383e-05, 'epoch': 6.93}
外层迭代结束！
外层迭代结束！
{'loss': 0.0644, 'learning_rate': 9.25233644859813e-05, 'epoch': 7.02}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0023, 'learning_rate': 8.971962616822429e-05, 'epoch': 7.11}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.00it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.74it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.10it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.47it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.99it/s][A                                                  
                                               [A 71%|███████▏  | 800/1120 [13:52<04:25,  1.20it/s]
100%|██████████| 13/13 [00:03<00:00,  3.99it/s][A
                                               [A 72%|███████▏  | 801/1120 [13:53<11:01,  2.07s/it] 72%|███████▏  | 802/1120 [13:54<09:27,  1.78s/it] 72%|███████▏  | 803/1120 [13:55<08:02,  1.52s/it] 72%|███████▏  | 804/1120 [13:56<06:56,  1.32s/it] 72%|███████▏  | 805/1120 [13:57<06:35,  1.26s/it] 72%|███████▏  | 806/1120 [13:58<06:28,  1.24s/it] 72%|███████▏  | 807/1120 [13:59<05:42,  1.09s/it] 72%|███████▏  | 808/1120 [14:00<05:16,  1.01s/it] 72%|███████▏  | 809/1120 [14:01<05:17,  1.02s/it] 72%|███████▏  | 810/1120 [14:02<04:47,  1.08it/s]                                                   72%|███████▏  | 810/1120 [14:02<04:47,  1.08it/s] 72%|███████▏  | 811/1120 [14:03<04:32,  1.13it/s] 72%|███████▎  | 812/1120 [14:03<04:36,  1.11it/s] 73%|███████▎  | 813/1120 [14:05<05:04,  1.01it/s] 73%|███████▎  | 814/1120 [14:06<04:54,  1.04it/s] 73%|███████▎  | 815/1120 [14:06<04:46,  1.06it/s] 73%|███████▎  | 816/1120 [14:07<04:28,  1.13it/s] 73%|███████▎  | 817/1120 [14:09<05:08,  1.02s/it] 73%|███████▎  | 818/1120 [14:09<04:42,  1.07it/s] 73%|███████▎  | 819/1120 [14:10<04:34,  1.10it/s] 73%|███████▎  | 820/1120 [14:11<04:34,  1.09it/s]                                                   73%|███████▎  | 820/1120 [14:11<04:34,  1.09it/s] 73%|███████▎  | 821/1120 [14:12<04:38,  1.07it/s] 73%|███████▎  | 822/1120 [14:13<04:29,  1.11it/s] 73%|███████▎  | 823/1120 [14:14<04:22,  1.13it/s] 74%|███████▎  | 824/1120 [14:15<04:34,  1.08it/s] 74%|███████▎  | 825/1120 [14:16<04:54,  1.00it/s] 74%|███████▍  | 826/1120 [14:17<04:35,  1.07it/s] 74%|███████▍  | 827/1120 [14:18<04:38,  1.05it/s] 74%|███████▍  | 828/1120 [14:19<04:26,  1.10it/s] 74%|███████▍  | 829/1120 [14:20<04:40,  1.04it/s] 74%|███████▍  | 830/1120 [14:20<04:32,  1.06it/s]                                                   74%|███████▍  | 830/1120 [14:20<04:32,  1.06it/s] 74%|███████▍  | 831/1120 [14:21<04:27,  1.08it/s] 74%|███████▍  | 832/1120 [14:22<04:29,  1.07it/s] 74%|███████▍  | 833/1120 [14:23<04:34,  1.05it/s] 74%|███████▍  | 834/1120 [14:24<04:20,  1.10it/s] 75%|███████▍  | 835/1120 [14:25<04:32,  1.04it/s] 75%|███████▍  | 836/1120 [14:26<04:18,  1.10it/s] 75%|███████▍  | 837/1120 [14:27<04:23,  1.07it/s] 75%|███████▍  | 838/1120 [14:28<04:19,  1.08it/s] 75%|███████▍  | 839/1120 [14:29<04:29,  1.04it/s] 75%|███████▌  | 840/1120 [14:30<04:12,  1.11it/s]                                                   75%|███████▌  | 840/1120 [14:30<04:12,  1.11it/s]{'eval_loss': 0.13566181063652039, 'eval_runtime': 3.8652, 'eval_samples_per_second': 25.872, 'eval_steps_per_second': 3.363, 'epoch': 7.11}
外层迭代结束！
外层迭代结束！
{'loss': 0.0289, 'learning_rate': 8.691588785046728e-05, 'epoch': 7.2}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0073, 'learning_rate': 8.411214953271027e-05, 'epoch': 7.29}
外层迭代结束！
外层迭代结束！
{'loss': 0.0033, 'learning_rate': 8.130841121495326e-05, 'epoch': 7.38}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0715, 'learning_rate': 7.850467289719625e-05, 'epoch': 7.47}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.02it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.86it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.47it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.98it/s][A                                                  
                                               [A 75%|███████▌  | 840/1120 [14:34<04:12,  1.11it/s]
100%|██████████| 13/13 [00:03<00:00,  3.98it/s][A
                                               [A 75%|███████▌  | 841/1120 [14:35<10:05,  2.17s/it] 75%|███████▌  | 842/1120 [14:36<08:28,  1.83s/it] 75%|███████▌  | 843/1120 [14:37<07:01,  1.52s/it] 75%|███████▌  | 844/1120 [14:38<06:13,  1.35s/it] 75%|███████▌  | 845/1120 [14:39<05:57,  1.30s/it] 76%|███████▌  | 846/1120 [14:40<05:29,  1.20s/it] 76%|███████▌  | 847/1120 [14:41<05:01,  1.10s/it] 76%|███████▌  | 848/1120 [14:42<05:09,  1.14s/it] 76%|███████▌  | 849/1120 [14:43<05:37,  1.24s/it] 76%|███████▌  | 850/1120 [14:44<05:08,  1.14s/it]                                                   76%|███████▌  | 850/1120 [14:44<05:08,  1.14s/it] 76%|███████▌  | 851/1120 [14:45<04:52,  1.09s/it] 76%|███████▌  | 852/1120 [14:46<04:43,  1.06s/it] 76%|███████▌  | 853/1120 [14:47<04:42,  1.06s/it] 76%|███████▋  | 854/1120 [14:48<04:26,  1.00s/it] 76%|███████▋  | 855/1120 [14:49<04:24,  1.00it/s] 76%|███████▋  | 856/1120 [14:50<04:23,  1.00it/s] 77%|███████▋  | 857/1120 [14:51<04:36,  1.05s/it] 77%|███████▋  | 858/1120 [14:52<04:21,  1.00it/s] 77%|███████▋  | 859/1120 [14:53<04:22,  1.01s/it] 77%|███████▋  | 860/1120 [14:54<04:27,  1.03s/it]                                                   77%|███████▋  | 860/1120 [14:55<04:27,  1.03s/it] 77%|███████▋  | 861/1120 [14:55<04:36,  1.07s/it] 77%|███████▋  | 862/1120 [14:56<04:23,  1.02s/it] 77%|███████▋  | 863/1120 [14:57<04:04,  1.05it/s] 77%|███████▋  | 864/1120 [14:58<04:03,  1.05it/s] 77%|███████▋  | 865/1120 [14:59<04:12,  1.01it/s] 77%|███████▋  | 866/1120 [15:00<04:06,  1.03it/s] 77%|███████▋  | 867/1120 [15:01<04:11,  1.01it/s] 78%|███████▊  | 868/1120 [15:02<03:54,  1.07it/s] 78%|███████▊  | 869/1120 [15:03<04:07,  1.02it/s] 78%|███████▊  | 870/1120 [15:04<03:55,  1.06it/s]                                                   78%|███████▊  | 870/1120 [15:04<03:55,  1.06it/s] 78%|███████▊  | 871/1120 [15:05<04:02,  1.03it/s] 78%|███████▊  | 872/1120 [15:06<03:47,  1.09it/s] 78%|███████▊  | 873/1120 [15:07<03:59,  1.03it/s] 78%|███████▊  | 874/1120 [15:08<03:56,  1.04it/s] 78%|███████▊  | 875/1120 [15:09<03:40,  1.11it/s] 78%|███████▊  | 876/1120 [15:10<03:50,  1.06it/s] 78%|███████▊  | 877/1120 [15:11<04:05,  1.01s/it] 78%|███████▊  | 878/1120 [15:12<04:04,  1.01s/it] 78%|███████▊  | 879/1120 [15:13<03:58,  1.01it/s] 79%|███████▊  | 880/1120 [15:13<03:42,  1.08it/s]                                                   79%|███████▊  | 880/1120 [15:14<03:42,  1.08it/s]{'eval_loss': 0.14106522500514984, 'eval_runtime': 3.8688, 'eval_samples_per_second': 25.848, 'eval_steps_per_second': 3.36, 'epoch': 7.47}
外层迭代结束！
外层迭代结束！
{'loss': 0.0369, 'learning_rate': 7.570093457943924e-05, 'epoch': 7.56}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.008, 'learning_rate': 7.289719626168223e-05, 'epoch': 7.64}
外层迭代结束！
外层迭代结束！
{'loss': 0.0268, 'learning_rate': 7.009345794392522e-05, 'epoch': 7.73}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0011, 'learning_rate': 6.728971962616821e-05, 'epoch': 7.82}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.01it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.99it/s][A                                                  
                                               [A 79%|███████▊  | 880/1120 [15:18<03:42,  1.08it/s]
100%|██████████| 13/13 [00:03<00:00,  3.99it/s][A
                                               [A 79%|███████▊  | 881/1120 [15:18<08:34,  2.15s/it] 79%|███████▉  | 882/1120 [15:19<06:59,  1.76s/it] 79%|███████▉  | 883/1120 [15:20<05:56,  1.51s/it] 79%|███████▉  | 884/1120 [15:21<05:24,  1.38s/it] 79%|███████▉  | 885/1120 [15:23<05:12,  1.33s/it] 79%|███████▉  | 886/1120 [15:23<04:41,  1.20s/it] 79%|███████▉  | 887/1120 [15:24<04:26,  1.14s/it] 79%|███████▉  | 888/1120 [15:25<04:15,  1.10s/it] 79%|███████▉  | 889/1120 [15:27<04:21,  1.13s/it] 79%|███████▉  | 890/1120 [15:28<04:02,  1.05s/it]                                                   79%|███████▉  | 890/1120 [15:28<04:02,  1.05s/it] 80%|███████▉  | 891/1120 [15:28<03:46,  1.01it/s] 80%|███████▉  | 892/1120 [15:29<03:53,  1.02s/it] 80%|███████▉  | 893/1120 [15:31<03:56,  1.04s/it] 80%|███████▉  | 894/1120 [15:31<03:43,  1.01it/s] 80%|███████▉  | 895/1120 [15:32<03:40,  1.02it/s] 80%|████████  | 896/1120 [15:33<03:38,  1.03it/s] 80%|████████  | 897/1120 [15:35<04:01,  1.08s/it] 80%|████████  | 898/1120 [15:36<03:50,  1.04s/it] 80%|████████  | 899/1120 [15:37<03:55,  1.07s/it] 80%|████████  | 900/1120 [15:38<03:35,  1.02it/s]                                                   80%|████████  | 900/1120 [15:38<03:35,  1.02it/s] 80%|████████  | 901/1120 [15:39<03:54,  1.07s/it] 81%|████████  | 902/1120 [15:40<03:46,  1.04s/it] 81%|████████  | 903/1120 [15:41<03:39,  1.01s/it] 81%|████████  | 904/1120 [15:41<03:22,  1.07it/s] 81%|████████  | 905/1120 [15:43<03:32,  1.01it/s] 81%|████████  | 906/1120 [15:43<03:22,  1.06it/s] 81%|████████  | 907/1120 [15:44<03:19,  1.07it/s] 81%|████████  | 908/1120 [15:45<03:27,  1.02it/s] 81%|████████  | 909/1120 [15:47<03:38,  1.03s/it] 81%|████████▏ | 910/1120 [15:47<03:23,  1.03it/s]                                                   81%|████████▏ | 910/1120 [15:47<03:23,  1.03it/s] 81%|████████▏ | 911/1120 [15:48<03:13,  1.08it/s] 81%|████████▏ | 912/1120 [15:49<03:11,  1.09it/s] 82%|████████▏ | 913/1120 [15:50<03:18,  1.04it/s] 82%|████████▏ | 914/1120 [15:51<03:12,  1.07it/s] 82%|████████▏ | 915/1120 [15:52<03:11,  1.07it/s] 82%|████████▏ | 916/1120 [15:53<03:14,  1.05it/s] 82%|████████▏ | 917/1120 [15:54<03:17,  1.03it/s] 82%|████████▏ | 918/1120 [15:55<03:12,  1.05it/s] 82%|████████▏ | 919/1120 [15:56<03:15,  1.03it/s] 82%|████████▏ | 920/1120 [15:57<03:01,  1.10it/s]                                                   82%|████████▏ | 920/1120 [15:57<03:01,  1.10it/s]{'eval_loss': 0.14747940003871918, 'eval_runtime': 3.8668, 'eval_samples_per_second': 25.861, 'eval_steps_per_second': 3.362, 'epoch': 7.82}
外层迭代结束！
外层迭代结束！
{'loss': 0.0349, 'learning_rate': 6.44859813084112e-05, 'epoch': 7.91}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.006, 'learning_rate': 6.168224299065419e-05, 'epoch': 8.0}
外层迭代结束！
外层迭代结束！
{'loss': 0.0812, 'learning_rate': 5.887850467289719e-05, 'epoch': 8.09}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0606, 'learning_rate': 5.607476635514018e-05, 'epoch': 8.18}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.01it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.99it/s][A                                                  
                                               [A 82%|████████▏ | 920/1120 [16:01<03:01,  1.10it/s]
100%|██████████| 13/13 [00:03<00:00,  3.99it/s][A
                                               [A 82%|████████▏ | 921/1120 [16:02<07:05,  2.14s/it] 82%|████████▏ | 922/1120 [16:03<05:56,  1.80s/it] 82%|████████▏ | 923/1120 [16:04<05:08,  1.57s/it] 82%|████████▎ | 924/1120 [16:05<04:20,  1.33s/it] 83%|████████▎ | 925/1120 [16:06<04:08,  1.27s/it] 83%|████████▎ | 926/1120 [16:07<03:47,  1.17s/it] 83%|████████▎ | 927/1120 [16:08<03:31,  1.10s/it] 83%|████████▎ | 928/1120 [16:09<03:26,  1.08s/it] 83%|████████▎ | 929/1120 [16:10<03:26,  1.08s/it] 83%|████████▎ | 930/1120 [16:11<03:16,  1.04s/it]                                                   83%|████████▎ | 930/1120 [16:11<03:16,  1.04s/it] 83%|████████▎ | 931/1120 [16:11<03:02,  1.03it/s] 83%|████████▎ | 932/1120 [16:12<02:57,  1.06it/s] 83%|████████▎ | 933/1120 [16:14<03:21,  1.08s/it] 83%|████████▎ | 934/1120 [16:15<03:07,  1.01s/it] 83%|████████▎ | 935/1120 [16:16<03:06,  1.01s/it] 84%|████████▎ | 936/1120 [16:17<03:09,  1.03s/it] 84%|████████▎ | 937/1120 [16:18<03:09,  1.03s/it] 84%|████████▍ | 938/1120 [16:19<03:04,  1.02s/it] 84%|████████▍ | 939/1120 [16:19<02:51,  1.06it/s] 84%|████████▍ | 940/1120 [16:20<02:40,  1.12it/s]                                                   84%|████████▍ | 940/1120 [16:20<02:40,  1.12it/s] 84%|████████▍ | 941/1120 [16:21<02:44,  1.09it/s] 84%|████████▍ | 942/1120 [16:22<02:43,  1.09it/s] 84%|████████▍ | 943/1120 [16:23<02:45,  1.07it/s] 84%|████████▍ | 944/1120 [16:24<02:37,  1.12it/s] 84%|████████▍ | 945/1120 [16:25<02:50,  1.02it/s] 84%|████████▍ | 946/1120 [16:26<02:53,  1.00it/s] 85%|████████▍ | 947/1120 [16:27<02:49,  1.02it/s] 85%|████████▍ | 948/1120 [16:28<02:42,  1.06it/s] 85%|████████▍ | 949/1120 [16:29<02:52,  1.01s/it] 85%|████████▍ | 950/1120 [16:30<02:42,  1.05it/s]                                                   85%|████████▍ | 950/1120 [16:30<02:42,  1.05it/s] 85%|████████▍ | 951/1120 [16:31<02:41,  1.05it/s] 85%|████████▌ | 952/1120 [16:32<02:32,  1.10it/s] 85%|████████▌ | 953/1120 [16:33<02:34,  1.08it/s] 85%|████████▌ | 954/1120 [16:34<02:34,  1.07it/s] 85%|████████▌ | 955/1120 [16:34<02:35,  1.06it/s] 85%|████████▌ | 956/1120 [16:35<02:34,  1.06it/s] 85%|████████▌ | 957/1120 [16:37<02:57,  1.09s/it] 86%|████████▌ | 958/1120 [16:38<02:48,  1.04s/it] 86%|████████▌ | 959/1120 [16:39<02:40,  1.01it/s] 86%|████████▌ | 960/1120 [16:39<02:31,  1.05it/s]                                                   86%|████████▌ | 960/1120 [16:40<02:31,  1.05it/s]{'eval_loss': 0.15145792067050934, 'eval_runtime': 3.8672, 'eval_samples_per_second': 25.859, 'eval_steps_per_second': 3.362, 'epoch': 8.18}
外层迭代结束！
外层迭代结束！
{'loss': 0.0028, 'learning_rate': 5.327102803738317e-05, 'epoch': 8.27}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0271, 'learning_rate': 5.046728971962616e-05, 'epoch': 8.36}
外层迭代结束！
外层迭代结束！
{'loss': 0.047, 'learning_rate': 4.766355140186915e-05, 'epoch': 8.44}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0027, 'learning_rate': 4.485981308411214e-05, 'epoch': 8.53}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.00it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.99it/s][A                                                  
                                               [A 86%|████████▌ | 960/1120 [16:44<02:31,  1.05it/s]
100%|██████████| 13/13 [00:03<00:00,  3.99it/s][A
                                               [A 86%|████████▌ | 961/1120 [16:45<05:46,  2.18s/it] 86%|████████▌ | 962/1120 [16:45<04:38,  1.76s/it] 86%|████████▌ | 963/1120 [16:46<04:05,  1.56s/it] 86%|████████▌ | 964/1120 [16:47<03:27,  1.33s/it] 86%|████████▌ | 965/1120 [16:49<03:30,  1.36s/it] 86%|████████▋ | 966/1120 [16:50<03:11,  1.24s/it] 86%|████████▋ | 967/1120 [16:51<02:58,  1.17s/it] 86%|████████▋ | 968/1120 [16:52<02:48,  1.11s/it] 87%|████████▋ | 969/1120 [16:53<02:45,  1.10s/it] 87%|████████▋ | 970/1120 [16:54<02:37,  1.05s/it]                                                   87%|████████▋ | 970/1120 [16:54<02:37,  1.05s/it] 87%|████████▋ | 971/1120 [16:54<02:26,  1.02it/s] 87%|████████▋ | 972/1120 [16:55<02:24,  1.02it/s] 87%|████████▋ | 973/1120 [16:56<02:23,  1.02it/s] 87%|████████▋ | 974/1120 [16:57<02:18,  1.06it/s] 87%|████████▋ | 975/1120 [16:58<02:23,  1.01it/s] 87%|████████▋ | 976/1120 [16:59<02:26,  1.01s/it] 87%|████████▋ | 977/1120 [17:01<02:32,  1.07s/it] 87%|████████▋ | 978/1120 [17:01<02:21,  1.00it/s] 87%|████████▋ | 979/1120 [17:02<02:21,  1.00s/it] 88%|████████▊ | 980/1120 [17:03<02:17,  1.02it/s]                                                   88%|████████▊ | 980/1120 [17:04<02:17,  1.02it/s] 88%|████████▊ | 981/1120 [17:05<02:26,  1.05s/it] 88%|████████▊ | 982/1120 [17:05<02:12,  1.04it/s] 88%|████████▊ | 983/1120 [17:06<02:16,  1.01it/s] 88%|████████▊ | 984/1120 [17:07<02:17,  1.01s/it] 88%|████████▊ | 985/1120 [17:09<02:24,  1.07s/it] 88%|████████▊ | 986/1120 [17:10<02:18,  1.03s/it] 88%|████████▊ | 987/1120 [17:11<02:13,  1.00s/it] 88%|████████▊ | 988/1120 [17:11<02:08,  1.02it/s] 88%|████████▊ | 989/1120 [17:12<02:08,  1.02it/s] 88%|████████▊ | 990/1120 [17:13<02:00,  1.08it/s]                                                   88%|████████▊ | 990/1120 [17:13<02:00,  1.08it/s] 88%|████████▊ | 991/1120 [17:14<01:58,  1.09it/s] 89%|████████▊ | 992/1120 [17:15<01:53,  1.13it/s] 89%|████████▊ | 993/1120 [17:16<02:06,  1.01it/s] 89%|████████▉ | 994/1120 [17:17<02:03,  1.02it/s] 89%|████████▉ | 995/1120 [17:18<01:59,  1.04it/s] 89%|████████▉ | 996/1120 [17:19<02:02,  1.01it/s] 89%|████████▉ | 997/1120 [17:20<02:02,  1.00it/s] 89%|████████▉ | 998/1120 [17:21<02:00,  1.02it/s] 89%|████████▉ | 999/1120 [17:22<01:50,  1.09it/s] 89%|████████▉ | 1000/1120 [17:23<01:45,  1.13it/s]                                                    89%|████████▉ | 1000/1120 [17:23<01:45,  1.13it/s]{'eval_loss': 0.14716626703739166, 'eval_runtime': 3.8674, 'eval_samples_per_second': 25.857, 'eval_steps_per_second': 3.361, 'epoch': 8.53}
外层迭代结束！
外层迭代结束！
{'loss': 0.0106, 'learning_rate': 4.2056074766355134e-05, 'epoch': 8.62}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0184, 'learning_rate': 3.9252336448598124e-05, 'epoch': 8.71}
外层迭代结束！
外层迭代结束！
{'loss': 0.0062, 'learning_rate': 3.6448598130841115e-05, 'epoch': 8.8}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0009, 'learning_rate': 3.3644859813084105e-05, 'epoch': 8.89}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.01it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.98it/s][A                                                   
                                               [A 89%|████████▉ | 1000/1120 [17:27<01:45,  1.13it/s]
100%|██████████| 13/13 [00:03<00:00,  3.98it/s][A
                                               [A 89%|████████▉ | 1001/1120 [17:28<04:16,  2.16s/it] 89%|████████▉ | 1002/1120 [17:29<03:29,  1.78s/it] 90%|████████▉ | 1003/1120 [17:30<02:54,  1.49s/it] 90%|████████▉ | 1004/1120 [17:30<02:27,  1.27s/it] 90%|████████▉ | 1005/1120 [17:31<02:20,  1.23s/it] 90%|████████▉ | 1006/1120 [17:32<02:14,  1.18s/it] 90%|████████▉ | 1007/1120 [17:33<01:59,  1.06s/it] 90%|█████████ | 1008/1120 [17:34<01:54,  1.02s/it] 90%|█████████ | 1009/1120 [17:35<01:52,  1.02s/it] 90%|█████████ | 1010/1120 [17:36<01:53,  1.03s/it]                                                    90%|█████████ | 1010/1120 [17:36<01:53,  1.03s/it] 90%|█████████ | 1011/1120 [17:37<01:44,  1.04it/s] 90%|█████████ | 1012/1120 [17:38<01:42,  1.05it/s] 90%|█████████ | 1013/1120 [17:39<01:54,  1.07s/it] 91%|█████████ | 1014/1120 [17:40<01:46,  1.00s/it] 91%|█████████ | 1015/1120 [17:41<01:41,  1.03it/s] 91%|█████████ | 1016/1120 [17:42<01:42,  1.01it/s] 91%|█████████ | 1017/1120 [17:43<01:43,  1.01s/it] 91%|█████████ | 1018/1120 [17:44<01:34,  1.07it/s] 91%|█████████ | 1019/1120 [17:45<01:32,  1.09it/s] 91%|█████████ | 1020/1120 [17:46<01:28,  1.13it/s]                                                    91%|█████████ | 1020/1120 [17:46<01:28,  1.13it/s] 91%|█████████ | 1021/1120 [17:47<01:33,  1.06it/s] 91%|█████████▏| 1022/1120 [17:47<01:27,  1.11it/s] 91%|█████████▏| 1023/1120 [17:48<01:24,  1.15it/s] 91%|█████████▏| 1024/1120 [17:49<01:22,  1.16it/s] 92%|█████████▏| 1025/1120 [17:50<01:28,  1.08it/s] 92%|█████████▏| 1026/1120 [17:51<01:22,  1.14it/s] 92%|█████████▏| 1027/1120 [17:52<01:21,  1.14it/s] 92%|█████████▏| 1028/1120 [17:53<01:18,  1.17it/s] 92%|█████████▏| 1029/1120 [17:54<01:23,  1.09it/s] 92%|█████████▏| 1030/1120 [17:55<01:24,  1.07it/s]                                                    92%|█████████▏| 1030/1120 [17:55<01:24,  1.07it/s] 92%|█████████▏| 1031/1120 [17:55<01:18,  1.13it/s] 92%|█████████▏| 1032/1120 [17:56<01:19,  1.11it/s] 92%|█████████▏| 1033/1120 [17:58<01:25,  1.01it/s] 92%|█████████▏| 1034/1120 [17:58<01:19,  1.08it/s] 92%|█████████▏| 1035/1120 [17:59<01:17,  1.09it/s] 92%|█████████▎| 1036/1120 [18:00<01:21,  1.03it/s] 93%|█████████▎| 1037/1120 [18:02<01:26,  1.04s/it] 93%|█████████▎| 1038/1120 [18:03<01:25,  1.04s/it] 93%|█████████▎| 1039/1120 [18:03<01:17,  1.05it/s] 93%|█████████▎| 1040/1120 [18:04<01:15,  1.06it/s]                                                    93%|█████████▎| 1040/1120 [18:04<01:15,  1.06it/s]{'eval_loss': 0.14518052339553833, 'eval_runtime': 3.8676, 'eval_samples_per_second': 25.856, 'eval_steps_per_second': 3.361, 'epoch': 8.89}
外层迭代结束！
外层迭代结束！
{'loss': 0.0033, 'learning_rate': 3.0841121495327096e-05, 'epoch': 8.98}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0265, 'learning_rate': 2.803738317757009e-05, 'epoch': 9.07}
外层迭代结束！
外层迭代结束！
{'loss': 0.0111, 'learning_rate': 2.523364485981308e-05, 'epoch': 9.16}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0029, 'learning_rate': 2.242990654205607e-05, 'epoch': 9.24}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.01it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.98it/s][A                                                   
                                               [A 93%|█████████▎| 1040/1120 [18:08<01:15,  1.06it/s]
100%|██████████| 13/13 [00:03<00:00,  3.98it/s][A
                                               [A 93%|█████████▎| 1041/1120 [18:09<02:54,  2.21s/it] 93%|█████████▎| 1042/1120 [18:10<02:23,  1.84s/it] 93%|█████████▎| 1043/1120 [18:11<01:57,  1.52s/it] 93%|█████████▎| 1044/1120 [18:12<01:45,  1.39s/it] 93%|█████████▎| 1045/1120 [18:13<01:39,  1.33s/it] 93%|█████████▎| 1046/1120 [18:14<01:28,  1.20s/it] 93%|█████████▎| 1047/1120 [18:15<01:18,  1.08s/it] 94%|█████████▎| 1048/1120 [18:16<01:10,  1.01it/s] 94%|█████████▎| 1049/1120 [18:17<01:11,  1.01s/it] 94%|█████████▍| 1050/1120 [18:18<01:05,  1.07it/s]                                                    94%|█████████▍| 1050/1120 [18:18<01:05,  1.07it/s] 94%|█████████▍| 1051/1120 [18:19<01:05,  1.06it/s] 94%|█████████▍| 1052/1120 [18:19<01:01,  1.11it/s] 94%|█████████▍| 1053/1120 [18:21<01:09,  1.03s/it] 94%|█████████▍| 1054/1120 [18:22<01:05,  1.01it/s] 94%|█████████▍| 1055/1120 [18:23<01:02,  1.03it/s] 94%|█████████▍| 1056/1120 [18:23<00:58,  1.09it/s] 94%|█████████▍| 1057/1120 [18:25<01:06,  1.05s/it] 94%|█████████▍| 1058/1120 [18:26<01:03,  1.02s/it] 95%|█████████▍| 1059/1120 [18:27<00:59,  1.03it/s] 95%|█████████▍| 1060/1120 [18:28<00:56,  1.06it/s]                                                    95%|█████████▍| 1060/1120 [18:28<00:56,  1.06it/s] 95%|█████████▍| 1061/1120 [18:29<00:56,  1.04it/s] 95%|█████████▍| 1062/1120 [18:29<00:52,  1.11it/s] 95%|█████████▍| 1063/1120 [18:30<00:53,  1.06it/s] 95%|█████████▌| 1064/1120 [18:31<00:51,  1.08it/s] 95%|█████████▌| 1065/1120 [18:33<01:00,  1.10s/it] 95%|█████████▌| 1066/1120 [18:33<00:53,  1.01it/s] 95%|█████████▌| 1067/1120 [18:34<00:51,  1.03it/s] 95%|█████████▌| 1068/1120 [18:35<00:49,  1.05it/s] 95%|█████████▌| 1069/1120 [18:37<00:54,  1.07s/it] 96%|█████████▌| 1070/1120 [18:37<00:50,  1.01s/it]                                                    96%|█████████▌| 1070/1120 [18:37<00:50,  1.01s/it] 96%|█████████▌| 1071/1120 [18:38<00:49,  1.00s/it] 96%|█████████▌| 1072/1120 [18:39<00:47,  1.02it/s] 96%|█████████▌| 1073/1120 [18:40<00:46,  1.02it/s] 96%|█████████▌| 1074/1120 [18:41<00:45,  1.01it/s] 96%|█████████▌| 1075/1120 [18:42<00:42,  1.05it/s] 96%|█████████▌| 1076/1120 [18:43<00:41,  1.06it/s] 96%|█████████▌| 1077/1120 [18:44<00:41,  1.03it/s] 96%|█████████▋| 1078/1120 [18:45<00:38,  1.08it/s] 96%|█████████▋| 1079/1120 [18:46<00:39,  1.04it/s] 96%|█████████▋| 1080/1120 [18:47<00:37,  1.08it/s]                                                    96%|█████████▋| 1080/1120 [18:47<00:37,  1.08it/s]{'eval_loss': 0.14695028960704803, 'eval_runtime': 3.8664, 'eval_samples_per_second': 25.864, 'eval_steps_per_second': 3.362, 'epoch': 9.24}
外层迭代结束！
外层迭代结束！
{'loss': 0.0186, 'learning_rate': 1.9626168224299062e-05, 'epoch': 9.33}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0432, 'learning_rate': 1.6822429906542053e-05, 'epoch': 9.42}
外层迭代结束！
外层迭代结束！
{'loss': 0.0017, 'learning_rate': 1.4018691588785045e-05, 'epoch': 9.51}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0078, 'learning_rate': 1.1214953271028036e-05, 'epoch': 9.6}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.00it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.99it/s][A                                                   
                                               [A 96%|█████████▋| 1080/1120 [18:51<00:37,  1.08it/s]
100%|██████████| 13/13 [00:03<00:00,  3.99it/s][A
                                               [A 97%|█████████▋| 1081/1120 [18:52<01:25,  2.20s/it] 97%|█████████▋| 1082/1120 [18:53<01:10,  1.86s/it] 97%|█████████▋| 1083/1120 [18:54<01:00,  1.62s/it] 97%|█████████▋| 1084/1120 [18:55<00:51,  1.44s/it] 97%|█████████▋| 1085/1120 [18:56<00:45,  1.31s/it] 97%|█████████▋| 1086/1120 [18:57<00:41,  1.23s/it] 97%|█████████▋| 1087/1120 [18:58<00:37,  1.13s/it] 97%|█████████▋| 1088/1120 [18:59<00:36,  1.14s/it] 97%|█████████▋| 1089/1120 [19:00<00:34,  1.10s/it] 97%|█████████▋| 1090/1120 [19:01<00:30,  1.02s/it]                                                    97%|█████████▋| 1090/1120 [19:01<00:30,  1.02s/it] 97%|█████████▋| 1091/1120 [19:02<00:28,  1.01it/s] 98%|█████████▊| 1092/1120 [19:03<00:26,  1.04it/s] 98%|█████████▊| 1093/1120 [19:04<00:26,  1.04it/s] 98%|█████████▊| 1094/1120 [19:05<00:23,  1.12it/s] 98%|█████████▊| 1095/1120 [19:06<00:22,  1.12it/s] 98%|█████████▊| 1096/1120 [19:06<00:21,  1.13it/s] 98%|█████████▊| 1097/1120 [19:07<00:21,  1.09it/s] 98%|█████████▊| 1098/1120 [19:08<00:20,  1.06it/s] 98%|█████████▊| 1099/1120 [19:09<00:20,  1.03it/s] 98%|█████████▊| 1100/1120 [19:11<00:20,  1.00s/it]                                                    98%|█████████▊| 1100/1120 [19:11<00:20,  1.00s/it] 98%|█████████▊| 1101/1120 [19:12<00:18,  1.00it/s] 98%|█████████▊| 1102/1120 [19:13<00:18,  1.05s/it] 98%|█████████▊| 1103/1120 [19:14<00:17,  1.01s/it] 99%|█████████▊| 1104/1120 [19:15<00:15,  1.01it/s] 99%|█████████▊| 1105/1120 [19:16<00:16,  1.12s/it] 99%|█████████▉| 1106/1120 [19:17<00:14,  1.06s/it] 99%|█████████▉| 1107/1120 [19:18<00:12,  1.00it/s] 99%|█████████▉| 1108/1120 [19:19<00:11,  1.01it/s] 99%|█████████▉| 1109/1120 [19:20<00:10,  1.00it/s] 99%|█████████▉| 1110/1120 [19:21<00:10,  1.01s/it]                                                    99%|█████████▉| 1110/1120 [19:21<00:10,  1.01s/it] 99%|█████████▉| 1111/1120 [19:22<00:09,  1.04s/it] 99%|█████████▉| 1112/1120 [19:23<00:07,  1.00it/s] 99%|█████████▉| 1113/1120 [19:24<00:07,  1.06s/it] 99%|█████████▉| 1114/1120 [19:25<00:06,  1.07s/it]100%|█████████▉| 1115/1120 [19:26<00:04,  1.01it/s]100%|█████████▉| 1116/1120 [19:27<00:03,  1.01it/s]100%|█████████▉| 1117/1120 [19:28<00:03,  1.04s/it]100%|█████████▉| 1118/1120 [19:29<00:02,  1.02s/it]100%|█████████▉| 1119/1120 [19:30<00:00,  1.02it/s]100%|██████████| 1120/1120 [19:31<00:00,  1.04it/s]                                                   100%|██████████| 1120/1120 [19:31<00:00,  1.04it/s]{'eval_loss': 0.14778919517993927, 'eval_runtime': 3.8664, 'eval_samples_per_second': 25.864, 'eval_steps_per_second': 3.362, 'epoch': 9.6}
外层迭代结束！
外层迭代结束！
{'loss': 0.043, 'learning_rate': 8.411214953271026e-06, 'epoch': 9.69}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0022, 'learning_rate': 5.607476635514018e-06, 'epoch': 9.78}
外层迭代结束！
外层迭代结束！
{'loss': 0.0131, 'learning_rate': 2.803738317757009e-06, 'epoch': 9.87}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 0.0049, 'learning_rate': 0.0, 'epoch': 9.96}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:02,  5.00it/s][A
 23%|██▎       | 3/13 [00:00<00:03,  3.19it/s][A
 31%|███       | 4/13 [00:01<00:03,  2.85it/s][A
 38%|███▊      | 5/13 [00:01<00:03,  2.55it/s][A
 46%|████▌     | 6/13 [00:02<00:02,  2.73it/s][A
 54%|█████▍    | 7/13 [00:02<00:02,  2.73it/s][A
 62%|██████▏   | 8/13 [00:02<00:01,  3.09it/s][A
 69%|██████▉   | 9/13 [00:02<00:01,  3.48it/s][A
 77%|███████▋  | 10/13 [00:03<00:00,  3.80it/s][A
 85%|████████▍ | 11/13 [00:03<00:00,  3.43it/s][A
 92%|█████████▏| 12/13 [00:03<00:00,  3.99it/s][A                                                   
                                               [A100%|██████████| 1120/1120 [19:35<00:00,  1.04it/s]
100%|██████████| 13/13 [00:03<00:00,  3.99it/s][A
                                               [AThere were missing keys in the checkpoint model loaded: ['base_model.model.shared.weight', 'base_model.model.encoder.embed_tokens.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.encoder.block.0.layer.0.layer_norm.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.0.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.0.layer.1.layer_norm.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.1.layer.0.layer_norm.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.1.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.1.layer.1.layer_norm.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.2.layer.0.layer_norm.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.2.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.2.layer.1.layer_norm.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.3.layer.0.layer_norm.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.3.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.3.layer.1.layer_norm.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.4.layer.0.layer_norm.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.4.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.4.layer.1.layer_norm.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.5.layer.0.layer_norm.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.5.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.5.layer.1.layer_norm.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.6.layer.0.layer_norm.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.6.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.6.layer.1.layer_norm.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.7.layer.0.layer_norm.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.7.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.7.layer.1.layer_norm.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.8.layer.0.layer_norm.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.8.layer.1.layer_norm.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.9.layer.0.layer_norm.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.9.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.9.layer.1.layer_norm.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.10.layer.0.layer_norm.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.10.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.10.layer.1.layer_norm.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.11.layer.0.layer_norm.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.11.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.11.layer.1.layer_norm.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.12.layer.0.layer_norm.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.12.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.12.layer.1.layer_norm.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.13.layer.0.layer_norm.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.13.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.13.layer.1.layer_norm.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.14.layer.0.layer_norm.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.14.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.14.layer.1.layer_norm.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.15.layer.0.layer_norm.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.15.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.15.layer.1.layer_norm.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.16.layer.0.layer_norm.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.16.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.16.layer.1.layer_norm.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.17.layer.0.layer_norm.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.17.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.17.layer.1.layer_norm.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.18.layer.0.layer_norm.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.18.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.18.layer.1.layer_norm.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.19.layer.0.layer_norm.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.19.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.19.layer.1.layer_norm.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.20.layer.0.layer_norm.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.20.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.20.layer.1.layer_norm.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.21.layer.0.layer_norm.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.21.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.21.layer.1.layer_norm.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.22.layer.0.layer_norm.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.22.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.22.layer.1.layer_norm.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.encoder.block.23.layer.0.layer_norm.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wi.weight', 'base_model.model.encoder.block.23.layer.1.DenseReluDense.wo.weight', 'base_model.model.encoder.block.23.layer.1.layer_norm.weight', 'base_model.model.encoder.final_layer_norm.weight', 'base_model.model.decoder.embed_tokens.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'base_model.model.decoder.block.0.layer.0.layer_norm.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.0.layer.1.layer_norm.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.0.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.0.layer.2.layer_norm.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.1.layer.0.layer_norm.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.1.layer.1.layer_norm.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.1.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.1.layer.2.layer_norm.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.2.layer.0.layer_norm.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.2.layer.1.layer_norm.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.2.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.2.layer.2.layer_norm.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.3.layer.0.layer_norm.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.3.layer.1.layer_norm.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.3.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.3.layer.2.layer_norm.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.4.layer.0.layer_norm.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.4.layer.1.layer_norm.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.4.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.4.layer.2.layer_norm.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.5.layer.0.layer_norm.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.5.layer.1.layer_norm.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.5.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.5.layer.2.layer_norm.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.6.layer.0.layer_norm.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.6.layer.1.layer_norm.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.6.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.6.layer.2.layer_norm.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.7.layer.0.layer_norm.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.7.layer.1.layer_norm.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.7.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.7.layer.2.layer_norm.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.8.layer.0.layer_norm.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.8.layer.1.layer_norm.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.8.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.8.layer.2.layer_norm.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.9.layer.0.layer_norm.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.9.layer.1.layer_norm.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.9.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.9.layer.2.layer_norm.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.10.layer.0.layer_norm.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.10.layer.1.layer_norm.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.10.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.10.layer.2.layer_norm.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.11.layer.0.layer_norm.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.11.layer.1.layer_norm.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.11.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.11.layer.2.layer_norm.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.12.layer.0.layer_norm.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.12.layer.1.layer_norm.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.12.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.12.layer.2.layer_norm.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.13.layer.0.layer_norm.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.13.layer.1.layer_norm.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.13.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.13.layer.2.layer_norm.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.14.layer.0.layer_norm.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.14.layer.1.layer_norm.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.14.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.14.layer.2.layer_norm.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.15.layer.0.layer_norm.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.15.layer.1.layer_norm.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.15.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.15.layer.2.layer_norm.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.16.layer.0.layer_norm.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.16.layer.1.layer_norm.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.16.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.16.layer.2.layer_norm.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.17.layer.0.layer_norm.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.17.layer.1.layer_norm.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.17.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.17.layer.2.layer_norm.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.18.layer.0.layer_norm.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.18.layer.1.layer_norm.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.18.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.18.layer.2.layer_norm.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.19.layer.0.layer_norm.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.19.layer.1.layer_norm.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.19.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.19.layer.2.layer_norm.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.20.layer.0.layer_norm.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.20.layer.1.layer_norm.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.20.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.20.layer.2.layer_norm.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.21.layer.0.layer_norm.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.21.layer.1.layer_norm.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.21.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.21.layer.2.layer_norm.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.22.layer.0.layer_norm.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.22.layer.1.layer_norm.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.22.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.22.layer.2.layer_norm.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.k.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.o.weight', 'base_model.model.decoder.block.23.layer.0.layer_norm.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.k.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.default.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.o.weight', 'base_model.model.decoder.block.23.layer.1.layer_norm.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wi.weight', 'base_model.model.decoder.block.23.layer.2.DenseReluDense.wo.weight', 'base_model.model.decoder.block.23.layer.2.layer_norm.weight', 'base_model.model.decoder.final_layer_norm.weight', 'base_model.model.lm_head.weight'].
There were unexpected keys in the checkpoint model loaded: ['base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.encoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.6.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.7.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.8.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.9.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.10.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.11.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.12.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.13.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.14.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.15.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.16.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.17.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.18.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.19.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.20.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.21.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.22.layer.1.EncDecAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.0.SelfAttention.v.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.q.lora_B.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_A.weight', 'base_model.model.decoder.block.23.layer.1.EncDecAttention.v.lora_B.weight'].
                                                   100%|██████████| 1120/1120 [19:35<00:00,  1.04it/s]100%|██████████| 1120/1120 [19:35<00:00,  1.05s/it]
{'eval_loss': 0.1486579328775406, 'eval_runtime': 3.8676, 'eval_samples_per_second': 25.856, 'eval_steps_per_second': 3.361, 'epoch': 9.96}
{'train_runtime': 1175.646, 'train_samples_per_second': 7.655, 'train_steps_per_second': 0.953, 'train_loss': 0.11704335224016436, 'epoch': 9.96}

 If there's a warning about missing keys above, please disregard :)
Found cached dataset json (/data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 8
micro_batch_size: 2
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: yelp... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/8-yelp
current data path: ./data_longsequence/train/yelp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 778.02it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 985.27it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 861.96it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 786.48it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 458.29it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400, 选择的样本数量：8
task id: 4, history data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 628.93it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b05edc432aa3560.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 5, history data path: ./data_longsequence/train/boolqa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 462.18it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-856891a4945fd30a.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 6, history data path: ./data_longsequence/train/rte_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 485.62it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-239b26a3aab39f27.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 7, history data path: ./data_longsequence/train/imdb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 931.86it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-143a4706a27855d0.arrow
Loading cached split indices for dataset at /data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-a1e4ac29e39089de.arrow and /data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3c3ebe43a5092046.arrow
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-ba24f844b37e66ad.arrow
总样本数：1000, 选择的样本数量：20
lora_weights: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/7-imdb

pre-trained model's BOS EOS and PAD token id: None 1 0  => It should be 1,2,none
continual fine tune lora!
trainable params: 2359296 || all params: 740027392 || trainable%: 0.31881198257050464
训练数据总量：900
验证数据总量：100
Map:   0%|          | 0/900 [00:00<?, ? examples/s]/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3597: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  "`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your "
Map: 100%|██████████| 900/900 [00:00<00:00, 5153.26 examples/s]                                                               Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-559e05f043e064c2.arrow
Map:   0%|          | 0/100 [00:00<?, ? examples/s]                                                   Map:   0%|          | 0/133 [00:00<?, ? examples/s]                                                   memory data loader 2
  0%|          | 0/1120 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/1120 [00:01<27:12,  1.46s/it]  0%|          | 2/1120 [00:02<19:23,  1.04s/it]  0%|          | 3/1120 [00:02<16:49,  1.11it/s]  0%|          | 4/1120 [00:03<15:50,  1.17it/s]  0%|          | 5/1120 [00:04<17:30,  1.06it/s]  1%|          | 6/1120 [00:05<16:23,  1.13it/s]  1%|          | 7/1120 [00:06<15:31,  1.19it/s]  1%|          | 8/1120 [00:07<15:10,  1.22it/s]  1%|          | 9/1120 [00:08<16:56,  1.09it/s]  1%|          | 10/1120 [00:09<16:03,  1.15it/s]                                                   1%|          | 10/1120 [00:09<16:03,  1.15it/s]  1%|          | 11/1120 [00:09<15:23,  1.20it/s]  1%|          | 12/1120 [00:10<14:57,  1.23it/s]  1%|          | 13/1120 [00:11<16:06,  1.15it/s]  1%|▏         | 14/1120 [00:12<15:40,  1.18it/s]  1%|▏         | 15/1120 [00:13<15:43,  1.17it/s]  1%|▏         | 16/1120 [00:13<15:09,  1.21it/s]  2%|▏         | 17/1120 [00:15<16:39,  1.10it/s]  2%|▏         | 18/1120 [00:15<16:21,  1.12it/s]  2%|▏         | 19/1120 [00:16<15:40,  1.17it/s]  2%|▏         | 20/1120 [00:17<15:15,  1.20it/s]                                                   2%|▏         | 20/1120 [00:17<15:15,  1.20it/s]  2%|▏         | 21/1120 [00:18<15:58,  1.15it/s]  2%|▏         | 22/1120 [00:19<15:16,  1.20it/s]  2%|▏         | 23/1120 [00:19<14:52,  1.23it/s]  2%|▏         | 24/1120 [00:20<14:38,  1.25it/s]  2%|▏         | 25/1120 [00:21<16:13,  1.13it/s]  2%|▏         | 26/1120 [00:23<18:15,  1.00s/it]  2%|▏         | 27/1120 [00:23<17:00,  1.07it/s]  2%|▎         | 28/1120 [00:24<15:59,  1.14it/s]  3%|▎         | 29/1120 [00:25<16:50,  1.08it/s]  3%|▎         | 30/1120 [00:26<16:44,  1.09it/s]                                                   3%|▎         | 30/1120 [00:26<16:44,  1.09it/s]  3%|▎         | 31/1120 [00:27<15:54,  1.14it/s]  3%|▎         | 32/1120 [00:28<15:09,  1.20it/s]  3%|▎         | 33/1120 [00:29<19:11,  1.06s/it]  3%|▎         | 34/1120 [00:30<17:34,  1.03it/s]  3%|▎         | 35/1120 [00:31<16:31,  1.09it/s]  3%|▎         | 36/1120 [00:31<15:39,  1.15it/s]  3%|▎         | 37/1120 [00:32<16:25,  1.10it/s]  3%|▎         | 38/1120 [00:33<15:31,  1.16it/s]  3%|▎         | 39/1120 [00:34<14:55,  1.21it/s]  4%|▎         | 40/1120 [00:35<14:46,  1.22it/s]外层迭代结束！
外层迭代结束！
{'loss': 3.9929, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.09}
外层迭代结束！
外层迭代结束！
外层迭代结束！
{'loss': 3.0719, 'learning_rate': 0.00011999999999999999, 'epoch': 0.18}
外层迭代结束！
外层迭代结束！
{'loss': 1.287, 'learning_rate': 0.00017999999999999998, 'epoch': 0.27}
外层迭代结束！
外层迭代结束！
Traceback (most recent call last):
  File "finetune_bi-level_t5lora.py", line 333, in <module>
    fire.Fire(train)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/fire/core.py", line 141, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/fire/core.py", line 480, in _Fire
    target=component.__name__)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/fire/core.py", line 691, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "finetune_bi-level_t5lora.py", line 321, in train
    trainer.train(resume_from_checkpoint=resume_from_checkpoint)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/trainer.py", line 1762, in train
    ignore_keys_for_eval=ignore_keys_for_eval,
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/trainer.py", line 2152, in _inner_training_loop
    outer_loss = self.compute_loss(self.model, memory_inputs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/trainer.py", line 2946, in compute_loss
    outputs = model(**inputs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/peft/peft_model.py", line 880, in forward
    **kwargs,
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = old_forward(*args, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/models/t5/modeling_t5.py", line 1686, in forward
    return_dict=return_dict,
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = old_forward(*args, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/models/t5/modeling_t5.py", line 1097, in forward
    output_attentions=output_attentions,
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = old_forward(*args, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/models/t5/modeling_t5.py", line 700, in forward
    output_attentions=output_attentions,
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = old_forward(*args, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/models/t5/modeling_t5.py", line 607, in forward
    output_attentions=output_attentions,
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = old_forward(*args, **kwargs)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/transformers/models/t5/modeling_t5.py", line 564, in forward
    attn_weights, p=self.dropout, training=self.training
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/torch/nn/functional.py", line 1279, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
RuntimeError: CUDA out of memory. Tried to allocate 422.00 MiB (GPU 0; 23.48 GiB total capacity; 21.20 GiB already allocated; 193.38 MiB free; 21.51 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  4%|▎         | 40/1120 [00:35<16:06,  1.12it/s]Found cached dataset json (/data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 8
micro_batch_size: 2
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: amazon... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/9-amazon
current data path: ./data_longsequence/train/amazon_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 782.67it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 603.67it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 896.79it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 644.19it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 636.95it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400, 选择的样本数量：8
task id: 4, history data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 839.36it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b05edc432aa3560.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 5, history data path: ./data_longsequence/train/boolqa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 834.19it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-856891a4945fd30a.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 6, history data path: ./data_longsequence/train/rte_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 422.09it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-239b26a3aab39f27.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 7, history data path: ./data_longsequence/train/imdb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 827.93it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-143a4706a27855d0.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 8, history data path: ./data_longsequence/train/yelp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 811.75it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-dff3ce2f55261429.arrow
总样本数：1000, 选择的样本数量：20
lora_weights: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/8-yelp

pre-trained model's BOS EOS and PAD token id: None 1 0  => It should be 1,2,none
Traceback (most recent call last):
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/peft/utils/config.py", line 106, in from_pretrained
    config_file = hf_hub_download(pretrained_model_name_or_path, CONFIG_NAME, subfolder=subfolder)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/huggingface_hub/utils/_validators.py", line 112, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/huggingface_hub/utils/_validators.py", line 161, in validate_repo_id
    "Repo id must be in the form 'repo_name' or 'namespace/repo_name':"
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './checkpoint_files/t5largelora_bilevel_dataset_id_1/8-yelp'. Use `repo_type` argument if needed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "finetune_bi-level_t5lora.py", line 333, in <module>
    fire.Fire(train)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/fire/core.py", line 141, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/fire/core.py", line 480, in _Fire
    target=component.__name__)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/fire/core.py", line 691, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "finetune_bi-level_t5lora.py", line 220, in train
    model = PeftModel.from_pretrained(model, lora_weights, is_trainable=True)
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/peft/peft_model.py", line 164, in from_pretrained
    PeftConfig.from_pretrained(model_id, subfolder=kwargs.get("subfolder", None)).peft_type
  File "/home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/peft/utils/config.py", line 108, in from_pretrained
    raise ValueError(f"Can't find '{CONFIG_NAME}' at '{pretrained_model_name_or_path}'")
ValueError: Can't find 'adapter_config.json' at './checkpoint_files/t5largelora_bilevel_dataset_id_1/8-yelp'
Found cached dataset json (/data_8T2/yujie/cache/json/default-cc74d192d9f59811/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 8
micro_batch_size: 2
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: sst-2... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/10-sst-2
current data path: ./data_longsequence/train/sst-2_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 785.45it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 947.22it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 833.53it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 792.42it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 808.93it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400, 选择的样本数量：8
task id: 4, history data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 820.16it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b05edc432aa3560.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 5, history data path: ./data_longsequence/train/boolqa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 1028.52it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-856891a4945fd30a.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 6, history data path: ./data_longsequence/train/rte_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 767.34it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-239b26a3aab39f27.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 7, history data path: ./data_longsequence/train/imdb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 739.21it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-143a4706a27855d0.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 8, history data path: ./data_longsequence/train/yelp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 813.80it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-dff3ce2f55261429.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 9, history data path: ./data_longsequence/train/amazon_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 825.33it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-14b5d8e8282d70c1.arrow
总样本数：1000, 选择的样本数量：20
lora_weights dir ./checkpoint_files/t5largelora_bilevel_dataset_id_1/9-amazon not find!
Found cached dataset json (/data_8T2/yujie/cache/json/default-939986c5f8670c09/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 8
micro_batch_size: 2
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: dbpedia... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/11-dbpedia
current data path: ./data_longsequence/train/dbpedia_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 768.61it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 811.59it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 847.68it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 806.60it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 743.28it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400, 选择的样本数量：8
task id: 4, history data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 849.22it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b05edc432aa3560.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 5, history data path: ./data_longsequence/train/boolqa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 866.77it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-856891a4945fd30a.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 6, history data path: ./data_longsequence/train/rte_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 811.75it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-239b26a3aab39f27.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 7, history data path: ./data_longsequence/train/imdb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 880.42it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-143a4706a27855d0.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 8, history data path: ./data_longsequence/train/yelp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 564.59it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-dff3ce2f55261429.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 9, history data path: ./data_longsequence/train/amazon_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 908.05it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-14b5d8e8282d70c1.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-cc74d192d9f59811/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 10, history data path: ./data_longsequence/train/sst-2_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 884.13it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-cc74d192d9f59811/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-18a91adaaf40bd9d.arrow
总样本数：1000, 选择的样本数量：20
lora_weights dir ./checkpoint_files/t5largelora_bilevel_dataset_id_1/10-sst-2 not find!
Found cached dataset json (/data_8T2/yujie/cache/json/default-f06c0783431d596c/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 8
micro_batch_size: 2
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: agnews... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/12-agnews
current data path: ./data_longsequence/train/agnews_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 797.55it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 973.61it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 810.18it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 420.82it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 882.27it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400, 选择的样本数量：8
task id: 4, history data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 837.86it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b05edc432aa3560.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 5, history data path: ./data_longsequence/train/boolqa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 852.85it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-856891a4945fd30a.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 6, history data path: ./data_longsequence/train/rte_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 790.19it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-239b26a3aab39f27.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 7, history data path: ./data_longsequence/train/imdb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 819.68it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-143a4706a27855d0.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 8, history data path: ./data_longsequence/train/yelp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 814.11it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-dff3ce2f55261429.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 9, history data path: ./data_longsequence/train/amazon_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 815.06it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-14b5d8e8282d70c1.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-cc74d192d9f59811/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 10, history data path: ./data_longsequence/train/sst-2_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 840.71it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-cc74d192d9f59811/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-18a91adaaf40bd9d.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-939986c5f8670c09/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 11, history data path: ./data_longsequence/train/dbpedia_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 506.62it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-939986c5f8670c09/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-fc4f5d125dd42971.arrow
总样本数：1000, 选择的样本数量：20
lora_weights dir ./checkpoint_files/t5largelora_bilevel_dataset_id_1/11-dbpedia not find!
Found cached dataset json (/data_8T2/yujie/cache/json/default-5508fa5191315695/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 8
micro_batch_size: 2
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: multirc... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/13-multirc
current data path: ./data_longsequence/train/multirc_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 779.03it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 716.00it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 673.68it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 775.00it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 494.15it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400, 选择的样本数量：8
task id: 4, history data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 836.35it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b05edc432aa3560.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 5, history data path: ./data_longsequence/train/boolqa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 812.85it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-856891a4945fd30a.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 6, history data path: ./data_longsequence/train/rte_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 503.46it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-239b26a3aab39f27.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 7, history data path: ./data_longsequence/train/imdb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 713.44it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-143a4706a27855d0.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 8, history data path: ./data_longsequence/train/yelp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 818.08it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-dff3ce2f55261429.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 9, history data path: ./data_longsequence/train/amazon_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 579.24it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-14b5d8e8282d70c1.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-cc74d192d9f59811/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 10, history data path: ./data_longsequence/train/sst-2_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 831.71it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-cc74d192d9f59811/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-18a91adaaf40bd9d.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-939986c5f8670c09/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 11, history data path: ./data_longsequence/train/dbpedia_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 914.59it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-939986c5f8670c09/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-fc4f5d125dd42971.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-f06c0783431d596c/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 12, history data path: ./data_longsequence/train/agnews_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 816.65it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-f06c0783431d596c/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-f755e09198190cfb.arrow
总样本数：1000, 选择的样本数量：20
lora_weights dir ./checkpoint_files/t5largelora_bilevel_dataset_id_1/12-agnews not find!
Found cached dataset json (/data_8T2/yujie/cache/json/default-00956829d37bfea0/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA SETUP: CUDA runtime path found: /home/yujie/anaconda3/envs/bilevel/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/yujie/anaconda3/envs/bilevel/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Training T5 model with params:
base_model: /data_8T2/yujie/Backbones/t5large
batch_size: 8
micro_batch_size: 2
num_epochs: 10
learning_rate: 0.0003
max_input_length: 1024
max_target_length: 128
val_set_size: 100
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q', 'v']
ignore_pad_token_for_loss: True
add_eos_token: True
group_by_length: False
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

current service name: yahoo... begin fine tuning!
memory_data_ratio is : 0.02
output_dir: ./checkpoint_files/t5largelora_bilevel_dataset_id_1/14-yahoo
current data path: ./data_longsequence/train/yahoo_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 708.74it/s]
Found cached dataset json (/data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000
task id: 0, history data path: ./data_longsequence/train/mnli_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 834.52it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-010b642cd0f2dae4/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-637b5ff631837461.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 1, history data path: ./data_longsequence/train/cb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 883.38it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-d5a14a106564661f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-497e22f0780a0845.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：250, 选择的样本数量：5
task id: 2, history data path: ./data_longsequence/train/wic_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 837.69it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-e3060ce6bdc2fec8/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3ddd27ccd73343d2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 3, history data path: ./data_longsequence/train/copa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 521.16it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-fb909944c26832a7/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-96e75dab62eccdc2.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：400, 选择的样本数量：8
task id: 4, history data path: ./data_longsequence/train/qqp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 872.00it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-7563e703bf921296/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-7b05edc432aa3560.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 5, history data path: ./data_longsequence/train/boolqa_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 857.38it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-0d373ebdee234f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-856891a4945fd30a.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 6, history data path: ./data_longsequence/train/rte_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 478.04it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-324f381c2ad12197/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-239b26a3aab39f27.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 7, history data path: ./data_longsequence/train/imdb_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 890.89it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-01dfff1f4d83a146/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-143a4706a27855d0.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 8, history data path: ./data_longsequence/train/yelp_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 517.24it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-aed96b96bf663104/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-dff3ce2f55261429.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 9, history data path: ./data_longsequence/train/amazon_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 883.38it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-b14812b3650c7120/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-14b5d8e8282d70c1.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-cc74d192d9f59811/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 10, history data path: ./data_longsequence/train/sst-2_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 897.18it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-cc74d192d9f59811/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-18a91adaaf40bd9d.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-939986c5f8670c09/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 11, history data path: ./data_longsequence/train/dbpedia_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 551.66it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-939986c5f8670c09/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-fc4f5d125dd42971.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-f06c0783431d596c/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 12, history data path: ./data_longsequence/train/agnews_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 574.72it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-f06c0783431d596c/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-f755e09198190cfb.arrow
Found cached dataset json (/data_8T2/yujie/cache/json/default-5508fa5191315695/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
总样本数：1000, 选择的样本数量：20
task id: 13, history data path: ./data_longsequence/train/multirc_T5.json
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 860.55it/s]
Loading cached shuffled indices for dataset at /data_8T2/yujie/cache/json/default-5508fa5191315695/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-757599f6cf9ea2cf.arrow
总样本数：1000, 选择的样本数量：20
lora_weights dir ./checkpoint_files/t5largelora_bilevel_dataset_id_1/13-multirc not find!
